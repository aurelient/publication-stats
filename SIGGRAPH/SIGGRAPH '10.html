


<!doctype html>


<head><script type="text/javascript">_cf_loadingtexthtml="<img alt=' ' src='/CFIDE/scripts/ajax/resources/cf/images/loading.gif'/>";
_cf_contextpath="";
_cf_ajaxscriptsrc="/CFIDE/scripts/ajax";
_cf_jsonprefix='//';
_cf_clientid='A28EA0C1C997C69EAF10E89AED2F7FEE';</script><script type="text/javascript" src="/CFIDE/scripts/ajax/messages/cfmessage.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfajax.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfform.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/masks.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfformhistory.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfrichtexteditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/FCKeditor/fckeditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/yahoo-dom-event/yahoo-dom-event.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/animation/animation-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/adapter/yui/ext-yui-adapter.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/ext-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/resizable.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dragdrop/dragdrop.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/util.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/build/state/State-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/widget-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dialog/dialogs.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfwindow.js"></script>
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/ext/css/ext-all.css" />
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/cf/cf.css" />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="css/dl.css" />



<title>ACM SIGGRAPH 2010 papers</title>
<style type="text/css"><!--
    body {margin-left: 0em; margin-top: 0}
    a:link {text-decoration: underline; 	Color: #1d4d0f;}
    a:visited  { color: #990033; text-decoration: underline;}
    a:hover {color: red; text-decoration: none}
    a.dLink1:link {color:#336699}
    a.dLink1:visited {color:#666666}
	a.isblack:link {text-decoration: underline; 	Color: #000000;}
    a.isblack:visited  { color: #000000; text-decoration: underline;}
    a.isblack:hover {color: #000000; text-decoration: none}
    h1 {font-size: 140%; margin-bottom: 0}
	ul {margin-top: .25em; list-style-type: disc}
	ol {margin-top: .25em;}
	li {padding-bottom: .25em}
    h2 {color: white; background-color: #069; 
        font-size: 100%; padding-left: 1em;
		margin: 0}
	h3 {color: black; background-color: yellow; 
    	font-size: 100%;
		margin: 0}
	 h4 {color: black; background-color: #99c5e8; 
        font-size: 100%;
		margin: 0}
    hr {color: #39176d;}
    form {margin-top: 10}
    form.xrs {margin-top: 0}
	
	a {text-decoration: none; }
	
	input {font-size: 1em;}
	.chevron {color: #ff0000;}
	.light-blue {color:#336699;}
	.black {color:#000000;}
	
	/* ### standard text styles, smallest to largest ### */
	
	.footer-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .75em; line-height: 1.33em;
		text-indent: -.75 em; margin-left: 2em; margin-right: .75em;}
		
	.footer-copy-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em; line-height: 1.3em;
		margin-left: .75em; margin-right: .75em;}
		
	.small-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; padding-bottom : 2px;
	  	padding-top : 2px;}

	.smallerer-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .65em;}
	.smaller-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em;}		
	.small-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em;}
	.small-textb {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; font-weight: bold;}
	.medium-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em;}
	.mediumb-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em; font-weight: bold;}
	.large-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1.3em;}		
	.instr-text {font-family: Arial, Helvetica, sans-serif;
		color:#666666; font-size: .83em;}
		
	.list-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .83em; line-height: 1.3em;}
	.list-link-btext {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; line-height: 1.3em;}
	
	.searchbox-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;}
	.footer-header-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;
		margin-left: .75em; margin-right: .75em;}
	.medium-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold; line-height: 1em;
		text-indent: -1.25em; margin-left: 2em; margin-right: .75em;}
	
	.text16 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 16px;}
		
	.text14 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 14px;}
	
	.text12 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 12px;}
		
	.text10 {font-family: Arial, Helvetica, sans-serif;
	    color:#000000; font-size: 12px;}
		
	.text9 {font-family: Arial, Helvetica, sans-serif;
	   color:#000000; font-size: 12px;}
	
	.error-text {color:red;}
	
	.small-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: .75em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}

	.medium-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1.3em; line-height: 1.5em;
		margin-left: .75em; margin-right: .75em;}
	
	.medium-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1.5em;
		margin-left: .75em; margin-right: .75em;}

		#side {
			width: 10px;
			float: left;
			margin-left: -1px;
			padding: 2px;
			}
							
		#content {
			padding: 2px;
			margin-left: 25px;
			
		        
		        }
	 .fulltext_lnk {border:0px;
	 				 margin-right: 2px;
					 vertical-align:baseline;
	 				}
	 
	  .leftcoltab { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:530px;  /* for IE5/WIN */
		  width:520px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	  .rightcoltab {
    float: right;
    margin: 0;
    padding: 5px;
    position: relative;
    right: 50px;
    top: 25px;
    width: 350px;
    z-index: 99;
}
	  .centercoltab {
		  position:absolute;
		  padding:0 0px;
		  }
	  .alt {
		background: #ece9d8;
		margin: 0;
		padding: 1px;
		}
		.leftcolc { 
	position:relative;
	top:5px;
	left:5px;
	float:left;
	width:420px;  /* for IE5/WIN */
	width:400px; /* actual value */
	margin:0 0 0px 0;
	padding:5px;
	z-index:100;
	}
.rightcolc {
	position:relative;
	top:0px;
	right:0px;
	float:right;
	margin:0 0px;
	padding:0px;
	width:500px;
	z-index:99;
	}
.centercolc {
	position:absolute;
	padding:0 0px;
	}
	
	.leftcoltabv { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:460px;  /* for IE5/WIN */
		  width:350px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	.rightcoltabv {
		position:relative;
		top:5px;
		right:0px;
		float:right;
		margin:0 0px 0 0;
		padding:15px;
		width:480px;
		z-index:99;
		}
	
  --></style>
 


<script type="text/javascript" src="cfformprotect/js/cffp.js"></script>


<script type="text/javascript">
 function expandcollapse(anchor,whichone) {
	 var inner = document.getElementById(anchor);
	 var theshow = "toShow" + whichone;
 	 var thehide = "toHide" + whichone;
	 var span = document.getElementById(theshow);
     span.style.display = (span.style.display=='inline')?'none':'inline';
     var span = document.getElementById(thehide);
     span.style.display = (span.style.display=='none')?'inline':'none';
     inner.innerHTML = (inner.innerHTML=='collapse')?'expand':'collapse';
    }

  function setDiv() {
	var m = document.getElementById('divmain');
	var mh = m.offsetHeight;
	var t = document.getElementById('divtools');
	var th = t.offsetHeight;
	var tg = document.getElementById('divtags');
	var tgh = tg.offsetHeight;
	var calcheight = mh - th;
	if (tgh > calcheight  ){
	  var x = (th + tgh) - mh;
	  if ( (th + tgh) - mh < 65) {
	  }
	  else {
		 document.getElementById('divtags').innerHTML = ""; 
		 var tg = document.getElementById('divtags');
		 var tgh = tg.offsetHeight;
		 tg.style.height = tgh  + 'px';
	  }
	}
	else {
		tg.style.height = calcheight + 'px';
		document.getElementById('divtags').innerHTML = "";
	}

//  do I need to check after I resize to be sure I didn't go too big?
//	var tg2 = document.getElementById('divtags');
//	var tgh2 = tg.offsetHeight;	
//	if (tgh2 > mh + 65) {
//	  var y = mh + 65;
//	  alert('expanded too much ' + tgh2 + ' should be at most ' + y);
//	  tg.style.height = y + 'px';
//	  document.getElementById('divtags').innerHTML = "";
//	}

  }
</script>

<script type="text/javascript">
 /* <!-- Begin
	if(document.layers || document.all) {
	a = 1;
	setInterval("Jump()", 10);
	}
	function Jump() {
	a = a + 1;
	//self.moveBy((Math.random() * a * 2 - a), (Math.random() * a * 2) - a);
	}
//  End --> */
</script>



<meta name="citation_publisher" content="ACM"> <meta name="citation_authors" content="Hoppe, Hugues/Conference Chair-DeRose, Tony"> <meta name="citation_title" content="ACM SIGGRAPH 2010 papers"> <meta name="citation_date" content="07/26/2010"> <meta name="citation_isbn" content="978-1-4503-0210-4"> <meta name="citation_abstract_html_url" content="http://dl.acm.org/citation.cfm?id=1833349"> 



<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFAJAXPROXY');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFFORM');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFDIV');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFTEXTAREA');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFWINDOW');
</script>

<script type="text/javascript">
	var _cf_window_init_1338240686342=function()
	{
		_cf_bind_init_1338240686343=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'theguide_body','bindExpr':['whatisguide.cfm']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240686343);var _cf_window=ColdFusion.Window.create('theguide','The ACM Guide to Computing Literature','whatisguide.cfm',{ modal:false, closable:true, divid:'cf_window1338240686341', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240686342);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240686345=function()
	{
		_cf_bind_init_1338240686346=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'thetags_body','bindExpr':['showthetags.cfm?id=1833349']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240686346);var _cf_window=ColdFusion.Window.create('thetags','All Tags','showthetags.cfm?id=1833349',{ modal:false, closable:true, divid:'cf_window1338240686344', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240686345);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240686348=function()
	{
		var _cf_window=ColdFusion.Window.create('theformats','Export Formats','',{ modal:false, closable:true, divid:'cf_window1338240686347', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:250, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240686348);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240686350=function()
	{
		var _cf_window=ColdFusion.Window.create('theexplaination','','',{ modal:false, closable:true, divid:'cf_window1338240686349', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240686350);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240686352=function()
	{
		var _cf_window=ColdFusion.Window.create('theservices','','',{ modal:false, closable:true, divid:'cf_window1338240686351', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240686352);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240686354=function()
	{
		_cf_bind_init_1338240686355=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'savetobinder_body','bindExpr':['savetobinder.cfm?id=1833349']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240686355);var _cf_window=ColdFusion.Window.create('savetobinder','Save to Binder','savetobinder.cfm?id=1833349',{ modal:false, closable:true, divid:'cf_window1338240686353', draggable:true, resizable:true, fixedcenter:true, width:600, height:600, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false, _cf_refreshOnShow:true});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240686354);
</script>
</head>

<body style="text-align:center" onLoad="window.focus();">

<script type="text/javascript">
						addthis_pub             = 'acm'; 
						//addthis_logo            = 'http://www.addthis.com/images/yourlogo.png';
						addthis_logo            = 'http://dl.acm.org/images/ACM_transparent.png';
						addthis_logo_background = 'c2d5fc';
						addthis_logo_color      = '000000';
						addthis_brand           = 'Citation Page';
						addthis_options         = 'favorites, email, slashdot, citeulike, digg, delicious, twitter, myspace, facebook, google, more';
						</script>
                        
<script src='AC_RunActiveContent.js' type="text/javascript"></script>




<div style="width:940px; margin-left: auto; margin-right: auto; text-align:left">
<a id="CIT"></a>



<table style="table-layout:fixed; margin-top: 5px; margin-bottom: 10px; border:0px; width:100%; border-collapse:collapse;">
	
    <tr style="vertical-align:top">
		
		<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; width:300px" class="small-link-text"  ><img src="http://dl.acm.org/images/ACMDL_Logo.jpg" alt="ACM DL" style="border:0px" usemap="#port" />
		</td>
        
        <td style="padding-left: 5px; padding-right:10px; padding-bottom:0px;" class="small-link-text">
        	<table style="width:100%; border-collapse:collapse; padding:0px">
			<tr><td style="text-align:center">
				
                            <div style="margin:0px auto;color:#356b20;font-size:10pt;line-height:10%;"> </div>
                    
					</td>		
			</tr>
			</table> 
        </td>
		<td style="padding-top: 0px; padding-left: 0px; padding-bottom:0px; text-align:right;" class="small-link-text">
			 <p style="margin-top:0px; margin-bottom:10px;">
					
                            <a href="https://dl.acm.org/signin.cfm?cfid=105749981&amp;cftoken=64099081" class="small-link-text" title="Sign in to personalize your Digital Library experience">SIGN IN</a>
                            &nbsp;&nbsp;<a href="https://dl.acm.org/signin.cfm?cfid=105749981&amp;cftoken=64099081"  class="small-link-text" title="Sign up to personalize your Digital Library experience">SIGN UP</a>
						
			 </p>
            
			<table style="padding: 5px; border-collapse:collapse; float:right">
				
				
                            
                            <tr>
                            <td class="small-link-text" style="text-align:right">
                            <form name="qiksearch" action="results.cfm?h=1&amp;cfid=105749981&amp;cftoken=64099081" method="post">
                           
                           
                            
                                     
                                    <span style="margin-left:0px"><label><input type="text" name="query" size="34" value=" " /></label>&nbsp;
                                    <input style="vertical-align:top;" type="image" alt="Search" name="Go" src="http://dl.acm.org/images/search_small.jpg" />
                                    
                                    </span>
							  </form>
                                </td>
                            </tr>
                          
				  
			</table>

			
			
		</td>

	</tr>
    
    
    <tr><td colspan="3" class="small-link-text" style="padding-bottom:5px; padding-top:0px; text-align:center">
		<div style="margin:0px auto;color:#356b20;line-height:10%;"> </div>
         
         </td>
    </tr>
    </table>
	
<map name="port" id="port" > 
  <area shape="rect" coords="1,1,60,50" href="http://www.acm.org/" alt="ACM Home Page" />
  <area shape="rect" coords="65,1,275,68" href="http://dl.acm.org/dl.cfm?CFID=105749981&CFTOKEN=64099081" alt="ACM Digital Library Home Page" />
</map>

<table style="table-layout:fixed; padding-bottom:10px; width:100%; padding:0px;">
	<tr style="vertical-align:top">
		<td style="padding-right:10px; text-align:left" class="small-link-text">
        	<div id="divmain" style="border:1px solid #356b20;">
				 
				<div class="large-text" style="text-align:left; margin-left:2px;margin-bottom:5px;">
					
                    	<h1 class="mediumb-text" style="margin-top:0px; margin-bottom:0px;"><strong>ACM SIGGRAPH 2010 papers</strong></h1>
                        
                </div>
                
                  

<table class="medium-text" style="border-collapse:collapse; padding:0px;">

<col style="width:540px" />

<tr style="vertical-align:top">
  <td>
    <table style="border-collapse:collapse; padding:2px;" class="medium-text">
      <col style="width:80px;" />
      <col style="width:auto" />
      <tr style="vertical-align:top">
        
      </tr>
    </table>

	
        <table style="margin-top: 10px; border-collapse:collapse; padding:2px;" class="medium-text">
            <col style="width:80px" />
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             Conference Chairs:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100493833&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105749981&amp;cftoken=64099081" title="Author Profile Page" target="_self">Tony DeRose</a>
                
            </td>
            <td valign="bottom">
                	
            </td>
            </tr>
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             Editors:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100397561&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105749981&amp;cftoken=64099081" title="Author Profile Page" target="_self">Hugues Hoppe</a>
                
            </td>
            <td valign="bottom">
                
                        <a href="inst_page.cfm?id=1032644&CFID=105749981&CFTOKEN=64099081" title="Institutional Profile Page"><small>ACM Transactions on Graphics</small></a>
                      	
            </td>
            </tr>
            
        </table>
    
        <table style="margin-top: 10px" border="0" class="medium-text" cellpadding="2" cellspacing="0">
            <tr><td><table border="0" class="medium-text" cellpadding="1" cellspacing="0">

<tr valign="top">
    <td nowrap="nowrap" style="padding-top:10px;">Publication of:</td>
</tr>

	<tr valign="top">
    	<td nowrap="nowrap" style="padding-bottom:0px">&middot;&nbsp;Conference</td>
	</tr>
    <tr valign="top">
	    <td style="padding-left:10px;">
		   <a href="http://www.siggraph.org/s2010/" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '10</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    
    <tr valign="top">
	    <td style="padding-left:10px; padding-bottom:10px"> Los Angeles, CA, USA &mdash; July 26 - 30, 2010
                    
                  <br />
                    
                  <a href="http://www.acm.org/publications" class="small-link-text" title="ACM">ACM</a> <span class="small-link-text">New York, NY</span><span class="small-link-text">, USA</span> <span class="small-link-text">  &copy;2010</span> 
                  <br />           
                  
      </td>
	</tr>
	 

</table></td></tr>
        </table>
    

  </td>

  <td rowspan="20" nowrap="nowrap">
	<table border="0" class="medium-text" cellpadding="0" cellspacing="0">
		<tr>
        	<td align="center" style="padding-bottom: 5px;">
			  
               <img src="http://portalparts.acm.org/1840000/1833349/thumb/cover_thumb.jpg" title="ACM SIGGRAPH 2010 papers" height="100"  width="77" ALT="ACM SIGGRAPH 2010 papers" /> 
              </td>
              <td valign="top" align="left" nowrap="nowrap">
	             <img src="images/acm_mini.jpg" title="Published by ACM" alt="Published by ACM" /> 2010 Proceeding<br />
                 
        	 </td>
        </tr>
        
        <tr>
        	<td colspan="2" valign="baseline" style="padding-bottom:5px;">
            <img src="img/stats.jpg" alt="Bibliometrics Data" />&nbsp;
            <a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a>
            </td>
         </tr>
         <tr>
            <td  class="small-text" colspan="2" valign="top" style="padding-left:30px;">
				
	                    	&middot;&nbsp;Downloads (6 Weeks): 2,506<br />
    	                    &middot;&nbsp;Downloads (12 Months): 33,285<br />
                          
                        &middot;&nbsp;Citation Count: 434 
			</td>
         </tr>

	</table>
  </td>
</tr>
</table>

<br clear="all" />

                  
                 <br clear="all" />
			</div>
			
		</td>
		<td style="padding-left: 5px; vertical-align:top; text-align:left; width:170px" class="small-link-text">
	
            <div id="divtools" style="background-color:#ece9d8; text-align:left; padding-top:5px; padding-bottom:5px; ">
              <div class="medium-text" style="margin-left:3px; margin-top:10px;"><h1 class="mediumb-text" style="margin-top:-15px;"><strong>Tools and Resources</strong></h1></div>


<ul title="Tools and Resources" style="list-style: none; list-style-position:inside;
margin-left: 0px;
padding-left: 0em;
text-indent: 5px;
margin-bottom: 0px;">


<li style="list-style-image:url(img/toc_small.gif);margin-top:10px;"><span style="margin-left:6px;">
   <span class="small-link-text">TOC Service:</span>
   	  
	  <img src="http://dl.acm.org/images/blanks.gif" border="0" alt="Spacer Image reserves space for checkmark when TOC Service is updated" name="saved" />
      <ul style="margin-left: 0; padding-left: 0; display:inline;">
      	
        <li style="list-style:none; display:inline"><br /><img src="img/email_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Email</a></li>
        <li style="list-style:none; display:inline"><img src="img/rss_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');"  class="small-link-text">RSS</a></li>
		        
      </ul>
    </span>
</li>

        <li style="list-style-image:url(img/binder.gif);margin-top:10px;"><span style="margin-left:6px;">
        <a href="citation.cfm?id=1833349&preflayout=flat#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Save to Binder</a>
         </span></li>
    




<li style="list-style-image:url(img/binder_green.gif);margin-top:10px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Export Formats:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1833349&expformat=bibtex','theformats');" class="small-link-text">BibTeX</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1833349&expformat=endnotes','theformats');" class="small-link-text">EndNote</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1833349&expformat=acmref','theformats');" class="small-link-text">ACM&nbsp;Ref</a></li>
      </ul>
    </span>
</li>



 
   <li style="list-style-image:url(img/calbullet.jpg);margin-top:15px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Upcoming Conference:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px; margin-left:25px;"><a href="http://www.siggraph.org" title="Special Interest Group on Computer Graphics and Interactive Techniques Conference" class="small-link-text">SIGGRAPH '12</a></li>
      </ul>
    </span>
	</li>
    


</ul>           

  <!-- ADDTHIS BUTTON BEGIN -->
  
  <!-- ADDTHIS BUTTON END -->

<p class="small-link-text" style="padding-top: 0px; margin-left:6px; margin-bottom:0px">Share:</p>
  <!-- AddThis Button BEGIN -->



<!-- AddThis Button BEGIN -->
<div style="margin-left:5px;" class="addthis_toolbox addthis_default_style">
<a class="addthis_button_email"></a>
<a class="addthis_button_facebook"></a>
<a class="addthis_button_google"></a>
<a class="addthis_button_twitter"></a>
<a class="addthis_button_slashdot"></a>
<a class="addthis_button_reddit"></a>


<span class="addthis_separator">|</span>
<a href="http://www.addthis.com/bookmark.php?v=250&amp;username=acm" class="addthis_button_expanded" title="more"></a>
</div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=acm"></script>
<!-- AddThis Button END -->

  
 

  
  
            </div>
            
		</td>
	</tr>
    
</table>



</div>


<div class="layout" style="width:940px; margin-left: auto; margin-right: auto; text-align:left">




<div id="fback" style="text-align:left; padding-top:10px; padding-bottom:20px">
<span class="small-text" style="padding-right:10px; margin-bottom:0px;">
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design" style=" vertical-align:middle"><img src="img/feedbackg.gif" width="20" height="19" alt="feedback" border="0" /></a>
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design"><strong>Feedback</strong></a>

<span style="padding:10px;">|</span>




<span>Switch to <a href="citation.cfm?id=1833349&amp;preflayout=tabs">tabbed view</a> <noscript> (javascript required)</noscript></span>


</span>

 
<div class="small-text" style="margin-top:10px; margin-bottom:5px;"> 
<br />

    <a href="#abstract"  title="Abstract" style="padding:5px"><span>Abstract</span></a> |
    
    <a href="#authors"  title="Authors" style="padding:5px"><span>Authors</span></a> |
    <a href="#references"  title="References" style="padding:5px"><span style='color:#999999'>References</span></a> |
    <a href="#citedby"  title="Cited By" style="padding:5px"><span style='color:#999999'>Cited By</span></a> |
    <a href="#indexterms"  title="Index Terms" style="padding:5px"><span style='color:#999999'>Index Terms</span></a> |
    <a href="#source"  title="Publication" style="padding:5px"><span>Publication</span></a> |
    <a href="#revs"  title="Reviews" style="padding:5px"><span style='color:#999999'>Reviews</span></a> |               
	<a href="#comments"  title="Comments" style="padding:5px"><span>Comments</span></a>
	
     |               
	<a href="#prox"  title="Table of Contents" style="padding:5px"><span>Table of Contents</span></a>
    
</div>
    
<div style="right: 0pt; border-top:1px solid #356b20; font-size:1px; margin-bottom:20px;"/>



</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="abstract" class="small-text">ABSTRACT</A></h1>
       	
			<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

			

		
			
           
			
				
				<p>
					<div style="display:inline"><p>It has been an incredible honor and privilege to have chaired the process leading to these proceedings. As in past years, the papers contained herein represent the most exciting and diverse recent research in the area of computer graphics and interactive techniques. I thank the authors for choosing to send their work to SIGGRAPH 2010, I thank the hundreds of reviewers for all their effort, and I especially thank the Technical Papers committee --- 49 of the wisest, hardest working, and most devoted individuals in the field.</p> <p>This year a total of 390 complete submissions were received. This is down somewhat from the record of over 500 submitted to SIGGRAPH 2008 and 440 submitted to SIGGRAPH 2009. The reason is that SIGGRAPH Asia is having the desired effect of spreading out the submission load across two conferences. In fact, the total number of submissions continues to climb. Taken together, more than 650 papers have been submitted to SIGGRAPH and SIGGRAPH Asia over the last 12 months. The spreading of submissions across conferences is helpful in several ways. First, authors missing a deadline or having a paper rejected do not have to wait an entire year before resubmitting, and second, each committee can be smaller and more cohesive, leading to more informed and consistent decisions.</p> <p>In building the committee this year I felt it was particularly important for committee members to help keep SIGGRAPH fresh and vibrant by being expansive in their definition of what is appropriate for publication at SIGGRAPH, and by looking for the inspiring work that will stimulate future research and propel the field forward as quickly as possible. Doing so is crucial if SIGGRAPH is to remain a fertile breading ground for new research areas. I also asked the committee to select their tertiary reviewers with these goals in mind, and I'm happy to report that they responded enthusiastically. One measure is that the acceptance rate was up this year, as we accepted 103 papers, or just over 26%.</p></div>
				</p>
   				
           	</div>
			
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="authors" class="small-text"><SPAN class="heading">AUTHORS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<dl title="Authors" style="margin-top:0px">




<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 Conference Chairs 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Tony DeRose" href="author_page.cfm?id=81100493833&CFID=105749981&CFTOKEN=64099081">Tony DeRose</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1985-2012</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">45</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">2,376</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">23</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">442</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">3,237</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Tony DeRose" href="author_page.cfm?id=81100493833&amp;dsp=coll&amp;trk=1&amp;CFID=105749981&CFTOKEN=64099081" target="_self">View colleagues</a> of Tony DeRose
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              



<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 Editors 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="http://portalparts.acm.org/profiles/81100397561/hoppe_400.jpg" border="0" align="middle" alt="Hugues Hoppe" hspace="5" />
		 
		  
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" >
	<span class="small-text"><strong><a title="author page of Hugues Hoppe" href="author_page.cfm?id=81100397561&CFID=105749981&CFTOKEN=64099081">Hugues Hoppe</a></strong><br /></span>
	
	<span class="small-text"><br /><a href="http://research.microsoft.com/~hoppe/">http://hhoppe.com</a></span>
	
	
	
	<span class="small-text">
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1992-2011</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">63</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">3,867</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">51</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">787</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">6,093</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Hugues Hoppe" href="author_page.cfm?id=81100397561&amp;dsp=coll&amp;trk=1&amp;CFID=105749981&CFTOKEN=64099081" target="_self">View colleagues</a> of Hugues Hoppe
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              

</dl>
</div>

		  
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="references" class="small-text"><SPAN class="heading">REFERENCES</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	References are not available

</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="citedby" class="small-text"><SPAN class="heading">CITED BY</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	Citings are not available
		
 </div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="indexterms" class="small-text"><SPAN class="heading">INDEX TERMS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

Index Terms are not available


</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="source" class="small-text"><SPAN class="heading">PUBLICATION</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">



<table border="0" class="medium-text" cellpadding="0" cellspacing="5">



    <tr valign="top">
    	<td>Title</td> 
	    <td>
		   <a href="http://www.siggraph.org/s2010/" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '10</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    <tr><td></td><td>Los Angeles, CA, USA &mdash; July 26 - 30, 2010</td></tr> <tr><td>Pages</td><td>984</td></tr> 
                 <tr>
                 
                     <td>Sponsor</td>
                    
                  <td>
                  <a href="sig.cfm?id=SP932&CFID=105749981&CFTOKEN=64099081"> SIGGRAPH</a> ACM Special Interest Group on Computer Graphics and Interactive Techniques
                  </td>
                  </tr>
              
                  <tr><td>Publisher</td><td><a href="http://www.acm.org/publications">ACM</a> New York, NY, USA</td>
				  </tr>
             <tr><td>ISBN</td><td> 978-1-4503-0210-4</td></tr> <tr><td>Order Number</td><td>428103</td></tr> 
			<tr valign="top">
        	<td>Conference</td>
            <td valign="top" align="left"  style="padding-bottom: 25px;">
	            <strong style="padding-right:10px">GRAPH</strong><a href="event.cfm?id=RE214&CFID=105749981&CFTOKEN=64099081" title="International Conference on Computer Graphics and Interactive Techniques">International Conference on Computer Graphics and Interactive Techniques</a>
                
                       
                        <a href="event.cfm?id=RE214&CFID=105749981&CFTOKEN=64099081" title="International Conference on Computer Graphics and Interactive Techniques"><img border="0" src="http://portalparts.acm.org/event_logos/382/382.jpg" title="GRAPH logo" height="100"  width="100" ALT="GRAPH logo" style="vertical-align:top"></a>
						 

        	 </td>
            </tr>
		    <tr><td colspan="2">Paper Acceptance Rate 103 of 390 submissions, 26%</td></tr> <tr valign="top"><td style="pading-top:20px;" colspan="2">Overall Acceptance Rate 2,079 of 8,858 submissions, 23%</td></tr>
                       <tr valign="top">
                        <td colspan="2" style="padding-left:25px;">
                        	<table>
                            	<tr><td>
                                        <!-- WebCharts3D v5.1(2077) -->
<IMG SRC="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=Images/5550978090525559.JPG" id="Images_5550978090525559_JPG" name="Images_5550978090525559_JPG" usemap="#Images_5550978090525559_JPG_map" border="0"/>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAB' id='GP1338240687964AAAB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>120</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAC' id='GP1338240687964AAAC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>64</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAD' id='GP1338240687964AAAD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>110</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAE' id='GP1338240687964AAAE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAF' id='GP1338240687964AAAF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAG' id='GP1338240687964AAAG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAH' id='GP1338240687964AAAH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>132</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAI' id='GP1338240687964AAAI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAJ' id='GP1338240687964AAAJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>118</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAK' id='GP1338240687964AAAK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>41</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAL' id='GP1338240687964AAAL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>175</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAM' id='GP1338240687964AAAM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>35</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAN' id='GP1338240687964AAAN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAO' id='GP1338240687964AAAO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>33</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAP' id='GP1338240687964AAAP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>161</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAQ' id='GP1338240687964AAAQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>34</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAR' id='GP1338240687964AAAR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>190</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAS' id='GP1338240687964AAAS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAT' id='GP1338240687964AAAT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>210</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAU' id='GP1338240687964AAAU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAV' id='GP1338240687964AAAV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>213</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAW' id='GP1338240687964AAAW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAX' id='GP1338240687964AAAX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>225</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAY' id='GP1338240687964AAAY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>46</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AAAZ' id='GP1338240687964AAAZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>242</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABA' id='GP1338240687964AABA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>57</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABB' id='GP1338240687964AABB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABC' id='GP1338240687964AABC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>56</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABD' id='GP1338240687964AABD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>247</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABE' id='GP1338240687964AABE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABF' id='GP1338240687964AABF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>265</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABG' id='GP1338240687964AABG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>48</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABH' id='GP1338240687964AABH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>303</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABI' id='GP1338240687964AABI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABJ' id='GP1338240687964AABJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>320</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABK' id='GP1338240687964AABK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABL' id='GP1338240687964AABL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>304</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABM' id='GP1338240687964AABM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>59</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABN' id='GP1338240687964AABN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>300</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABO' id='GP1338240687964AABO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>65</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABP' id='GP1338240687964AABP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABQ' id='GP1338240687964AABQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABR' id='GP1338240687964AABR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>424</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABS' id='GP1338240687964AABS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>81</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABT' id='GP1338240687964AABT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>478</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABU' id='GP1338240687964AABU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>83</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABV' id='GP1338240687964AABV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>461</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABW' id='GP1338240687964AABW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>98</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABX' id='GP1338240687964AABX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>474</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABY' id='GP1338240687964AABY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>86</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AABZ' id='GP1338240687964AABZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>455</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACA' id='GP1338240687964AACA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>108</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACB' id='GP1338240687964AACB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>518</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACC' id='GP1338240687964AACC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>90</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACD' id='GP1338240687964AACD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>439</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACE' id='GP1338240687964AACE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>78</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACF' id='GP1338240687964AACF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>390</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACG' id='GP1338240687964AACG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>103</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACH' id='GP1338240687964AACH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>432</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240687964AACI' id='GP1338240687964AACI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>82</td></tr></table>
<MAP name='Images_5550978090525559_JPG_map'>
<AREA shape='rect' coords='0,0,1,1'/>
<AREA shape="rect" coords="287,179,290,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACI",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACI",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACI",event)'/>
<AREA shape="rect" coords="284,92,287,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACH",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACH",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACH",event)'/>
<AREA shape="rect" coords="278,174,281,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACG",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACG",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACG",event)'/>
<AREA shape="rect" coords="275,103,278,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACF",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACF",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACF",event)'/>
<AREA shape="rect" coords="270,180,273,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACE",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACE",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACE",event)'/>
<AREA shape="rect" coords="267,90,270,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACD",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACD",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACD",event)'/>
<AREA shape="rect" coords="261,177,264,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACC",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACC",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACC",event)'/>
<AREA shape="rect" coords="258,71,261,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACB",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACB",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACB",event)'/>
<AREA shape="rect" coords="253,173,256,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACA",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AACA",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AACA",event)'/>
<AREA shape="rect" coords="250,87,253,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABZ",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABZ",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABZ",event)'/>
<AREA shape="rect" coords="244,178,247,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABY",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABY",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABY",event)'/>
<AREA shape="rect" coords="241,82,244,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABX",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABX",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABX",event)'/>
<AREA shape="rect" coords="235,175,238,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABW",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABW",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABW",event)'/>
<AREA shape="rect" coords="232,85,235,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABV",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABV",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABV",event)'/>
<AREA shape="rect" coords="227,179,230,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABU",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABU",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABU",event)'/>
<AREA shape="rect" coords="224,81,227,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABT",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABT",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABT",event)'/>
<AREA shape="rect" coords="218,179,221,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABS",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABS",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABS",event)'/>
<AREA shape="rect" coords="215,94,218,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABR",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABR",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABR",event)'/>
<AREA shape="rect" coords="210,136,213,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABQ",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABQ",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABQ",event)'/>
<AREA shape="rect" coords="207,136,210,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABP",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABP",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABP",event)'/>
<AREA shape="rect" coords="201,183,204,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABO",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABO",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABO",event)'/>
<AREA shape="rect" coords="198,125,201,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABN",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABN",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABN",event)'/>
<AREA shape="rect" coords="192,185,195,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABM",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABM",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABM",event)'/>
<AREA shape="rect" coords="189,124,192,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABL",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABL",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABL",event)'/>
<AREA shape="rect" coords="184,187,187,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABK",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABK",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABK",event)'/>
<AREA shape="rect" coords="181,120,184,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABJ",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABJ",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABJ",event)'/>
<AREA shape="rect" coords="175,188,178,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABI",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABI",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABI",event)'/>
<AREA shape="rect" coords="172,124,175,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABH",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABH",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABH",event)'/>
<AREA shape="rect" coords="167,188,170,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABG",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABG",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABG",event)'/>
<AREA shape="rect" coords="164,134,167,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABF",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABF",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABF",event)'/>
<AREA shape="rect" coords="158,187,161,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABE",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABE",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABE",event)'/>
<AREA shape="rect" coords="155,138,158,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABD",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABD",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABD",event)'/>
<AREA shape="rect" coords="149,186,152,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABC",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABC",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABC",event)'/>
<AREA shape="rect" coords="146,136,149,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABB",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABB",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABB",event)'/>
<AREA shape="rect" coords="141,185,144,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABA",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AABA",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AABA",event)'/>
<AREA shape="rect" coords="138,139,141,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAZ",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAZ",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAZ",event)'/>
<AREA shape="rect" coords="132,188,135,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAY",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAY",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAY",event)'/>
<AREA shape="rect" coords="129,144,132,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAX",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAX",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAX",event)'/>
<AREA shape="rect" coords="124,188,127,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAW",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAW",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAW",event)'/>
<AREA shape="rect" coords="121,147,124,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAV",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAV",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAV",event)'/>
<AREA shape="rect" coords="115,189,118,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAU",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAU",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAU",event)'/>
<AREA shape="rect" coords="112,147,115,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAT",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAT",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAT",event)'/>
<AREA shape="rect" coords="106,190,109,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAS",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAS",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAS",event)'/>
<AREA shape="rect" coords="103,152,106,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAR",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAR",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAR",event)'/>
<AREA shape="rect" coords="98,191,101,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAQ",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAQ",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAQ",event)'/>
<AREA shape="rect" coords="95,160,98,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAP",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAP",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAP",event)'/>
<AREA shape="rect" coords="89,191,92,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAO",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAO",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAO",event)'/>
<AREA shape="rect" coords="86,165,89,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAN",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAN",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAN",event)'/>
<AREA shape="rect" coords="81,191,84,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAM",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAM",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAM",event)'/>
<AREA shape="rect" coords="78,156,81,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAL",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAL",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAL",event)'/>
<AREA shape="rect" coords="72,189,75,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAK",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAK",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAK",event)'/>
<AREA shape="rect" coords="69,170,72,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAJ",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAJ",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAJ",event)'/>
<AREA shape="rect" coords="63,190,66,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAI",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAI",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAI",event)'/>
<AREA shape="rect" coords="60,167,63,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAH",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAH",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAH",event)'/>
<AREA shape="rect" coords="55,187,58,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAG",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAG",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAG",event)'/>
<AREA shape="rect" coords="52,165,55,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAF",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAF",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAF",event)'/>
<AREA shape="rect" coords="46,189,49,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAE",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAE",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAE",event)'/>
<AREA shape="rect" coords="43,172,46,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAD",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAD",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAD",event)'/>
<AREA shape="rect" coords="38,184,41,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAC",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAC",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAC",event)'/>
<AREA shape="rect" coords="35,170,38,199" onMouseover='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAB",event,true)' onMouseout='xx_set_visible("Images_5550978090525559_JPG","GP1338240687964AAAB",event,false)' onMousemove='xx_move_tag("Images_5550978090525559_JPG","GP1338240687964AAAB",event)'/>
<AREA shape="rect" coords="160,13,227,27"/>
<AREA shape="rect" coords="89,13,160,27"/>
</MAP>

<script language="javascript" src="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=script.js"></script>

                                      </td>
                                      <td style="padding-left:20px;">
                                             <table style="border-width: 1px; border-style: solid; width:100%;  border-spacing: 6px;" class="text12">
                                                <tr bgcolor="#ffffff">
                                                  <th style="width:50%">Year</th>
                                                  <th  align="right" style="width:15%">Submitted</th>
                                                  <th  align="right" style="width:15%">Accepted</th>
                                                  <th  align="center">Rate</th>
                                                </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '78</td>
                                                            <td align="right">120</td>
                                                            <td align="right">64</td>
                                                            <td align="center">53%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '79</td>
                                                            <td align="right">110</td>
                                                            <td align="right">43</td>
                                                            <td align="center">39%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '80</td>
                                                            <td align="right">140</td>
                                                            <td align="right">52</td>
                                                            <td align="center">37%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '81</td>
                                                            <td align="right">132</td>
                                                            <td align="right">38</td>
                                                            <td align="center">29%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '84</td>
                                                            <td align="right">118</td>
                                                            <td align="right">41</td>
                                                            <td align="center">35%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '85</td>
                                                            <td align="right">175</td>
                                                            <td align="right">35</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '87</td>
                                                            <td align="right">140</td>
                                                            <td align="right">33</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '88</td>
                                                            <td align="right">161</td>
                                                            <td align="right">34</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '89</td>
                                                            <td align="right">190</td>
                                                            <td align="right">38</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '90</td>
                                                            <td align="right">210</td>
                                                            <td align="right">43</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '92</td>
                                                            <td align="right">213</td>
                                                            <td align="right">45</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '93</td>
                                                            <td align="right">225</td>
                                                            <td align="right">46</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '94</td>
                                                            <td align="right">242</td>
                                                            <td align="right">57</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '95</td>
                                                            <td align="right">257</td>
                                                            <td align="right">56</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '96</td>
                                                            <td align="right">247</td>
                                                            <td align="right">52</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '97</td>
                                                            <td align="right">265</td>
                                                            <td align="right">48</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '98</td>
                                                            <td align="right">303</td>
                                                            <td align="right">45</td>
                                                            <td align="center">15%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '99</td>
                                                            <td align="right">320</td>
                                                            <td align="right">52</td>
                                                            <td align="center">16%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '00</td>
                                                            <td align="right">304</td>
                                                            <td align="right">59</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '01</td>
                                                            <td align="right">300</td>
                                                            <td align="right">65</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">358</td>
                                                            <td align="right">67</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">257</td>
                                                            <td align="right">257</td>
                                                            <td align="center">100%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '03</td>
                                                            <td align="right">424</td>
                                                            <td align="right">81</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '04</td>
                                                            <td align="right">478</td>
                                                            <td align="right">83</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '05</td>
                                                            <td align="right">461</td>
                                                            <td align="right">98</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '06</td>
                                                            <td align="right">474</td>
                                                            <td align="right">86</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '07</td>
                                                            <td align="right">455</td>
                                                            <td align="right">108</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '08</td>
                                                            <td align="right">518</td>
                                                            <td align="right">90</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '09</td>
                                                            <td align="right">439</td>
                                                            <td align="right">78</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '10</td>
                                                            <td align="right">390</td>
                                                            <td align="right">103</td>
                                                            <td align="center">26%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '11</td>
                                                            <td align="right">432</td>
                                                            <td align="right">82</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                 <tr bgcolor="#ffffff">
                                                    <td><strong>Overall</strong></td>
                                                    <td align="right">8,858</td>
                                                    <td align="right">2,079</td>
                                                    <td align="center">23%</td>
                                                  </tr>
                                                </table>
                                       </td>
                                     </tr>
                               </table>
                        </td>
                    </tr>
                     
                     
            
</table>


</table>




</div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="revs" class="small-text"><SPAN class="heading">REVIEWS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	<br />Reviews are not available for this item
        
        <div align="left" style="margin-top:30px">
					<a title="Computing Reviews" href="ocr_review_main.cfm?CFID=105749981&CFTOKEN=64099081">
                 <img src="http://dl.acm.org/images/ocrs-s.jpg" alt="Computing Reviews logo" border="0" style="vertical-align:middle"></a>
        
        
       		<ul style="list-style:disc; display:inline-block">
	            <li>Access <a href="ocr_review_main.cfm?CFID=105749981&CFTOKEN=64099081" target="_blank">critical reviews</a> of computing literature.</li>
            	<li><a href="http://www.computingreviews.com/Reviewer/"  target="_blank">Become a reviewer</a> for Computing Reviews</li>
            </ul>
        </div>
        
</div>



<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="comments" class="small-text"><SPAN class="heading">COMMENTS</SPAN></A></h1>
         
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<div>
<div>
	
	<p style="margin-left:5px;">
    <strong>Be the first to comment</strong>
    	
          	To Post a comment please <a href="signin.cfm?CFID=105749981&CFTOKEN=64099081">sign in or create</a> a free Web account</a>
        
    
    
	 </p>
	   	
 
</div>


</div>

	
		<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="prox" class="small-text">Table of Contents</A></h1>
        
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" >

<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">ACM SIGGRAPH 2010 papers</h5>


<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>

<div style="clear:both">
    
        <div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><a href="citation.cfm?id=1836809&picked=prox&CFID=105749981&CFTOKEN=64099081" title="previous: SIGGRAPH '10"><img hspace="5" align="absmiddle" border="0" src="img/prev.gif" width="19" height="11" alt="previous" />previous proceeding</a> <span style="padding-left:5px;padding-right:5px;">|</span><a href="citation.cfm?id=1836786&picked=prox&CFID=105749981&CFTOKEN=64099081" title="Next: SIGGRAPH '10">next proceeding <img align="absmiddle" hspace="5" border="0" src="img/next.gif" width="19" height="11" alt="next" /></a></div>
        
</div>


 
<table class="text12" border="0">

  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Computational photography</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Rob Fergus 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778766&CFID=105749981&CFTOKEN=64099081">The Frankencamera: an experimental platform for computational photography</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81406596762&CFID=105749981&CFTOKEN=64099081">Andrew Adams</a>, 
                        <a href="author_page.cfm?id=81100243243&CFID=105749981&CFTOKEN=64099081">Eino-Ville Talvala</a>, 
                        <a href="author_page.cfm?id=81466642998&CFID=105749981&CFTOKEN=64099081">Sung Hee Park</a>, 
                        <a href="author_page.cfm?id=81466642408&CFID=105749981&CFTOKEN=64099081">David E. Jacobs</a>, 
                        <a href="author_page.cfm?id=81448602667&CFID=105749981&CFTOKEN=64099081">Boris Ajdin</a>, 
                        <a href="author_page.cfm?id=81100646467&CFID=105749981&CFTOKEN=64099081">Natasha Gelfand</a>, 
                        <a href="author_page.cfm?id=81440619437&CFID=105749981&CFTOKEN=64099081">Jennifer Dolson</a>, 
                        <a href="author_page.cfm?id=81310482354&CFID=105749981&CFTOKEN=64099081">Daniel Vaquero</a>, 
                        <a href="author_page.cfm?id=81466645825&CFID=105749981&CFTOKEN=64099081">Jongmin Baek</a>, 
                        <a href="author_page.cfm?id=81100595953&CFID=105749981&CFTOKEN=64099081">Marius Tico</a>, 
                        <a href="author_page.cfm?id=81100504611&CFID=105749981&CFTOKEN=64099081">Hendrik P. A. Lensch</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=105749981&CFTOKEN=64099081">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100567347&CFID=105749981&CFTOKEN=64099081">Kari Pulli</a>, 
                        <a href="author_page.cfm?id=81100480527&CFID=105749981&CFTOKEN=64099081">Mark Horowitz</a>, 
                        <a href="author_page.cfm?id=81100593780&CFID=105749981&CFTOKEN=64099081">Marc Levoy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 29</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778766" title="DOI">10.1145/1833349.1778766</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778766&ftid=798272&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow2" style="display:inline;"><br /><div style="display:inline">Although there has been much interest in computational photography within the research and photography communities, progress has been hampered by the lack of a portable, programmable camera with sufficient image quality and computing power. To address ...</div></span>
          <span id="toHide2" style="display:none;"><br /><div style="display:inline"><p>Although there has been much interest in computational photography within the research and photography communities, progress has been hampered by the lack of a portable, programmable camera with sufficient image quality and computing power. To address this problem, we have designed and implemented an open architecture and API for such cameras: the Frankencamera. It consists of a base hardware specification, a software stack based on Linux, and an API for C++. Our architecture permits control and synchronization of the sensor and image processing pipeline at the microsecond time scale, as well as the ability to incorporate and synchronize external hardware like lenses and flashes. This paper specifies our architecture and API, and it describes two reference implementations we have built. Using these implementations we demonstrate six computational photography applications: HDR viewfinding and capture, low-light viewfinding and capture, automated acquisition of extended dynamic range panoramas, foveal imaging, IMU-based hand shake detection, and rephotography. Our goal is to standardize the architecture and distribute Frankencameras to researchers and students, as a step towards creating a community of photographer-programmers who develop algorithms, applications, and hardware for computational cameras.</p></div></span> <a id="expcoll2" href="JavaScript: expandcollapse('expcoll2',2)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778767&CFID=105749981&CFTOKEN=64099081">Image deblurring using inertial measurement sensors</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81330493210&CFID=105749981&CFTOKEN=64099081">Neel Joshi</a>, 
                        <a href="author_page.cfm?id=81385598072&CFID=105749981&CFTOKEN=64099081">Sing Bing Kang</a>, 
                        <a href="author_page.cfm?id=81300102901&CFID=105749981&CFTOKEN=64099081">C. Lawrence Zitnick</a>, 
                        <a href="author_page.cfm?id=81100122769&CFID=105749981&CFTOKEN=64099081">Richard Szeliski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 30</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778767" title="DOI">10.1145/1833349.1778767</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778767&ftid=798273&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778767&ftid=978103&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow3" style="display:inline;"><br /><div style="display:inline">We present a deblurring algorithm that uses a hardware attachment coupled with a natural image prior to deblur images from consumer cameras. Our approach uses a combination of inexpensive gyroscopes and accelerometers in an energy optimization framework ...</div></span>
          <span id="toHide3" style="display:none;"><br /><div style="display:inline"><p>We present a deblurring algorithm that uses a hardware attachment coupled with a natural image prior to deblur images from consumer cameras. Our approach uses a combination of inexpensive gyroscopes and accelerometers in an energy optimization framework to estimate a blur function from the camera's acceleration and angular velocity during an exposure. We solve for the camera motion at a high sampling rate <i>during</i> an exposure and infer the latent image using a joint optimization. Our method is completely automatic, handles per-pixel, spatially-varying blur, and out-performs the current leading image-based methods. Our experiments show that it handles large kernels -- up to at least 100 pixels, with a typical size of 30 pixels. We also present a method to perform "ground-truth" measurements of camera motion blur. We use this method to validate our hardware and deconvolution approach. To the best of our knowledge, this is the first work that uses 6 DOF inertial sensors for dense, per-pixel spatially-varying image deblurring and the first work to gather dense ground-truth measurements for camera-shake blur.</p></div></span> <a id="expcoll3" href="JavaScript: expandcollapse('expcoll3',3)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778768&CFID=105749981&CFTOKEN=64099081">Diffusion coded photography for extended depth of field</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365598191&CFID=105749981&CFTOKEN=64099081">Oliver Cossairt</a>, 
                        <a href="author_page.cfm?id=81388591968&CFID=105749981&CFTOKEN=64099081">Changyin Zhou</a>, 
                        <a href="author_page.cfm?id=81100052215&CFID=105749981&CFTOKEN=64099081">Shree Nayar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 31</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778768" title="DOI">10.1145/1833349.1778768</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778768&ftid=798274&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778768&ftid=980016&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow4" style="display:inline;"><br /><div style="display:inline">In recent years, several cameras have been introduced which extend depth of field (DOF) by producing a depth-invariant point spread function (PSF). These cameras extend DOF by deblurring a captured image with a single spatially-invariant PSF. For these ...</div></span>
          <span id="toHide4" style="display:none;"><br /><div style="display:inline"><p>In recent years, several cameras have been introduced which extend depth of field (DOF) by producing a depth-invariant point spread function (PSF). These cameras extend DOF by deblurring a captured image with a single spatially-invariant PSF. For these cameras, the quality of recovered images depends both on the magnitude of the PSF spectrum (MTF) of the camera, and the similarity between PSFs at different depths. While researchers have compared the MTFs of different extended DOF cameras, relatively little attention has been paid to evaluating their depth invariances. In this paper, we compare the depth invariance of several cameras, and introduce a new camera that improves in this regard over existing designs, while still maintaining a good MTF.</p> <p>Our technique utilizes a novel optical element placed in the pupil plane of an imaging system. Whereas previous approaches use optical elements characterized by their amplitude or phase profile, our approach utilizes one whose behavior is characterized by its scattering properties. Such an element is commonly referred to as an optical diffuser, and thus we refer to our new approach as <i>diffusion coding</i>. We show that diffusion coding can be analyzed in a simple and intuitive way by modeling the effect of a diffuser as a kernel in light field space. We provide detailed analysis of diffusion coded cameras and show results from an implementation using a custom designed diffuser.</p></div></span> <a id="expcoll4" href="JavaScript: expandcollapse('expcoll4',4)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Editing motion</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Robert Sumner 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778769&CFID=105749981&CFTOKEN=64099081">Example-based facial rigging</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442610499&CFID=105749981&CFTOKEN=64099081">Hao Li</a>, 
                        <a href="author_page.cfm?id=81442612832&CFID=105749981&CFTOKEN=64099081">Thibaut Weise</a>, 
                        <a href="author_page.cfm?id=81100582775&CFID=105749981&CFTOKEN=64099081">Mark Pauly</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 32</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778769" title="DOI">10.1145/1833349.1778769</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778769&ftid=798275&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778769&ftid=980017&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow6" style="display:inline;"><br /><div style="display:inline">We introduce a method for generating facial blendshape rigs from a set of example poses of a CG character. Our system transfers controller semantics and expression dynamics from a generic template to the target blendshape model, while solving for an ...</div></span>
          <span id="toHide6" style="display:none;"><br /><div style="display:inline"><p>We introduce a method for generating facial blendshape rigs from a set of example poses of a CG character. Our system transfers controller semantics and expression dynamics from a generic template to the target blendshape model, while solving for an optimal reproduction of the training poses. This enables a scalable design process, where the user can iteratively add more training poses to refine the blendshape expression space. However, plausible animations can be obtained even with a single training pose. We show how formulating the optimization in gradient space yields superior results as compared to a direct optimization on blendshape vertices. We provide examples for both hand-crafted characters and 3D scans of a real actor and demonstrate the performance of our system in the context of markerless art-directable facial tracking.</p></div></span> <a id="expcoll6" href="JavaScript: expandcollapse('expcoll6',6)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778770&CFID=105749981&CFTOKEN=64099081">Spatial relationship preserving character motion adaptation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81309510722&CFID=105749981&CFTOKEN=64099081">Edmond S. L. Ho</a>, 
                        <a href="author_page.cfm?id=81100019163&CFID=105749981&CFTOKEN=64099081">Taku Komura</a>, 
                        <a href="author_page.cfm?id=81100311561&CFID=105749981&CFTOKEN=64099081">Chiew-Lan Tai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 33</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778770" title="DOI">10.1145/1833349.1778770</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778770&ftid=798276&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778770&ftid=980018&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow7" style="display:inline;"><br /><div style="display:inline">This paper presents a new method for editing and retargeting motions that involve close interactions between body parts of single or multiple articulated characters, such as dancing, wrestling, and sword fighting, or between characters and a restricted ...</div></span>
          <span id="toHide7" style="display:none;"><br /><div style="display:inline"><p>This paper presents a new method for editing and retargeting motions that involve close interactions between body parts of single or multiple articulated characters, such as dancing, wrestling, and sword fighting, or between characters and a restricted environment, such as getting into a car. In such motions, the implicit spatial relationships between body parts/objects are important for capturing the scene semantics. We introduce a simple structure called an interaction mesh to represent such spatial relationships. By minimizing the local deformation of the interaction meshes of animation frames, such relationships are preserved during motion editing while reducing the number of inappropriate interpenetrations. The interaction mesh representation is general and applicable to various kinds of close interactions. It also works well for interactions involving contacts and tangles as well as those without any contacts. The method is computationally efficient, allowing real-time character control. We demonstrate its effectiveness and versatility in synthesizing a wide variety of motions with close interactions.</p></div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Lighting & material design</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Peter-Pike Sloan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778771&CFID=105749981&CFTOKEN=64099081"><i>envyLight</i>: an interface for editing natural illumination</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100112064&CFID=105749981&CFTOKEN=64099081">Fabio Pellacini</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 34</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778771" title="DOI">10.1145/1833349.1778771</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778771&ftid=798277&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778771&ftid=978104&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow9" style="display:inline;"><br /><div style="display:inline">Scenes lit with high dynamic range environment maps of real-world environments exhibit all the complex nuances of natural illumination. For applications that need lighting adjustments to the rendered images, editing environment maps directly is still ...</div></span>
          <span id="toHide9" style="display:none;"><br /><div style="display:inline"><p>Scenes lit with high dynamic range environment maps of real-world environments exhibit all the complex nuances of natural illumination. For applications that need lighting adjustments to the rendered images, editing environment maps directly is still cumbersome. First, designers have to determine which region in the environment map is responsible for the specific lighting feature (e.g. diffuse gradients, highlights and shadows) they desire to edit. Second, determining the parameters of image-editing operations needed to achieve specific changes to the selected lighting feature requires extensive trial-and-error.</p> <p>This paper presents <i>envyLight</i>, an interactive interface for editing natural illumination that combines an algorithm to select environment map regions, by sketching strokes on lighting features in the rendered image, with a small set of editing operations to quickly adjust the selected feature. The <i>envyLight</i> selection algorithm works well for indoor and outdoor lighting corresponding to rendered images where lighting features vary widely in number, size, contrast and edge blur. Furthermore, <i>envyLight</i> selection is general with respect to material type, from matte to sharp glossy, and the complexity of scenes' shapes. <i>envyLight</i> editing operations allow designers to quickly alter the position, contrast and edge blur of the selected lighting feature and can be keyframed to support animation.</p></div></span> <a id="expcoll9" href="JavaScript: expandcollapse('expcoll9',9)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778772&CFID=105749981&CFTOKEN=64099081">Toward evaluating material design interface paradigms for novice users</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440603027&CFID=105749981&CFTOKEN=64099081">William B. Kerr</a>, 
                        <a href="author_page.cfm?id=81100112064&CFID=105749981&CFTOKEN=64099081">Fabio Pellacini</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 35</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778772" title="DOI">10.1145/1833349.1778772</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778772&ftid=798278&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778772&ftid=978105&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow10" style="display:inline;"><br /><div style="display:inline">Material design is the process by which artists specify the reflectance properties of a surface, such as its diffuse color and specular roughness. We present a user study to evaluate the relative benefits of different material design interfaces, focusing ...</div></span>
          <span id="toHide10" style="display:none;"><br /><div style="display:inline"><p>Material design is the process by which artists specify the reflectance properties of a surface, such as its diffuse color and specular roughness. We present a user study to evaluate the relative benefits of different material design interfaces, focusing on novice users since they stand to gain the most from intuitive interfaces. Specifically, we investigate the editing of the parameters of analytic bidirectional distribution functions (BRDFs) using three interface paradigms: <i>physical sliders</i> by which users set the parameters of analytic BRDF models, such as diffuse albedo and specular roughness; <i>perceptual sliders</i> by which users set perceptually-inspired parameters, such as diffuse luminance and gloss contrast; and <i>image navigation</i> by which material variations are displayed in arrays of image thumbnails and users make edits by selecting them.</p> <p>We investigate two design tasks: precise adjustment and artistic exploration. We collect objective and subjective data, finding that subjects can perform equally well with physical and perceptual sliders as long as the interface responds interactively. Image navigation performs worse than the other interfaces on precise adjustment tasks, but excels at aiding in artistic exploration. We find that given enough time, novices can perform relatively complex material editing tasks with little training, and most novices work similarly to one another.</p></div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778773&CFID=105749981&CFTOKEN=64099081">Interactive on-surface signal deformation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81351607404&CFID=105749981&CFTOKEN=64099081">Tobias Ritschel</a>, 
                        <a href="author_page.cfm?id=81317501299&CFID=105749981&CFTOKEN=64099081">Thorsten Thorm&#228;hlen</a>, 
                        <a href="author_page.cfm?id=81100209816&CFID=105749981&CFTOKEN=64099081">Carsten Dachsbacher</a>, 
                        <a href="author_page.cfm?id=81100016395&CFID=105749981&CFTOKEN=64099081">Jan Kautz</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105749981&CFTOKEN=64099081">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 36</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778773" title="DOI">10.1145/1833349.1778773</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778773&ftid=798279&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778773&ftid=980019&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow11" style="display:inline;"><br /><div style="display:inline">We present an interactive system for the artistic control of visual phenomena visible on surfaces. Our method allows the user to intuitively reposition shadows, caustics, and indirect illumination using a simple click-and-drag user interface working ...</div></span>
          <span id="toHide11" style="display:none;"><br /><div style="display:inline"><p>We present an interactive system for the artistic control of visual phenomena visible on surfaces. Our method allows the user to intuitively reposition shadows, caustics, and indirect illumination using a simple click-and-drag user interface working directly on surfaces. In contrast to previous approaches, the positions of the lights or objects in the scene remain unchanged, enabling localized edits of individual shading components. Our method facilitates the editing by computing a mapping from one surface location to another. Based on this mapping, we can not only edit shadows, caustics, and indirect illumination but also other surface properties, such as color or texture, in a unified way. This is achieved using an intuitive user-interface that allows the user to specify position constraints with drag-and-drop or sketching operations directly on the surface. Our approach requires no explicit surface parametrization and handles scenes with arbitrary topology. We demonstrate the applicability of the approach to interactive editing of shadows, reflections, refractions, textures, caustics, and diffuse indirect light. The effectiveness of the system to achieve an artistic goal is evaluated by a user study.</p></div></span> <a id="expcoll11" href="JavaScript: expandcollapse('expcoll11',11)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778774&CFID=105749981&CFTOKEN=64099081">PantaRay: fast ray-traced occlusion caching of massive scenes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466648367&CFID=105749981&CFTOKEN=64099081">Jacopo Pantaleoni</a>, 
                        <a href="author_page.cfm?id=81466647248&CFID=105749981&CFTOKEN=64099081">Luca Fascione</a>, 
                        <a href="author_page.cfm?id=81466646427&CFID=105749981&CFTOKEN=64099081">Martin Hill</a>, 
                        <a href="author_page.cfm?id=81100649025&CFID=105749981&CFTOKEN=64099081">Timo Aila</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 37</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778774" title="DOI">10.1145/1833349.1778774</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778774&ftid=798435&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow12" style="display:inline;"><br /><div style="display:inline">We describe the architecture of a novel system for precomputing sparse directional occlusion caches. These caches are used for accelerating a fast cinematic lighting pipeline that works in the spherical harmonics domain. The system was used as a primary ...</div></span>
          <span id="toHide12" style="display:none;"><br /><div style="display:inline"><p>We describe the architecture of a novel system for precomputing sparse directional occlusion caches. These caches are used for accelerating a fast cinematic lighting pipeline that works in the spherical harmonics domain. The system was used as a primary lighting technology in the movie Avatar, and is able to efficiently handle massive scenes of unprecedented complexity through the use of a flexible, stream-based geometry processing architecture, a novel out-of-core algorithm for creating efficient ray tracing acceleration structures, and a novel out-of-core GPU ray tracing algorithm for the computation of directional occlusion and spherical integrals at arbitrary points.</p></div></span> <a id="expcoll12" href="JavaScript: expandcollapse('expcoll12',12)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Elastic models</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Doug James 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778775&CFID=105749981&CFTOKEN=64099081">A simple geometric model for elastic deformations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466644464&CFID=105749981&CFTOKEN=64099081">Isaac Chao</a>, 
                        <a href="author_page.cfm?id=81365591193&CFID=105749981&CFTOKEN=64099081">Ulrich Pinkall</a>, 
                        <a href="author_page.cfm?id=81466647719&CFID=105749981&CFTOKEN=64099081">Patrick Sanan</a>, 
                        <a href="author_page.cfm?id=81100117380&CFID=105749981&CFTOKEN=64099081">Peter Schr&#246;der</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 38</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778775" title="DOI">10.1145/1833349.1778775</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778775&ftid=798280&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778775&ftid=980020&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow14" style="display:inline;"><br /><div style="display:inline">We advocate a simple geometric model for elasticity: distance between the differential of a deformation and the rotation group. It comes with rigorous differential geometric underpinnings, both smooth and discrete, and is computationally almost ...</div></span>
          <span id="toHide14" style="display:none;"><br /><div style="display:inline"><p>We advocate a simple geometric model for elasticity: <i>distance between the differential of a deformation and the rotation group</i>. It comes with rigorous differential geometric underpinnings, both smooth and discrete, and is computationally almost as simple and efficient as linear elasticity. Owing to its geometric non-linearity, though, it does not suffer from the usual linearization artifacts. A material model with standard elastic moduli (Lam&eacute; parameters) falls out naturally, and a minimizer for static problems is easily augmented to construct a fully variational 2<sup>nd</sup> order time integrator. It has excellent conservation properties even for very coarse simulations, making it very robust.</p> <p>Our analysis was motivated by a number of heuristic, physics-like algorithms from geometry processing (editing, morphing, parameterization, and simulation). Starting with a continuous energy formulation and taking the underlying geometry into account, we simplify and accelerate these algorithms while avoiding common pitfalls. Through the connection with the Biot strain of mechanics, the intuition of previous work that these ideas are "like" elasticity is shown to be spot on.</p></div></span> <a id="expcoll14" href="JavaScript: expandcollapse('expcoll14',14)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778776&CFID=105749981&CFTOKEN=64099081">Unified simulation of elastic rods, shells, and solids</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81435594668&CFID=105749981&CFTOKEN=64099081">Sebastian Martin</a>, 
                        <a href="author_page.cfm?id=81100002966&CFID=105749981&CFTOKEN=64099081">Peter Kaufmann</a>, 
                        <a href="author_page.cfm?id=81100347774&CFID=105749981&CFTOKEN=64099081">Mario Botsch</a>, 
                        <a href="author_page.cfm?id=81320489894&CFID=105749981&CFTOKEN=64099081">Eitan Grinspun</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105749981&CFTOKEN=64099081">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 39</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778776" title="DOI">10.1145/1833349.1778776</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778776&ftid=798281&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778776&ftid=978106&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow15" style="display:inline;"><br /><div style="display:inline">We develop an accurate, unified treatment of elastica. Following the method of resultant-based formulation to its logical extreme, we derive a higher-order integration rule, or elaston, measuring stretching, shearing, bending, and twisting along ...</div></span>
          <span id="toHide15" style="display:none;"><br /><div style="display:inline"><p>We develop an accurate, unified treatment of elastica. Following the method of resultant-based formulation to its logical extreme, we derive a higher-order integration rule, or <i>elaston</i>, measuring stretching, shearing, bending, and twisting along any axis. The theory and accompanying implementation do not distinguish between forms of different dimension (solids, shells, rods), nor between manifold regions and non-manifold junctions. Consequently, a single code accurately models a diverse range of elastoplastic behaviors, including buckling, writhing, cutting and merging. Emphasis on convergence to the continuum sets us apart from early unification efforts.</p></div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Faces & capture</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Hanspeter Pfister 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778777&CFID=105749981&CFTOKEN=64099081">High-quality single-shot capture of facial geometry</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466647897&CFID=105749981&CFTOKEN=64099081">Thabo Beeler</a>, 
                        <a href="author_page.cfm?id=81314493860&CFID=105749981&CFTOKEN=64099081">Bernd Bickel</a>, 
                        <a href="author_page.cfm?id=81100489358&CFID=105749981&CFTOKEN=64099081">Paul Beardsley</a>, 
                        <a href="author_page.cfm?id=81466642386&CFID=105749981&CFTOKEN=64099081">Bob Sumner</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105749981&CFTOKEN=64099081">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 40</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778777" title="DOI">10.1145/1833349.1778777</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778777&ftid=798282&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow17" style="display:inline;"><br /><div style="display:inline">This paper describes a passive stereo system for capturing the 3D geometry of a face in a single-shot under standard light sources. The system is low-cost and easy to deploy. Results are submillimeter accurate and commensurate with those from state-of-the-art ...</div></span>
          <span id="toHide17" style="display:none;"><br /><div style="display:inline"><p>This paper describes a passive stereo system for capturing the 3D geometry of a face in a single-shot under standard light sources. The system is low-cost and easy to deploy. Results are submillimeter accurate and commensurate with those from state-of-the-art systems based on active lighting, and the models meet the quality requirements of a demanding domain like the movie industry. Recovered models are shown for captures from both high-end cameras in a studio setting and from a consumer binocular-stereo camera, demonstrating scalability across a spectrum of camera deployments, and showing the potential for 3D face modeling to move beyond the professional arena and into the emerging consumer market in stereoscopic photography.</p> <p>Our primary technical contribution is a modification of standard stereo refinement methods to capture pore-scale geometry, using a qualitative approach that produces visually realistic results. The second technical contribution is a calibration method suited to face capture systems. The systemic contribution includes multiple demonstrations of system robustness and quality. These include capture in a studio setup, capture off a consumer binocular-stereo camera, scanning of faces of varying gender and ethnicity and age, capture of highly-transient facial expression, and scanning a physical mask to provide ground-truth validation.</p></div></span> <a id="expcoll17" href="JavaScript: expandcollapse('expcoll17',17)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778778&CFID=105749981&CFTOKEN=64099081">High resolution passive facial performance capture</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81319488885&CFID=105749981&CFTOKEN=64099081">Derek Bradley</a>, 
                        <a href="author_page.cfm?id=81100644737&CFID=105749981&CFTOKEN=64099081">Wolfgang Heidrich</a>, 
                        <a href="author_page.cfm?id=81331501922&CFID=105749981&CFTOKEN=64099081">Tiberiu Popa</a>, 
                        <a href="author_page.cfm?id=81100389496&CFID=105749981&CFTOKEN=64099081">Alla Sheffer</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 41</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778778" title="DOI">10.1145/1833349.1778778</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778778&ftid=798283&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778778&ftid=980021&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow18" style="display:inline;"><br /><div style="display:inline">We introduce a purely passive facial capture approach that uses only an array of video cameras, but requires no template facial geometry, no special makeup or markers, and no active lighting. We obtain initial geometry using multi-view stereo, and then ...</div></span>
          <span id="toHide18" style="display:none;"><br /><div style="display:inline"><p>We introduce a purely passive facial capture approach that uses only an array of video cameras, but requires no template facial geometry, no special makeup or markers, and no active lighting. We obtain initial geometry using multi-view stereo, and then use a novel approach for automatically tracking texture detail across the frames. As a result, we obtain a high-resolution sequence of compatibly triangulated and parameterized meshes. The resulting sequence can be rendered with dynamically captured textures, while also consistently applying texture changes such as virtual makeup.</p></div></span> <a id="expcoll18" href="JavaScript: expandcollapse('expcoll18',18)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778779&CFID=105749981&CFTOKEN=64099081">VideoMocap: modeling physically realistic human motion from monocular video sequences</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81387595299&CFID=105749981&CFTOKEN=64099081">Xiaolin Wei</a>, 
                        <a href="author_page.cfm?id=81100205074&CFID=105749981&CFTOKEN=64099081">Jinxiang Chai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 42</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778779" title="DOI">10.1145/1833349.1778779</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778779&ftid=798284&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778779&ftid=980022&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow19" style="display:inline;"><br /><div style="display:inline">This paper presents a video-based motion modeling technique for capturing physically realistic human motion from monocular video sequences. We formulate the video-based motion modeling process in an image-based keyframe animation framework. The system ...</div></span>
          <span id="toHide19" style="display:none;"><br /><div style="display:inline"><p>This paper presents a video-based motion modeling technique for capturing physically realistic human motion from monocular video sequences. We formulate the video-based motion modeling process in an image-based keyframe animation framework. The system first computes camera parameters, human skeletal size, and a small number of 3D key poses from video and then uses 2D image measurements at intermediate frames to automatically calculate the "in between" poses. During reconstruction, we leverage Newtonian physics, contact constraints, and 2D image measurements to simultaneously reconstruct full-body poses, joint torques, and contact forces. We have demonstrated the power and effectiveness of our system by generating a wide variety of physically realistic human actions from uncalibrated monocular video sequences such as sports video footage.</p></div></span> <a id="expcoll19" href="JavaScript: expandcollapse('expcoll19',19)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Architectural patterns</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          John Snyder 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778780&CFID=105749981&CFTOKEN=64099081">Geodesic patterns</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100537406&CFID=105749981&CFTOKEN=64099081">Helmut Pottmann</a>, 
                        <a href="author_page.cfm?id=81313484038&CFID=105749981&CFTOKEN=64099081">Qixing Huang</a>, 
                        <a href="author_page.cfm?id=81466645579&CFID=105749981&CFTOKEN=64099081">Bailin Deng</a>, 
                        <a href="author_page.cfm?id=81365598099&CFID=105749981&CFTOKEN=64099081">Alexander Schiftner</a>, 
                        <a href="author_page.cfm?id=81365594691&CFID=105749981&CFTOKEN=64099081">Martin Kilian</a>, 
                        <a href="author_page.cfm?id=81452606669&CFID=105749981&CFTOKEN=64099081">Leonidas Guibas</a>, 
                        <a href="author_page.cfm?id=81100493818&CFID=105749981&CFTOKEN=64099081">Johannes Wallner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 43</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778780" title="DOI">10.1145/1833349.1778780</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778780&ftid=798285&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow21" style="display:inline;"><br /><div style="display:inline">Geodesic curves in surfaces are not only minimizers of distance, but they are also the curves of zero geodesic (sideways) curvature. It turns out that this property makes patterns of geodesics the basic geometric entity when dealing with the cladding ...</div></span>
          <span id="toHide21" style="display:none;"><br /><div style="display:inline"><p>Geodesic curves in surfaces are not only minimizers of distance, but they are also the curves of zero geodesic (sideways) curvature. It turns out that this property makes <i>patterns of geodesics</i> the basic geometric entity when dealing with the cladding of a freeform surface with wooden panels which do not bend sideways. Likewise a geodesic is the favored shape of timber support elements in freeform architecture, for reasons of manufacturing and statics. Both problem areas are fundamental in freeform architecture, but so far only experimental solutions have been available. This paper provides a systematic treatment and shows how to design geodesic patterns in different ways: The evolution of geodesic curves is good for local studies and simple patterns; the level set formulation can deal with the global layout of multiple patterns of geodesics; finally geodesic vector fields allow us to interactively model geodesic patterns and perform surface segmentation into panelizable parts.</p></div></span> <a id="expcoll21" href="JavaScript: expandcollapse('expcoll21',21)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778781&CFID=105749981&CFTOKEN=64099081">K-set tilable surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100244740&CFID=105749981&CFTOKEN=64099081">Chi-Wing Fu</a>, 
                        <a href="author_page.cfm?id=81466646914&CFID=105749981&CFTOKEN=64099081">Chi-Fu Lai</a>, 
                        <a href="author_page.cfm?id=81100331607&CFID=105749981&CFTOKEN=64099081">Ying He</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105749981&CFTOKEN=64099081">Daniel Cohen-Or</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 44</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778781" title="DOI">10.1145/1833349.1778781</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778781&ftid=798286&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778781&ftid=978107&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow22" style="display:inline;"><br /><div style="display:inline">This paper introduces a method for optimizing the tiles of a quad-mesh. Given a quad-based surface, the goal is to generate a set of K quads whose instances can produce a tiled surface that approximates the input surface. A solution to the problem ...</div></span>
          <span id="toHide22" style="display:none;"><br /><div style="display:inline"><p>This paper introduces a method for optimizing the tiles of a quad-mesh. Given a quad-based surface, the goal is to generate a set of <i>K</i> quads whose instances can produce a tiled surface that approximates the input surface. A solution to the problem is a K-set tilable surface, which can lead to an effective cost reduction in the physical construction of the given surface. Rather than molding lots of different building blocks, a K-set tilable surface requires the construction of <i>K</i> prefabricated components only. To realize the K-set tilable surface, we use a cluster-optimize approach. First, we iteratively cluster and analyze: clusters of similar shapes are merged, while edge connections between the <i>K</i> quads on the target surface are analyzed to learn the induced flexibility of the K-set tilable surface. Then, we apply a non-linear optimization model with constraints that maintain the <i>K</i> quads connections and shapes, and show how quad-based surfaces are optimized into K-set tilable surfaces. Our algorithm is demonstrated on various surfaces, including some that mimic the exteriors of certain renowned building landmarks.</p></div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778782&CFID=105749981&CFTOKEN=64099081">Paneling architectural freeform surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466647836&CFID=105749981&CFTOKEN=64099081">Michael Eigensatz</a>, 
                        <a href="author_page.cfm?id=81365594691&CFID=105749981&CFTOKEN=64099081">Martin Kilian</a>, 
                        <a href="author_page.cfm?id=81365598099&CFID=105749981&CFTOKEN=64099081">Alexander Schiftner</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=105749981&CFTOKEN=64099081">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81100537406&CFID=105749981&CFTOKEN=64099081">Helmut Pottmann</a>, 
                        <a href="author_page.cfm?id=81100582775&CFID=105749981&CFTOKEN=64099081">Mark Pauly</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 45</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778782" title="DOI">10.1145/1833349.1778782</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778782&ftid=798287&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778782&ftid=978108&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow23" style="display:inline;"><br /><div style="display:inline">The emergence of large-scale freeform shapes in architecture poses big challenges to the fabrication of such structures. A key problem is the approximation of the design surface by a union of patches, so-called panels, that can be manufactured with a ...</div></span>
          <span id="toHide23" style="display:none;"><br /><div style="display:inline"><p>The emergence of large-scale freeform shapes in architecture poses big challenges to the fabrication of such structures. A key problem is the approximation of the design surface by a union of patches, so-called panels, that can be manufactured with a selected technology at reasonable cost, while meeting the design intent and achieving the desired aesthetic quality of panel layout and surface smoothness. The production of curved panels is mostly based on molds. Since the cost of mold fabrication often dominates the panel cost, there is strong incentive to use the same mold for multiple panels. We cast the major practical requirements for architectural surface paneling, including mold reuse, into a global optimization framework that interleaves discrete and continuous optimization steps to minimize production cost while meeting user-specified quality constraints. The search space for optimization is mainly generated through controlled deviation from the design surface and tolerances on positional and normal continuity between neighboring panels. A novel 6-dimensional metric space allows us to quickly compute approximate inter-panel distances, which dramatically improves the performance of the optimization and enables the handling of complex arrangements with thousands of panels. The practical relevance of our system is demonstrated by paneling solutions for real, cutting-edge architectural freeform design projects.</p></div></span> <a id="expcoll23" href="JavaScript: expandcollapse('expcoll23',23)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778783&CFID=105749981&CFTOKEN=64099081">Triangle surfaces with discrete equivalence classes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466642120&CFID=105749981&CFTOKEN=64099081">Mayank Singh</a>, 
                        <a href="author_page.cfm?id=81100603187&CFID=105749981&CFTOKEN=64099081">Scott Schaefer</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 46</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778783" title="DOI">10.1145/1833349.1778783</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778783&ftid=798288&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778783&ftid=978010&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow24" style="display:inline;"><br /><div style="display:inline">We propose a technique that takes a triangulated surface as input and outputs a surface with the same topology but altered geometry such that each polygon falls into a set of discrete equivalence classes. We begin by describing an error function that ...</div></span>
          <span id="toHide24" style="display:none;"><br /><div style="display:inline"><p>We propose a technique that takes a triangulated surface as input and outputs a surface with the same topology but altered geometry such that each polygon falls into a set of discrete equivalence classes. We begin by describing an error function that measures how close the polygons are to satisfying this criteria. To optimize this error function, we first cluster triangles into discrete sets such that the assignment of sets minimizes our error. We then find canonical polygons for each set using nonlinear optimization. Next, we solve a Poisson equation to find positions of vertices such that the surface polygons match the canonical polygons as close as possible. We also describe how to incorporate a fairness criteria into the optimization to avoid oscillations of the surface. We iterate this entire process until we reach a user specified tolerance, possibly adding clusters during iteration to guarantee convergence. We have been able to successfully reduce the number of unique triangles to lie within a small percentage of the total number of triangles in the surface and demonstrate our technique on various examples.</p></div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Fluids I</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Miguel Otaduy 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778784&CFID=105749981&CFTOKEN=64099081">Matching fluid simulation elements to surface geometry and topology</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81447602530&CFID=105749981&CFTOKEN=64099081">Tyson Brochu</a>, 
                        <a href="author_page.cfm?id=81320487818&CFID=105749981&CFTOKEN=64099081">Christopher Batty</a>, 
                        <a href="author_page.cfm?id=81100248660&CFID=105749981&CFTOKEN=64099081">Robert Bridson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 47</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778784" title="DOI">10.1145/1833349.1778784</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778784&ftid=798289&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778784&ftid=978011&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow26" style="display:inline;"><br /><div style="display:inline">We introduce an Eulerian liquid simulation framework based on the Voronoi diagram of a potentially unorganized collection of pressure samples. Constructing the simulation mesh in this way allows us to place samples anywhere in the computational domain; ...</div></span>
          <span id="toHide26" style="display:none;"><br /><div style="display:inline"><p>We introduce an Eulerian liquid simulation framework based on the Voronoi diagram of a potentially unorganized collection of pressure samples. Constructing the simulation mesh in this way allows us to place samples anywhere in the computational domain; we exploit this by choosing samples that accurately capture the geometry and topology of the liquid surface. When combined with high-resolution explicit surface tracking this allows us to simulate nearly arbitrarily thin features, while eliminating noise and other artifacts that arise when there is a resolution mismatch between the simulation and the surface---and allowing a precise inclusion of surface tension based directly on and at the same resolution as the surface mesh. In addition, we present a simplified Voronoi/Delaunay mesh velocity interpolation scheme, and a direct extension of embedded free surfaces and solid boundaries to Voronoi meshes.</p></div></span> <a id="expcoll26" href="JavaScript: expandcollapse('expcoll26',26)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778785&CFID=105749981&CFTOKEN=64099081">A multiscale approach to mesh-based surface tension flows</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335498663&CFID=105749981&CFTOKEN=64099081">Nils Th&#252;rey</a>, 
                        <a href="author_page.cfm?id=81323497785&CFID=105749981&CFTOKEN=64099081">Chris Wojtan</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105749981&CFTOKEN=64099081">Markus Gross</a>, 
                        <a href="author_page.cfm?id=81100457973&CFID=105749981&CFTOKEN=64099081">Greg Turk</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 48</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778785" title="DOI">10.1145/1833349.1778785</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778785&ftid=798290&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778785&ftid=978012&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow27" style="display:inline;"><br /><div style="display:inline">We present an approach to simulate flows driven by surface tension based on triangle meshes. Our method consists of two simulation layers: the first layer is an Eulerian method for simulating surface tension forces that is free from typical strict time ...</div></span>
          <span id="toHide27" style="display:none;"><br /><div style="display:inline"><p>We present an approach to simulate flows driven by surface tension based on triangle meshes. Our method consists of two simulation layers: the first layer is an Eulerian method for simulating surface tension forces that is free from typical strict time step constraints. The second simulation layer is a Lagrangian finite element method that simulates sub-grid scale wave details on the fluid surface. The surface wave simulation employs an unconditionally stable, symplectic time integration method that allows for a high propagation speed due to strong surface tension. Our approach can naturally separate the grid- and sub-grid scales based on a volume-preserving mean curvature flow. As our model for the sub-grid dynamics enforces a local conservation of mass, it leads to realistic pinch off and merging effects. In addition to this method for simulating dynamic surface tension effects, we also present an efficient non-oscillatory approximation for capturing damped surface tension behavior. These approaches allow us to efficiently simulate complex phenomena associated with strong surface tension, such as Rayleigh-Plateau instabilities and crown splashes, in a short amount of time.</p></div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778786&CFID=105749981&CFTOKEN=64099081">Dynamic local remeshing for elastoplastic simulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100476422&CFID=105749981&CFTOKEN=64099081">Martin Wicke</a>, 
                        <a href="author_page.cfm?id=81440609397&CFID=105749981&CFTOKEN=64099081">Daniel Ritchie</a>, 
                        <a href="author_page.cfm?id=81100573144&CFID=105749981&CFTOKEN=64099081">Bryan M. Klingner</a>, 
                        <a href="author_page.cfm?id=81466643384&CFID=105749981&CFTOKEN=64099081">Sebastian Burke</a>, 
                        <a href="author_page.cfm?id=81100474718&CFID=105749981&CFTOKEN=64099081">Jonathan R. Shewchuk</a>, 
                        <a href="author_page.cfm?id=81100311781&CFID=105749981&CFTOKEN=64099081">James F. O'Brien</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 49</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778786" title="DOI">10.1145/1833349.1778786</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778786&ftid=798291&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778786&ftid=979466&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow28" style="display:inline;"><br /><div style="display:inline">We propose a finite element simulation method that addresses the full range of material behavior, from purely elastic to highly plastic, for physical domains that are substantially reshaped by plastic flow, fracture, or large elastic deformations. To ...</div></span>
          <span id="toHide28" style="display:none;"><br /><div style="display:inline"><p>We propose a finite element simulation method that addresses the full range of material behavior, from purely elastic to highly plastic, for physical domains that are substantially reshaped by plastic flow, fracture, or large elastic deformations. To mitigate artificial plasticity, we maintain a simulation mesh in both the current state and the rest shape, and store plastic offsets only to represent the non-embeddable portion of the plastic deformation. To maintain high element quality in a tetrahedral mesh undergoing gross changes, we use a dynamic meshing algorithm that attempts to replace as few tetrahedra as possible, and thereby limits the visual artifacts and artificial diffusion that would otherwise be introduced by repeatedly remeshing the domain from scratch. Our dynamic mesher also locally refines and coarsens a mesh, and even creates anisotropic tetrahedra, wherever a simulation requests it. We illustrate these features with animations of elastic and plastic behavior, extreme deformations, and fracture.</p></div></span> <a id="expcoll28" href="JavaScript: expandcollapse('expcoll28',28)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778787&CFID=105749981&CFTOKEN=64099081">Physics-inspired topology changes for thin fluid features</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81323497785&CFID=105749981&CFTOKEN=64099081">Chris Wojtan</a>, 
                        <a href="author_page.cfm?id=81466646122&CFID=105749981&CFTOKEN=64099081">Nils Th&#252;rey</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105749981&CFTOKEN=64099081">Markus Gross</a>, 
                        <a href="author_page.cfm?id=81100457973&CFID=105749981&CFTOKEN=64099081">Greg Turk</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 50</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778787" title="DOI">10.1145/1833349.1778787</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778787&ftid=798292&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778787&ftid=979467&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow29" style="display:inline;"><br /><div style="display:inline">We propose a mesh-based surface tracking method for fluid animation that both preserves fine surface details and robustly adjusts the topology of the surface in the presence of arbitrarily thin features like sheets and strands. We replace traditional ...</div></span>
          <span id="toHide29" style="display:none;"><br /><div style="display:inline"><p>We propose a mesh-based surface tracking method for fluid animation that both preserves fine surface details and robustly adjusts the topology of the surface in the presence of arbitrarily thin features like sheets and strands. We replace traditional re-sampling methods with a convex hull method for connecting surface features during topological changes. This technique permits arbitrarily thin fluid features with minimal re-sampling errors by reusing points from the original surface. We further reduce re-sampling artifacts with a subdivision-based mesh-stitching algorithm, and we use a higher order interpolating subdivision scheme to determine the location of any newly-created vertices. The resulting algorithm efficiently produces detailed fluid surfaces with arbitrarily thin features while maintaining a consistent topology with the underlying fluid simulation.</p></div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Stylized rendering & illusions</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Maneesh Agrawala 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778788&CFID=105749981&CFTOKEN=64099081">Camouflage images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100141344&CFID=105749981&CFTOKEN=64099081">Hung-Kuo Chu</a>, 
                        <a href="author_page.cfm?id=81466642854&CFID=105749981&CFTOKEN=64099081">Wei-Hsin Hsu</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=105749981&CFTOKEN=64099081">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105749981&CFTOKEN=64099081">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81343509200&CFID=105749981&CFTOKEN=64099081">Tien-Tsin Wong</a>, 
                        <a href="author_page.cfm?id=81409592133&CFID=105749981&CFTOKEN=64099081">Tong-Yee Lee</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 51</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778788" title="DOI">10.1145/1833349.1778788</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778788&ftid=798293&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778788&ftid=978292&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow31" style="display:inline;"><br /><div style="display:inline">Camouflage images contain one or more hidden figures that remain imperceptible or unnoticed for a while. In one possible explanation, the ability to delay the perception of the hidden figures is attributed to the theory that human perception works in ...</div></span>
          <span id="toHide31" style="display:none;"><br /><div style="display:inline"><p>Camouflage images contain one or more hidden figures that remain imperceptible or unnoticed for a while. In one possible explanation, the ability to delay the perception of the hidden figures is attributed to the theory that human perception works in two main phases: feature search and conjunction search. Effective camouflage images make feature based recognition difficult, and thus force the recognition process to employ conjunction search, which takes considerable effort and time. In this paper, we present a technique for creating camouflage images. To foil the feature search, we remove the original subtle texture details of the hidden figures and replace them by that of the surrounding apparent image. To leave an appropriate degree of clues for the conjunction search, we compute and assign new tones to regions in the embedded figures by performing an optimization between two conflicting terms, which we call <i>immersion</i> and <i>standout</i>, corresponding to hiding and leaving clues, respectively. We show a large number of camouflage images generated by our technique, with or without user guidance. We have tested the quality of the images in an extensive user study, showing a good control of the difficulty levels.</p></div></span> <a id="expcoll31" href="JavaScript: expandcollapse('expcoll31',31)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778789&CFID=105749981&CFTOKEN=64099081">Structure-based ASCII art</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81385601783&CFID=105749981&CFTOKEN=64099081">Xuemiao Xu</a>, 
                        <a href="author_page.cfm?id=81408598533&CFID=105749981&CFTOKEN=64099081">Linling Zhang</a>, 
                        <a href="author_page.cfm?id=81343509200&CFID=105749981&CFTOKEN=64099081">Tien-Tsin Wong</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 52</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778789" title="DOI">10.1145/1833349.1778789</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778789&ftid=798294&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778789&ftid=977284&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow32" style="display:inline;"><br /><div style="display:inline">The wide availability and popularity of text-based communication channels encourage the usage of ASCII art in representing images. Existing tone-based ASCII art generation methods lead to halftone-like results and require high text resolution for display, ...</div></span>
          <span id="toHide32" style="display:none;"><br /><div style="display:inline"><p>The wide availability and popularity of text-based communication channels encourage the usage of ASCII art in representing images. Existing tone-based ASCII art generation methods lead to halftone-like results and require high text resolution for display, as higher text resolution offers more tone variety. This paper presents a novel method to generate <i>structure-based</i> ASCII art that is currently mostly created by hand. It approximates the major line structure of the reference image content with the shape of characters. Representing the unlimited image content with the extremely limited shapes and restrictive placement of characters makes this problem challenging. Most existing shape similarity metrics either fail to address the misalignment in real-world scenarios, or are unable to account for the differences in position, orientation and scaling. Our key contribution is a novel <i>alignment-insensitive shape similarity (AISS) metric</i> that tolerates misalignment of shapes while accounting for the differences in position, orientation and scaling. Together with the constrained deformation approach, we formulate the ASCII art generation as an optimization that minimizes <i>shape dissimilarity</i> and <i>deformation</i>. Convincing results and user study are shown to demonstrate its effectiveness.</p></div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Rendering hair & scattering</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Philip Dutr&#233; 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778790&CFID=105749981&CFTOKEN=64099081">A radiative transfer framework for rendering materials with anisotropic structure</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448598202&CFID=105749981&CFTOKEN=64099081">Wenzel Jakob</a>, 
                        <a href="author_page.cfm?id=81100118944&CFID=105749981&CFTOKEN=64099081">Adam Arbree</a>, 
                        <a href="author_page.cfm?id=81100243515&CFID=105749981&CFTOKEN=64099081">Jonathan T. Moon</a>, 
                        <a href="author_page.cfm?id=81100081277&CFID=105749981&CFTOKEN=64099081">Kavita Bala</a>, 
                        <a href="author_page.cfm?id=81100238316&CFID=105749981&CFTOKEN=64099081">Steve Marschner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 53</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778790" title="DOI">10.1145/1833349.1778790</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778790&ftid=798295&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778790&ftid=977285&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow34" style="display:inline;"><br /><div style="display:inline">The radiative transfer framework that underlies all current rendering of volumes is limited to scattering media whose properties are invariant to rotation. Many systems allow for "anisotropic scattering," in the sense that scattered intensity depends ...</div></span>
          <span id="toHide34" style="display:none;"><br /><div style="display:inline"><p>The radiative transfer framework that underlies all current rendering of volumes is limited to scattering media whose properties are invariant to rotation. Many systems allow for "anisotropic scattering," in the sense that scattered intensity depends on the scattering angle, but the standard equation assumes that the structure of the medium is isotropic. This limitation impedes physics-based rendering of volume models of cloth, hair, skin, and other important volumetric or translucent materials that do have anisotropic structure. This paper presents an end-to-end formulation of physics-based volume rendering of anisotropic scattering structures, allowing these materials to become full participants in global illumination simulations.</p> <p>We begin with a generalized radiative transfer equation, derived from scattering by oriented non-spherical particles. Within this framework, we propose a new volume scattering model analogous to the well-known family of microfacet surface reflection models; we derive an anisotropic diffusion approximation, including the weak form required for finite element solution and a way to compute the diffusion matrix from the parameters of the scattering model; and we also derive a new anisotropic dipole BSSRDF for anisotropic translucent materials. We demonstrate results from Monte Carlo, finite element, and dipole simulations. All these contributions are readily implemented in existing rendering systems for volumes and translucent materials, and they all reduce to the standard practice in the isotropic case.</p></div></span> <a id="expcoll34" href="JavaScript: expandcollapse('expcoll34',34)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778791&CFID=105749981&CFTOKEN=64099081">Line space gathering for single scattering in large scenes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81330498607&CFID=105749981&CFTOKEN=64099081">Xin Sun</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=105749981&CFTOKEN=64099081">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81100221388&CFID=105749981&CFTOKEN=64099081">Stephen Lin</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=105749981&CFTOKEN=64099081">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 54</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778791" title="DOI">10.1145/1833349.1778791</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778791&ftid=798296&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778791&ftid=978293&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow35" style="display:inline;"><br /><div style="display:inline">We present an efficient technique to render single scattering in large scenes with reflective and refractive objects and homogeneous participating media. Efficiency is obtained by evaluating the final radiance along a viewing ray directly from the lighting ...</div></span>
          <span id="toHide35" style="display:none;"><br /><div style="display:inline"><p>We present an efficient technique to render single scattering in large scenes with reflective and refractive objects and homogeneous participating media. Efficiency is obtained by evaluating the final radiance along a viewing ray directly from the lighting rays passing near to it, and by rapidly identifying such lighting rays in the scene. To facilitate the search for nearby lighting rays, we convert lighting rays and viewing rays into 6D points and planes according to their Pl&uuml;cker coordinates and coefficients, respectively. In this 6D line space, the problem of closest lines search becomes one of closest points to a plane query, which we significantly accelerate using a spatial hierarchy of the 6D points. This approach to lighting ray gathering supports complex light paths with multiple reflections and refractions, and avoids the use of a volume representation, which is expensive for large-scale scenes. This method also utilizes far fewer lighting rays than the number of photons needed in traditional volumetric photon mapping, and does not discretize viewing rays into numerous steps for ray marching. With this approach, results similar to volumetric photon mapping are obtained efficiently in terms of both storage and computation.</p></div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778792&CFID=105749981&CFTOKEN=64099081">Interactive hair rendering under environment lighting</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314494646&CFID=105749981&CFTOKEN=64099081">Zhong Ren</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=105749981&CFTOKEN=64099081">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81466641698&CFID=105749981&CFTOKEN=64099081">Tengfei Li</a>, 
                        <a href="author_page.cfm?id=81100533923&CFID=105749981&CFTOKEN=64099081">Wei Hua</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=105749981&CFTOKEN=64099081">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 55</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778792" title="DOI">10.1145/1833349.1778792</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778792&ftid=798297&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778792&ftid=978294&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow36" style="display:inline;"><br /><div style="display:inline">We present an algorithm for interactive hair rendering with both single and multiple scattering effects under complex environment lighting. The outgoing radiance due to single scattering is determined by the integral of the product of the environment ...</div></span>
          <span id="toHide36" style="display:none;"><br /><div style="display:inline"><p>We present an algorithm for interactive hair rendering with both single and multiple scattering effects under complex environment lighting. The outgoing radiance due to single scattering is determined by the integral of the product of the environment lighting, the scattering function, and the transmittance that accounts for self-shadowing among hair fibers. We approximate the environment light by a set of spherical radial basis functions (SRBFs) and thus convert the outgoing radiance integral into the sum of radiance contributions of all SRBF lights. For each SRBF light, we factor out the effective transmittance to represent the radiance integral as the product of two terms: the transmittance and the convolution of the SRBF light and the scattering function. Observing that the convolution term is independent of the hair geometry, we precompute it for commonly-used scattering models, and reduce the run-time computation to table lookups. We further propose a technique, called the <i>convolution optical depth map</i>, to efficiently approximate the effective transmittance by filtering the optical depth maps generated at the center of the SRBF using a depth-dependent kernel. As for the multiple scattering computation, we handle SRBF lights by using similar factorization and precomputation schemes, and adopt sparse sampling and interpolation to speed up the computation. Compared to off-line algorithms, our algorithm can generate images of comparable quality, but at interactive frame rates.</p></div></span> <a id="expcoll36" href="JavaScript: expandcollapse('expcoll36',36)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778793&CFID=105749981&CFTOKEN=64099081">An artist friendly hair shading system</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81342509900&CFID=105749981&CFTOKEN=64099081">Iman Sadeghi</a>, 
                        <a href="author_page.cfm?id=81332522066&CFID=105749981&CFTOKEN=64099081">Heather Pritchett</a>, 
                        <a href="author_page.cfm?id=81100640205&CFID=105749981&CFTOKEN=64099081">Henrik Wann Jensen</a>, 
                        <a href="author_page.cfm?id=81100289069&CFID=105749981&CFTOKEN=64099081">Rasmus Tamstorf</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 56</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778793" title="DOI">10.1145/1833349.1778793</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778793&ftid=798298&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow37" style="display:inline;"><br /><div style="display:inline">Rendering hair in motion pictures is an important and challenging task. Despite much research on physically based hair rendering, it is currently difficult to benefit from this work because physically based shading models do not offer artist friendly ...</div></span>
          <span id="toHide37" style="display:none;"><br /><div style="display:inline"><p>Rendering hair in motion pictures is an important and challenging task. Despite much research on physically based hair rendering, it is currently difficult to benefit from this work because physically based shading models do not offer artist friendly controls. As a consequence much production work so far has used ad hoc shaders that are easier to control, but often lack the richness seen in real hair. We show that physically based shading models fail to provide intuitive artist controls and we introduce a novel approach for creating an art-directable hair shading model from existing physically based models. Through an informal user study we show that this system is easier to use compared to existing systems. Our shader has been integrated into the production pipeline at the Walt Disney Animation Studios and is being used in the production of the upcoming animated feature film Tangled.</p></div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Expressive rendering & illustrations</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Victor Ostromoukhov 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778794&CFID=105749981&CFTOKEN=64099081">Programmable motion effects</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335497130&CFID=105749981&CFTOKEN=64099081">Johannes Schmid</a>, 
                        <a href="author_page.cfm?id=81100099182&CFID=105749981&CFTOKEN=64099081">Robert W. Sumner</a>, 
                        <a href="author_page.cfm?id=81466648161&CFID=105749981&CFTOKEN=64099081">Huw Bowles</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105749981&CFTOKEN=64099081">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 57</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778794" title="DOI">10.1145/1833349.1778794</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778794&ftid=798299&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow39" style="display:inline;"><br /><div style="display:inline">Although animation is one of the most compelling aspects of computer graphics, the possibilities for depicting the movement that make dynamic scenes so exciting remain limited for both still images and animations. In our work, we experiment with motion ...</div></span>
          <span id="toHide39" style="display:none;"><br /><div style="display:inline"><p>Although animation is one of the most compelling aspects of computer graphics, the possibilities for depicting the movement that make dynamic scenes so exciting remain limited for both still images and animations. In our work, we experiment with motion depiction as a first-class entity within the rendering process. We extend the concept of a surface shader, which is evaluated on an infinitesimal portion of an object's surface at one instant in time, to that of a programmable motion effect, which is evaluated with global knowledge about all portions of an object's surface that pass in front of a pixel during an arbitrary long sequence of time. With this added information, our programmable motion effects can decide to color pixels long after (or long before) an object has passed in front of them. In order to compute the input required by the motion effects, we propose a 4D data structure that aggregates an object's movement into a single geometric representation by sampling an object's position at different time instances and connecting corresponding edges in two adjacent samples with a bilinear patch. We present example motion effects for various styles of speed lines, multiple stroboscopic images, temporal offsetting, and photorealistic and stylized blurring on both simple and production examples.</p></div></span> <a id="expcoll39" href="JavaScript: expandcollapse('expcoll39',39)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778795&CFID=105749981&CFTOKEN=64099081">Illustrating how mechanical assemblies work</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335494949&CFID=105749981&CFTOKEN=64099081">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81375599060&CFID=105749981&CFTOKEN=64099081">Yong-Liang Yang</a>, 
                        <a href="author_page.cfm?id=81384618258&CFID=105749981&CFTOKEN=64099081">Dong-Ming Yan</a>, 
                        <a href="author_page.cfm?id=81100480929&CFID=105749981&CFTOKEN=64099081">Wilmot Li</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=105749981&CFTOKEN=64099081">Maneesh Agrawala</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 58</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778795" title="DOI">10.1145/1833349.1778795</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778795&ftid=798300&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778795&ftid=978013&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow40" style="display:inline;"><br /><div style="display:inline">How things work visualizations use a variety of visual techniques to depict the operation of complex mechanical assemblies. We present an automated approach for generating such visualizations. Starting with a 3D CAD model of an assembly, we first ...</div></span>
          <span id="toHide40" style="display:none;"><br /><div style="display:inline"><p><i>How things work</i> visualizations use a variety of visual techniques to depict the operation of complex mechanical assemblies. We present an automated approach for generating such visualizations. Starting with a 3D CAD model of an assembly, we first infer the motions of individual parts and the interactions between parts based on their geometry and a few user specified constraints. We then use this information to generate visualizations that incorporate motion arrows, frame sequences and animation to convey the causal chain of motions and mechanical interactions between parts. We present results for a wide variety of assemblies.</p></div></span> <a id="expcoll40" href="JavaScript: expandcollapse('expcoll40',40)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778796&CFID=105749981&CFTOKEN=64099081">2.5D cartoon models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466646535&CFID=105749981&CFTOKEN=64099081">Alec Rivers</a>, 
                        <a href="author_page.cfm?id=81100444444&CFID=105749981&CFTOKEN=64099081">Takeo Igarashi</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=105749981&CFTOKEN=64099081">Fr&#233;do Durand</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 59</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778796" title="DOI">10.1145/1833349.1778796</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778796&ftid=798301&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778796&ftid=978014&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow41" style="display:inline;"><br /><div style="display:inline">We present a way to bring cartoon objects and characters into the third dimension, by giving them the ability to rotate and be viewed from any angle. We show how 2D vector art drawings of a cartoon from different views can be used to generate a novel ...</div></span>
          <span id="toHide41" style="display:none;"><br /><div style="display:inline"><p>We present a way to bring cartoon objects and characters into the third dimension, by giving them the ability to rotate and be viewed from any angle. We show how 2D vector art drawings of a cartoon from different views can be used to generate a novel structure, the 2.5D cartoon model, which can be used to simulate 3D rotations and generate plausible renderings of the cartoon from any view. 2.5D cartoon models are easier to create than a full 3D model, and retain the 2D nature of hand-drawn vector art, supporting a wide range of stylizations that need not correspond to any real 3D shape.</p></div></span> <a id="expcoll41" href="JavaScript: expandcollapse('expcoll41',41)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Fabrication</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Tim Weyrich 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778797&CFID=105749981&CFTOKEN=64099081">Reliefs as images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100235480&CFID=105749981&CFTOKEN=64099081">Marc Alexa</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=105749981&CFTOKEN=64099081">Wojciech Matusik</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 60</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778797" title="DOI">10.1145/1833349.1778797</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778797&ftid=798302&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow43" style="display:inline;"><br /><div style="display:inline">We describe how to create relief surfaces whose diffuse reflection approximates given images under known directional illumination. This allows using any surface with a significant diffuse reflection component as an image display. We propose a discrete ...</div></span>
          <span id="toHide43" style="display:none;"><br /><div style="display:inline"><p>We describe how to create relief surfaces whose diffuse reflection approximates given images under known directional illumination. This allows using any surface with a significant diffuse reflection component as an image display. We propose a discrete model for the area in the relief surface that corresponds to a pixel in the desired image. This model introduces the necessary degrees of freedom to overcome theoretical limitations in shape from shading and practical requirements such as stability of the image under changes in viewing condition and limited overall variation in depth. The discrete surface is determined using an iterative least squares optimization. We show several resulting relief surfaces conveying one image for varying lighting directions as well as two images for two specific lighting directions.</p></div></span> <a id="expcoll43" href="JavaScript: expandcollapse('expcoll43',43)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778798&CFID=105749981&CFTOKEN=64099081">Physical reproduction of materials with specified subsurface scattering</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314494073&CFID=105749981&CFTOKEN=64099081">Milo&#353; Ha&#353;an</a>, 
                        <a href="author_page.cfm?id=81332499566&CFID=105749981&CFTOKEN=64099081">Martin Fuchs</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=105749981&CFTOKEN=64099081">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100199891&CFID=105749981&CFTOKEN=64099081">Hanspeter Pfister</a>, 
                        <a href="author_page.cfm?id=81100203803&CFID=105749981&CFTOKEN=64099081">Szymon Rusinkiewicz</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 61</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778798" title="DOI">10.1145/1833349.1778798</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778798&ftid=798303&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow44" style="display:inline;"><br /><div style="display:inline">We investigate a complete pipeline for measuring, modeling, and fabricating objects with specified subsurface scattering behaviors. The process starts with measuring the scattering properties of a given set of base materials, determining their radial ...</div></span>
          <span id="toHide44" style="display:none;"><br /><div style="display:inline"><p>We investigate a complete pipeline for measuring, modeling, and fabricating objects with specified subsurface scattering behaviors. The process starts with measuring the scattering properties of a given set of base materials, determining their radial reflection and transmission profiles. We describe a mathematical model that predicts the profiles of different stackings of base materials, at arbitrary thicknesses. In an inverse process, we can then specify a desired reflection profile and compute a layered composite material that best approximates it. Our algorithm efficiently searches the space of possible combinations of base materials, pruning unsatisfactory states imposed by physical constraints. We validate our process by producing both homogeneous and heterogeneous composites fabricated using a multi-material 3D printer. We demonstrate reproductions that have scattering properties approximating complex materials.</p></div></span> <a id="expcoll44" href="JavaScript: expandcollapse('expcoll44',44)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778799&CFID=105749981&CFTOKEN=64099081">Fabricating spatially-varying subsurface scattering</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440597278&CFID=105749981&CFTOKEN=64099081">Yue Dong</a>, 
                        <a href="author_page.cfm?id=81100233349&CFID=105749981&CFTOKEN=64099081">Jiaping Wang</a>, 
                        <a href="author_page.cfm?id=81100112064&CFID=105749981&CFTOKEN=64099081">Fabio Pellacini</a>, 
                        <a href="author_page.cfm?id=81314492380&CFID=105749981&CFTOKEN=64099081">Xin Tong</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=105749981&CFTOKEN=64099081">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 62</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778799" title="DOI">10.1145/1833349.1778799</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778799&ftid=798304&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778799&ftid=979468&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow45" style="display:inline;"><br /><div style="display:inline">Many real world surfaces exhibit translucent appearance due to subsurface scattering. Although various methods exists to measure, edit and render subsurface scattering effects, no solution exists for manufacturing physical objects with desired translucent ...</div></span>
          <span id="toHide45" style="display:none;"><br /><div style="display:inline"><p>Many real world surfaces exhibit translucent appearance due to subsurface scattering. Although various methods exists to measure, edit and render subsurface scattering effects, no solution exists for manufacturing physical objects with desired translucent appearance. In this paper, we present a complete solution for fabricating a material volume with a desired surface BSSRDF. We stack layers from a fixed set of manufacturing materials whose thickness is varied spatially to reproduce the heterogeneity of the input BSSRDF. Given an input BSSRDF and the optical properties of the manufacturing materials, our system efficiently determines the optimal order and thickness of the layers. We demonstrate our approach by printing a variety of homogenous and heterogenous BSSRDFs using two hardware setups: a milling machine and a 3D printer.</p></div></span> <a id="expcoll45" href="JavaScript: expandcollapse('expcoll45',45)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778800&CFID=105749981&CFTOKEN=64099081">Design and fabrication of materials with desired deformation behavior</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314493860&CFID=105749981&CFTOKEN=64099081">Bernd Bickel</a>, 
                        <a href="author_page.cfm?id=81414613217&CFID=105749981&CFTOKEN=64099081">Moritz B&#228;cher</a>, 
                        <a href="author_page.cfm?id=81100035394&CFID=105749981&CFTOKEN=64099081">Miguel A. Otaduy</a>, 
                        <a href="author_page.cfm?id=81466643721&CFID=105749981&CFTOKEN=64099081">Hyunho Richard Lee</a>, 
                        <a href="author_page.cfm?id=81100199891&CFID=105749981&CFTOKEN=64099081">Hanspeter Pfister</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105749981&CFTOKEN=64099081">Markus Gross</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=105749981&CFTOKEN=64099081">Wojciech Matusik</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 63</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778800" title="DOI">10.1145/1833349.1778800</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778800&ftid=798305&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow46" style="display:inline;"><br /><div style="display:inline">This paper introduces a data-driven process for designing and fabricating materials with desired deformation behavior. Our process starts with measuring deformation properties of base materials. For each base material we acquire a set of example deformations, ...</div></span>
          <span id="toHide46" style="display:none;"><br /><div style="display:inline"><p>This paper introduces a data-driven process for designing and fabricating materials with desired deformation behavior. Our process starts with measuring deformation properties of base materials. For each base material we acquire a set of example deformations, and we represent the material as a non-linear stress-strain relationship in a finite-element model. We have validated our material measurement process by comparing simulations of arbitrary stacks of base materials with measured deformations of fabricated material stacks. After material measurement, our process continues with designing stacked layers of base materials. We introduce an optimization process that finds the best combination of stacked layers that meets a user's criteria specified by example deformations. Our algorithm employs a number of strategies to prune poor solutions from the combinatorial search space. We demonstrate the complete process by designing and fabricating objects with complex heterogeneous materials using modern multi-material 3D printers.</p></div></span> <a id="expcoll46" href="JavaScript: expandcollapse('expcoll46',46)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>GPU rendering</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Sylvain Lefebvre 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778801&CFID=105749981&CFTOKEN=64099081">Micropolygon ray tracing with defocus and motion blur</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365597044&CFID=105749981&CFTOKEN=64099081">Qiming Hou</a>, 
                        <a href="author_page.cfm?id=81466640458&CFID=105749981&CFTOKEN=64099081">Hao Qin</a>, 
                        <a href="author_page.cfm?id=81466642511&CFID=105749981&CFTOKEN=64099081">Wenyao Li</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=105749981&CFTOKEN=64099081">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=105749981&CFTOKEN=64099081">Kun Zhou</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 64</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778801" title="DOI">10.1145/1833349.1778801</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778801&ftid=798306&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778801&ftid=979469&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow48" style="display:inline;"><br /><div style="display:inline">We present a micropolygon ray tracing algorithm that is capable of efficiently rendering high quality defocus and motion blur effects. A key component of our algorithm is a BVH (bounding volume hierarchy) based on 4D hyper-trapezoids that project into ...</div></span>
          <span id="toHide48" style="display:none;"><br /><div style="display:inline"><p>We present a micropolygon ray tracing algorithm that is capable of efficiently rendering high quality defocus and motion blur effects. A key component of our algorithm is a BVH (bounding volume hierarchy) based on 4D hyper-trapezoids that project into 3D OBBs (oriented bounding boxes) in spatial dimensions. This acceleration structure is able to provide tight bounding volumes for scene geometries, and is thus efficient in pruning intersection tests during ray traversal. More importantly, it can exploit the natural coherence on the time dimension in motion blurred scenes. The structure can be quickly constructed by utilizing the micropolygon grids generated during micropolygon tessellation. Ray tracing of defocused and motion blurred scenes is efficiently performed by traversing the structure. Both the BVH construction and ray traversal are easily implemented on GPUs and integrated into a GPU-based micropolygon renderer. In our experiments, our ray tracer performs up to an order of magnitude faster than the state-of-art rasterizers while consistently delivering an image quality equivalent to a maximum-quality rasterizer. We also demonstrate that the ray tracing algorithm can be extended to handle a variety of effects, such as secondary ray effects and transparency.</p></div></span> <a id="expcoll48" href="JavaScript: expandcollapse('expcoll48',48)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778802&CFID=105749981&CFTOKEN=64099081">Real-time lens blur effects and focus control</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448593503&CFID=105749981&CFTOKEN=64099081">Sungkil Lee</a>, 
                        <a href="author_page.cfm?id=81310501633&CFID=105749981&CFTOKEN=64099081">Elmar Eisemann</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105749981&CFTOKEN=64099081">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 65</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778802" title="DOI">10.1145/1833349.1778802</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778802&ftid=798307&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778802&ftid=978015&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow49" style="display:inline;"><br /><div style="display:inline">We present a novel rendering system for defocus blur and lens effects. It supports physically-based rendering and outperforms previous approaches by involving a novel GPU-based tracing method. Our solution achieves more precision than competing real-time ...</div></span>
          <span id="toHide49" style="display:none;"><br /><div style="display:inline"><p>We present a novel rendering system for defocus blur and lens effects. It supports physically-based rendering and outperforms previous approaches by involving a novel GPU-based tracing method. Our solution achieves more precision than competing real-time solutions and our results are mostly indistinguishable from offline rendering. Our method is also more general and can integrate advanced simulations, such as simple geometric lens models enabling various lens aberration effects. These latter is crucial for realism, but are often employed in artistic contexts, too. We show that available artistic lenses can be simulated by our method. In this spirit, our work introduces an intuitive control over depth-of-field effects. The physical basis is crucial as a starting point to enable new artistic renderings based on a generalized focal surface to emphasize particular elements in the scene while retaining a realistic look. Our real-time solution provides realistic, as well as plausible expressive results.</p></div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778803&CFID=105749981&CFTOKEN=64099081">OptiX: a general purpose ray tracing engine</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350577009&CFID=105749981&CFTOKEN=64099081">Steven G. Parker</a>, 
                        <a href="author_page.cfm?id=81416607207&CFID=105749981&CFTOKEN=64099081">James Bigler</a>, 
                        <a href="author_page.cfm?id=81100128205&CFID=105749981&CFTOKEN=64099081">Andreas Dietrich</a>, 
                        <a href="author_page.cfm?id=81100594219&CFID=105749981&CFTOKEN=64099081">Heiko Friedrich</a>, 
                        <a href="author_page.cfm?id=81100128774&CFID=105749981&CFTOKEN=64099081">Jared Hoberock</a>, 
                        <a href="author_page.cfm?id=81100131290&CFID=105749981&CFTOKEN=64099081">David Luebke</a>, 
                        <a href="author_page.cfm?id=81100125718&CFID=105749981&CFTOKEN=64099081">David McAllister</a>, 
                        <a href="author_page.cfm?id=81327490282&CFID=105749981&CFTOKEN=64099081">Morgan McGuire</a>, 
                        <a href="author_page.cfm?id=81466644249&CFID=105749981&CFTOKEN=64099081">Keith Morley</a>, 
                        <a href="author_page.cfm?id=81416606771&CFID=105749981&CFTOKEN=64099081">Austin Robison</a>, 
                        <a href="author_page.cfm?id=81440615400&CFID=105749981&CFTOKEN=64099081">Martin Stich</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 66</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778803" title="DOI">10.1145/1833349.1778803</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778803&ftid=798308&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow50" style="display:inline;"><br /><div style="display:inline">The NVIDIA&reg; OptiX&trade; ray tracing engine is a programmable system designed for NVIDIA GPUs and other highly parallel architectures. The OptiX engine builds on the key observation that most ray tracing algorithms can be implemented using a small ...</div></span>
          <span id="toHide50" style="display:none;"><br /><div style="display:inline"><p>The NVIDIA&reg; OptiX&trade; ray tracing engine is a programmable system designed for NVIDIA GPUs and other highly parallel architectures. The OptiX engine builds on the key observation that most ray tracing algorithms can be implemented using a small set of programmable operations. Consequently, the core of OptiX is a domain-specific just-in-time compiler that generates custom ray tracing kernels by combining user-supplied programs for ray generation, material shading, object intersection, and scene traversal. This enables the implementation of a highly diverse set of ray tracing-based algorithms and applications, including interactive rendering, offline rendering, collision detection systems, artificial intelligence queries, and scientific simulations such as sound propagation. OptiX achieves high performance through a compact object model and application of several ray tracing-specific compiler optimizations. For ease of use it exposes a single-ray programming model with full support for recursion and a dynamic dispatch mechanism similar to virtual function calls.</p></div></span> <a id="expcoll50" href="JavaScript: expandcollapse('expcoll50',50)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778804&CFID=105749981&CFTOKEN=64099081">Reducing shading on GPUs using quad-fragment merging</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100626902&CFID=105749981&CFTOKEN=64099081">Kayvon Fatahalian</a>, 
                        <a href="author_page.cfm?id=81322489114&CFID=105749981&CFTOKEN=64099081">Solomon Boulos</a>, 
                        <a href="author_page.cfm?id=81377591215&CFID=105749981&CFTOKEN=64099081">James Hegarty</a>, 
                        <a href="author_page.cfm?id=81100563035&CFID=105749981&CFTOKEN=64099081">Kurt Akeley</a>, 
                        <a href="author_page.cfm?id=81100279370&CFID=105749981&CFTOKEN=64099081">William R. Mark</a>, 
                        <a href="author_page.cfm?id=81100412948&CFID=105749981&CFTOKEN=64099081">Henry Moreton</a>, 
                        <a href="author_page.cfm?id=81100482576&CFID=105749981&CFTOKEN=64099081">Pat Hanrahan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 67</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778804" title="DOI">10.1145/1833349.1778804</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778804&ftid=798636&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778804&ftid=979470&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow51" style="display:inline;"><br /><div style="display:inline">Current GPUs perform a significant amount of redundant shading when surfaces are tessellated into small triangles. We address this inefficiency by augmenting the GPU pipeline to gather and merge rasterized fragments from adjacent triangles in a mesh. ...</div></span>
          <span id="toHide51" style="display:none;"><br /><div style="display:inline"><p>Current GPUs perform a significant amount of redundant shading when surfaces are tessellated into small triangles. We address this inefficiency by augmenting the GPU pipeline to gather and merge rasterized fragments from adjacent triangles in a mesh. This approach has minimal impact on output image quality, is amenable to implementation in fixed-function hardware, and, when rendering pixel-sized triangles, requires only a small amount of buffering to reduce overall pipeline shading work by a factor of eight. We find that a fragment-shading pipeline with this optimization is competitive with the REYES pipeline approach of shading at micropolygon vertices and, in cases of complex occlusion, can perform up to two times less shading work.</p></div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Physics-based sound & bubbles</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          George Drettakis 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778805&CFID=105749981&CFTOKEN=64099081">Precomputed wave simulation for real-time sound propagation of dynamic sources in complex scenes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100483046&CFID=105749981&CFTOKEN=64099081">Nikunj Raghuvanshi</a>, 
                        <a href="author_page.cfm?id=81100167784&CFID=105749981&CFTOKEN=64099081">John Snyder</a>, 
                        <a href="author_page.cfm?id=81448597087&CFID=105749981&CFTOKEN=64099081">Ravish Mehra</a>, 
                        <a href="author_page.cfm?id=81453605922&CFID=105749981&CFTOKEN=64099081">Ming Lin</a>, 
                        <a href="author_page.cfm?id=81100383019&CFID=105749981&CFTOKEN=64099081">Naga Govindaraju</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 68</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778805" title="DOI">10.1145/1833349.1778805</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778805&ftid=798309&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778805&ftid=977286&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow53" style="display:inline;"><br /><div style="display:inline">We present a method for real-time sound propagation that captures all wave effects, including diffraction and reverberation, for multiple moving sources and a moving listener in a complex, static 3D scene. It performs an offline numerical simulation ...</div></span>
          <span id="toHide53" style="display:none;"><br /><div style="display:inline"><p>We present a method for real-time sound propagation that captures all wave effects, including diffraction and reverberation, for multiple moving sources and a moving listener in a complex, static 3D scene. It performs an offline numerical simulation over the scene and then applies a novel technique to extract and compactly encode the perceptually salient information in the resulting acoustic responses. Each response is automatically broken into two phases: early reflections (ER) and late reverberation (LR), via a threshold on the temporal density of arriving wavefronts. The LR is simulated and stored in the frequency domain, once per room in the scene. The ER accounts for more detailed spatial variation, by recording a set of peak delays/amplitudes in the time domain and a residual frequency response sampled in octave frequency bands, at each source/receiver point pair in a 5D grid. An efficient run-time uses this precomputed representation to perform binaural sound rendering based on frequency-domain convolution. Our system demonstrates realistic, wave-based acoustic effects in real time, including diffraction low-passing behind obstructions, sound focusing, hollow reverberation in empty rooms, sound diffusion in fully-furnished rooms, and realistic late reverberation.</p></div></span> <a id="expcoll53" href="JavaScript: expandcollapse('expcoll53',53)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778806&CFID=105749981&CFTOKEN=64099081">Rigid-body fracture sound with precomputed soundbanks</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414596051&CFID=105749981&CFTOKEN=64099081">Changxi Zheng</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=105749981&CFTOKEN=64099081">Doug L. James</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 69</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778806" title="DOI">10.1145/1833349.1778806</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778806&ftid=798310&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778806&ftid=978295&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow54" style="display:inline;"><br /><div style="display:inline">We propose a physically based algorithm for synthesizing sounds synchronized with brittle fracture animations. Motivated by laboratory experiments, we approximate brittle fracture sounds using time-varying rigid-body sound models. We extend methods for ...</div></span>
          <span id="toHide54" style="display:none;"><br /><div style="display:inline"><p>We propose a physically based algorithm for synthesizing sounds synchronized with brittle fracture animations. Motivated by laboratory experiments, we approximate brittle fracture sounds using time-varying rigid-body sound models. We extend methods for fracturing rigid materials by proposing a fast quasistatic stress solver to resolve near-audio-rate fracture events, energy-based fracture pattern modeling and estimation of "crack"-related fracture impulses. Multipole radiation models provide scalable sound radiation for complex debris and level of detail control. To reduce soundmodel generation costs for complex fracture debris, we propose Precomputed Rigid-Body Soundbanks comprised of precomputed ellipsoidal sound proxies. Examples and experiments are presented that demonstrate plausible and affordable brittle fracture sounds.</p></div></span> <a id="expcoll54" href="JavaScript: expandcollapse('expcoll54',54)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778807&CFID=105749981&CFTOKEN=64099081">A practical simulation of dispersed bubble flow</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81452618639&CFID=105749981&CFTOKEN=64099081">Doyub Kim</a>, 
                        <a href="author_page.cfm?id=81384601172&CFID=105749981&CFTOKEN=64099081">Oh-young Song</a>, 
                        <a href="author_page.cfm?id=81423594747&CFID=105749981&CFTOKEN=64099081">Hyeong-Seok Ko</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 70</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778807" title="DOI">10.1145/1833349.1778807</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778807&ftid=798311&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778807&ftid=978296&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow55" style="display:inline;"><br /><div style="display:inline">In this paper, we propose a simple and efficient framework for simulating dispersed bubble flow. Instead of modeling the complex hydrodynamics of numerous small bubbles explicitly, our method approximates the average motion of these bubbles using a continuum ...</div></span>
          <span id="toHide55" style="display:none;"><br /><div style="display:inline"><p>In this paper, we propose a simple and efficient framework for simulating dispersed bubble flow. Instead of modeling the complex hydrodynamics of numerous small bubbles explicitly, our method approximates the average motion of these bubbles using a continuum multiphase solver. Then, the subgrid interactions among bubbles are computed using our new stochastic solver. Using the proposed scheme, we can efficiently simulate complex scenes with millions of bubbles.</p></div></span> <a id="expcoll55" href="JavaScript: expandcollapse('expcoll55',55)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Planning & terrain</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Michiel van de Panne 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778808&CFID=105749981&CFTOKEN=64099081">Robust physics-based locomotion using low-dimensional planning</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335495027&CFID=105749981&CFTOKEN=64099081">Igor Mordatch</a>, 
                        <a href="author_page.cfm?id=81456638012&CFID=105749981&CFTOKEN=64099081">Martin de Lasa</a>, 
                        <a href="author_page.cfm?id=81100015154&CFID=105749981&CFTOKEN=64099081">Aaron Hertzmann</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 71</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778808" title="DOI">10.1145/1833349.1778808</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778808&ftid=798312&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778808&ftid=977287&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow57" style="display:inline;"><br /><div style="display:inline">This paper presents a physics-based locomotion controller based on online planning. At each time-step, a planner optimizes locomotion over multiple phases of gait. Stance dynamics are modeled using a simplified Spring-Load Inverted (SLIP) model, while ...</div></span>
          <span id="toHide57" style="display:none;"><br /><div style="display:inline"><p>This paper presents a physics-based locomotion controller based on online planning. At each time-step, a planner optimizes locomotion over multiple phases of gait. Stance dynamics are modeled using a simplified Spring-Load Inverted (SLIP) model, while flight dynamics are modeled using projectile motion equations. Full-body control at each instant is optimized to match the instantaneous plan values, while also maintaining balance. Different types of gaits, including walking, running, and jumping, emerge automatically, as do transitions between different gaits. The controllers can traverse challenging terrain and withstand large external disturbances, while following high-level user commands at interactive rates.</p></div></span> <a id="expcoll57" href="JavaScript: expandcollapse('expcoll57',57)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778809&CFID=105749981&CFTOKEN=64099081">Terrain-adaptive bipedal locomotion control</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81322510560&CFID=105749981&CFTOKEN=64099081">Jia-chi Wu</a>, 
                        <a href="author_page.cfm?id=81100620346&CFID=105749981&CFTOKEN=64099081">Zoran Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 72</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778809" title="DOI">10.1145/1833349.1778809</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778809&ftid=798313&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778809&ftid=977288&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow58" style="display:inline;"><br /><div style="display:inline">We describe a framework for the automatic synthesis of biped locomotion controllers that adapt to uneven terrain at run-time. The framework consists of two components: a per-footstep end-effector path planner and a per-timestep generalized-force solver. ...</div></span>
          <span id="toHide58" style="display:none;"><br /><div style="display:inline"><p>We describe a framework for the automatic synthesis of biped locomotion controllers that adapt to uneven terrain at run-time. The framework consists of two components: a per-footstep end-effector path planner and a per-timestep generalized-force solver. At the start of each footstep, the planner performs short-term planning in the space of end-effector trajectories. These trajectories adapt to the interactive task goals and the features of the surrounding uneven terrain at run-time. We solve for the parameters of the planner for different tasks in offline optimizations. Using the per-footstep plan, the generalized-force solver takes ground contacts into consideration and solves a quadratic program at each simulation timestep to obtain joint torques that drive the biped. We demonstrate the capabilities of the controllers in complex navigation tasks where they perform gradual or sharp turns and transition between moving forwards, backwards, and sideways on uneven terrain (including hurdles and stairs) according to the interactive task goals. We also show that the resulting controllers are capable of handling morphology changes to the character.</p></div></span> <a id="expcoll58" href="JavaScript: expandcollapse('expcoll58',58)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778810&CFID=105749981&CFTOKEN=64099081">Optimizing walking controllers for uncertain inputs and environments</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350583011&CFID=105749981&CFTOKEN=64099081">Jack M. Wang</a>, 
                        <a href="author_page.cfm?id=81100620901&CFID=105749981&CFTOKEN=64099081">David J. Fleet</a>, 
                        <a href="author_page.cfm?id=81100015154&CFID=105749981&CFTOKEN=64099081">Aaron Hertzmann</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 73</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778810" title="DOI">10.1145/1833349.1778810</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778810&ftid=798314&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778810&ftid=978297&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow59" style="display:inline;"><br /><div style="display:inline">We introduce methods for optimizing physics-based walking controllers for robustness to uncertainty. Many unknown factors, such as external forces, control torques, and user control inputs, cannot be known in advance and must be treated as uncertain. ...</div></span>
          <span id="toHide59" style="display:none;"><br /><div style="display:inline"><p>We introduce methods for optimizing physics-based walking controllers for robustness to uncertainty. Many unknown factors, such as external forces, control torques, and user control inputs, cannot be known in advance and must be treated as uncertain. These variables are represented with probability distributions, and a return function scores the desirability of a single motion. Controller optimization entails maximizing the expected value of the return, which is computed by Monte Carlo methods. We demonstrate examples with different sources of uncertainty and task constraints. Optimizing control strategies under uncertainty increases robustness and produces natural variations in style.</p></div></span> <a id="expcoll59" href="JavaScript: expandcollapse('expcoll59',59)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778811&CFID=105749981&CFTOKEN=64099081">Optimal feedback control for character animation using an abstract model</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335499985&CFID=105749981&CFTOKEN=64099081">Yuting Ye</a>, 
                        <a href="author_page.cfm?id=81452598193&CFID=105749981&CFTOKEN=64099081">C. Karen Liu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 74</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778811" title="DOI">10.1145/1833349.1778811</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778811&ftid=798315&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778811&ftid=978298&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow60" style="display:inline;"><br /><div style="display:inline">Real-time adaptation of a motion capture sequence to virtual environments with physical perturbations requires robust control strategies. This paper describes an optimal feedback controller for motion tracking that allows for on-the-fly re-planning of ...</div></span>
          <span id="toHide60" style="display:none;"><br /><div style="display:inline"><p>Real-time adaptation of a motion capture sequence to virtual environments with physical perturbations requires robust control strategies. This paper describes an optimal feedback controller for motion tracking that allows for on-the-fly re-planning of long-term goals and adjustments in the final completion time. We first solve an offline optimal trajectory problem for an abstract dynamic model that captures the essential relation between contact forces and momenta. A feedback control policy is then derived and used to simulate the abstract model online. Simulation results become dynamic constraints for online reconstruction of full-body motion from a reference. We applied our controller to a wide range of motions including walking, long stepping, and a squat exercise. Results show that our controllers are robust to large perturbations and changes in the environment.</p></div></span> <a id="expcoll60" href="JavaScript: expandcollapse('expcoll60',60)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Displays and eyes</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Marc Levoy 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778812&CFID=105749981&CFTOKEN=64099081">Nonlinear disparity mapping for stereoscopic 3D</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81444601891&CFID=105749981&CFTOKEN=64099081">Manuel Lang</a>, 
                        <a href="author_page.cfm?id=81100346709&CFID=105749981&CFTOKEN=64099081">Alexander Hornung</a>, 
                        <a href="author_page.cfm?id=81365594740&CFID=105749981&CFTOKEN=64099081">Oliver Wang</a>, 
                        <a href="author_page.cfm?id=81466647812&CFID=105749981&CFTOKEN=64099081">Steven Poulakos</a>, 
                        <a href="author_page.cfm?id=81100168168&CFID=105749981&CFTOKEN=64099081">Aljoscha Smolic</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105749981&CFTOKEN=64099081">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 75</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778812" title="DOI">10.1145/1833349.1778812</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778812&ftid=798316&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow62" style="display:inline;"><br /><div style="display:inline">This paper addresses the problem of remapping the disparity range of stereoscopic images and video. Such operations are highly important for a variety of issues arising from the production, live broadcast, and consumption of 3D content. Our work is motivated ...</div></span>
          <span id="toHide62" style="display:none;"><br /><div style="display:inline"><p>This paper addresses the problem of remapping the disparity range of stereoscopic images and video. Such operations are highly important for a variety of issues arising from the production, live broadcast, and consumption of 3D content. Our work is motivated by the observation that the displayed depth and the resulting 3D viewing experience are dictated by a complex combination of perceptual, technological, and artistic constraints. We first discuss the most important perceptual aspects of stereo vision and their implications for stereoscopic content creation. We then formalize these insights into a set of basic <i>disparity mapping operators.</i> These operators enable us to control and retarget the depth of a stereoscopic scene in a nonlinear and locally adaptive fashion. To implement our operators, we propose a new strategy based on <i>stereoscopic warping</i> of the input video streams. From a sparse set of stereo correspondences, our algorithm computes disparity and image-based saliency estimates, and uses them to compute a deformation of the input views so as to meet the target disparities. Our approach represents a practical solution for actual stereo production and display that does not require camera calibration, accurate dense depth maps, occlusion handling, or inpainting. We demonstrate the performance and versatility of our method using examples from live action post-production, 3D display size adaptation, and live broadcast. An additional user study and ground truth comparison further provide evidence for the quality and practical relevance of the presented work.</p></div></span> <a id="expcoll62" href="JavaScript: expandcollapse('expcoll62',62)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778813&CFID=105749981&CFTOKEN=64099081">A multi-layered display with water drops</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81453656905&CFID=105749981&CFTOKEN=64099081">Peter C. Barnum</a>, 
                        <a href="author_page.cfm?id=81100599730&CFID=105749981&CFTOKEN=64099081">Srinivasa G. Narasimhan</a>, 
                        <a href="author_page.cfm?id=81100496698&CFID=105749981&CFTOKEN=64099081">Takeo Kanade</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 76</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778813" title="DOI">10.1145/1833349.1778813</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778813&ftid=798317&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778813&ftid=979471&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow63" style="display:inline;"><br /><div style="display:inline">We present a multi-layered display that uses water drops as voxels. Water drops refract most incident light, making them excellent wide-angle lenses. Each 2D layer of our display can exhibit arbitrary visual content, creating a layered-depth (2.5D) display. ...</div></span>
          <span id="toHide63" style="display:none;"><br /><div style="display:inline"><p>We present a multi-layered display that uses water drops as voxels. Water drops refract most incident light, making them excellent wide-angle lenses. Each 2D layer of our display can exhibit arbitrary visual content, creating a layered-depth (2.5D) display. Our system consists of a single projector-camera system and a set of linear drop generator manifolds that are tightly synchronized and controlled using a computer. Following the principles of fluid mechanics, we are able to accurately generate and control drops so that, at any time instant, no two drops occupy the same projector pixel's line-of-sight. This drop control is combined with an algorithm for space-time division of projector light rays. Our prototype system has up to four layers, with each layer consisting of an row of 50 drops that can be generated at up to 60 Hz. The effective resolution of the display is 50x <i>projector vertical-resolution x number of layers.</i> We show how this water drop display can be used for text, videos, and interactive games.</p></div></span> <a id="expcoll63" href="JavaScript: expandcollapse('expcoll63',63)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778814&CFID=105749981&CFTOKEN=64099081">NETRA: interactive display for estimating refractive errors and focal range</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442619125&CFID=105749981&CFTOKEN=64099081">Vitor F. Pamplona</a>, 
                        <a href="author_page.cfm?id=81320492783&CFID=105749981&CFTOKEN=64099081">Ankit Mohan</a>, 
                        <a href="author_page.cfm?id=81100516478&CFID=105749981&CFTOKEN=64099081">Manuel M. Oliveira</a>, 
                        <a href="author_page.cfm?id=81100022847&CFID=105749981&CFTOKEN=64099081">Ramesh Raskar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 77</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778814" title="DOI">10.1145/1833349.1778814</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778814&ftid=798318&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778814&ftid=977296&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow64" style="display:inline;"><br /><div style="display:inline">We introduce an interactive, portable, and inexpensive solution for estimating refractive errors in the human eye. While expensive optical devices for automatic estimation of refractive correction exist, our goal is to greatly simplify the mechanism ...</div></span>
          <span id="toHide64" style="display:none;"><br /><div style="display:inline"><p>We introduce an interactive, portable, and inexpensive solution for estimating refractive errors in the human eye. While expensive optical devices for automatic estimation of refractive correction exist, our goal is to greatly simplify the mechanism by putting the human subject in the loop. Our solution is based on a high-resolution programmable display and combines inexpensive optical elements, interactive GUI, and computational reconstruction. The key idea is to interface a lenticular view-dependent display with the human eye in <i>close range</i> - a few millimeters apart. Via this platform, we create a new range of interactivity that is extremely sensitive to parameters of the human eye, like refractive errors, focal range, focusing speed, lens opacity, etc. We propose several simple optical setups, verify their accuracy, precision, and validate them in a user study.</p></div></span> <a id="expcoll64" href="JavaScript: expandcollapse('expcoll64',64)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Geometry algorithms & sampling</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Pedro Sander 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778815&CFID=105749981&CFTOKEN=64099081">Controllable conformal maps for shape deformation and interpolation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81384605811&CFID=105749981&CFTOKEN=64099081">Ofir Weber</a>, 
                        <a href="author_page.cfm?id=81100294813&CFID=105749981&CFTOKEN=64099081">Craig Gotsman</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 78</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778815" title="DOI">10.1145/1833349.1778815</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778815&ftid=798319&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778815&ftid=978016&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow66" style="display:inline;"><br /><div style="display:inline">Conformal maps are considered very desirable for planar deformation applications, since they allow only local rotations and scale, avoiding shear and other visually disturbing distortions of local detail. Conformal maps are also orientation-preserving ...</div></span>
          <span id="toHide66" style="display:none;"><br /><div style="display:inline"><p>Conformal maps are considered very desirable for planar deformation applications, since they allow only local rotations and scale, avoiding shear and other visually disturbing distortions of local detail. Conformal maps are also orientation-preserving C<sup>&infin;</sup> diffeomorphisms, meaning they are extremely smooth and prevent unacceptable "foldovers" in the plane. Unfortunately, these maps are also notoriously difficult to control, so working with them in an interactive animation scenario to achieve specific effects is a significant challenge, sometimes even impossible.</p> <p>We describe a novel 2D shape deformation system which generates conformal maps, yet provides the user a large degree of control over the result. For example, it allows discontinuities at user-specified boundary points, so true "bends" can be introduced into the deformation. It also allows the prescription of angular constraints at corners of the target image. Combining these provides for a very effective user experience. At the heart of our method is a very natural differential shape representation for conformal maps, using so-called "conformal factors" and "angular factors", which allow more intuitive control compared to representation in the usual spatial domain. Beyond deforming a given shape into a new one at each key frame, our method also provides the ability to interpolate between shapes in a very natural way, such that also the intermediate deformations are conformal.</p> <p>Our method is extremely efficient: it requires only the solution of a small dense linear system at preprocess time and a matrix-vector multiplication during runtime (which can be implemented on a modern GPU), thus the deformations, even on extremely large images, may be performed in real-time.</p></div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778816&CFID=105749981&CFTOKEN=64099081">Multi-class blue noise sampling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81452594229&CFID=105749981&CFTOKEN=64099081">Li-Yi Wei</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 79</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778816" title="DOI">10.1145/1833349.1778816</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778816&ftid=798320&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778816&ftid=978017&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow67" style="display:inline;"><br /><div style="display:inline">Sampling is a core process for a variety of graphics applications. Among existing sampling methods, blue noise sampling remains popular thanks to its spatial uniformity and absence of aliasing artifacts. However, research so far has been mainly focused ...</div></span>
          <span id="toHide67" style="display:none;"><br /><div style="display:inline"><p>Sampling is a core process for a variety of graphics applications. Among existing sampling methods, blue noise sampling remains popular thanks to its spatial uniformity and absence of aliasing artifacts. However, research so far has been mainly focused on blue noise sampling with a single class of samples. This could be insufficient for common natural as well as man-made phenomena requiring multiple classes of samples, such as object placement, imaging sensors, and stippling patterns.</p> <p>We extend blue noise sampling to multiple classes where each individual class as well as their unions exhibit blue noise characteristics. We propose two flavors of algorithms to generate such multi-class blue noise samples, one extended from traditional Poisson <i>hard</i> disk sampling for explicit control of sample spacing, and another based on our <i>soft</i> disk sampling for explicit control of sample count. Our algorithms support uniform and adaptive sampling, and are applicable to both discrete and continuous sample space in arbitrary dimensions. We study characteristics of samples generated by our methods, and demonstrate applications in object placement, sensor layout, and color stippling.</p></div></span> <a id="expcoll67" href="JavaScript: expandcollapse('expcoll67',67)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Collisions and contact</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Joseph Teran 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778817&CFID=105749981&CFTOKEN=64099081">Star-contours for efficient hierarchical self-collision detection</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442618328&CFID=105749981&CFTOKEN=64099081">Sara C. Schvartzman</a>, 
                        <a href="author_page.cfm?id=81466642382&CFID=105749981&CFTOKEN=64099081">&#193;lvaro G. P&#233;rez</a>, 
                        <a href="author_page.cfm?id=81100035394&CFID=105749981&CFTOKEN=64099081">Miguel A. Otaduy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 80</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778817" title="DOI">10.1145/1833349.1778817</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778817&ftid=798321&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778817&ftid=979472&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow69" style="display:inline;"><br /><div style="display:inline">Collision detection is a problem that has often been addressed efficiently with the use of hierarchical culling data structures. In the subproblem of self-collision detection for triangle meshes, however, such hierarchical data structures lose much of ...</div></span>
          <span id="toHide69" style="display:none;"><br /><div style="display:inline"><p>Collision detection is a problem that has often been addressed efficiently with the use of hierarchical culling data structures. In the subproblem of self-collision detection for triangle meshes, however, such hierarchical data structures lose much of their power, because triangles adjacent to each other cannot be distinguished from actually colliding ones unless individually tested. Shape regularity of surface patches, described in terms of orientation and contour conditions, was proposed long ago as a culling criterion for hierarchical self-collision detection. However, to date, algorithms based on shape regularity had to trade conservativeness for efficiency, because there was no known algorithm for efficiently performing 2D contour self-intersection tests.</p> <p>In this paper, we introduce a star-contour criterion that is amenable to hierarchical computations. Together with a thorough analysis of the tree traversal process in hierarchical self-collision detection, it has led us to novel hierarchical data structures and algorithms for efficient yet conservative self-collision detection. We demonstrate the application of our algorithm to several example animations, and we show that it consistently outperforms other approaches.</p></div></span> <a id="expcoll69" href="JavaScript: expandcollapse('expcoll69',69)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778818&CFID=105749981&CFTOKEN=64099081">Subspace self-collision culling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100158368&CFID=105749981&CFTOKEN=64099081">Jernej Barbi&#269;</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=105749981&CFTOKEN=64099081">Doug L. James</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 81</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778818" title="DOI">10.1145/1833349.1778818</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778818&ftid=798322&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778818&ftid=979473&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow70" style="display:inline;"><br /><div style="display:inline">We show how to greatly accelerate self-collision detection (SCD) for reduced deformable models. Given a triangle mesh and a set of deformation modes, our method precomputes Subspace Self-Collision Culling (SSCC) certificates which, if satisfied, ...</div></span>
          <span id="toHide70" style="display:none;"><br /><div style="display:inline"><p>We show how to greatly accelerate self-collision detection (SCD) for reduced deformable models. Given a triangle mesh and a set of deformation modes, our method precomputes <i>Subspace Self-Collision Culling (SSCC) certificates</i> which, if satisfied, prove the absence of self-collisions for large parts of the model. At runtime, bounding volume hierarchies augmented with our certificates can aggressively cull overlap tests and reduce hierarchy updates. Our method supports both discrete and continuous SCD, can handle complex geometry, and makes no assumptions about geometric smoothness or normal bounds. It is particularly effective for simulations with modest subspace deformations, where it can often verify the absence of self-collisions in <i>constant time.</i> Our certificates enable low amortized costs, in time and across many objects in multi-body dynamics simulations. Finally, SSCC is effective enough to support self-collision tests at audio rates, which we demonstrate by producing the first sound simulations of clattering objects.</p></div></span> <a id="expcoll70" href="JavaScript: expandcollapse('expcoll70',70)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778819&CFID=105749981&CFTOKEN=64099081">Volume contact constraints at arbitrary resolution</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100097644&CFID=105749981&CFTOKEN=64099081">J&#233;r&#233;mie Allard</a>, 
                        <a href="author_page.cfm?id=81100210102&CFID=105749981&CFTOKEN=64099081">Fran&#231;ois Faure</a>, 
                        <a href="author_page.cfm?id=81440622142&CFID=105749981&CFTOKEN=64099081">Hadrien Courtecuisse</a>, 
                        <a href="author_page.cfm?id=81444607008&CFID=105749981&CFTOKEN=64099081">Florent Falipou</a>, 
                        <a href="author_page.cfm?id=81331491870&CFID=105749981&CFTOKEN=64099081">Christian Duriez</a>, 
                        <a href="author_page.cfm?id=81100269547&CFID=105749981&CFTOKEN=64099081">Paul G. Kry</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 82</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778819" title="DOI">10.1145/1833349.1778819</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778819&ftid=798323&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778819&ftid=978018&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow71" style="display:inline;"><br /><div style="display:inline">We introduce a new method for simulating frictional contact between volumetric objects using interpenetration volume constraints. When applied to complex geometries, our formulation results in dramatically simpler systems of equations than those of traditional ...</div></span>
          <span id="toHide71" style="display:none;"><br /><div style="display:inline"><p>We introduce a new method for simulating frictional contact between volumetric objects using interpenetration volume constraints. When applied to complex geometries, our formulation results in dramatically simpler systems of equations than those of traditional mesh contact models. Contact between highly detailed meshes can be simplified to a single unilateral constraint equation, or accurately processed at arbitrary geometry-independent resolution with simultaneous sticking and sliding across contact patches. We exploit fast GPU methods for computing layered depth images, which provides us with the intersection volumes and gradients necessary to formulate the contact equations as linear complementarity problems. Straightforward and popular numerical methods, such as projected Gauss-Seidel, can be used to solve the system. We demonstrate our method in a number of scenarios and present results involving both rigid and deformable objects at interactive rates.</p></div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Boundaries, edges & gradients</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Sylvain Paris 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778820&CFID=105749981&CFTOKEN=64099081">RepFinder: finding approximately repeated scene elements for image editing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448596359&CFID=105749981&CFTOKEN=64099081">Ming-Ming Cheng</a>, 
                        <a href="author_page.cfm?id=81466642187&CFID=105749981&CFTOKEN=64099081">Fang-Lue Zhang</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=105749981&CFTOKEN=64099081">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81388594299&CFID=105749981&CFTOKEN=64099081">Xiaolei Huang</a>, 
                        <a href="author_page.cfm?id=81100254073&CFID=105749981&CFTOKEN=64099081">Shi-Min Hu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 83</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778820" title="DOI">10.1145/1833349.1778820</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778820&ftid=798324&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778820&ftid=979474&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow73" style="display:inline;"><br /><div style="display:inline">Repeated elements are ubiquitous and abundant in both manmade and natural scenes. Editing such images while preserving the repetitions and their relations is nontrivial due to overlap, missing parts, deformation across instances, illumination variation, ...</div></span>
          <span id="toHide73" style="display:none;"><br /><div style="display:inline"><p>Repeated elements are ubiquitous and abundant in both manmade and natural scenes. Editing such images while preserving the repetitions and their relations is nontrivial due to overlap, missing parts, deformation across instances, illumination variation, etc. Manually enforcing such relations is laborious and error-prone. We propose a novel framework where user scribbles are used to guide detection and extraction of such repeated elements. Our detection process, which is based on a novel boundary band method, robustly extracts the repetitions along with their deformations. The algorithm only considers the shape of the elements, and ignores similarity based on color, texture, etc. We then use topological sorting to establish a partial depth ordering of overlapping repeated instances. Missing parts on occluded instances are completed using information from other instances. The extracted repeated instances can then be seamlessly edited and manipulated for a variety of high level tasks that are otherwise difficult to perform. We demonstrate the versatility of our framework on a large set of inputs of varying complexity, showing applications to image rearrangement, edit transfer, deformation propagation, and instance replacement.</p></div></span> <a id="expcoll73" href="JavaScript: expandcollapse('expcoll73',73)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Textures</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Greg Turk 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778821&CFID=105749981&CFTOKEN=64099081">By-example synthesis of architectural textures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100198784&CFID=105749981&CFTOKEN=64099081">Sylvain Lefebvre</a>, 
                        <a href="author_page.cfm?id=81100304397&CFID=105749981&CFTOKEN=64099081">Samuel Hornus</a>, 
                        <a href="author_page.cfm?id=81466648089&CFID=105749981&CFTOKEN=64099081">Anass Lasram</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 84</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778821" title="DOI">10.1145/1833349.1778821</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778821&ftid=798325&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778821&ftid=977289&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow75" style="display:inline;"><br /><div style="display:inline">Textures are often reused on different surfaces in large virtual environments. This leads to unpleasing stretch and cropping of features when textures contain architectural elements. Existing retargeting methods could adapt each texture to the size of ...</div></span>
          <span id="toHide75" style="display:none;"><br /><div style="display:inline"><p>Textures are often reused on different surfaces in large virtual environments. This leads to unpleasing stretch and cropping of features when textures contain architectural elements. Existing retargeting methods could adapt each texture to the size of their support surface, but this would imply storing a different image for each and every surface, saturating memory. Our new texture synthesis approach casts synthesis as a shortest path problem in a graph describing the space of images that can be synthesized. Each path in the graph describes how to form a new image by cutting strips of the source image and reassembling them in a different order. Only the paths describing the result need to be stored in memory: synthesized textures are reconstructed at rendering time. The user can control repetition of features, and may specify positional constraints. We demonstrate our approach on a variety of textures, from facades for large city rendering to structured textures commonly used in video games.</p></div></span> <a id="expcoll75" href="JavaScript: expandcollapse('expcoll75',75)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778822&CFID=105749981&CFTOKEN=64099081">Synthesizing structured image hybrids</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81331502452&CFID=105749981&CFTOKEN=64099081">Eric Risser</a>, 
                        <a href="author_page.cfm?id=81335491392&CFID=105749981&CFTOKEN=64099081">Charles Han</a>, 
                        <a href="author_page.cfm?id=81331490576&CFID=105749981&CFTOKEN=64099081">Rozenn Dahyot</a>, 
                        <a href="author_page.cfm?id=81441592259&CFID=105749981&CFTOKEN=64099081">Eitan Grinspun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 85</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778822" title="DOI">10.1145/1833349.1778822</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778822&ftid=798326&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778822&ftid=978299&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow76" style="display:inline;"><br /><div style="display:inline">Example-based texture synthesis algorithms generate novel texture images from example data. A popular hierarchical pixel-based approach uses spatial jitter to introduce diversity, at the risk of breaking coarse structure beyond repair. We propose a multiscale ...</div></span>
          <span id="toHide76" style="display:none;"><br /><div style="display:inline"><p>Example-based texture synthesis algorithms generate novel texture images from example data. A popular hierarchical pixel-based approach uses spatial jitter to introduce diversity, at the risk of breaking coarse structure beyond repair. We propose a multiscale descriptor that enables appearance-space jitter, which retains structure. This idea enables repurposing of existing texture synthesis implementations for a qualitatively different problem statement and class of inputs: generating hybrids of structured images.</p></div></span> <a id="expcoll76" href="JavaScript: expandcollapse('expcoll76',76)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778823&CFID=105749981&CFTOKEN=64099081">Vector solid textures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440604427&CFID=105749981&CFTOKEN=64099081">Lvdi Wang</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=105749981&CFTOKEN=64099081">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81100472713&CFID=105749981&CFTOKEN=64099081">Yizhou Yu</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=105749981&CFTOKEN=64099081">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 86</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778823" title="DOI">10.1145/1833349.1778823</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778823&ftid=798327&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778823&ftid=977290&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow77" style="display:inline;"><br /><div style="display:inline">In this paper, we introduce a compact random-access vector representation for solid textures made of intermixed regions with relatively smooth internal color variations. It is feature-preserving and resolution-independent. In this representation, a texture ...</div></span>
          <span id="toHide77" style="display:none;"><br /><div style="display:inline"><p>In this paper, we introduce a compact random-access vector representation for solid textures made of intermixed regions with relatively smooth internal color variations. It is feature-preserving and resolution-independent. In this representation, a texture volume is divided into multiple regions. Region boundaries are implicitly defined using a signed distance function. Color variations within the regions are represented using compactly supported radial basis functions (RBFs). With a spatial indexing structure, such RBFs enable efficient color evaluation during real-time solid texture mapping. Effective techniques have been developed for generating such a vector representation from bitmap solid textures. Data structures and techniques have also been developed to compactly store region labels and distance values for efficient random access during boundary and color evaluation.</p></div></span> <a id="expcoll77" href="JavaScript: expandcollapse('expcoll77',77)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Video</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Rick Szeliski 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778824&CFID=105749981&CFTOKEN=64099081">Unstructured video-based rendering: interactive exploration of casually captured videos</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81330488116&CFID=105749981&CFTOKEN=64099081">Luca Ballan</a>, 
                        <a href="author_page.cfm?id=81100137312&CFID=105749981&CFTOKEN=64099081">Gabriel J. Brostow</a>, 
                        <a href="author_page.cfm?id=81466647776&CFID=105749981&CFTOKEN=64099081">Jens Puwein</a>, 
                        <a href="author_page.cfm?id=81100638521&CFID=105749981&CFTOKEN=64099081">Marc Pollefeys</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 87</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778824" title="DOI">10.1145/1833349.1778824</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778824&ftid=798328&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778824&ftid=978300&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow79" style="display:inline;"><br /><div style="display:inline">We present an algorithm designed for navigating around a performance that was filmed as a "casual" multi-view video collection: real-world footage captured on hand held cameras by a few audience members. The objective is to easily navigate in 3D, generating ...</div></span>
          <span id="toHide79" style="display:none;"><br /><div style="display:inline"><p>We present an algorithm designed for navigating around a performance that was filmed as a "casual" multi-view video collection: real-world footage captured on hand held cameras by a few audience members. The objective is to easily navigate in 3D, generating a video-based rendering (VBR) of a performance filmed with widely separated cameras. Casually filmed events are especially challenging because they yield footage with complicated backgrounds and camera motion. Such challenging conditions preclude the use of most algorithms that depend on correlation-based stereo or 3D shape-from-silhouettes.</p> <p>Our algorithm builds on the concepts developed for the exploration of photo-collections of empty scenes. Interactive performer-specific view-interpolation is now possible through innovations in interactive rendering and offline-matting relating to i) modeling the foreground subject as video-sprites on billboards, ii) modeling the background geometry with adaptive view-dependent textures, and iii) view interpolation that follows a performer. The billboards are embedded in a simple but realistic reconstruction of the environment. The reconstructed environment provides very effective visual cues for spatial navigation as the user transitions between viewpoints. The prototype is tested on footage from several challenging events, and demonstrates the editorial utility of the whole system and the particular value of our new inter-billboard optimization.</p></div></span> <a id="expcoll79" href="JavaScript: expandcollapse('expcoll79',79)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778825&CFID=105749981&CFTOKEN=64099081">Dynamic video narratives</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100085579&CFID=105749981&CFTOKEN=64099081">Carlos D. Correa</a>, 
                        <a href="author_page.cfm?id=81452595774&CFID=105749981&CFTOKEN=64099081">Kwan-Liu Ma</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 88</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778825" title="DOI">10.1145/1833349.1778825</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778825&ftid=798329&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778825&ftid=978301&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow80" style="display:inline;"><br /><div style="display:inline">This paper presents a system for generating dynamic narratives from videos. These narratives are characterized for being compact, coherent and interactive, as inspired by principles of sequential art. Narratives depict the motion of one or several actors ...</div></span>
          <span id="toHide80" style="display:none;"><br /><div style="display:inline"><p>This paper presents a system for generating dynamic narratives from videos. These narratives are characterized for being compact, coherent and interactive, as inspired by principles of sequential art. Narratives depict the motion of one or several actors over time. Creating compact narratives is challenging as it is desired to combine the video frames in a way that reuses redundant backgrounds and depicts the stages of a motion. In addition, previous approaches focus on the generation of static summaries and can afford expensive image composition techniques. A dynamic narrative, on the other hand, must be played and skimmed in real-time, which imposes certain cost limitations in the video processing. In this paper, we define a novel process to compose foreground and background regions of video frames in a single interactive image using a series of spatio-temporal masks. These masks are created to improve the output of automatic video processing techniques such as image stitching and foreground segmentation. Unlike hand-drawn narratives, often limited to static representations, the proposed system allows users to explore the narrative dynamically and produce different representations of motion. We have built an authoring system that incorporates these methods and demonstrated successful results on a number of video clips. The authoring system can be used to create interactive posters of video clips, browse video in a compact manner or highlight a motion sequence in a movie.</p></div></span> <a id="expcoll80" href="JavaScript: expandcollapse('expcoll80',80)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778826&CFID=105749981&CFTOKEN=64099081">Video tapestries with continuous temporal zoom</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81385595142&CFID=105749981&CFTOKEN=64099081">Connelly Barnes</a>, 
                        <a href="author_page.cfm?id=81100026255&CFID=105749981&CFTOKEN=64099081">Dan B. Goldman</a>, 
                        <a href="author_page.cfm?id=81100538015&CFID=105749981&CFTOKEN=64099081">Eli Shechtman</a>, 
                        <a href="author_page.cfm?id=81100576882&CFID=105749981&CFTOKEN=64099081">Adam Finkelstein</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 89</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778826" title="DOI">10.1145/1833349.1778826</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778826&ftid=798330&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow81" style="display:inline;"><br /><div style="display:inline">We present a novel approach for summarizing video in the form of a multiscale image that is continuous in both the spatial domain and across the scale dimension: There are no hard borders between discrete moments in time, and a user can zoom smoothly ...</div></span>
          <span id="toHide81" style="display:none;"><br /><div style="display:inline"><p>We present a novel approach for summarizing video in the form of a multiscale image that is continuous in both the spatial domain and across the scale dimension: There are no hard borders between discrete moments in time, and a user can zoom smoothly into the image to reveal additional temporal details. We call these artifacts <i>tapestries</i> because their continuous nature is akin to medieval tapestries and other narrative depictions predating the advent of motion pictures. We propose a set of criteria for such a summarization, and a series of optimizations motivated by these criteria. These can be performed as an entirely offline computation to produce high quality renderings, or by adjusting some optimization parameters the later stages can be solved in real time, enabling an interactive interface for video navigation. Our video tapestries combine the best aspects of two common visualizations, providing the visual clarity of DVD chapter menus with the information density and multiple scales of a video editing timeline representation. In addition, they provide continuous transitions between zoom levels. In a user study, participants preferred both the aesthetics and efficiency of tapestries over other interfaces for visual browsing.</p></div></span> <a id="expcoll81" href="JavaScript: expandcollapse('expcoll81',81)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778827&CFID=105749981&CFTOKEN=64099081">Motion-based video retargeting with optimized crop-and-warp</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81318496997&CFID=105749981&CFTOKEN=64099081">Yu-Shuen Wang</a>, 
                        <a href="author_page.cfm?id=81466643324&CFID=105749981&CFTOKEN=64099081">Hui-Chih Lin</a>, 
                        <a href="author_page.cfm?id=81100036540&CFID=105749981&CFTOKEN=64099081">Olga Sorkine</a>, 
                        <a href="author_page.cfm?id=81409592133&CFID=105749981&CFTOKEN=64099081">Tong-Yee Lee</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 90</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778827" title="DOI">10.1145/1833349.1778827</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778827&ftid=799779&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778827&ftid=977291&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow82" style="display:inline;"><br /><div style="display:inline">We introduce a video retargeting method that achieves high-quality resizing to arbitrary aspect ratios for complex videos containing diverse camera and dynamic motions. Previous content-aware retargeting methods mostly concentrated on spatial considerations, ...</div></span>
          <span id="toHide82" style="display:none;"><br /><div style="display:inline"><p>We introduce a video retargeting method that achieves high-quality resizing to arbitrary aspect ratios for complex videos containing diverse camera and dynamic motions. Previous content-aware retargeting methods mostly concentrated on spatial considerations, attempting to preserve the shape of salient objects in each frame by removing or distorting homogeneous background content. However, sacrificeable space is fundamentally limited in video, since object motion makes foreground and background regions correlated, causing waving and squeezing artifacts. We solve the retargeting problem by explicitly employing motion information and by distributing distortion in both spatial and temporal dimensions. We combine novel cropping and warping operators, where the cropping removes temporally-recurring contents and the warping utilizes available homogeneous regions to mask deformations while preserving motion. Variational optimization allows to find the best balance between the two operations, enabling retargeting of challenging videos with complex motions, numerous prominent objects and arbitrary depth variability. Our method compares favorably with state-of-the-art retargeting systems, as demonstrated in the examples and widely supported by the conducted user study.</p></div></span> <a id="expcoll82" href="JavaScript: expandcollapse('expcoll82',82)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Perception, presence & animation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Ravin Balakrishnan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778828&CFID=105749981&CFTOKEN=64099081">Seeing is believing: body motion dominates in multisensory conversations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365598721&CFID=105749981&CFTOKEN=64099081">Cathy Ennis</a>, 
                        <a href="author_page.cfm?id=81328489544&CFID=105749981&CFTOKEN=64099081">Rachel McDonnell</a>, 
                        <a href="author_page.cfm?id=81100465557&CFID=105749981&CFTOKEN=64099081">Carol O'Sullivan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 91</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778828" title="DOI">10.1145/1833349.1778828</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778828&ftid=799780&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778828&ftid=979475&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow84" style="display:inline;"><br /><div style="display:inline">In many scenes with human characters, interacting groups are an important factor for maintaining a sense of realism. However, little is known about what makes these characters appear realistic. In this paper, we investigate human sensitivity to audio ...</div></span>
          <span id="toHide84" style="display:none;"><br /><div style="display:inline"><p>In many scenes with human characters, interacting groups are an important factor for maintaining a sense of realism. However, little is known about what makes these characters appear realistic. In this paper, we investigate human sensitivity to audio mismatches (i.e., when individuals' voices are not matched to their gestures) and visual desynchronization (i.e., when the body motions of the individuals in a group are mis-aligned in time) in virtual human conversers. Using motion capture data from a range of both polite conversations and arguments, we conduct a series of perceptual experiments and determine some factors that contribute to the plausibility of virtual conversing groups. We found that participants are more sensitive to visual desynchronization of body motions, than to mismatches between the characters' gestures and their voices. Furthermore, synthetic conversations can appear sufficiently realistic once there is an appropriate balance between talker and listener roles. This is regardless of body motion desynchronization or mismatched audio.</p></div></span> <a id="expcoll84" href="JavaScript: expandcollapse('expcoll84',84)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778829&CFID=105749981&CFTOKEN=64099081">Simulating virtual environments within virtual environments as the basis for a psychophysics of presence</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100615391&CFID=105749981&CFTOKEN=64099081">Mel Slater</a>, 
                        <a href="author_page.cfm?id=81100085187&CFID=105749981&CFTOKEN=64099081">Bernhard Spanlang</a>, 
                        <a href="author_page.cfm?id=81466648717&CFID=105749981&CFTOKEN=64099081">David Corominas</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 92</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778829" title="DOI">10.1145/1833349.1778829</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778829&ftid=799781&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778829&ftid=978019&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow85" style="display:inline;"><br /><div style="display:inline">A new definition of immersion with respect to virtual environment (VE) systems has been proposed in earlier work, based on the concept of simulation. One system (A) is said to be more immersive than another (B) if A can be used to ...</div></span>
          <span id="toHide85" style="display:none;"><br /><div style="display:inline"><p>A new definition of immersion with respect to virtual environment (VE) systems has been proposed in earlier work, based on the concept of simulation. One system (<i>A</i>) is said to be more immersive than another (<i>B</i>) if <i>A</i> can be used to simulate an application as if it were running on <i>B.</i> Here we show how this concept can be used as the basis for a psychophysics of presence in VEs, the sensation of being in the place depicted by the virtual environment displays (Place Illusion, PI), and also the illusion that events occurring in the virtual environment are real (Plausibility Illusion, Psi). The new methodology involves matching experiments akin to those in color science. Twenty participants first experienced PI or Psi in the initial highest level immersive system, and then in 5 different trials chose transitions from lower to higher order systems and declared a match whenever they felt the same level of PI or Psi as they had in the initial system. In each transition they could change the type of illumination model used, or the field-of-view, or the display type (powerwall or HMD) or the extent of self-representation by an avatar. The results showed that the 10 participants instructed to choose transitions to attain a level of PI corresponding to that in the initial system tended to first choose a wide field-of-view and head-mounted display, and then ensure that they had a virtual body that moved as they did. The other 10 in the Psi group concentrated far more on achieving a higher level of illumination realism, although having a virtual body representation was important for both groups. This methodology is offered as a way forward in the evaluation of the responses of people to immersive virtual environments, a unified theory and methodology for psychophysical measurement.</p></div></span> <a id="expcoll85" href="JavaScript: expandcollapse('expcoll85',85)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Urban reconstruction & explanation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Brian Curless 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778830&CFID=105749981&CFTOKEN=64099081">SmartBoxes for interactive urban reconstruction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81317498102&CFID=105749981&CFTOKEN=64099081">Liangliang Nan</a>, 
                        <a href="author_page.cfm?id=81100404504&CFID=105749981&CFTOKEN=64099081">Andrei Sharf</a>, 
                        <a href="author_page.cfm?id=81336494344&CFID=105749981&CFTOKEN=64099081">Hao Zhang</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105749981&CFTOKEN=64099081">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81100108037&CFID=105749981&CFTOKEN=64099081">Baoquan Chen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 93</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778830" title="DOI">10.1145/1833349.1778830</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778830&ftid=799782&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778830&ftid=977292&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow87" style="display:inline;"><br /><div style="display:inline">We introduce an interactive tool which enables a user to quickly assemble an architectural model directly over a 3D point cloud acquired from large-scale scanning of an urban scene. The user loosely defines and manipulates simple building blocks, which ...</div></span>
          <span id="toHide87" style="display:none;"><br /><div style="display:inline"><p>We introduce an interactive tool which enables a user to quickly assemble an architectural model directly over a 3D point cloud acquired from large-scale scanning of an urban scene. The user loosely defines and manipulates simple building blocks, which we call SmartBoxes, over the point samples. These boxes quickly snap to their proper locations to conform to common architectural structures. The key idea is that the building blocks are smart in the sense that their locations and sizes are automatically adjusted on-the-fly to fit well to the point data, while at the same time respecting contextual relations with nearby similar blocks. SmartBoxes are assembled through a discrete optimization to balance between two snapping forces defined respectively by a data-fitting term and a contextual term, which together assist the user in reconstructing the architectural model from a sparse and noisy point cloud. We show that a combination of the user's interactive guidance and high-level knowledge about the semantics of the underlying model, together with the snapping forces, allows the reconstruction of structures which are partially or even completely missing from the input.</p></div></span> <a id="expcoll87" href="JavaScript: expandcollapse('expcoll87',87)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778831&CFID=105749981&CFTOKEN=64099081">Non-local scan consolidation for 3D urban scenes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466641795&CFID=105749981&CFTOKEN=64099081">Qian Zheng</a>, 
                        <a href="author_page.cfm?id=81100404504&CFID=105749981&CFTOKEN=64099081">Andrei Sharf</a>, 
                        <a href="author_page.cfm?id=81466640594&CFID=105749981&CFTOKEN=64099081">Guowei Wan</a>, 
                        <a href="author_page.cfm?id=81466641543&CFID=105749981&CFTOKEN=64099081">Yangyan Li</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=105749981&CFTOKEN=64099081">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105749981&CFTOKEN=64099081">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81100108037&CFID=105749981&CFTOKEN=64099081">Baoquan Chen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 94</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778831" title="DOI">10.1145/1833349.1778831</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778831&ftid=799783&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778831&ftid=978302&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow88" style="display:inline;"><br /><div style="display:inline">Recent advances in scanning technologies, in particular devices that extract depth through active sensing, allow fast scanning of urban scenes. Such rapid acquisition incurs imperfections: large regions remain missing, significant variation in sampling ...</div></span>
          <span id="toHide88" style="display:none;"><br /><div style="display:inline"><p>Recent advances in scanning technologies, in particular devices that extract depth through active sensing, allow fast scanning of urban scenes. Such rapid acquisition incurs imperfections: large regions remain missing, significant variation in sampling density is common, and the data is often corrupted with noise and outliers. However, buildings often exhibit large scale repetitions and self-similarities. Detecting, extracting, and utilizing such large scale repetitions provide powerful means to consolidate the imperfect data. Our key observation is that the same geometry, when scanned multiple times over reoccurrences of instances, allow application of a simple yet effective non-local filtering. The multiplicity of the geometry is fused together and projected to a <i>base-geometry</i> defined by clustering corresponding surfaces. Denoising is applied by separating the process into off-plane and in-plane phases. We show that the consolidation of the reoccurrences provides robust denoising and allow reliable completion of missing parts. We present evaluation results of the algorithm on several LiDAR scans of buildings of varying complexity and styles.</p></div></span> <a id="expcoll88" href="JavaScript: expandcollapse('expcoll88',88)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778832&CFID=105749981&CFTOKEN=64099081">Ambient point clouds for view interpolation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100051843&CFID=105749981&CFTOKEN=64099081">Michael Goesele</a>, 
                        <a href="author_page.cfm?id=81464643252&CFID=105749981&CFTOKEN=64099081">Jens Ackermann</a>, 
                        <a href="author_page.cfm?id=81464656929&CFID=105749981&CFTOKEN=64099081">Simon Fuhrmann</a>, 
                        <a href="author_page.cfm?id=81466647708&CFID=105749981&CFTOKEN=64099081">Carsten Haubold</a>, 
                        <a href="author_page.cfm?id=81464670564&CFID=105749981&CFTOKEN=64099081">Ronny Klowsky</a>, 
                        <a href="author_page.cfm?id=81100541868&CFID=105749981&CFTOKEN=64099081">Drew Steedly</a>, 
                        <a href="author_page.cfm?id=81100122769&CFID=105749981&CFTOKEN=64099081">Richard Szeliski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 95</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778832" title="DOI">10.1145/1833349.1778832</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778832&ftid=799784&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778832&ftid=978303&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow89" style="display:inline;"><br /><div style="display:inline">View interpolation and image-based rendering algorithms often produce visual artifacts in regions where the 3D scene geometry is erroneous, uncertain, or incomplete. We introduce ambient point clouds constructed from colored pixels with uncertain depth, ...</div></span>
          <span id="toHide89" style="display:none;"><br /><div style="display:inline"><p>View interpolation and image-based rendering algorithms often produce visual artifacts in regions where the 3D scene geometry is erroneous, uncertain, or incomplete. We introduce ambient point clouds constructed from colored pixels with uncertain depth, which help reduce these artifacts while providing non-photorealistic background coloring and emphasizing reconstructed 3D geometry. Ambient point clouds are created by randomly sampling colored points along the viewing rays associated with uncertain pixels. Our real-time rendering system combines these with more traditional rigid 3D point clouds and colored surface meshes obtained using multiview stereo. Our resulting system can handle larger-range view transitions with fewer visible artifacts than previous approaches.</p></div></span> <a id="expcoll89" href="JavaScript: expandcollapse('expcoll89',89)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778833&CFID=105749981&CFTOKEN=64099081">Street slide: browsing street level imagery</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335493017&CFID=105749981&CFTOKEN=64099081">Johannes Kopf</a>, 
                        <a href="author_page.cfm?id=81100108014&CFID=105749981&CFTOKEN=64099081">Billy Chen</a>, 
                        <a href="author_page.cfm?id=81100122769&CFID=105749981&CFTOKEN=64099081">Richard Szeliski</a>, 
                        <a href="author_page.cfm?id=81406592138&CFID=105749981&CFTOKEN=64099081">Michael Cohen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 96</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778833" title="DOI">10.1145/1833349.1778833</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778833&ftid=799785&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778833&ftid=977293&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow90" style="display:inline;"><br /><div style="display:inline">Systems such as Google Street View and Bing Maps Streetside enable users to virtually visit cities by navigating between immersive 360&deg; panoramas, or bubbles. The discrete moves from bubble to bubble enabled in these systems do not provide ...</div></span>
          <span id="toHide90" style="display:none;"><br /><div style="display:inline"><p>Systems such as Google Street View and Bing Maps Streetside enable users to virtually visit cities by navigating between immersive 360&deg; panoramas, or <i>bubbles.</i> The discrete moves from bubble to bubble enabled in these systems do not provide a good visual sense of a larger aggregate such as a whole city block. Multi-perspective "strip" panoramas can provide a visual summary of a city street but lack the full realism of immersive panoramas.</p> <p>We present Street Slide, which combines the best aspects of the immersive nature of bubbles with the overview provided by multi-perspective strip panoramas. We demonstrate a seamless transition between bubbles and multi-perspective panoramas. We also present a dynamic construction of the panoramas which overcomes many of the limitations of previous systems. As the user slides sideways, the multi-perspective panorama is constructed and rendered dynamically to simulate either a perspective or <i>hyper-perspective</i> view. This provides a strong sense of parallax, which adds to the immersion. We call this form of sliding sideways while looking at a street fa&ccedil;ade a <i>street slide.</i> Finally we integrate annotations and a mini-map within the user interface to provide geographic information as well additional affordances for navigation. We demonstrate our Street Slide system on a series of intersecting streets in an urban setting. We report the results of a user study, which shows that visual searching is greatly enhanced with the Street Slide interface over existing systems from Google and Bing.</p></div></span> <a id="expcoll90" href="JavaScript: expandcollapse('expcoll90',90)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Appearance capture & image processing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Steve Marschner 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778834&CFID=105749981&CFTOKEN=64099081">Acquisition and analysis of bispectral bidirectional reflectance and reradiation distribution functions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365598554&CFID=105749981&CFTOKEN=64099081">Matthias B. Hullin</a>, 
                        <a href="author_page.cfm?id=81416596166&CFID=105749981&CFTOKEN=64099081">Johannes Hanika</a>, 
                        <a href="author_page.cfm?id=81466644827&CFID=105749981&CFTOKEN=64099081">Boris Ajdin</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105749981&CFTOKEN=64099081">Hans-Peter Seidel</a>, 
                        <a href="author_page.cfm?id=81100016395&CFID=105749981&CFTOKEN=64099081">Jan Kautz</a>, 
                        <a href="author_page.cfm?id=81100504611&CFID=105749981&CFTOKEN=64099081">Hendrik P. A. Lensch</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 97</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778834" title="DOI">10.1145/1833349.1778834</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778834&ftid=799786&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow92" style="display:inline;"><br /><div style="display:inline">In fluorescent materials, light from a certain band of incident wavelengths is reradiated at longer wavelengths, i.e., with a reduced per-photon energy. While fluorescent materials are common in everyday life, they have received little attention in computer ...</div></span>
          <span id="toHide92" style="display:none;"><br /><div style="display:inline"><p>In fluorescent materials, light from a certain band of incident wavelengths is reradiated at longer wavelengths, i.e., with a reduced per-photon energy. While fluorescent materials are common in everyday life, they have received little attention in computer graphics. Especially, no bidirectional reradiation measurements of fluorescent materials have been available so far. In this paper, we extend the well-known concept of the bidirectional reflectance distribution function (BRDF) to account for energy transfer between wavelengths, resulting in a <i>Bispectral Bidirectional Reflectance and Reradiation Distribution Function (bispectral BRRDF).</i> Using a bidirectional and bispectral measurement setup, we acquire reflectance and reradiation data of a variety of fluorescent materials, including vehicle paints, paper and fabric, and compare their renderings with RGB, RGBxRGB, and spectral BRDFs. Our acquisition is guided by a principal component analysis on complete bispectral data taken under a sparse set of angles. We show that in order to faithfully reproduce the full bispectral information for all other angles, only a very small number of wavelength pairs needs to be measured at a high angular resolution.</p></div></span> <a id="expcoll92" href="JavaScript: expandcollapse('expcoll92',92)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778835&CFID=105749981&CFTOKEN=64099081">Manifold bootstrapping for SVBRDF capture</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440597278&CFID=105749981&CFTOKEN=64099081">Yue Dong</a>, 
                        <a href="author_page.cfm?id=81100233349&CFID=105749981&CFTOKEN=64099081">Jiaping Wang</a>, 
                        <a href="author_page.cfm?id=81314492380&CFID=105749981&CFTOKEN=64099081">Xin Tong</a>, 
                        <a href="author_page.cfm?id=81100167784&CFID=105749981&CFTOKEN=64099081">John Snyder</a>, 
                        <a href="author_page.cfm?id=81466646152&CFID=105749981&CFTOKEN=64099081">Yanxiang Lan</a>, 
                        <a href="author_page.cfm?id=81100444620&CFID=105749981&CFTOKEN=64099081">Moshe Ben-Ezra</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=105749981&CFTOKEN=64099081">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 98</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778835" title="DOI">10.1145/1833349.1778835</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778835&ftid=799787&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778835&ftid=978020&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow93" style="display:inline;"><br /><div style="display:inline">Manifold bootstrapping is a new method for data-driven modeling of real-world, spatially-varying reflectance, based on the idea that reflectance over a given material sample forms a low-dimensional manifold. It provides a high-resolution result in both ...</div></span>
          <span id="toHide93" style="display:none;"><br /><div style="display:inline"><p>Manifold bootstrapping is a new method for data-driven modeling of real-world, spatially-varying reflectance, based on the idea that reflectance over a given material sample forms a low-dimensional manifold. It provides a high-resolution result in both the spatial and angular domains by decomposing reflectance measurement into two lower-dimensional phases. The first acquires <i>representatives</i> of high angular dimension but sampled sparsely over the surface, while the second acquires <i>keys</i> of low angular dimension but sampled densely over the surface.</p> <p>We develop a hand-held, high-speed BRDF capturing device for phase one measurements. A condenser-based optical setup collects a dense hemisphere of rays emanating from a single point on the target sample as it is manually scanned over it, yielding 10 BRDF point measurements per second. Lighting directions from 6 LEDs are applied at each measurement; these are amplified to a full 4D BRDF using the general (NDF-tabulated) microfacet model. The second phase captures <i>N</i>=20-200 images of the entire sample from a fixed view and lit by a varying area source. We show that the resulting <i>N</i>-dimensional keys capture much of the distance information in the original BRDF space, so that they effectively discriminate among representatives, though they lack sufficient angular detail to reconstruct the SVBRDF by themselves. At each surface position, a local linear combination of a small number of neighboring representatives is computed to match each key, yielding a high-resolution SVBRDF. A quick capture session (10-20 minutes) on simple devices yields results showing sharp and anisotropic specularity and rich spatial detail.</p></div></span> <a id="expcoll93" href="JavaScript: expandcollapse('expcoll93',93)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778836&CFID=105749981&CFTOKEN=64099081">A coaxial optical scanner for synchronous acquisition of 3D geometry and surface reflectance</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81416594360&CFID=105749981&CFTOKEN=64099081">Michael Holroyd</a>, 
                        <a href="author_page.cfm?id=81100574409&CFID=105749981&CFTOKEN=64099081">Jason Lawrence</a>, 
                        <a href="author_page.cfm?id=81100015971&CFID=105749981&CFTOKEN=64099081">Todd Zickler</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 99</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778836" title="DOI">10.1145/1833349.1778836</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778836&ftid=799788&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778836&ftid=979476&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow94" style="display:inline;"><br /><div style="display:inline">We present a novel optical setup and processing pipeline for measuring the 3D geometry and spatially-varying surface reflectance of physical objects. Central to our design is a digital camera and a high frequency spatially-modulated light source aligned ...</div></span>
          <span id="toHide94" style="display:none;"><br /><div style="display:inline"><p>We present a novel optical setup and processing pipeline for measuring the 3D geometry and spatially-varying surface reflectance of physical objects. Central to our design is a digital camera and a high frequency spatially-modulated light source aligned to share a common focal point and optical axis. Pairs of such devices allow capturing a sequence of images from which precise measurements of geometry <i>and</i> reflectance can be recovered. Our approach is enabled by two technical contributions: a new active multiview stereo algorithm and an analysis of light descattering that has important implications for image-based reflectometry. We show that the geometry measured by our scanner is accurate to within 50 microns at a resolution of roughly 200 microns and that the reflectance agrees with reference data to within 5.5%. Additionally, we present an image relighting application and show renderings that agree very well with reference images at light and view positions far from those that were initially measured.</p></div></span> <a id="expcoll94" href="JavaScript: expandcollapse('expcoll94',94)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778837&CFID=105749981&CFTOKEN=64099081">Smoothed local histogram filters</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100215003&CFID=105749981&CFTOKEN=64099081">Michael Kass</a>, 
                        <a href="author_page.cfm?id=81335497710&CFID=105749981&CFTOKEN=64099081">Justin Solomon</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 100</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778837" title="DOI">10.1145/1833349.1778837</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778837&ftid=799789&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow95" style="display:inline;"><br /><div style="display:inline">Local image histograms contain a great deal of information useful for applications in computer graphics, computer vision and computational photography. Making use of that information has been challenging because of the expense of computing histogram ...</div></span>
          <span id="toHide95" style="display:none;"><br /><div style="display:inline"><p>Local image histograms contain a great deal of information useful for applications in computer graphics, computer vision and computational photography. Making use of that information has been challenging because of the expense of computing histogram properties over large neighborhoods. Efficient algorithms exist for some specific computations like the bilateral filter, but not others. Here, we present an efficient and practical method for computing accurate derivatives and integrals of locally-weighted histograms over large neighborhoods. The method allows us to compute the location, height, width and integral of all local histogram modes at interactive rates. Among other things, it enables the first constant-time isotropic median filter, robust isotropic image morphology operators, an efficient "dominant mode" filter and a non-iterative alternative to the mean shift. In addition, we present a method to combat the over-sharpening that is typical of histogram-based edge-preserving smoothing. This post-processing step should make histogram-based filters not only fast and efficient, but also suitable for a variety of new applications.</p></div></span> <a id="expcoll95" href="JavaScript: expandcollapse('expcoll95',95)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Understanding shape</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Misha Kazhdan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778838&CFID=105749981&CFTOKEN=64099081">Discrete scale axis representations for 3D geometry</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81331499858&CFID=105749981&CFTOKEN=64099081">Balint Miklos</a>, 
                        <a href="author_page.cfm?id=81100569816&CFID=105749981&CFTOKEN=64099081">Joachim Giesen</a>, 
                        <a href="author_page.cfm?id=81100582775&CFID=105749981&CFTOKEN=64099081">Mark Pauly</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 101</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778838" title="DOI">10.1145/1833349.1778838</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778838&ftid=799790&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778838&ftid=978304&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow97" style="display:inline;"><br /><div style="display:inline">This paper addresses the fundamental problem of computing stable medial representations of 3D shapes. We propose a spatially adaptive classification of geometric features that yields a robust algorithm for generating medial representations at ...</div></span>
          <span id="toHide97" style="display:none;"><br /><div style="display:inline"><p>This paper addresses the fundamental problem of computing stable medial representations of 3D shapes. We propose a <i>spatially adaptive</i> classification of geometric features that yields a robust algorithm for generating medial representations at different levels of abstraction. The recently introduced continuous scale axis transform serves as the mathematical foundation of our algorithm. We show how geometric and topological properties of the continuous setting carry over to discrete shape representations. Our method combines scaling operations of medial balls for geometric simplification with filtrations of the medial axis and provably good conversion steps to and from union of balls, to enable efficient processing of a wide variety shape representations including polygon meshes, 3D images, implicit surfaces, and point clouds. We demonstrate the robustness and versatility of our algorithm with an extensive validation on hundreds of shapes including complex geometries consisting of millions of triangles.</p></div></span> <a id="expcoll97" href="JavaScript: expandcollapse('expcoll97',97)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778839&CFID=105749981&CFTOKEN=64099081">Learning 3D mesh segmentation and labeling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335492224&CFID=105749981&CFTOKEN=64099081">Evangelos Kalogerakis</a>, 
                        <a href="author_page.cfm?id=81441592237&CFID=105749981&CFTOKEN=64099081">Aaron Hertzmann</a>, 
                        <a href="author_page.cfm?id=81335497253&CFID=105749981&CFTOKEN=64099081">Karan Singh</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 102</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778839" title="DOI">10.1145/1833349.1778839</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778839&ftid=799791&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778839&ftid=978305&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow98" style="display:inline;"><br /><div style="display:inline">This paper presents a data-driven approach to simultaneous segmentation and labeling of parts in 3D meshes. An objective function is formulated as a Conditional Random Field model, with terms assessing the consistency of faces with labels, and terms ...</div></span>
          <span id="toHide98" style="display:none;"><br /><div style="display:inline"><p>This paper presents a data-driven approach to simultaneous segmentation and labeling of parts in 3D meshes. An objective function is formulated as a Conditional Random Field model, with terms assessing the consistency of faces with labels, and terms between labels of neighboring faces. The objective function is learned from a collection of labeled training meshes. The algorithm uses hundreds of geometric and contextual label features and learns different types of segmentations for different tasks, without requiring manual parameter tuning. Our algorithm achieves a significant improvement in results over the state-of-the-art when evaluated on the Princeton Segmentation Benchmark, often producing segmentations and labelings comparable to those produced by humans.</p></div></span> <a id="expcoll98" href="JavaScript: expandcollapse('expcoll98',98)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778840&CFID=105749981&CFTOKEN=64099081">Symmetry factored embedding and distance</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100456149&CFID=105749981&CFTOKEN=64099081">Yaron Lipman</a>, 
                        <a href="author_page.cfm?id=81440600812&CFID=105749981&CFTOKEN=64099081">Xiaobai Chen</a>, 
                        <a href="author_page.cfm?id=81100149669&CFID=105749981&CFTOKEN=64099081">Ingrid Daubechies</a>, 
                        <a href="author_page.cfm?id=81100182132&CFID=105749981&CFTOKEN=64099081">Thomas Funkhouser</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 103</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778840" title="DOI">10.1145/1833349.1778840</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778840&ftid=799792&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778840&ftid=977294&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow99" style="display:inline;"><br /><div style="display:inline">We introduce the Symmetry Factored Embedding (SFE) and the Symmetry Factored Distance (SFD) as new tools to analyze and represent symmetries in a point set. The SFE provides new coordinates in which symmetry is "factored out," and the SFD is the Euclidean ...</div></span>
          <span id="toHide99" style="display:none;"><br /><div style="display:inline"><p>We introduce the Symmetry Factored Embedding (SFE) and the Symmetry Factored Distance (SFD) as new tools to analyze and represent symmetries in a point set. The SFE provides new coordinates in which symmetry is "factored out," and the SFD is the Euclidean distance in that space. These constructions characterize the space of symmetric correspondences between points -- i.e., orbits. A key observation is that a set of points in the same orbit appears as a clique in a correspondence graph induced by pairwise similarities. As a result, the problem of finding approximate and partial symmetries in a point set reduces to the problem of measuring connectedness in the correspondence graph, a well-studied problem for which spectral methods provide a robust solution. We provide methods for computing the SFE and SFD for extrinsic global symmetries and then extend them to consider partial extrinsic and intrinsic cases. During experiments with difficult examples, we find that the proposed methods can characterize symmetries in inputs with noise, missing data, non-rigid deformations, and complex symmetries, without a priori knowledge of the symmetry group. As such, we believe that it provides a useful tool for automatic shape analysis in applications such as segmentation and stationary point detection.</p></div></span> <a id="expcoll99" href="JavaScript: expandcollapse('expcoll99',99)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778841&CFID=105749981&CFTOKEN=64099081">A connection between partial symmetry and inverse procedural modeling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503386&CFID=105749981&CFTOKEN=64099081">Martin Bokeloh</a>, 
                        <a href="author_page.cfm?id=81100072588&CFID=105749981&CFTOKEN=64099081">Michael Wand</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105749981&CFTOKEN=64099081">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 104</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778841" title="DOI">10.1145/1833349.1778841</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778841&ftid=799793&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778841&ftid=977295&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow100" style="display:inline;"><br /><div style="display:inline">In this paper, we address the problem of inverse procedural modeling: Given a piece of exemplar 3D geometry, we would like to find a set of rules that describe objects that are similar to the exemplar. We consider local similarity, i.e., each ...</div></span>
          <span id="toHide100" style="display:none;"><br /><div style="display:inline"><p>In this paper, we address the problem of <i>inverse</i> procedural modeling: Given a piece of exemplar 3D geometry, we would like to find a set of rules that describe objects that are similar to the exemplar. We consider local similarity, i.e., each local neighborhood of the newly created object must match some local neighborhood of the exemplar. We show that we can find explicit shape modification rules that guarantee strict local similarity by looking at the structure of the partial symmetries of the object. By cutting the object into pieces along curves within symmetric areas, we can build shape operations that maintain local similarity by construction. We systematically collect such editing operations and analyze their dependency to build a shape grammar. We discuss how to extract general rewriting systems, context free hierarchical rules, and grid-based rules. All of this information is derived directly from the model, without user interaction. The extracted rules are then used to implement tools for semi-automatic shape modeling by example, which are demonstrated on a number of different example data sets. Overall, our paper provides a concise theoretical and practical framework for inverse procedural modeling of 3D objects.</p></div></span> <a id="expcoll100" href="JavaScript: expandcollapse('expcoll100',100)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Cloth animation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Mario Botsch 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778842&CFID=105749981&CFTOKEN=64099081">Efficient yarn-based cloth with adaptive contact linearization</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81421597937&CFID=105749981&CFTOKEN=64099081">Jonathan M. Kaldor</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=105749981&CFTOKEN=64099081">Doug L. James</a>, 
                        <a href="author_page.cfm?id=81100238316&CFID=105749981&CFTOKEN=64099081">Steve Marschner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 105</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778842" title="DOI">10.1145/1833349.1778842</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778842&ftid=799794&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778842&ftid=979477&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow102" style="display:inline;"><br /><div style="display:inline">Yarn-based cloth simulation can improve visual quality but at high computational costs due to the reliance on numerous persistent yarn-yarn contacts to generate material behavior. Finding so many contacts in densely interlinked geometry is a pathological ...</div></span>
          <span id="toHide102" style="display:none;"><br /><div style="display:inline"><p>Yarn-based cloth simulation can improve visual quality but at high computational costs due to the reliance on numerous persistent yarn-yarn contacts to generate material behavior. Finding so many contacts in densely interlinked geometry is a pathological case for traditional collision detection, and the sheer number of contact interactions makes contact processing the simulation bottleneck. In this paper, we propose a method for approximating penalty-based contact forces in yarn-yarn collisions by computing the exact contact response at one time step, then using a rotated linear force model to approximate forces in nearby deformed configurations. Because contacts internal to the cloth exhibit good temporal coherence, sufficient accuracy can be obtained with infrequent updates to the approximation, which are done adaptively in space and time. Furthermore, by tracking contact models we reduce the time to detect new contacts. The end result is a 7- to 9-fold speedup in contact processing and a 4- to 5-fold overall speedup, enabling simulation of character-scale garments.</p></div></span> <a id="expcoll102" href="JavaScript: expandcollapse('expcoll102',102)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778843&CFID=105749981&CFTOKEN=64099081">Stable spaces for real-time clothing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81309506780&CFID=105749981&CFTOKEN=64099081">Edilson de Aguiar</a>, 
                        <a href="author_page.cfm?id=81100541669&CFID=105749981&CFTOKEN=64099081">Leonid Sigal</a>, 
                        <a href="author_page.cfm?id=81100606901&CFID=105749981&CFTOKEN=64099081">Adrien Treuille</a>, 
                        <a href="author_page.cfm?id=81100049661&CFID=105749981&CFTOKEN=64099081">Jessica K. Hodgins</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 106</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778843" title="DOI">10.1145/1833349.1778843</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778843&ftid=799795&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow103" style="display:inline;"><br /><div style="display:inline">We present a technique for learning clothing models that enables the simultaneous animation of thousands of detailed garments in real-time. This surprisingly simple conditional model learns and preserves the key dynamic properties of a cloth motion along ...</div></span>
          <span id="toHide103" style="display:none;"><br /><div style="display:inline"><p>We present a technique for learning clothing models that enables the simultaneous animation of thousands of detailed garments in real-time. This surprisingly simple conditional model learns and preserves the key dynamic properties of a cloth motion along with folding details. Our approach requires no <i>a priori</i> physical model, but rather treats training data as a "black box." We show that the models learned with our method are stable over large time-steps and can approximately resolve cloth-body collisions. We also show that within a class of methods, no simpler model covers the full range of cloth dynamics captured by ours. Our method bridges the current gap between skinning and physical simulation, combining benefits of speed from the former with dynamic effects from the latter. We demonstrate our approach on a variety of apparel worn by male and female human characters performing a varied set of motions typically used in video games (<i>e.g.</i>, walking, running, jumping, <i>etc.</i>).</p></div></span> <a id="expcoll103" href="JavaScript: expandcollapse('expcoll103',103)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778844&CFID=105749981&CFTOKEN=64099081">Example-based wrinkle synthesis for clothing animation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466648783&CFID=105749981&CFTOKEN=64099081">Huamin Wang</a>, 
                        <a href="author_page.cfm?id=81466644726&CFID=105749981&CFTOKEN=64099081">Florian Hecht</a>, 
                        <a href="author_page.cfm?id=81100019585&CFID=105749981&CFTOKEN=64099081">Ravi Ramamoorthi</a>, 
                        <a href="author_page.cfm?id=81100311781&CFID=105749981&CFTOKEN=64099081">James O'Brien</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 107</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778844" title="DOI">10.1145/1833349.1778844</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778844&ftid=799796&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778844&ftid=978021&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow104" style="display:inline;"><br /><div style="display:inline">This paper describes a method for animating the appearance of clothing, such as pants or a shirt, that fits closely to a figure's body. Compared to flowing cloth, such as loose dresses or capes, these types of garments involve nearly continuous collision ...</div></span>
          <span id="toHide104" style="display:none;"><br /><div style="display:inline"><p>This paper describes a method for animating the appearance of clothing, such as pants or a shirt, that fits closely to a figure's body. Compared to flowing cloth, such as loose dresses or capes, these types of garments involve nearly continuous collision contact and small wrinkles, that can be troublesome for traditional cloth simulation methods. Based on the observation that the wrinkles in close-fitting clothing behave in a predominantly kinematic fashion, we have developed an example-based wrinkle synthesis technique. Our method drives wrinkle generation from the pose of the figure's kinematic skeleton. This approach allows high quality clothing wrinkles to be combined with a coarse cloth simulation that computes the global and dynamic aspects of the clothing motion. While the combined results do not exactly match a high-resolution reference simulation, they do capture many of the characteristic fine-scale features and wrinkles. Further, the combined system runs at interactive rates, making it suitable for applications where high-resolution offline simulations would not be a viable option. The wrinkle synthesis method uses a precomputed database built by simulating the high-resolution clothing as the articulated figure is moved over a range of poses. In principle, the space of poses is exponential in the total number of degrees of freedom; however clothing wrinkles are primarily affected by the nearest joints, allowing each joint to be processed independently. During synthesis, mesh interpolation is used to consider the influence of multiple joints, and combined with a coarse simulation to produce the final results at interactive rates.</p></div></span> <a id="expcoll104" href="JavaScript: expandcollapse('expcoll104',104)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778845&CFID=105749981&CFTOKEN=64099081">A deformation transformer for real-time cloth animation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314493746&CFID=105749981&CFTOKEN=64099081">Wei-Wen Feng</a>, 
                        <a href="author_page.cfm?id=81100472713&CFID=105749981&CFTOKEN=64099081">Yizhou Yu</a>, 
                        <a href="author_page.cfm?id=81365593919&CFID=105749981&CFTOKEN=64099081">Byung-Uck Kim</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 108</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778845" title="DOI">10.1145/1833349.1778845</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778845&ftid=799797&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778845&ftid=979478&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow105" style="display:inline;"><br /><div style="display:inline">Achieving interactive performance in cloth animation has significant implications in computer games and other interactive graphics applications. Although much progress has been made, it is still much desired to have real-time high-quality results that ...</div></span>
          <span id="toHide105" style="display:none;"><br /><div style="display:inline"><p>Achieving interactive performance in cloth animation has significant implications in computer games and other interactive graphics applications. Although much progress has been made, it is still much desired to have real-time high-quality results that well preserve dynamic folds and wrinkles. In this paper, we introduce a hybrid method for real-time cloth animation. It relies on data-driven models to capture the relationship between cloth deformations at two resolutions. Such data-driven models are responsible for transforming low-quality simulated deformations at the low resolution into high-resolution cloth deformations with dynamically introduced fine details. Our data-driven transformation is trained using rotation invariant quantities extracted from the cloth models, and is independent of the simulation technique chosen for the lower resolution model. We have also developed a fast collision detection and handling scheme based on dynamically transformed bounding volumes. All the components in our algorithm can be efficiently implemented on programmable graphics hardware to achieve an overall real-time performance on high-resolution cloth models.</p></div></span> <a id="expcoll105" href="JavaScript: expandcollapse('expcoll105',105)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>3D modeling</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Peter Wonka 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778846&CFID=105749981&CFTOKEN=64099081">3D modeling with silhouettes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335496868&CFID=105749981&CFTOKEN=64099081">Alec Rivers</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=105749981&CFTOKEN=64099081">Fr&#233;do Durand</a>, 
                        <a href="author_page.cfm?id=81100444444&CFID=105749981&CFTOKEN=64099081">Takeo Igarashi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 109</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778846" title="DOI">10.1145/1833349.1778846</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778846&ftid=799798&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778846&ftid=979479&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow107" style="display:inline;"><br /><div style="display:inline">We present a new sketch-based modeling approach in which models are interactively designed by drawing their 2D silhouettes from different views. The core idea of our paper is to limit the input to 2D silhouettes, removing the need to explicitly create ...</div></span>
          <span id="toHide107" style="display:none;"><br /><div style="display:inline"><p>We present a new sketch-based modeling approach in which models are interactively designed by drawing their 2D silhouettes from different views. The core idea of our paper is to limit the input to 2D silhouettes, removing the need to explicitly create or position 3D elements. Arbitrarily complex models can be constructed by assembling them out of parts defined by their silhouettes, which can be combined using CSG operations. We introduce a new simplified algorithm to compute CSG solids that leverages special properties of silhouette cylinders to convert the 3D CSG problem into one that can be handled entirely with 2D operations, making implementation simpler and more robust. We evaluate our approach by modeling a random sampling of man-made objects taken from the words in WordNet, and show that all of the tested man-made objects can be modeled quickly and easily using our approach.</p></div></span> <a id="expcoll107" href="JavaScript: expandcollapse('expcoll107',107)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778847&CFID=105749981&CFTOKEN=64099081">Apparent layer operations for the manipulation of deformable objects</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100444444&CFID=105749981&CFTOKEN=64099081">Takeo Igarashi</a>, 
                        <a href="author_page.cfm?id=81100209891&CFID=105749981&CFTOKEN=64099081">Jun Mitani</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 110</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778847" title="DOI">10.1145/1833349.1778847</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778847&ftid=799799&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778847&ftid=978022&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow108" style="display:inline;"><br /><div style="display:inline">We introduce layer operations for single-view 3D deformable object manipulation, in which the user can control the depth order of layered 3D objects resting on a flat ground with simple clicks and drags, as in 2D drawing systems. We present two interaction ...</div></span>
          <span id="toHide108" style="display:none;"><br /><div style="display:inline"><p>We introduce layer operations for single-view 3D deformable object manipulation, in which the user can control the depth order of layered 3D objects resting on a flat ground with simple clicks and drags, as in 2D drawing systems. We present two interaction techniques based on this idea and describe their implementation. The first technique is explicit layer swap. The user clicks the target layer, and the system swaps the layer with the one directly underneath it. The second technique is layer-aware dragging. As the user drags the object, the system adjusts its depth automatically to pass over or under a colliding object in the screen space, according to user control. Although the user interface is 2.5D, all scene representations are true 3D, and thus the system naturally supports local layering, self-occlusions, and folds. Internally, the system dynamically computes the apparent layer structure in the current configuration and makes appropriate depth adjustments to obtain the desired results. We demonstrate the effectiveness of this approach in cloth and rope manipulation systems.</p></div></span> <a id="expcoll108" href="JavaScript: expandcollapse('expcoll108',108)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778848&CFID=105749981&CFTOKEN=64099081">Popup: automatic paper architectures from 3D models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466646757&CFID=105749981&CFTOKEN=64099081">Xian-Ying Li</a>, 
                        <a href="author_page.cfm?id=81466644065&CFID=105749981&CFTOKEN=64099081">Chao-Hui Shen</a>, 
                        <a href="author_page.cfm?id=81466640514&CFID=105749981&CFTOKEN=64099081">Shi-Sheng Huang</a>, 
                        <a href="author_page.cfm?id=81100098726&CFID=105749981&CFTOKEN=64099081">Tao Ju</a>, 
                        <a href="author_page.cfm?id=81100254073&CFID=105749981&CFTOKEN=64099081">Shi-Min Hu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 111</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778848" title="DOI">10.1145/1833349.1778848</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778848&ftid=799800&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778848&ftid=978023&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow109" style="display:inline;"><br /><div style="display:inline">Paper architectures are 3D paper buildings created by folding and cutting. The creation process of paper architecture is often labor-intensive and highly skill-demanding, even with the aid of existing computer-aided design tools. We propose an automatic ...</div></span>
          <span id="toHide109" style="display:none;"><br /><div style="display:inline"><p>Paper architectures are 3D paper buildings created by folding and cutting. The creation process of paper architecture is often labor-intensive and highly skill-demanding, even with the aid of existing computer-aided design tools. We propose an automatic algorithm for generating paper architectures given a user-specified 3D model. The algorithm is grounded on geometric formulation of planar layout for paper architectures that can be popped-up in a rigid and stable manner, and sufficient conditions for a 3D surface to be popped-up from such a planar layout. Based on these conditions, our algorithm computes a class of paper architectures containing two sets of parallel patches that approximate the input geometry while guaranteed to be physically realizable. The method is demonstrated on a number of architectural examples, and physically engineered results are presented.</p></div></span> <a id="expcoll109" href="JavaScript: expandcollapse('expcoll109',109)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Perceptual rendering methods</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Adam Finkelstein 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778849&CFID=105749981&CFTOKEN=64099081">Effects of global illumination approximations on material appearance</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100294023&CFID=105749981&CFTOKEN=64099081">Jaroslav K&#345;iv&#225;nek</a>, 
                        <a href="author_page.cfm?id=81100459651&CFID=105749981&CFTOKEN=64099081">James A. Ferwerda</a>, 
                        <a href="author_page.cfm?id=81100081277&CFID=105749981&CFTOKEN=64099081">Kavita Bala</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 112</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778849" title="DOI">10.1145/1833349.1778849</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778849&ftid=799801&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778849&ftid=979480&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow111" style="display:inline;"><br /><div style="display:inline">Rendering applications in design, manufacturing, ecommerce and other fields are used to simulate the appearance of objects and scenes. Fidelity with respect to appearance is often critical, and calculating global illumination (GI) is an important contributor ...</div></span>
          <span id="toHide111" style="display:none;"><br /><div style="display:inline"><p>Rendering applications in design, manufacturing, ecommerce and other fields are used to simulate the appearance of objects and scenes. Fidelity with respect to appearance is often critical, and calculating global illumination (GI) is an important contributor to image fidelity; but it is expensive to compute. GI approximation methods, such as virtual point light (VPL) algorithms, are efficient, but they can induce image artifacts and distortions of object appearance. In this paper we systematically study the perceptual effects on image quality and material appearance of global illumination approximations made by VPL algorithms. In a series of psychophysical experiments we investigate the relationships between rendering parameters, object properties and image fidelity in a VPL renderer. Using the results of these experiments we analyze how VPL counts and energy clamping levels affect the visibility of image artifacts and distortions of material appearance, and show how object geometry and material properties modulate these effects. We find the ranges of these parameters that produce VPL renderings that are visually equivalent to reference renderings. Further we identify classes of shapes and materials that cannot be accurately rendered using VPL methods with limited resources. Using these findings we propose simple heuristics to guide visually equivalent and efficient rendering, and present a method for correcting energy losses in VPL renderings. This work provides a strong perceptual foundation for a popular and efficient class of GI algorithms.</p></div></span> <a id="expcoll111" href="JavaScript: expandcollapse('expcoll111',111)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778850&CFID=105749981&CFTOKEN=64099081">Apparent display resolution enhancement for moving images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466647837&CFID=105749981&CFTOKEN=64099081">Piotr Didyk</a>, 
                        <a href="author_page.cfm?id=81310501633&CFID=105749981&CFTOKEN=64099081">Elmar Eisemann</a>, 
                        <a href="author_page.cfm?id=81351607404&CFID=105749981&CFTOKEN=64099081">Tobias Ritschel</a>, 
                        <a href="author_page.cfm?id=81332517742&CFID=105749981&CFTOKEN=64099081">Karol Myszkowski</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105749981&CFTOKEN=64099081">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 113</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778850" title="DOI">10.1145/1833349.1778850</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778850&ftid=799802&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778850&ftid=979481&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow112" style="display:inline;"><br /><div style="display:inline">Limited spatial resolution of current displays makes the depiction of very fine spatial details difficult. This work proposes a novel method applied to moving images that takes into account the human visual system and leads to an improved perception ...</div></span>
          <span id="toHide112" style="display:none;"><br /><div style="display:inline"><p>Limited spatial resolution of current displays makes the depiction of very fine spatial details difficult. This work proposes a novel method applied to moving images that takes into account the human visual system and leads to an improved perception of such details. To this end, we display images rapidly varying over time along a given trajectory on a high refresh rate display. Due to the retinal integration time the information is fused and yields apparent super-resolution pixels on a conventional-resolution display. We discuss how to find optimal temporal pixel variations based on linear eye-movement and image content and extend our solution to arbitrary trajectories. This step involves an efficient method to predict and successfully treat potentially visible flickering. Finally, we evaluate the resolution enhancement in a perceptual study that shows that significant improvements can be achieved both for computer generated images and photographs.</p></div></span> <a id="expcoll112" href="JavaScript: expandcollapse('expcoll112',112)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Fluids II</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Michael Kass 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778851&CFID=105749981&CFTOKEN=64099081">A novel algorithm for incompressible flow using only a coarse grid projection</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365597634&CFID=105749981&CFTOKEN=64099081">Michael Lentine</a>, 
                        <a href="author_page.cfm?id=81466642757&CFID=105749981&CFTOKEN=64099081">Wen Zheng</a>, 
                        <a href="author_page.cfm?id=81100612327&CFID=105749981&CFTOKEN=64099081">Ronald Fedkiw</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 114</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778851" title="DOI">10.1145/1833349.1778851</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778851&ftid=798637&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778851&ftid=978024&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow114" style="display:inline;"><br /><div style="display:inline">Large scale fluid simulation can be difficult using existing techniques due to the high computational cost of using large grids. We present a novel technique for simulating detailed fluids quickly. Our technique coarsens the Eulerian fluid grid during ...</div></span>
          <span id="toHide114" style="display:none;"><br /><div style="display:inline"><p>Large scale fluid simulation can be difficult using existing techniques due to the high computational cost of using large grids. We present a novel technique for simulating detailed fluids quickly. Our technique coarsens the Eulerian fluid grid during the pressure solve, allowing for a fast implicit update but still maintaining the resolution obtained with a large grid. This allows our simulations to run at a fraction of the cost of existing techniques while still providing the fine scale structure and details obtained with a full projection. Our algorithm scales well to very large grids and large numbers of processors, allowing for high fidelity simulations that would otherwise be intractable.</p></div></span> <a id="expcoll114" href="JavaScript: expandcollapse('expcoll114',114)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778852&CFID=105749981&CFTOKEN=64099081">Filament-based smoke with vortex shedding and variational reconnection</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81444594092&CFID=105749981&CFTOKEN=64099081">Steffen Wei&#223;mann</a>, 
                        <a href="author_page.cfm?id=81365591193&CFID=105749981&CFTOKEN=64099081">Ulrich Pinkall</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 115</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778852" title="DOI">10.1145/1833349.1778852</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778852&ftid=799803&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778852&ftid=979482&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow115" style="display:inline;"><br /><div style="display:inline">Simulating fluids based on vortex filaments is highly attractive for the creation of special effects because it gives artists full control over the simulation using familiar tools like curve editors or the scripted generation of new vortex filaments ...</div></span>
          <span id="toHide115" style="display:none;"><br /><div style="display:inline"><p>Simulating fluids based on vortex filaments is highly attractive for the creation of special effects because it gives artists full control over the simulation using familiar tools like curve editors or the scripted generation of new vortex filaments over time. Because filaments offer a very compact description of fluid flow, real time applications like games or virtual reality are also possible.</p> <p>We present a complete model that includes moving obstacles with vortex shedding, all represented as filaments. Due to variational reconnection the long-time behavior of our method is excellent: Energy and momentum stay constant within reasonable bounds and computational complexity does not increase over time.</p></div></span> <a id="expcoll115" href="JavaScript: expandcollapse('expcoll115',115)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778853&CFID=105749981&CFTOKEN=64099081">Discrete viscous threads</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81320488452&CFID=105749981&CFTOKEN=64099081">Mikl&#243;s Bergou</a>, 
                        <a href="author_page.cfm?id=81314493420&CFID=105749981&CFTOKEN=64099081">Basile Audoly</a>, 
                        <a href="author_page.cfm?id=81365594364&CFID=105749981&CFTOKEN=64099081">Etienne Vouga</a>, 
                        <a href="author_page.cfm?id=81320496298&CFID=105749981&CFTOKEN=64099081">Max Wardetzky</a>, 
                        <a href="author_page.cfm?id=81320489894&CFID=105749981&CFTOKEN=64099081">Eitan Grinspun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 116</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778853" title="DOI">10.1145/1833349.1778853</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778853&ftid=799804&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778853&ftid=978025&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow116" style="display:inline;"><br /><div style="display:inline">We present a continuum-based discrete model for thin threads of viscous fluid by drawing upon the Rayleigh analogy to elastic rods, demonstrating canonical coiling, folding, and breakup in dynamic simulations. Our derivation emphasizes space-time symmetry, ...</div></span>
          <span id="toHide116" style="display:none;"><br /><div style="display:inline"><p>We present a continuum-based discrete model for thin threads of viscous fluid by drawing upon the Rayleigh analogy to elastic rods, demonstrating canonical coiling, folding, and breakup in dynamic simulations. Our derivation emphasizes space-time symmetry, which sheds light on the role of time-parallel transport in eliminating---without approximation---all but an <i>O</i>(<i>n</i>) band of entries of the physical system's energy Hessian. The result is a fast, unified, implicit treatment of viscous threads and elastic rods that closely reproduces a variety of fascinating physical phenomena, including hysteretic transitions between coiling regimes, competition between surface tension and gravity, and the first numerical fluid-mechanical sewing machine. The novel implicit treatment also yields an order of magnitude speedup in our elastic rod dynamics.</p></div></span> <a id="expcoll116" href="JavaScript: expandcollapse('expcoll116',116)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Meshing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Mark Meyer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778854&CFID=105749981&CFTOKEN=64099081">Feature-aligned T-meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81330495246&CFID=105749981&CFTOKEN=64099081">Ashish Myles</a>, 
                        <a href="author_page.cfm?id=81416593724&CFID=105749981&CFTOKEN=64099081">Nico Pietroni</a>, 
                        <a href="author_page.cfm?id=81414606980&CFID=105749981&CFTOKEN=64099081">Denis Kovacs</a>, 
                        <a href="author_page.cfm?id=81100328351&CFID=105749981&CFTOKEN=64099081">Denis Zorin</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 117</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778854" title="DOI">10.1145/1833349.1778854</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778854&ftid=799805&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778854&ftid=979483&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow118" style="display:inline;"><br /><div style="display:inline">High-order and regularly sampled surface representations are more efficient and compact than general meshes and considerably simplify many geometric modeling and processing algorithms. A number of recent algorithms for conversion of arbitrary meshes ...</div></span>
          <span id="toHide118" style="display:none;"><br /><div style="display:inline"><p>High-order and regularly sampled surface representations are more efficient and compact than general meshes and considerably simplify many geometric modeling and processing algorithms. A number of recent algorithms for conversion of arbitrary meshes to regularly sampled form (typically quadrangulation) aim to align the resulting mesh with feature lines of the geometry. While resulting in a substantial improvement in mesh quality, feature alignment makes it difficult to obtain coarse regular patch partitions of the mesh.</p> <p>In this paper, we propose an approach to constructing patch layouts consisting of small numbers of quadrilateral patches while maintaining good feature alignment. To achieve this, we use quadrilateral T-meshes, for which the intersection of two faces may not be the whole edge or vertex, but a part of an edge. T-meshes offer more flexibility for reduction of the number of patches and vertices in a base domain while maintaining alignment with geometric features. At the same time, T-meshes retain many desirable features of quadrangulations, allowing construction of high-order representations, easy packing of regularly sampled geometric data into textures, as well as supporting different types of discretizations for physical simulation.</p></div></span> <a id="expcoll118" href="JavaScript: expandcollapse('expcoll118',118)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778855&CFID=105749981&CFTOKEN=64099081">A wave-based anisotropic quadrangulation method</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81385599574&CFID=105749981&CFTOKEN=64099081">Muyang Zhang</a>, 
                        <a href="author_page.cfm?id=81385597791&CFID=105749981&CFTOKEN=64099081">Jin Huang</a>, 
                        <a href="author_page.cfm?id=81351599319&CFID=105749981&CFTOKEN=64099081">Xinguo Liu</a>, 
                        <a href="author_page.cfm?id=81100451028&CFID=105749981&CFTOKEN=64099081">Hujun Bao</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 118</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778855" title="DOI">10.1145/1833349.1778855</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778855&ftid=799806&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778855&ftid=979484&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow119" style="display:inline;"><br /><div style="display:inline">This paper proposes a new method for remeshing a surface into anisotropically sized quads. The basic idea is to construct a special standing wave on the surface to generate the global quadrilateral structure. This wave based quadrangulation method is ...</div></span>
          <span id="toHide119" style="display:none;"><br /><div style="display:inline"><p>This paper proposes a new method for remeshing a surface into anisotropically sized quads. The basic idea is to construct a special standing wave on the surface to generate the global quadrilateral structure. This wave based quadrangulation method is capable of controlling the quad size in two directions and precisely aligning the quads with feature lines. Similar to the previous methods, we augment the input surface with a vector field to guide the quad orientation. The anisotropic size control is achieved by using two size fields on the surface. In order to reduce singularity points, the size fields are optimized by a new curl minimization method. The experimental results show that the proposed method can successfully handle various quadrangulation requirements and complex shapes, which is difficult for the existing state-of-the-art methods.</p></div></span> <a id="expcoll119" href="JavaScript: expandcollapse('expcoll119',119)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778856&CFID=105749981&CFTOKEN=64099081"><i>L</i><sub><i>p</i></sub> Centroidal Voronoi Tessellation and its applications</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100154829&CFID=105749981&CFTOKEN=64099081">Bruno L&#233;vy</a>, 
                        <a href="author_page.cfm?id=81410594060&CFID=105749981&CFTOKEN=64099081">Yang Liu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 119</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778856" title="DOI">10.1145/1833349.1778856</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778856&ftid=799807&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778856&ftid=978026&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow120" style="display:inline;"><br /><div style="display:inline">This paper introduces Lp-Centroidal Voronoi Tessellation (Lp-CVT), a generalization of CVT that minimizes a higher-order moment of the coordinates on the Voronoi cells. This generalization allows for ...</div></span>
          <span id="toHide120" style="display:none;"><br /><div style="display:inline"><p>This paper introduces <i>L</i><sub><i>p</i></sub>-Centroidal Voronoi Tessellation (<i>L</i><sub><i>p</i></sub>-CVT), a generalization of CVT that minimizes a higher-order moment of the coordinates on the Voronoi cells. This generalization allows for aligning the axes of the Voronoi cells with a predefined background tensor field (anisotropy). <i>L</i><sub><i>p</i></sub>-CVT is computed by a quasi-Newton optimization framework, based on closed-form derivations of the objective function and its gradient. The derivations are given for both surface meshing (&Omega; is a triangulated mesh with per-facet anisotropy) and volume meshing (&Omega; is the interior of a closed triangulated mesh with a 3D anisotropy field). Applications to anisotropic, quad-dominant surface remeshing and to hexdominant volume meshing are presented. Unlike previous work, <i>L</i><sub><i>p</i></sub>-CVT captures sharp features and intersections without requiring any pre-tagging.</p></div></span> <a id="expcoll120" href="JavaScript: expandcollapse('expcoll120',120)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Surface fields</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Charles Loop 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778857&CFID=105749981&CFTOKEN=64099081">Parameterizing subdivision surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466644555&CFID=105749981&CFTOKEN=64099081">Lei He</a>, 
                        <a href="author_page.cfm?id=81100603187&CFID=105749981&CFTOKEN=64099081">Scott Schaefer</a>, 
                        <a href="author_page.cfm?id=81100567620&CFID=105749981&CFTOKEN=64099081">Kai Hormann</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 120</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778857" title="DOI">10.1145/1833349.1778857</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778857&ftid=799808&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778857&ftid=978306&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow122" style="display:inline;"><br /><div style="display:inline">We present a method for parameterizing subdivision surfaces in an as-rigid-as-possible fashion. While much work has concentrated on parameterizing polygon meshes, little if any work has focused on subdivision surfaces despite their popularity. We show ...</div></span>
          <span id="toHide122" style="display:none;"><br /><div style="display:inline"><p>We present a method for parameterizing subdivision surfaces in an as-rigid-as-possible fashion. While much work has concentrated on parameterizing polygon meshes, little if any work has focused on subdivision surfaces despite their popularity. We show that polygon parameterization methods produce suboptimal results when applied to subdivision surfaces and describe how these methods may be modified to operate on subdivision surfaces. We also describe a method for creating extended charts to further reduce the distortion of the parameterization. Finally we demonstrate how to take advantage of the multi-resolution structure of subdivision surfaces to accelerate convergence of our optimization.</p></div></span> <a id="expcoll122" href="JavaScript: expandcollapse('expcoll122',122)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778858&CFID=105749981&CFTOKEN=64099081">A multi-resolution approach to heat kernels on discrete surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81384616048&CFID=105749981&CFTOKEN=64099081">Amir Vaxman</a>, 
                        <a href="author_page.cfm?id=81440618656&CFID=105749981&CFTOKEN=64099081">Mirela Ben-Chen</a>, 
                        <a href="author_page.cfm?id=81100294813&CFID=105749981&CFTOKEN=64099081">Craig Gotsman</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 121</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778858" title="DOI">10.1145/1833349.1778858</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778858&ftid=799809&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778858&ftid=978307&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow123" style="display:inline;"><br /><div style="display:inline">Studying the behavior of the heat diffusion process on a manifold is emerging as an important tool for analyzing the geometry of the manifold. Unfortunately, the high complexity of the computation of the heat kernel -- the key to the diffusion process ...</div></span>
          <span id="toHide123" style="display:none;"><br /><div style="display:inline"><p>Studying the behavior of the heat diffusion process on a manifold is emerging as an important tool for analyzing the geometry of the manifold. Unfortunately, the high complexity of the computation of the heat kernel -- the key to the diffusion process - limits this type of analysis to 3D models of modest resolution. We show how to use the unique properties of the heat kernel of a discrete two dimensional manifold to overcome these limitations. Combining a multi-resolution approach with a novel approximation method for the heat kernel at short times results in an efficient and robust algorithm for computing the heat kernels of detailed models. We show experimentally that our method can achieve good approximations in a fraction of the time required by traditional algorithms. Finally, we demonstrate how these heat kernels can be used to improve a diffusion-based feature extraction algorithm.</p></div></span> <a id="expcoll123" href="JavaScript: expandcollapse('expcoll123',123)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Human modeling</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          David Forsyth 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778859&CFID=105749981&CFTOKEN=64099081">Learning behavior styles with inverse reinforcement learning</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448593502&CFID=105749981&CFTOKEN=64099081">Seong Jae Lee</a>, 
                        <a href="author_page.cfm?id=81100620346&CFID=105749981&CFTOKEN=64099081">Zoran Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 122</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778859" title="DOI">10.1145/1833349.1778859</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778859&ftid=799810&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778859&ftid=978027&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow125" style="display:inline;"><br /><div style="display:inline">We present a method for inferring the behavior styles of character controllers from a small set of examples. We show that a rich set of behavior variations can be captured by determining the appropriate reward function in the reinforcement learning framework, ...</div></span>
          <span id="toHide125" style="display:none;"><br /><div style="display:inline"><p>We present a method for inferring the behavior styles of character controllers from a small set of examples. We show that a rich set of behavior variations can be captured by determining the appropriate reward function in the reinforcement learning framework, and show that the discovered reward function can be applied to different environments and scenarios. We also introduce a new algorithm to recover the unknown reward function that improves over the original apprenticeship learning algorithm. We show that the reward function representing a behavior style can be applied to a variety of different tasks, while still preserving the key features of the style present in the given examples. We describe an adaptive process where an author can, with just a few additional examples, refine the behavior so that it has better generalization properties.</p></div></span> <a id="expcoll125" href="JavaScript: expandcollapse('expcoll125',125)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778860&CFID=105749981&CFTOKEN=64099081">A synthetic-vision based steering approach for crowd simulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442618244&CFID=105749981&CFTOKEN=64099081">Jan Ond&#345;ej</a>, 
                        <a href="author_page.cfm?id=81100306359&CFID=105749981&CFTOKEN=64099081">Julien Pettr&#233;</a>, 
                        <a href="author_page.cfm?id=81442610152&CFID=105749981&CFTOKEN=64099081">Anne-H&#233;l&#232;ne Olivier</a>, 
                        <a href="author_page.cfm?id=81100454991&CFID=105749981&CFTOKEN=64099081">St&#233;phane Donikian</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 123</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778860" title="DOI">10.1145/1833349.1778860</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778860&ftid=799811&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778860&ftid=979485&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow126" style="display:inline;"><br /><div style="display:inline">In the everyday exercise of controlling their locomotion, humans rely on their optic flow of the perceived environment to achieve collision-free navigation. In crowds, in spite of the complexity of the environment made of numerous obstacles, humans demonstrate ...</div></span>
          <span id="toHide126" style="display:none;"><br /><div style="display:inline"><p>In the everyday exercise of controlling their locomotion, humans rely on their optic flow of the perceived environment to achieve collision-free navigation. In crowds, in spite of the complexity of the environment made of numerous obstacles, humans demonstrate remarkable capacities in avoiding collisions. Cognitive science work on human locomotion states that relatively succinct information is extracted from the optic flow to achieve safe locomotion. In this paper, we explore a novel vision-based approach of collision avoidance between walkers that fits the requirements of interactive crowd simulation. By simulating humans based on cognitive science results, we detect future collisions as well as the level of danger from visual stimuli. The motor-response is twofold: a reorientation strategy prevents future collision, whereas a deceleration strategy prevents imminent collisions. Several examples of our simulation results show that the emergence of self-organized patterns of walkers is reinforced using our approach. The emergent phenomena are visually appealing. More importantly, they improve the overall efficiency of the walkers' traffic and avoid improbable locking situations.</p></div></span> <a id="expcoll126" href="JavaScript: expandcollapse('expcoll126',126)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778861&CFID=105749981&CFTOKEN=64099081">Gesture controllers</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81410595230&CFID=105749981&CFTOKEN=64099081">Sergey Levine</a>, 
                        <a href="author_page.cfm?id=81448601988&CFID=105749981&CFTOKEN=64099081">Philipp Kr&#228;henb&#252;hl</a>, 
                        <a href="author_page.cfm?id=81100590972&CFID=105749981&CFTOKEN=64099081">Sebastian Thrun</a>, 
                        <a href="author_page.cfm?id=81100662243&CFID=105749981&CFTOKEN=64099081">Vladlen Koltun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 124</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778861" title="DOI">10.1145/1833349.1778861</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778861&ftid=799812&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778861&ftid=979486&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow127" style="display:inline;"><br /><div style="display:inline">We introduce gesture controllers, a method for animating the body language of avatars engaged in live spoken conversation. A gesture controller is an optimal-policy controller that schedules gesture animations in real time based on acoustic features ...</div></span>
          <span id="toHide127" style="display:none;"><br /><div style="display:inline"><p>We introduce <i>gesture controllers</i>, a method for animating the body language of avatars engaged in live spoken conversation. A gesture controller is an optimal-policy controller that schedules gesture animations in real time based on acoustic features in the user's speech. The controller consists of an inference layer, which infers a distribution over a set of hidden states from the speech signal, and a control layer, which selects the optimal motion based on the inferred state distribution. The inference layer, consisting of a specialized conditional random field, learns the hidden structure in body language style and associates it with acoustic features in speech. The control layer uses reinforcement learning to construct an optimal policy for selecting motion clips from a distribution over the learned hidden states. The modularity of the proposed method allows customization of a character's gesture repertoire, animation of non-human characters, and the use of additional inputs such as speech recognition or direct user control.</p></div></span> <a id="expcoll127" href="JavaScript: expandcollapse('expcoll127',127)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Image enhancement</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Dan Goldman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778862&CFID=105749981&CFTOKEN=64099081">Multi-scale image harmonization</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448599532&CFID=105749981&CFTOKEN=64099081">Kalyan Sunkavalli</a>, 
                        <a href="author_page.cfm?id=81442593869&CFID=105749981&CFTOKEN=64099081">Micah K. Johnson</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=105749981&CFTOKEN=64099081">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100199891&CFID=105749981&CFTOKEN=64099081">Hanspeter Pfister</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 125</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778862" title="DOI">10.1145/1833349.1778862</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778862&ftid=799813&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow129" style="display:inline;"><br /><div style="display:inline">Traditional image compositing techniques, such as alpha matting and gradient domain compositing, are used to create composites that have plausible boundaries. But when applied to images taken from different sources or shot under different conditions, ...</div></span>
          <span id="toHide129" style="display:none;"><br /><div style="display:inline"><p>Traditional image compositing techniques, such as alpha matting and gradient domain compositing, are used to create composites that have plausible boundaries. But when applied to images taken from different sources or shot under different conditions, these techniques can produce unrealistic results. In this work, we present a framework that explicitly matches the visual appearance of images through a process we call <i>image harmonization</i>, before blending them. At the heart of this framework is a multi-scale technique that allows us to transfer the appearance of one image to another. We show that by carefully manipulating the scales of a pyramid decomposition of an image, we can match contrast, texture, noise, and blur, while avoiding image artifacts. The output composite can then be reconstructed from the modified pyramid coefficients while enforcing both alpha-based and seamless boundary constraints. We show how the proposed framework can be used to produce realistic composites with minimal user interaction in a number of different scenarios.</p></div></span> <a id="expcoll129" href="JavaScript: expandcollapse('expcoll129',129)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778863&CFID=105749981&CFTOKEN=64099081">Parametric reshaping of human bodies in images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448592559&CFID=105749981&CFTOKEN=64099081">Shizhe Zhou</a>, 
                        <a href="author_page.cfm?id=81331492402&CFID=105749981&CFTOKEN=64099081">Hongbo Fu</a>, 
                        <a href="author_page.cfm?id=81335493715&CFID=105749981&CFTOKEN=64099081">Ligang Liu</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105749981&CFTOKEN=64099081">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81466645856&CFID=105749981&CFTOKEN=64099081">Xiaoguang Han</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 126</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778863" title="DOI">10.1145/1833349.1778863</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778863&ftid=799814&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778863&ftid=978028&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow130" style="display:inline;"><br /><div style="display:inline">We present an easy-to-use image retouching technique for realistic reshaping of human bodies in a single image. A model-based approach is taken by integrating a 3D whole-body morphable model into the reshaping process to achieve globally consistent ...</div></span>
          <span id="toHide130" style="display:none;"><br /><div style="display:inline"><p>We present an easy-to-use image retouching technique for realistic reshaping of human bodies in a single image. A <i>model-based</i> approach is taken by integrating a 3D whole-body morphable model into the reshaping process to achieve globally consistent editing effects. A novel <i>body-aware image warping</i> approach is introduced to reliably transfer the reshaping effects from the model to the image, even under moderate fitting errors. Thanks to the parametric nature of the model, our technique parameterizes the degree of reshaping by a small set of semantic attributes, such as weight and height. It allows easy creation of desired reshaping effects by changing the full-body attributes, while producing visually pleasing results even for loosely-dressed humans in casual photographs with a variety of poses and shapes.</p></div></span> <a id="expcoll130" href="JavaScript: expandcollapse('expcoll130',130)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778864&CFID=105749981&CFTOKEN=64099081">Image warps for artistic perspective manipulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100112519&CFID=105749981&CFTOKEN=64099081">Robert Carroll</a>, 
                        <a href="author_page.cfm?id=81100035467&CFID=105749981&CFTOKEN=64099081">Aseem Agarwala</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=105749981&CFTOKEN=64099081">Maneesh Agrawala</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 127</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778864" title="DOI">10.1145/1833349.1778864</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778864&ftid=799815&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778864&ftid=979487&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow131" style="display:inline;"><br /><div style="display:inline">Painters and illustrators commonly sketch vanishing points and lines to guide the construction of perspective images. We present a tool that gives users the ability to manipulate perspective in photographs using image space controls similar to those ...</div></span>
          <span id="toHide131" style="display:none;"><br /><div style="display:inline"><p>Painters and illustrators commonly sketch vanishing points and lines to guide the construction of perspective images. We present a tool that gives users the ability to manipulate perspective in photographs using image space controls similar to those used by artists. Our approach computes a 2D warp guided by constraints based on projective geometry. A user annotates an image by marking a number of image space constraints including planar regions of the scene, straight lines, and associated vanishing points. The user can then use the lines, vanishing points, and other point constraints as handles to control the warp. Our system optimizes the warp such that straight lines remain straight, planar regions transform according to a homography, and the entire mapping is as shape-preserving as possible. While the result of this warp is not necessarily an accurate perspective projection of the scene, it is often visually plausible. We demonstrate how this approach can be used to produce a variety of effects, such as changing the perspective composition of a scene, exploring artistic perspectives not realizable with a camera, and matching perspectives of objects from different images so that they appear consistent for compositing.</p></div></span> <a id="expcoll131" href="JavaScript: expandcollapse('expcoll131',131)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Biped control</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jovan Popovi&#263; 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1778865&CFID=105749981&CFTOKEN=64099081">Sampling-based contact-rich motion control</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466641527&CFID=105749981&CFTOKEN=64099081">Libin Liu</a>, 
                        <a href="author_page.cfm?id=81100408711&CFID=105749981&CFTOKEN=64099081">KangKang Yin</a>, 
                        <a href="author_page.cfm?id=81319502903&CFID=105749981&CFTOKEN=64099081">Michiel van de Panne</a>, 
                        <a href="author_page.cfm?id=81466643375&CFID=105749981&CFTOKEN=64099081">Tianjia Shao</a>, 
                        <a href="author_page.cfm?id=81335499418&CFID=105749981&CFTOKEN=64099081">Weiwei Xu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 128</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1778865" title="DOI">10.1145/1833349.1778865</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1778865&ftid=799816&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1778865&ftid=979488&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow133" style="display:inline;"><br /><div style="display:inline">Human motions are the product of internal and external forces, but these forces are very difficult to measure in a general setting. Given a motion capture trajectory, we propose a method to reconstruct its open-loop control and the implicit contact forces. ...</div></span>
          <span id="toHide133" style="display:none;"><br /><div style="display:inline"><p>Human motions are the product of internal and external forces, but these forces are very difficult to measure in a general setting. Given a motion capture trajectory, we propose a method to reconstruct its open-loop control and the implicit contact forces. The method employs a strategy based on randomized sampling of the control within user-specified bounds, coupled with forward dynamics simulation. Sampling-based techniques are well suited to this task because of their lack of dependence on derivatives, which are difficult to estimate in contact-rich scenarios. They are also easy to parallelize, which we exploit in our implementation on a compute cluster. We demonstrate reconstruction of a diverse set of captured motions, including walking, running, and contact rich tasks such as rolls and kip-up jumps. We further show how the method can be applied to physically based motion transformation and retargeting, physically plausible motion variations, and reference-trajectory-free idling motions. Alongside the successes, we point out a number of limitations and directions for future work.</p></div></span> <a id="expcoll133" href="JavaScript: expandcollapse('expcoll133',133)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1781155&CFID=105749981&CFTOKEN=64099081">Data-driven biped control</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466646279&CFID=105749981&CFTOKEN=64099081">Yoonsang Lee</a>, 
                        <a href="author_page.cfm?id=81100663786&CFID=105749981&CFTOKEN=64099081">Sungeun Kim</a>, 
                        <a href="author_page.cfm?id=81100429553&CFID=105749981&CFTOKEN=64099081">Jehee Lee</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 129</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1781155" title="DOI">10.1145/1833349.1781155</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1781155&ftid=799817&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1781155&ftid=978029&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow134" style="display:inline;"><br /><div style="display:inline">We present a dynamic controller to physically simulate under-actuated three-dimensional full-body biped locomotion. Our data-driven controller takes motion capture reference data to reproduce realistic human locomotion through realtime physically based ...</div></span>
          <span id="toHide134" style="display:none;"><br /><div style="display:inline"><p>We present a dynamic controller to physically simulate under-actuated three-dimensional full-body biped locomotion. Our data-driven controller takes motion capture reference data to reproduce realistic human locomotion through realtime physically based simulation. The key idea is modulating the reference trajectory continuously and seamlessly such that even a simple dynamic tracking controller can follow the reference trajectory while maintaining its balance. In our framework, biped control can be facilitated by a large array of existing data-driven animation techniques because our controller can take a stream of reference data generated on-the-fly at runtime. We demonstrate the effectiveness of our approach through examples that allow bipeds to turn, spin, and walk while steering its direction interactively.</p></div></span> <a id="expcoll134" href="JavaScript: expandcollapse('expcoll134',134)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1781156&CFID=105749981&CFTOKEN=64099081">Generalized biped walking control</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81320488815&CFID=105749981&CFTOKEN=64099081">Stelian Coros</a>, 
                        <a href="author_page.cfm?id=81100525234&CFID=105749981&CFTOKEN=64099081">Philippe Beaudoin</a>, 
                        <a href="author_page.cfm?id=81319502903&CFID=105749981&CFTOKEN=64099081">Michiel van de Panne</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 130</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1781156" title="DOI">10.1145/1833349.1781156</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1781156&ftid=799818&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1781156&ftid=978030&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow135" style="display:inline;"><br /><div style="display:inline">We present a control strategy for physically-simulated walking motions that generalizes well across gait parameters, motion styles, character proportions, and a variety of skills. The control is realtime, requires no character-specific or motion-specific ...</div></span>
          <span id="toHide135" style="display:none;"><br /><div style="display:inline"><p>We present a control strategy for physically-simulated walking motions that generalizes well across gait parameters, motion styles, character proportions, and a variety of skills. The control is realtime, requires no character-specific or motion-specific tuning, is robust to disturbances, and is simple to compute. The method works by integrating tracking, using proportional-derivative control; foot placement, using an inverted pendulum model; and adjustments for gravity and velocity errors, using Jacobian transpose control. High-level gait parameters allow for forwards-and-backwards walking, various walking speeds, turns, walk-to-stop, idling, and stop-to-walk behaviors. Character proportions and motion styles can be authored interactively, with edits resulting in the instant realization of a suitable controller. The control is further shown to generalize across a variety of walking-related skills, including picking up objects placed at any height, lifting and walking with heavy crates, pushing and pulling crates, stepping over obstacles, ducking under obstacles, and climbing steps.</p></div></span> <a id="expcoll135" href="JavaScript: expandcollapse('expcoll135',135)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1781157&CFID=105749981&CFTOKEN=64099081">Feature-based locomotion controllers</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466641561&CFID=105749981&CFTOKEN=64099081">Martin de Lasa</a>, 
                        <a href="author_page.cfm?id=81466644023&CFID=105749981&CFTOKEN=64099081">Igor Mordatch</a>, 
                        <a href="author_page.cfm?id=81100015154&CFID=105749981&CFTOKEN=64099081">Aaron Hertzmann</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 131</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1833349.1781157" title="DOI">10.1145/1833349.1781157</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1781157&ftid=799819&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1781157&ftid=979489&dwn=1&CFID=105749981&CFTOKEN=64099081" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow136" style="display:inline;"><br /><div style="display:inline">This paper introduces an approach to control of physics-based characters based on high-level features of movement, such as center-of-mass, angular momentum, and end-effectors. Objective terms are used to control each feature, and are combined by a prioritization ...</div></span>
          <span id="toHide136" style="display:none;"><br /><div style="display:inline"><p>This paper introduces an approach to control of physics-based characters based on high-level features of movement, such as center-of-mass, angular momentum, and end-effectors. Objective terms are used to control each feature, and are combined by a prioritization algorithm. We show how locomotion can be expressed in terms of a small number of features that control balance and end-effectors. This approach is used to build controllers for human balancing, standing jump, and walking. These controllers provide numerous benefits: human-like qualities such as arm-swing, heel-off, and hip-shoulder counter-rotation emerge automatically during walking; controllers are robust to changes in body parameters; control parameters and goals may be modified at run-time; control parameters apply to intuitive properties such as center-of-mass height; and controllers may be mapped onto entirely new bipeds with different topology and mass distribution, without modifications to the controller itself. No motion capture or off-line optimization process is used.</p></div></span> <a id="expcoll136" href="JavaScript: expandcollapse('expcoll136',136)">expand</a>
          </div>
		  </td>
          </tr>          
          
</table>


</div> 
</div>


 <p class="small-text" align="center">Powered by <a id="theguide" name="theguide" href="javascript:ColdFusion.Window.show('theguide')"><img src="img/poweredbyacm.jpg" width="336" height="11" alt="The ACM Guide to Computing Literature" border="0" /></a></p>



 <br />
<div class="footerbody" align="center" >
	

	The ACM Digital Library is published by the Association for Computing Machinery. Copyright &copy; 2012 ACM, Inc.<br />
	<a href="http://www.acm.org/publications/policies/usage">Terms of Usage</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/privacy-policy">Privacy Policy</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/code-of-ethics">Code of Ethics</a>&nbsp;&nbsp;	  
	<a href="http://www.acm.org/about/contact-us">Contact Us</a>

<br /><br />
Useful downloads: 
<a href="http://www.adobe.com/products/acrobat/readstep2.html"><img src="http://dl.acm.org/images/pdf_logo.gif" width="16" height="16" alt="" border="0" /> Adobe Acrobat</a>
&nbsp;&nbsp;
<a href="http://www.apple.com/quicktime/download/" target="_blank"><img src="http://dl.acm.org/images/qtlogo.gif" width="16" height="16" alt="" border="0" /> QuickTime</a>
&nbsp;&nbsp;
<a href="http://www.microsoft.com/windows/windowsmedia/download/default.asp" target="_blank"><img src="http://dl.acm.org/images/wmv.gif" width="16" height="15" alt="" border="0" /> Windows Media Player</a>
&nbsp;&nbsp;
<a href="http://www.real.com/" target="_blank"><img src="http://dl.acm.org/images/realplayer.gif" width="20" height="18" alt="" border="0" /> Real Player</a>

</div> 



<div  id="cf_window1338240686341" class="yuiextdlg">
	
	<div  id="theguide_title" class="x-dlg-hd">
		The ACM Guide to Computing Literature
	 </div>
	<div  id="theguide_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240686344" class="yuiextdlg">
	
	<div  id="thetags_title" class="x-dlg-hd">
		All Tags
	 </div>
	<div  id="thetags_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240686347" class="yuiextdlg">
	
	<div  id="theformats_title" class="x-dlg-hd">
		Export Formats
	 </div>
	<div  id="theformats_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240686349" class="yuiextdlg">
	
	<div  id="theexplaination_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theexplaination_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240686351" class="yuiextdlg">
	
	<div  id="theservices_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theservices_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240686353" class="yuiextdlg">
	
	<div  id="savetobinder_title" class="x-dlg-hd">
		Save to Binder
	 </div>
	<div  id="savetobinder_body" class="x-dlg-bd">
		
		
	 </div>
 </div> 

</body>
</html>