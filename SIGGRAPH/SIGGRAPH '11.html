


<!doctype html>


<head><script type="text/javascript">_cf_loadingtexthtml="<img alt=' ' src='/CFIDE/scripts/ajax/resources/cf/images/loading.gif'/>";
_cf_contextpath="";
_cf_ajaxscriptsrc="/CFIDE/scripts/ajax";
_cf_jsonprefix='//';
_cf_clientid='D9789B5F280E56F86C303D760AD6BE74';</script><script type="text/javascript" src="/CFIDE/scripts/ajax/messages/cfmessage.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfajax.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfform.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/masks.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfformhistory.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfrichtexteditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/FCKeditor/fckeditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/yahoo-dom-event/yahoo-dom-event.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/animation/animation-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/adapter/yui/ext-yui-adapter.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/ext-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/resizable.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dragdrop/dragdrop.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/util.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/build/state/State-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/widget-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dialog/dialogs.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfwindow.js"></script>
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/ext/css/ext-all.css" />
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/cf/cf.css" />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="css/dl.css" />



<title>ACM SIGGRAPH 2011 papers</title>
<style type="text/css"><!--
    body {margin-left: 0em; margin-top: 0}
    a:link {text-decoration: underline; 	Color: #1d4d0f;}
    a:visited  { color: #990033; text-decoration: underline;}
    a:hover {color: red; text-decoration: none}
    a.dLink1:link {color:#336699}
    a.dLink1:visited {color:#666666}
	a.isblack:link {text-decoration: underline; 	Color: #000000;}
    a.isblack:visited  { color: #000000; text-decoration: underline;}
    a.isblack:hover {color: #000000; text-decoration: none}
    h1 {font-size: 140%; margin-bottom: 0}
	ul {margin-top: .25em; list-style-type: disc}
	ol {margin-top: .25em;}
	li {padding-bottom: .25em}
    h2 {color: white; background-color: #069; 
        font-size: 100%; padding-left: 1em;
		margin: 0}
	h3 {color: black; background-color: yellow; 
    	font-size: 100%;
		margin: 0}
	 h4 {color: black; background-color: #99c5e8; 
        font-size: 100%;
		margin: 0}
    hr {color: #39176d;}
    form {margin-top: 10}
    form.xrs {margin-top: 0}
	
	a {text-decoration: none; }
	
	input {font-size: 1em;}
	.chevron {color: #ff0000;}
	.light-blue {color:#336699;}
	.black {color:#000000;}
	
	/* ### standard text styles, smallest to largest ### */
	
	.footer-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .75em; line-height: 1.33em;
		text-indent: -.75 em; margin-left: 2em; margin-right: .75em;}
		
	.footer-copy-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em; line-height: 1.3em;
		margin-left: .75em; margin-right: .75em;}
		
	.small-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; padding-bottom : 2px;
	  	padding-top : 2px;}

	.smallerer-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .65em;}
	.smaller-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em;}		
	.small-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em;}
	.small-textb {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; font-weight: bold;}
	.medium-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em;}
	.mediumb-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em; font-weight: bold;}
	.large-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1.3em;}		
	.instr-text {font-family: Arial, Helvetica, sans-serif;
		color:#666666; font-size: .83em;}
		
	.list-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .83em; line-height: 1.3em;}
	.list-link-btext {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; line-height: 1.3em;}
	
	.searchbox-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;}
	.footer-header-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;
		margin-left: .75em; margin-right: .75em;}
	.medium-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold; line-height: 1em;
		text-indent: -1.25em; margin-left: 2em; margin-right: .75em;}
	
	.text16 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 16px;}
		
	.text14 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 14px;}
	
	.text12 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 12px;}
		
	.text10 {font-family: Arial, Helvetica, sans-serif;
	    color:#000000; font-size: 12px;}
		
	.text9 {font-family: Arial, Helvetica, sans-serif;
	   color:#000000; font-size: 12px;}
	
	.error-text {color:red;}
	
	.small-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: .75em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}

	.medium-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1.3em; line-height: 1.5em;
		margin-left: .75em; margin-right: .75em;}
	
	.medium-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1.5em;
		margin-left: .75em; margin-right: .75em;}

		#side {
			width: 10px;
			float: left;
			margin-left: -1px;
			padding: 2px;
			}
							
		#content {
			padding: 2px;
			margin-left: 25px;
			
		        
		        }
	 .fulltext_lnk {border:0px;
	 				 margin-right: 2px;
					 vertical-align:baseline;
	 				}
	 
	  .leftcoltab { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:530px;  /* for IE5/WIN */
		  width:520px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	  .rightcoltab {
    float: right;
    margin: 0;
    padding: 5px;
    position: relative;
    right: 50px;
    top: 25px;
    width: 350px;
    z-index: 99;
}
	  .centercoltab {
		  position:absolute;
		  padding:0 0px;
		  }
	  .alt {
		background: #ece9d8;
		margin: 0;
		padding: 1px;
		}
		.leftcolc { 
	position:relative;
	top:5px;
	left:5px;
	float:left;
	width:420px;  /* for IE5/WIN */
	width:400px; /* actual value */
	margin:0 0 0px 0;
	padding:5px;
	z-index:100;
	}
.rightcolc {
	position:relative;
	top:0px;
	right:0px;
	float:right;
	margin:0 0px;
	padding:0px;
	width:500px;
	z-index:99;
	}
.centercolc {
	position:absolute;
	padding:0 0px;
	}
	
	.leftcoltabv { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:460px;  /* for IE5/WIN */
		  width:350px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	.rightcoltabv {
		position:relative;
		top:5px;
		right:0px;
		float:right;
		margin:0 0px 0 0;
		padding:15px;
		width:480px;
		z-index:99;
		}
	
  --></style>
 


<script type="text/javascript" src="cfformprotect/js/cffp.js"></script>


<script type="text/javascript">
 function expandcollapse(anchor,whichone) {
	 var inner = document.getElementById(anchor);
	 var theshow = "toShow" + whichone;
 	 var thehide = "toHide" + whichone;
	 var span = document.getElementById(theshow);
     span.style.display = (span.style.display=='inline')?'none':'inline';
     var span = document.getElementById(thehide);
     span.style.display = (span.style.display=='none')?'inline':'none';
     inner.innerHTML = (inner.innerHTML=='collapse')?'expand':'collapse';
    }

  function setDiv() {
	var m = document.getElementById('divmain');
	var mh = m.offsetHeight;
	var t = document.getElementById('divtools');
	var th = t.offsetHeight;
	var tg = document.getElementById('divtags');
	var tgh = tg.offsetHeight;
	var calcheight = mh - th;
	if (tgh > calcheight  ){
	  var x = (th + tgh) - mh;
	  if ( (th + tgh) - mh < 65) {
	  }
	  else {
		 document.getElementById('divtags').innerHTML = ""; 
		 var tg = document.getElementById('divtags');
		 var tgh = tg.offsetHeight;
		 tg.style.height = tgh  + 'px';
	  }
	}
	else {
		tg.style.height = calcheight + 'px';
		document.getElementById('divtags').innerHTML = "";
	}

//  do I need to check after I resize to be sure I didn't go too big?
//	var tg2 = document.getElementById('divtags');
//	var tgh2 = tg.offsetHeight;	
//	if (tgh2 > mh + 65) {
//	  var y = mh + 65;
//	  alert('expanded too much ' + tgh2 + ' should be at most ' + y);
//	  tg.style.height = y + 'px';
//	  document.getElementById('divtags').innerHTML = "";
//	}

  }
</script>

<script type="text/javascript">
 /* <!-- Begin
	if(document.layers || document.all) {
	a = 1;
	setInterval("Jump()", 10);
	}
	function Jump() {
	a = a + 1;
	//self.moveBy((Math.random() * a * 2 - a), (Math.random() * a * 2) - a);
	}
//  End --> */
</script>



<meta name="citation_publisher" content="ACM"> <meta name="citation_authors" content="Hoppe, Hugues"> <meta name="citation_title" content="ACM SIGGRAPH 2011 papers"> <meta name="citation_date" content="08/07/2011"> <meta name="citation_isbn" content="978-1-4503-0943-1"> <meta name="citation_abstract_html_url" content="http://dl.acm.org/citation.cfm?id=1964921"> 



<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFAJAXPROXY');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFFORM');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFDIV');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFTEXTAREA');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFWINDOW');
</script>

<script type="text/javascript">
	var _cf_window_init_1338240864386=function()
	{
		_cf_bind_init_1338240864387=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'theguide_body','bindExpr':['whatisguide.cfm']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240864387);var _cf_window=ColdFusion.Window.create('theguide','The ACM Guide to Computing Literature','whatisguide.cfm',{ modal:false, closable:true, divid:'cf_window1338240864385', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240864386);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240864389=function()
	{
		_cf_bind_init_1338240864390=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'thetags_body','bindExpr':['showthetags.cfm?id=1964921']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240864390);var _cf_window=ColdFusion.Window.create('thetags','All Tags','showthetags.cfm?id=1964921',{ modal:false, closable:true, divid:'cf_window1338240864388', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240864389);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240864392=function()
	{
		var _cf_window=ColdFusion.Window.create('theformats','Export Formats','',{ modal:false, closable:true, divid:'cf_window1338240864391', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:250, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240864392);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240864394=function()
	{
		var _cf_window=ColdFusion.Window.create('theexplaination','','',{ modal:false, closable:true, divid:'cf_window1338240864393', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240864394);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240864396=function()
	{
		var _cf_window=ColdFusion.Window.create('theservices','','',{ modal:false, closable:true, divid:'cf_window1338240864395', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240864396);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240864398=function()
	{
		_cf_bind_init_1338240864399=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'savetobinder_body','bindExpr':['savetobinder.cfm?id=1964921']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240864399);var _cf_window=ColdFusion.Window.create('savetobinder','Save to Binder','savetobinder.cfm?id=1964921',{ modal:false, closable:true, divid:'cf_window1338240864397', draggable:true, resizable:true, fixedcenter:true, width:600, height:600, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false, _cf_refreshOnShow:true});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240864398);
</script>
</head>

<body style="text-align:center" onLoad="window.focus();">

<script type="text/javascript">
						addthis_pub             = 'acm'; 
						//addthis_logo            = 'http://www.addthis.com/images/yourlogo.png';
						addthis_logo            = 'http://dl.acm.org/images/ACM_transparent.png';
						addthis_logo_background = 'c2d5fc';
						addthis_logo_color      = '000000';
						addthis_brand           = 'Citation Page';
						addthis_options         = 'favorites, email, slashdot, citeulike, digg, delicious, twitter, myspace, facebook, google, more';
						</script>
                        
<script src='AC_RunActiveContent.js' type="text/javascript"></script>




<div style="width:940px; margin-left: auto; margin-right: auto; text-align:left">
<a id="CIT"></a>



<table style="table-layout:fixed; margin-top: 5px; margin-bottom: 10px; border:0px; width:100%; border-collapse:collapse;">
	
    <tr style="vertical-align:top">
		
		<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; width:300px" class="small-link-text"  ><img src="http://dl.acm.org/images/ACMDL_Logo.jpg" alt="ACM DL" style="border:0px" usemap="#port" />
		</td>
        
        <td style="padding-left: 5px; padding-right:10px; padding-bottom:0px;" class="small-link-text">
        	<table style="width:100%; border-collapse:collapse; padding:0px">
			<tr><td style="text-align:center">
				
                            <div style="margin:0px auto;color:#356b20;font-size:10pt;line-height:10%;"> </div>
                    
					</td>		
			</tr>
			</table> 
        </td>
		<td style="padding-top: 0px; padding-left: 0px; padding-bottom:0px; text-align:right;" class="small-link-text">
			 <p style="margin-top:0px; margin-bottom:10px;">
					
                            <a href="https://dl.acm.org/signin.cfm?cfid=105750247&amp;cftoken=50542134" class="small-link-text" title="Sign in to personalize your Digital Library experience">SIGN IN</a>
                            &nbsp;&nbsp;<a href="https://dl.acm.org/signin.cfm?cfid=105750247&amp;cftoken=50542134"  class="small-link-text" title="Sign up to personalize your Digital Library experience">SIGN UP</a>
						
			 </p>
            
			<table style="padding: 5px; border-collapse:collapse; float:right">
				
				
                            
                            <tr>
                            <td class="small-link-text" style="text-align:right">
                            <form name="qiksearch" action="results.cfm?h=1&amp;cfid=105750247&amp;cftoken=50542134" method="post">
                           
                           
                            
                                     
                                    <span style="margin-left:0px"><label><input type="text" name="query" size="34" value=" " /></label>&nbsp;
                                    <input style="vertical-align:top;" type="image" alt="Search" name="Go" src="http://dl.acm.org/images/search_small.jpg" />
                                    
                                    </span>
							  </form>
                                </td>
                            </tr>
                          
				  
			</table>

			
			
		</td>

	</tr>
    
    
    <tr><td colspan="3" class="small-link-text" style="padding-bottom:5px; padding-top:0px; text-align:center">
		<div style="margin:0px auto;color:#356b20;line-height:10%;"> </div>
         
         </td>
    </tr>
    </table>
	
<map name="port" id="port" > 
  <area shape="rect" coords="1,1,60,50" href="http://www.acm.org/" alt="ACM Home Page" />
  <area shape="rect" coords="65,1,275,68" href="http://dl.acm.org/dl.cfm?CFID=105750247&CFTOKEN=50542134" alt="ACM Digital Library Home Page" />
</map>

<table style="table-layout:fixed; padding-bottom:10px; width:100%; padding:0px;">
	<tr style="vertical-align:top">
		<td style="padding-right:10px; text-align:left" class="small-link-text">
        	<div id="divmain" style="border:1px solid #356b20;">
				 
				<div class="large-text" style="text-align:left; margin-left:2px;margin-bottom:5px;">
					
                    	<h1 class="mediumb-text" style="margin-top:0px; margin-bottom:0px;"><strong>ACM SIGGRAPH 2011 papers</strong></h1>
                        
                </div>
                
                  

<table class="medium-text" style="border-collapse:collapse; padding:0px;">

<col style="width:540px" />

<tr style="vertical-align:top">
  <td>
    <table style="border-collapse:collapse; padding:2px;" class="medium-text">
      <col style="width:80px;" />
      <col style="width:auto" />
      <tr style="vertical-align:top">
        
      </tr>
    </table>

	
        <table style="margin-top: 10px; border-collapse:collapse; padding:2px;" class="medium-text">
            <col style="width:80px" />
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             Editor:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81487644122&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105750247&amp;cftoken=50542134" title="Author Profile Page" target="_self">Hugues Hoppe</a>
                
            </td>
            <td valign="bottom">
                	
            </td>
            </tr>
            
        </table>
    
        <table style="margin-top: 10px" border="0" class="medium-text" cellpadding="2" cellspacing="0">
            <tr><td><table border="0" class="medium-text" cellpadding="1" cellspacing="0">

<tr valign="top">
    <td nowrap="nowrap" style="padding-top:10px;">Publication of:</td>
</tr>

	<tr valign="top">
    	<td nowrap="nowrap" style="padding-bottom:0px">&middot;&nbsp;Conference</td>
	</tr>
    <tr valign="top">
	    <td style="padding-left:10px;">
		   <a href="http://www.siggraph.org/s2011/" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '11</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    
    <tr valign="top">
	    <td style="padding-left:10px; padding-bottom:10px"> Vancouver, BC, Canada &mdash; August 07 - 11, 2011
                    
                  <br />
                    
                  <a href="http://www.acm.org/publications" class="small-link-text" title="ACM">ACM</a> <span class="small-link-text">New York, NY</span><span class="small-link-text">, USA</span> <span class="small-link-text">  &copy;2011</span> 
                  <br />           
                  
      </td>
	</tr>
	 

</table></td></tr>
        </table>
    

  </td>

  <td rowspan="20" nowrap="nowrap">
	<table border="0" class="medium-text" cellpadding="0" cellspacing="0">
		<tr>
        	<td align="center" style="padding-bottom: 5px;">
			  
               <img src="http://portalparts.acm.org/1970000/1964921/thumb/cover_thumb.jpg" title="ACM SIGGRAPH 2011 papers" height="100"  width="77" ALT="ACM SIGGRAPH 2011 papers" /> 
              </td>
              <td valign="top" align="left" nowrap="nowrap">
	             <img src="images/acm_mini.jpg" title="Published by ACM" alt="Published by ACM" /> 2011 Proceeding<br />
                 
        	 </td>
        </tr>
        
        <tr>
        	<td colspan="2" valign="baseline" style="padding-bottom:5px;">
            <img src="img/stats.jpg" alt="Bibliometrics Data" />&nbsp;
            <a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a>
            </td>
         </tr>
         <tr>
            <td  class="small-text" colspan="2" valign="top" style="padding-left:30px;">
				
	                    	&middot;&nbsp;Downloads (6 Weeks): 4,245<br />
    	                    &middot;&nbsp;Downloads (12 Months): 51,565<br />
                          
                        &middot;&nbsp;Citation Count: 43 
			</td>
         </tr>

	</table>
  </td>
</tr>
</table>

<br clear="all" />

                  
                 <br clear="all" />
			</div>
			
		</td>
		<td style="padding-left: 5px; vertical-align:top; text-align:left; width:170px" class="small-link-text">
	
            <div id="divtools" style="background-color:#ece9d8; text-align:left; padding-top:5px; padding-bottom:5px; ">
              <div class="medium-text" style="margin-left:3px; margin-top:10px;"><h1 class="mediumb-text" style="margin-top:-15px;"><strong>Tools and Resources</strong></h1></div>


<ul title="Tools and Resources" style="list-style: none; list-style-position:inside;
margin-left: 0px;
padding-left: 0em;
text-indent: 5px;
margin-bottom: 0px;">


<li style="list-style-image:url(img/toc_small.gif);margin-top:10px;"><span style="margin-left:6px;">
   <span class="small-link-text">TOC Service:</span>
   	  
	  <img src="http://dl.acm.org/images/blanks.gif" border="0" alt="Spacer Image reserves space for checkmark when TOC Service is updated" name="saved" />
      <ul style="margin-left: 0; padding-left: 0; display:inline;">
      	
        <li style="list-style:none; display:inline"><br /><img src="img/email_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Email</a></li>
        <li style="list-style:none; display:inline"><img src="img/rss_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');"  class="small-link-text">RSS</a></li>
		        
      </ul>
    </span>
</li>

        <li style="list-style-image:url(img/binder.gif);margin-top:10px;"><span style="margin-left:6px;">
        <a href="citation.cfm?id=1964921&preflayout=flat#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Save to Binder</a>
         </span></li>
    




<li style="list-style-image:url(img/binder_green.gif);margin-top:10px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Export Formats:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1964921&expformat=bibtex','theformats');" class="small-link-text">BibTeX</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1964921&expformat=endnotes','theformats');" class="small-link-text">EndNote</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1964921&expformat=acmref','theformats');" class="small-link-text">ACM&nbsp;Ref</a></li>
      </ul>
    </span>
</li>



 
   <li style="list-style-image:url(img/calbullet.jpg);margin-top:15px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Upcoming Conference:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px; margin-left:25px;"><a href="http://www.siggraph.org" title="Special Interest Group on Computer Graphics and Interactive Techniques Conference" class="small-link-text">SIGGRAPH '12</a></li>
      </ul>
    </span>
	</li>
    


</ul>           

  <!-- ADDTHIS BUTTON BEGIN -->
  
  <!-- ADDTHIS BUTTON END -->

<p class="small-link-text" style="padding-top: 0px; margin-left:6px; margin-bottom:0px">Share:</p>
  <!-- AddThis Button BEGIN -->



<!-- AddThis Button BEGIN -->
<div style="margin-left:5px;" class="addthis_toolbox addthis_default_style">
<a class="addthis_button_email"></a>
<a class="addthis_button_facebook"></a>
<a class="addthis_button_google"></a>
<a class="addthis_button_twitter"></a>
<a class="addthis_button_slashdot"></a>
<a class="addthis_button_reddit"></a>


<span class="addthis_separator">|</span>
<a href="http://www.addthis.com/bookmark.php?v=250&amp;username=acm" class="addthis_button_expanded" title="more"></a>
</div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=acm"></script>
<!-- AddThis Button END -->

  
 

  
  
            </div>
            
		</td>
	</tr>
    
</table>



</div>


<div class="layout" style="width:940px; margin-left: auto; margin-right: auto; text-align:left">




<div id="fback" style="text-align:left; padding-top:10px; padding-bottom:20px">
<span class="small-text" style="padding-right:10px; margin-bottom:0px;">
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design" style=" vertical-align:middle"><img src="img/feedbackg.gif" width="20" height="19" alt="feedback" border="0" /></a>
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design"><strong>Feedback</strong></a>

<span style="padding:10px;">|</span>




<span>Switch to <a href="citation.cfm?id=1964921&amp;preflayout=tabs">tabbed view</a> <noscript> (javascript required)</noscript></span>


</span>

 
<div class="small-text" style="margin-top:10px; margin-bottom:5px;"> 
<br />

    <a href="#abstract"  title="Abstract" style="padding:5px"><span>Abstract</span></a> |
    
    <a href="#formats"  title="Source Materials" style="padding:5px"><span>Source Materials</span></a> |
    
    <a href="#authors"  title="Authors" style="padding:5px"><span>Authors</span></a> |
    <a href="#references"  title="References" style="padding:5px"><span style='color:#999999'>References</span></a> |
    <a href="#citedby"  title="Cited By" style="padding:5px"><span style='color:#999999'>Cited By</span></a> |
    <a href="#indexterms"  title="Index Terms" style="padding:5px"><span style='color:#999999'>Index Terms</span></a> |
    <a href="#source"  title="Publication" style="padding:5px"><span>Publication</span></a> |
    <a href="#revs"  title="Reviews" style="padding:5px"><span style='color:#999999'>Reviews</span></a> |               
	<a href="#comments"  title="Comments" style="padding:5px"><span>Comments</span></a>
	
     |               
	<a href="#prox"  title="Table of Contents" style="padding:5px"><span>Table of Contents</span></a>
    
</div>
    
<div style="right: 0pt; border-top:1px solid #356b20; font-size:1px; margin-bottom:20px;"/>



</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="abstract" class="small-text">ABSTRACT</A></h1>
       	
			<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

			

		
			
           
			
				
				<p>
					<div style="display:inline"><p>Welcome to the SIGGRAPH 2011 Technical Papers Program!</p> <p>It has been an amazing honor to chair the technical papers program. This rare opportunity let me experience the process from a unique perspective, and I am now even more impressed by the dedication and professionalism of everyone involved, from authors and reviewers to all those working behind the scenes. Over many years, we have fine-tuned a conference program that does our community proud.</p> <p>This proceedings contains some of the most exciting and inspiring recent research in the area of computer graphics and interactive techniques. There were 432 submissions, a 10% increase over last year. The papers committee, comprised of 51 experts from academia and industry, accepted 82 papers. Although this acceptance rate of 19% is lower than last year, it is in line with the long-term distribution (2006=18%, 2007=24%, 2008=17%, 2009=18%, 2010=27%). Another 10 papers were referred to ACM Transactions on Graphics (TOG) as "Accept with major revision." If one counts those papers, acceptance rate was 21%.</p></div>
				</p>
   				
           	</div>
			
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="formats" class="small-text"><SPAN class="heading">SOURCE MATERIALS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


  <div class="abstract">
        <SPAN><strong>FRONT MATTER</strong></span>
  </div>
  <div style="margin-left:10px; line-height:180%;">
      
          <A NAME="FullText" HREF="http://portalparts.acm.org/1970000/1964921/fm/frontmatter.pdf?ip=188.194.239.219&CFID=105750247&CFTOKEN=50542134" title="PDF" target="_blank">
          <img src="http://dl.acm.org/imagetypes/pdf_logo.gif" alt="PDF" border="0" align="middle" style="margin-right: 2px">PDF</A>
          &nbsp;Front matter (Covers, Title page, TOC, Preface, 2011 ACM SIGGRAPH Awards) 
  </div>          
  
  <div style="margin-top: 10px;"  class="abstract">
        <SPAN><strong>BACK MATTER</strong></span>
  </div>
  <div style="margin-left:10px; line-height:180%;">
      
          <A NAME="FullText" HREF="http://portalparts.acm.org/1970000/1964921/bm/backmatter.pdf?ip=188.194.239.219&CFID=105750247&CFTOKEN=50542134" title="PDF" target="_blank">
          <img src="http://dl.acm.org/imagetypes/pdf_logo.gif" alt="PDF" border="0" align="middle" style="margin-right: 2px">PDF</A>
          &nbsp;Back matter (Committees and reviewers, SIGGRAPH 2011 Exhibitors, ACM SIGGRAPH Professional and Student Chapters, Cover image credits, Author index) 
  </div>          
  
<div style="margin-top: 10px; height: auto; padding: 5px; ">
		
		
        
         <div  style="margin-top:20px;" class="abstract">
              <SPAN><strong>APPENDICES and SUPPLEMENTS</strong></span>
	        </div>
          <div style="margin-left:10px; line-height:180%;">
			  
		                  <A title="PDF" HREF="ft_gateway.cfm?id=1964921&type=pdf&path=%2F1970000%2F1964921%2Fsupp%2Fpapers%2Dfirst%2Dpages%2Dsiggraph%2D2011%2Epdf&supp=1&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank">
        	              <img src="http://dl.acm.org/imagetypes/pdf_logo.gif" alt="PDF" border="0" align="middle" style="margin-right: 2px">First Pages of SIGGraph 2011 papers</A>
					  (44.74&nbsp;MB)
                &nbsp;
                This file contains the first pages of each of the papers presented at SIGGraph 2011, with eye-catching graphics at the top, and links to the full papers in the Digital Library. The papers are organized by topic. 
          </div>
       


	</div>

<br clear="all" />
</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="authors" class="small-text"><SPAN class="heading">AUTHORS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<dl title="Authors" style="margin-top:0px">




<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 Editor 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Hugues Hoppe" href="author_page.cfm?id=81487644122&CFID=105750247&CFTOKEN=50542134">Hugues Hoppe</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td>&nbsp;</td>

</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Hugues Hoppe" href="author_page.cfm?id=81487644122&amp;dsp=coll&amp;trk=1&amp;CFID=105750247&CFTOKEN=50542134" target="_self">View colleagues</a> of Hugues Hoppe
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              

</dl>
</div>

		  
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="references" class="small-text"><SPAN class="heading">REFERENCES</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	References are not available

</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="citedby" class="small-text"><SPAN class="heading">CITED BY</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	Citings are not available
		
 </div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="indexterms" class="small-text"><SPAN class="heading">INDEX TERMS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

Index Terms are not available


</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="source" class="small-text"><SPAN class="heading">PUBLICATION</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">



<table border="0" class="medium-text" cellpadding="0" cellspacing="5">



    <tr valign="top">
    	<td>Title</td> 
	    <td>
		   <a href="http://www.siggraph.org/s2011/" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '11</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    <tr><td></td><td>Vancouver, BC, Canada &mdash; August 07 - 11, 2011</td></tr> <tr><td>Pages</td><td>869</td></tr> 
                 <tr>
                 
                     <td>Sponsor</td>
                    
                  <td>
                  <a href="sig.cfm?id=SP932&CFID=105750247&CFTOKEN=50542134"> SIGGRAPH</a> ACM Special Interest Group on Computer Graphics and Interactive Techniques
                  </td>
                  </tr>
              
                  <tr><td>Publisher</td><td><a href="http://www.acm.org/publications">ACM</a> New York, NY, USA</td>
				  </tr>
             <tr><td>ISBN</td><td> 978-1-4503-0943-1</td></tr> 
			<tr valign="top">
        	<td>Conference</td>
            <td valign="top" align="left"  style="padding-bottom: 25px;">
	            <strong style="padding-right:10px">GRAPH</strong><a href="event.cfm?id=RE214&CFID=105750247&CFTOKEN=50542134" title="International Conference on Computer Graphics and Interactive Techniques">International Conference on Computer Graphics and Interactive Techniques</a>
                
                       
                        <a href="event.cfm?id=RE214&CFID=105750247&CFTOKEN=50542134" title="International Conference on Computer Graphics and Interactive Techniques"><img border="0" src="http://portalparts.acm.org/event_logos/382/382.jpg" title="GRAPH logo" height="100"  width="100" ALT="GRAPH logo" style="vertical-align:top"></a>
						 

        	 </td>
            </tr>
		    <tr><td colspan="2">Paper Acceptance Rate 82 of 432 submissions, 19%</td></tr> <tr valign="top"><td style="pading-top:20px;" colspan="2">Overall Acceptance Rate 2,079 of 8,858 submissions, 23%</td></tr>
                       <tr valign="top">
                        <td colspan="2" style="padding-left:25px;">
                        	<table>
                            	<tr><td>
                                        <!-- WebCharts3D v5.1(2077) -->
<IMG SRC="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=Images/9728041430525573.JPG" id="Images_9728041430525573_JPG" name="Images_9728041430525573_JPG" usemap="#Images_9728041430525573_JPG_map" border="0"/>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAB' id='GP1338240836372AAAB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>120</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAC' id='GP1338240836372AAAC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>64</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAD' id='GP1338240836372AAAD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>110</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAE' id='GP1338240836372AAAE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAF' id='GP1338240836372AAAF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAG' id='GP1338240836372AAAG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAH' id='GP1338240836372AAAH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>132</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAI' id='GP1338240836372AAAI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAJ' id='GP1338240836372AAAJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>118</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAK' id='GP1338240836372AAAK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>41</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAL' id='GP1338240836372AAAL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>175</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAM' id='GP1338240836372AAAM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>35</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAN' id='GP1338240836372AAAN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAO' id='GP1338240836372AAAO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>33</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAP' id='GP1338240836372AAAP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>161</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAQ' id='GP1338240836372AAAQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>34</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAR' id='GP1338240836372AAAR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>190</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAS' id='GP1338240836372AAAS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAT' id='GP1338240836372AAAT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>210</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAU' id='GP1338240836372AAAU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAV' id='GP1338240836372AAAV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>213</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAW' id='GP1338240836372AAAW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAX' id='GP1338240836372AAAX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>225</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAY' id='GP1338240836372AAAY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>46</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AAAZ' id='GP1338240836372AAAZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>242</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABA' id='GP1338240836372AABA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>57</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABB' id='GP1338240836372AABB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABC' id='GP1338240836372AABC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>56</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABD' id='GP1338240836372AABD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>247</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABE' id='GP1338240836372AABE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABF' id='GP1338240836372AABF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>265</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABG' id='GP1338240836372AABG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>48</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABH' id='GP1338240836372AABH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>303</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABI' id='GP1338240836372AABI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABJ' id='GP1338240836372AABJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>320</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABK' id='GP1338240836372AABK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABL' id='GP1338240836372AABL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>304</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABM' id='GP1338240836372AABM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>59</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABN' id='GP1338240836372AABN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>300</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABO' id='GP1338240836372AABO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>65</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABP' id='GP1338240836372AABP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABQ' id='GP1338240836372AABQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABR' id='GP1338240836372AABR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>424</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABS' id='GP1338240836372AABS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>81</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABT' id='GP1338240836372AABT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>478</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABU' id='GP1338240836372AABU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>83</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABV' id='GP1338240836372AABV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>461</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABW' id='GP1338240836372AABW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>98</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABX' id='GP1338240836372AABX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>474</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABY' id='GP1338240836372AABY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>86</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AABZ' id='GP1338240836372AABZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>455</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACA' id='GP1338240836372AACA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>108</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACB' id='GP1338240836372AACB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>518</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACC' id='GP1338240836372AACC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>90</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACD' id='GP1338240836372AACD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>439</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACE' id='GP1338240836372AACE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>78</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACF' id='GP1338240836372AACF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>390</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACG' id='GP1338240836372AACG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>103</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACH' id='GP1338240836372AACH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>432</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240836372AACI' id='GP1338240836372AACI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>82</td></tr></table>
<MAP name='Images_9728041430525573_JPG_map'>
<AREA shape='rect' coords='0,0,1,1'/>
<AREA shape="rect" coords="287,179,290,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACI",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACI",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACI",event)'/>
<AREA shape="rect" coords="284,92,287,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACH",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACH",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACH",event)'/>
<AREA shape="rect" coords="278,174,281,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACG",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACG",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACG",event)'/>
<AREA shape="rect" coords="275,103,278,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACF",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACF",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACF",event)'/>
<AREA shape="rect" coords="270,180,273,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACE",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACE",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACE",event)'/>
<AREA shape="rect" coords="267,90,270,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACD",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACD",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACD",event)'/>
<AREA shape="rect" coords="261,177,264,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACC",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACC",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACC",event)'/>
<AREA shape="rect" coords="258,71,261,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACB",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACB",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACB",event)'/>
<AREA shape="rect" coords="253,173,256,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACA",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AACA",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AACA",event)'/>
<AREA shape="rect" coords="250,87,253,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABZ",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABZ",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABZ",event)'/>
<AREA shape="rect" coords="244,178,247,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABY",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABY",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABY",event)'/>
<AREA shape="rect" coords="241,82,244,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABX",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABX",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABX",event)'/>
<AREA shape="rect" coords="235,175,238,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABW",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABW",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABW",event)'/>
<AREA shape="rect" coords="232,85,235,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABV",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABV",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABV",event)'/>
<AREA shape="rect" coords="227,179,230,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABU",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABU",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABU",event)'/>
<AREA shape="rect" coords="224,81,227,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABT",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABT",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABT",event)'/>
<AREA shape="rect" coords="218,179,221,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABS",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABS",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABS",event)'/>
<AREA shape="rect" coords="215,94,218,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABR",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABR",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABR",event)'/>
<AREA shape="rect" coords="210,136,213,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABQ",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABQ",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABQ",event)'/>
<AREA shape="rect" coords="207,136,210,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABP",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABP",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABP",event)'/>
<AREA shape="rect" coords="201,183,204,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABO",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABO",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABO",event)'/>
<AREA shape="rect" coords="198,125,201,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABN",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABN",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABN",event)'/>
<AREA shape="rect" coords="192,185,195,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABM",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABM",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABM",event)'/>
<AREA shape="rect" coords="189,124,192,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABL",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABL",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABL",event)'/>
<AREA shape="rect" coords="184,187,187,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABK",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABK",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABK",event)'/>
<AREA shape="rect" coords="181,120,184,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABJ",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABJ",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABJ",event)'/>
<AREA shape="rect" coords="175,188,178,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABI",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABI",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABI",event)'/>
<AREA shape="rect" coords="172,124,175,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABH",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABH",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABH",event)'/>
<AREA shape="rect" coords="167,188,170,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABG",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABG",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABG",event)'/>
<AREA shape="rect" coords="164,134,167,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABF",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABF",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABF",event)'/>
<AREA shape="rect" coords="158,187,161,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABE",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABE",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABE",event)'/>
<AREA shape="rect" coords="155,138,158,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABD",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABD",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABD",event)'/>
<AREA shape="rect" coords="149,186,152,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABC",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABC",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABC",event)'/>
<AREA shape="rect" coords="146,136,149,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABB",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABB",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABB",event)'/>
<AREA shape="rect" coords="141,185,144,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABA",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AABA",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AABA",event)'/>
<AREA shape="rect" coords="138,139,141,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAZ",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAZ",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAZ",event)'/>
<AREA shape="rect" coords="132,188,135,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAY",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAY",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAY",event)'/>
<AREA shape="rect" coords="129,144,132,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAX",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAX",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAX",event)'/>
<AREA shape="rect" coords="124,188,127,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAW",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAW",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAW",event)'/>
<AREA shape="rect" coords="121,147,124,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAV",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAV",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAV",event)'/>
<AREA shape="rect" coords="115,189,118,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAU",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAU",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAU",event)'/>
<AREA shape="rect" coords="112,147,115,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAT",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAT",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAT",event)'/>
<AREA shape="rect" coords="106,190,109,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAS",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAS",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAS",event)'/>
<AREA shape="rect" coords="103,152,106,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAR",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAR",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAR",event)'/>
<AREA shape="rect" coords="98,191,101,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAQ",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAQ",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAQ",event)'/>
<AREA shape="rect" coords="95,160,98,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAP",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAP",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAP",event)'/>
<AREA shape="rect" coords="89,191,92,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAO",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAO",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAO",event)'/>
<AREA shape="rect" coords="86,165,89,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAN",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAN",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAN",event)'/>
<AREA shape="rect" coords="81,191,84,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAM",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAM",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAM",event)'/>
<AREA shape="rect" coords="78,156,81,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAL",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAL",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAL",event)'/>
<AREA shape="rect" coords="72,189,75,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAK",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAK",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAK",event)'/>
<AREA shape="rect" coords="69,170,72,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAJ",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAJ",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAJ",event)'/>
<AREA shape="rect" coords="63,190,66,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAI",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAI",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAI",event)'/>
<AREA shape="rect" coords="60,167,63,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAH",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAH",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAH",event)'/>
<AREA shape="rect" coords="55,187,58,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAG",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAG",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAG",event)'/>
<AREA shape="rect" coords="52,165,55,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAF",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAF",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAF",event)'/>
<AREA shape="rect" coords="46,189,49,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAE",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAE",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAE",event)'/>
<AREA shape="rect" coords="43,172,46,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAD",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAD",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAD",event)'/>
<AREA shape="rect" coords="38,184,41,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAC",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAC",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAC",event)'/>
<AREA shape="rect" coords="35,170,38,199" onMouseover='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAB",event,true)' onMouseout='xx_set_visible("Images_9728041430525573_JPG","GP1338240836372AAAB",event,false)' onMousemove='xx_move_tag("Images_9728041430525573_JPG","GP1338240836372AAAB",event)'/>
<AREA shape="rect" coords="160,13,227,27"/>
<AREA shape="rect" coords="89,13,160,27"/>
</MAP>

<script language="javascript" src="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=script.js"></script>

                                      </td>
                                      <td style="padding-left:20px;">
                                             <table style="border-width: 1px; border-style: solid; width:100%;  border-spacing: 6px;" class="text12">
                                                <tr bgcolor="#ffffff">
                                                  <th style="width:50%">Year</th>
                                                  <th  align="right" style="width:15%">Submitted</th>
                                                  <th  align="right" style="width:15%">Accepted</th>
                                                  <th  align="center">Rate</th>
                                                </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '78</td>
                                                            <td align="right">120</td>
                                                            <td align="right">64</td>
                                                            <td align="center">53%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '79</td>
                                                            <td align="right">110</td>
                                                            <td align="right">43</td>
                                                            <td align="center">39%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '80</td>
                                                            <td align="right">140</td>
                                                            <td align="right">52</td>
                                                            <td align="center">37%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '81</td>
                                                            <td align="right">132</td>
                                                            <td align="right">38</td>
                                                            <td align="center">29%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '84</td>
                                                            <td align="right">118</td>
                                                            <td align="right">41</td>
                                                            <td align="center">35%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '85</td>
                                                            <td align="right">175</td>
                                                            <td align="right">35</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '87</td>
                                                            <td align="right">140</td>
                                                            <td align="right">33</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '88</td>
                                                            <td align="right">161</td>
                                                            <td align="right">34</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '89</td>
                                                            <td align="right">190</td>
                                                            <td align="right">38</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '90</td>
                                                            <td align="right">210</td>
                                                            <td align="right">43</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '92</td>
                                                            <td align="right">213</td>
                                                            <td align="right">45</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '93</td>
                                                            <td align="right">225</td>
                                                            <td align="right">46</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '94</td>
                                                            <td align="right">242</td>
                                                            <td align="right">57</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '95</td>
                                                            <td align="right">257</td>
                                                            <td align="right">56</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '96</td>
                                                            <td align="right">247</td>
                                                            <td align="right">52</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '97</td>
                                                            <td align="right">265</td>
                                                            <td align="right">48</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '98</td>
                                                            <td align="right">303</td>
                                                            <td align="right">45</td>
                                                            <td align="center">15%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '99</td>
                                                            <td align="right">320</td>
                                                            <td align="right">52</td>
                                                            <td align="center">16%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '00</td>
                                                            <td align="right">304</td>
                                                            <td align="right">59</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '01</td>
                                                            <td align="right">300</td>
                                                            <td align="right">65</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">358</td>
                                                            <td align="right">67</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">257</td>
                                                            <td align="right">257</td>
                                                            <td align="center">100%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '03</td>
                                                            <td align="right">424</td>
                                                            <td align="right">81</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '04</td>
                                                            <td align="right">478</td>
                                                            <td align="right">83</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '05</td>
                                                            <td align="right">461</td>
                                                            <td align="right">98</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '06</td>
                                                            <td align="right">474</td>
                                                            <td align="right">86</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '07</td>
                                                            <td align="right">455</td>
                                                            <td align="right">108</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '08</td>
                                                            <td align="right">518</td>
                                                            <td align="right">90</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '09</td>
                                                            <td align="right">439</td>
                                                            <td align="right">78</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '10</td>
                                                            <td align="right">390</td>
                                                            <td align="right">103</td>
                                                            <td align="center">26%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '11</td>
                                                            <td align="right">432</td>
                                                            <td align="right">82</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                 <tr bgcolor="#ffffff">
                                                    <td><strong>Overall</strong></td>
                                                    <td align="right">8,858</td>
                                                    <td align="right">2,079</td>
                                                    <td align="center">23%</td>
                                                  </tr>
                                                </table>
                                       </td>
                                     </tr>
                               </table>
                        </td>
                    </tr>
                     
                     
            
</table>


</table>




</div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="revs" class="small-text"><SPAN class="heading">REVIEWS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	<br />Reviews are not available for this item
        
        <div align="left" style="margin-top:30px">
					<a title="Computing Reviews" href="ocr_review_main.cfm?CFID=105750247&CFTOKEN=50542134">
                 <img src="http://dl.acm.org/images/ocrs-s.jpg" alt="Computing Reviews logo" border="0" style="vertical-align:middle"></a>
        
        
       		<ul style="list-style:disc; display:inline-block">
	            <li>Access <a href="ocr_review_main.cfm?CFID=105750247&CFTOKEN=50542134" target="_blank">critical reviews</a> of computing literature.</li>
            	<li><a href="http://www.computingreviews.com/Reviewer/"  target="_blank">Become a reviewer</a> for Computing Reviews</li>
            </ul>
        </div>
        
</div>



<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="comments" class="small-text"><SPAN class="heading">COMMENTS</SPAN></A></h1>
         
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<div>
<div>
	
	<p style="margin-left:5px;">
    <strong>Be the first to comment</strong>
    	
          	To Post a comment please <a href="signin.cfm?CFID=105750247&CFTOKEN=50542134">sign in or create</a> a free Web account</a>
        
    
    
	 </p>
	   	
 
</div>


</div>

	
		<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="prox" class="small-text">Table of Contents</A></h1>
        
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" >

<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">ACM SIGGRAPH 2011 papers</h5>


<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>

<div style="clear:both">
    
        <div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><a href="citation.cfm?id=2019001&picked=prox&CFID=105750247&CFTOKEN=50542134" title="previous: SIGGRAPH '11"><img hspace="5" align="absmiddle" border="0" src="img/prev.gif" width="19" height="11" alt="previous" />previous proceeding</a> <span style="padding-left:5px;padding-right:5px;">|</span><a href="citation.cfm?id=2018996&picked=prox&CFID=105750247&CFTOKEN=50542134" title="Next: SIGGRAPH '11">next proceeding <img align="absmiddle" hspace="5" border="0" src="img/next.gif" width="19" height="11" alt="next" /></a></div>
        
</div>


 
<table class="text12" border="0">

  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Drawing, painting & stylization</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Adam Finkelstein 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964922&CFID=105750247&CFTOKEN=50542134">ShadowDraw: real-time user guidance for freehand drawing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442607456&CFID=105750247&CFTOKEN=50542134">Yong Jae Lee</a>, 
                        <a href="author_page.cfm?id=81300102901&CFID=105750247&CFTOKEN=50542134">C. Lawrence Zitnick</a>, 
                        <a href="author_page.cfm?id=81406592138&CFID=105750247&CFTOKEN=50542134">Michael F. Cohen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 27</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964922" title="DOI">10.1145/1964921.1964922</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964922&ftid=1006121&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964922&ftid=1073996&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow2" style="display:inline;"><br /><div style="display:inline">We present ShadowDraw, a system for guiding the freeform drawing of objects. As the user draws, ShadowDraw dynamically updates a shadow image underlying the user's strokes. The shadows are suggestive of object contours that guide the user as they ...</div></span>
          <span id="toHide2" style="display:none;"><br /><div style="display:inline"><p>We present ShadowDraw, a system for guiding the freeform drawing of objects. As the user draws, ShadowDraw dynamically updates a <i>shadow image</i> underlying the user's strokes. The shadows are suggestive of object contours that guide the user as they continue drawing. This paradigm is similar to tracing, with two major differences. First, we do not provide a single image from which the user can trace; rather ShadowDraw automatically blends relevant images from a large database to construct the shadows. Second, the system dynamically adapts to the user's drawings in real-time and produces suggestions accordingly. ShadowDraw works by efficiently matching local edge patches between the query, constructed from the current drawing, and a database of images. A hashing technique enforces both local and global similarity and provides sufficient speed for interactive feedback. Shadows are created by aggregating the edge maps from the best database matches, spatially weighted by their match scores. We test our approach with human subjects and show comparisons between the drawings that were produced with and without the system. The results show that our system produces more realistically proportioned line drawings.</p></div></span> <a id="expcoll2" href="JavaScript: expandcollapse('expcoll2',2)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964923&CFID=105750247&CFTOKEN=50542134">OverCoat: an implicit canvas for 3D painting</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335497130&CFID=105750247&CFTOKEN=50542134">Johannes Schmid</a>, 
                        <a href="author_page.cfm?id=81487647580&CFID=105750247&CFTOKEN=50542134">Martin Sebastian Senn</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105750247&CFTOKEN=50542134">Markus Gross</a>, 
                        <a href="author_page.cfm?id=81100099182&CFID=105750247&CFTOKEN=50542134">Robert W. Sumner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 28</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964923" title="DOI">10.1145/1964921.1964923</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964923&ftid=1006122&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow3" style="display:inline;"><br /><div style="display:inline">We present a technique to generalize the 2D painting metaphor to 3D that allows the artist to treat the full 3D space as a canvas. Strokes painted in the 2D viewport window must be embedded in 3D space in a way that gives creative freedom to the artist ...</div></span>
          <span id="toHide3" style="display:none;"><br /><div style="display:inline"><p>We present a technique to generalize the 2D painting metaphor to 3D that allows the artist to treat the full 3D space as a canvas. Strokes painted in the 2D viewport window must be embedded in 3D space in a way that gives creative freedom to the artist while maintaining an acceptable level of controllability. We address this challenge by proposing a canvas concept defined implicitly by a 3D scalar field. The artist shapes the implicit canvas by creating approximate 3D proxy geometry. An optimization procedure is then used to embed painted strokes in space by satisfying different objective criteria defined on the scalar field. This functionality allows us to implement tools for painting along level set surfaces or across different level sets. Our method gives the power of fine-tuning the implicit canvas to the artist using a unified painting/sculpting metaphor. A sculpting tool can be used to paint into the implicit canvas. Rather than adding color, this tool creates a local change in the scalar field that results in outward or inward protrusions along the field's gradient direction. We address a visibility ambiguity inherent in 3D stroke rendering with a depth offsetting method that is well suited for hardware acceleration. We demonstrate results with a number of 3D paintings that exhibit effects difficult to realize with existing systems.</p></div></span> <a id="expcoll3" href="JavaScript: expandcollapse('expcoll3',3)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964924&CFID=105750247&CFTOKEN=50542134">A programmable system for artistic volumetric lighting</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81319498527&CFID=105750247&CFTOKEN=50542134">Derek Nowrouzezahrai</a>, 
                        <a href="author_page.cfm?id=81487643872&CFID=105750247&CFTOKEN=50542134">Jared Johnson</a>, 
                        <a href="author_page.cfm?id=81100351513&CFID=105750247&CFTOKEN=50542134">Andrew Selle</a>, 
                        <a href="author_page.cfm?id=81466647309&CFID=105750247&CFTOKEN=50542134">Dylan Lacewell</a>, 
                        <a href="author_page.cfm?id=81466648514&CFID=105750247&CFTOKEN=50542134">Michael Kaschalk</a>, 
                        <a href="author_page.cfm?id=81100389194&CFID=105750247&CFTOKEN=50542134">Wojciech Jarosz</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 29</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964924" title="DOI">10.1145/1964921.1964924</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964924&ftid=1006123&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow4" style="display:inline;"><br /><div style="display:inline">We present a method for generating art-directable volumetric effects, ranging from physically-accurate to non-physical results. Our system mimics the way experienced artists think about volumetric effects by using an intuitive lighting primitive, and ...</div></span>
          <span id="toHide4" style="display:none;"><br /><div style="display:inline"><p>We present a method for generating art-directable volumetric effects, ranging from physically-accurate to non-physical results. Our system mimics the way experienced artists think about volumetric effects by using an intuitive lighting primitive, and decoupling the <i>modeling</i> and <i>shading</i> of this primitive. To accomplish this, we generalize the physically-based photon beams method to allow arbitrarily programmable simulation and shading phases. This provides an intuitive design space for artists to rapidly explore a wide range of physically-based as well as plausible, but exaggerated, volumetric effects. We integrate our approach into a real-world production pipeline and couple our volumetric effects to surface shading.</p></div></span> <a id="expcoll4" href="JavaScript: expandcollapse('expcoll4',4)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964925&CFID=105750247&CFTOKEN=50542134">Coherent noise for non-photorealistic rendering</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81486657459&CFID=105750247&CFTOKEN=50542134">Michael Kass</a>, 
                        <a href="author_page.cfm?id=81487653192&CFID=105750247&CFTOKEN=50542134">Davide Pesare</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 30</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964925" title="DOI">10.1145/1964921.1964925</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964925&ftid=1006124&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964925&ftid=1073997&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow5" style="display:inline;"><br /><div style="display:inline">A wide variety of non-photorealistic rendering techniques make use of random variation in the placement or appearance of primitives. In order to avoid the "shower-door" effect, this random variation should move with the objects in the scene. Here we ...</div></span>
          <span id="toHide5" style="display:none;"><br /><div style="display:inline"><p>A wide variety of non-photorealistic rendering techniques make use of random variation in the placement or appearance of primitives. In order to avoid the "shower-door" effect, this random variation should move with the objects in the scene. Here we present <i>coherent noise</i> tailored to this purpose. We compute the coherent noise with a specialized filter that uses the depth and velocity fields of a source sequence. The computation is fast and suitable for interactive applications like games.</p></div></span> <a id="expcoll5" href="JavaScript: expandcollapse('expcoll5',5)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Capturing & modeling humans</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Karen Liu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964926&CFID=105750247&CFTOKEN=50542134">Motion capture from body-mounted cameras</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81384604905&CFID=105750247&CFTOKEN=50542134">Takaaki Shiratori</a>, 
                        <a href="author_page.cfm?id=81453633049&CFID=105750247&CFTOKEN=50542134">Hyun Soo Park</a>, 
                        <a href="author_page.cfm?id=81100541669&CFID=105750247&CFTOKEN=50542134">Leonid Sigal</a>, 
                        <a href="author_page.cfm?id=81100630001&CFID=105750247&CFTOKEN=50542134">Yaser Sheikh</a>, 
                        <a href="author_page.cfm?id=81100049661&CFID=105750247&CFTOKEN=50542134">Jessica K. Hodgins</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 31</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964926" title="DOI">10.1145/1964921.1964926</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964926&ftid=1006125&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow7" style="display:inline;"><br /><div style="display:inline">Motion capture technology generally requires that recordings be performed in a laboratory or closed stage setting with controlled lighting. This restriction precludes the capture of motions that require an outdoor setting or the traversal of large areas. ...</div></span>
          <span id="toHide7" style="display:none;"><br /><div style="display:inline"><p>Motion capture technology generally requires that recordings be performed in a laboratory or closed stage setting with controlled lighting. This restriction precludes the capture of motions that require an outdoor setting or the traversal of large areas. In this paper, we present the theory and practice of using body-mounted cameras to reconstruct the motion of a subject. Outward-looking cameras are attached to the limbs of the subject, and the joint angles and root pose are estimated through non-linear optimization. The optimization objective function incorporates terms for image matching error and temporal continuity of motion. Structure-from-motion is used to estimate the skeleton structure and to provide initialization for the non-linear optimization procedure. Global motion is estimated and drift is controlled by matching the captured set of videos to reference imagery. We show results in settings where capture would be difficult or impossible with traditional motion capture systems, including walking outside and swinging on monkey bars. The quality of the motion reconstruction is evaluated by comparing our results against motion capture data produced by a commercially available optical system.</p></div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964927&CFID=105750247&CFTOKEN=50542134">Video-based characters: creating new human performances from a multi-view video database</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81450592711&CFID=105750247&CFTOKEN=50542134">Feng Xu</a>, 
                        <a href="author_page.cfm?id=81385595421&CFID=105750247&CFTOKEN=50542134">Yebin Liu</a>, 
                        <a href="author_page.cfm?id=81365595377&CFID=105750247&CFTOKEN=50542134">Carsten Stoll</a>, 
                        <a href="author_page.cfm?id=81453653111&CFID=105750247&CFTOKEN=50542134">James Tompkin</a>, 
                        <a href="author_page.cfm?id=81487652899&CFID=105750247&CFTOKEN=50542134">Gaurav Bharaj</a>, 
                        <a href="author_page.cfm?id=81100171998&CFID=105750247&CFTOKEN=50542134">Qionghai Dai</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105750247&CFTOKEN=50542134">Hans-Peter Seidel</a>, 
                        <a href="author_page.cfm?id=81100016395&CFID=105750247&CFTOKEN=50542134">Jan Kautz</a>, 
                        <a href="author_page.cfm?id=81331505042&CFID=105750247&CFTOKEN=50542134">Christian Theobalt</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 32</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964927" title="DOI">10.1145/1964921.1964927</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964927&ftid=1006126&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964927&ftid=1073998&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow8" style="display:inline;"><br /><div style="display:inline">We present a method to synthesize plausible video sequences of humans according to user-defined body motions and viewpoints. We first capture a small database of multi-view video sequences of an actor performing various basic motions. This database needs ...</div></span>
          <span id="toHide8" style="display:none;"><br /><div style="display:inline"><p>We present a method to synthesize plausible video sequences of humans according to user-defined body motions and viewpoints. We first capture a small database of multi-view video sequences of an actor performing various basic motions. This database needs to be captured only once and serves as the input to our synthesis algorithm. We then apply a marker-less model-based performance capture approach to the entire database to obtain pose and geometry of the actor in each database frame. To create novel video sequences of the actor from the database, a user animates a 3D human skeleton with novel motion and viewpoints. Our technique then synthesizes a realistic video sequence of the actor performing the specified motion based only on the initial database. The first key component of our approach is a new efficient retrieval strategy to find appropriate spatio-temporally coherent database frames from which to synthesize target video frames. The second key component is a warping-based texture synthesis approach that uses the retrieved most-similar database frames to synthesize spatio-temporally coherent target video frames. For instance, this enables us to easily create video sequences of actors performing dangerous stunts without them being placed in harm's way. We show through a variety of result videos and a user study that we can synthesize realistic videos of people, even if the target motions and camera views are different from the database content.</p></div></span> <a id="expcoll8" href="JavaScript: expandcollapse('expcoll8',8)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Understanding shapes</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Tom Funkhouser 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964928&CFID=105750247&CFTOKEN=50542134">Exploration of continuous variability in collections of 3D shapes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335495785&CFID=105750247&CFTOKEN=50542134">Maks Ovsjanikov</a>, 
                        <a href="author_page.cfm?id=81100480929&CFID=105750247&CFTOKEN=50542134">Wilmot Li</a>, 
                        <a href="author_page.cfm?id=81452606669&CFID=105750247&CFTOKEN=50542134">Leonidas Guibas</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=105750247&CFTOKEN=50542134">Niloy J. Mitra</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 33</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964928" title="DOI">10.1145/1964921.1964928</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964928&ftid=1006127&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964928&ftid=1073999&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow10" style="display:inline;"><br /><div style="display:inline">As large public repositories of 3D shapes continue to grow, the amount of shape variability in such collections also increases, both in terms of the number of different classes of shapes, as well as the geometric variability of shapes within each class. ...</div></span>
          <span id="toHide10" style="display:none;"><br /><div style="display:inline"><p>As large public repositories of 3D shapes continue to grow, the amount of shape variability in such collections also increases, both in terms of the number of different classes of shapes, as well as the geometric variability of shapes within each class. While this gives users more choice for shape selection, it can be difficult to explore large collections and understand the range of variations amongst the shapes. Exploration is particularly challenging for public shape repositories, which are often only loosely tagged and contain neither point-based nor part-based correspondences. In this paper, we present a method for discovering and exploring continuous variability in a collection of 3D shapes without correspondences. Our method is based on a novel navigation interface that allows users to explore a collection of related shapes by deforming a base template shape through a set of intuitive deformation controls. We also help the user to select the most meaningful deformations using a novel technique for learning shape variability in terms of deformations of the template. Our technique assumes that the set of shapes lies near a low-dimensional manifold in a certain descriptor space, which allows us to avoid establishing correspondences between shapes, while being rotation and scaling invariant. We present results on several shape collections taken directly from public repositories.</p></div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964929&CFID=105750247&CFTOKEN=50542134">Characterizing structural relationships in scenes using graph kernels</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81332498586&CFID=105750247&CFTOKEN=50542134">Matthew Fisher</a>, 
                        <a href="author_page.cfm?id=81487650815&CFID=105750247&CFTOKEN=50542134">Manolis Savva</a>, 
                        <a href="author_page.cfm?id=81100482576&CFID=105750247&CFTOKEN=50542134">Pat Hanrahan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 34</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964929" title="DOI">10.1145/1964921.1964929</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964929&ftid=1006128&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964929&ftid=1074000&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow11" style="display:inline;"><br /><div style="display:inline">Modeling virtual environments is a time consuming and expensive task that is becoming increasingly popular for both professional and casual artists. The model density and complexity of the scenes representing these virtual environments is rising rapidly. ...</div></span>
          <span id="toHide11" style="display:none;"><br /><div style="display:inline"><p>Modeling virtual environments is a time consuming and expensive task that is becoming increasingly popular for both professional and casual artists. The model density and complexity of the scenes representing these virtual environments is rising rapidly. This trend suggests that data-mining a 3D scene corpus could be a very powerful tool enabling more efficient scene design. In this paper, we show how to represent scenes as graphs that encode models and their semantic relationships. We then define a kernel between these relationship graphs that compares common virtual substructures in two graphs and captures the similarity between their corresponding scenes. We apply this framework to several scene modeling problems, such as finding similar scenes, relevance feedback, and context-based model search. We show that incorporating structural relationships allows our method to provide a more relevant set of results when compared against previous approaches to model context search.</p></div></span> <a id="expcoll11" href="JavaScript: expandcollapse('expcoll11',11)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964930&CFID=105750247&CFTOKEN=50542134">Probabilistic reasoning for assembly-based 3D modeling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81430660091&CFID=105750247&CFTOKEN=50542134">Siddhartha Chaudhuri</a>, 
                        <a href="author_page.cfm?id=81335492224&CFID=105750247&CFTOKEN=50542134">Evangelos Kalogerakis</a>, 
                        <a href="author_page.cfm?id=81452606669&CFID=105750247&CFTOKEN=50542134">Leonidas Guibas</a>, 
                        <a href="author_page.cfm?id=81100662243&CFID=105750247&CFTOKEN=50542134">Vladlen Koltun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 35</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964930" title="DOI">10.1145/1964921.1964930</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964930&ftid=1006129&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964930&ftid=1074001&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow12" style="display:inline;"><br /><div style="display:inline">Assembly-based modeling is a promising approach to broadening the accessibility of 3D modeling. In assembly-based modeling, new models are assembled from shape components extracted from a database. A key challenge in assembly-based modeling is the identification ...</div></span>
          <span id="toHide12" style="display:none;"><br /><div style="display:inline"><p>Assembly-based modeling is a promising approach to broadening the accessibility of 3D modeling. In assembly-based modeling, new models are assembled from shape components extracted from a database. A key challenge in assembly-based modeling is the identification of relevant components to be presented to the user. In this paper, we introduce a probabilistic reasoning approach to this problem. Given a repository of shapes, our approach learns a probabilistic graphical model that encodes semantic and geometric relationships among shape components. The probabilistic model is used to present components that are semantically and stylistically compatible with the 3D model that is being assembled. Our experiments indicate that the probabilistic model increases the relevance of presented components.</p></div></span> <a id="expcoll12" href="JavaScript: expandcollapse('expcoll12',12)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Contact & constraints</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Adam Bargteil 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964931&CFID=105750247&CFTOKEN=50542134">Eulerian solid simulation with contact</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466645026&CFID=105750247&CFTOKEN=50542134">David I. W. Levin</a>, 
                        <a href="author_page.cfm?id=81487654533&CFID=105750247&CFTOKEN=50542134">Joshua Litven</a>, 
                        <a href="author_page.cfm?id=81487651368&CFID=105750247&CFTOKEN=50542134">Garrett L. Jones</a>, 
                        <a href="author_page.cfm?id=81335498230&CFID=105750247&CFTOKEN=50542134">Shinjiro Sueda</a>, 
                        <a href="author_page.cfm?id=81100642559&CFID=105750247&CFTOKEN=50542134">Dinesh K. Pai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 36</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964931" title="DOI">10.1145/1964921.1964931</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964931&ftid=1006130&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964931&ftid=1074002&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow14" style="display:inline;"><br /><div style="display:inline">Simulating viscoelastic solids undergoing large, nonlinear deformations in close contact is challenging. In addition to inter-object contact, methods relying on Lagrangian discretizations must handle degenerate cases by explicitly remeshing or resampling ...</div></span>
          <span id="toHide14" style="display:none;"><br /><div style="display:inline"><p>Simulating viscoelastic solids undergoing large, nonlinear deformations in close contact is challenging. In addition to inter-object contact, methods relying on Lagrangian discretizations must handle degenerate cases by explicitly remeshing or resampling the object. Eulerian methods, which discretize space itself, provide an interesting alternative due to the fixed nature of the discretization. In this paper we present a new Eulerian method for viscoelastic materials that features a collision detection and resolution scheme which does not require explicit surface tracking to achieve accurate collision response. Time-stepping with contact is performed by the efficient solution of large sparse quadratic programs; this avoids constraint sticking and other difficulties. Simulation and collision processing can share the same uniform grid, making the algorithm easy to parallelize. We demonstrate an implementation of all the steps of the algorithm on the GPU. The method is effective for simulation of complicated contact scenarios involving multiple highly deformable objects, and can directly simulate volumetric models obtained from medical imaging techniques such as CT and MRI.</p></div></span> <a id="expcoll14" href="JavaScript: expandcollapse('expcoll14',14)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964932&CFID=105750247&CFTOKEN=50542134">Efficient elasticity for character skinning with contact and collisions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440608792&CFID=105750247&CFTOKEN=50542134">Aleka McAdams</a>, 
                        <a href="author_page.cfm?id=81460644232&CFID=105750247&CFTOKEN=50542134">Yongning Zhu</a>, 
                        <a href="author_page.cfm?id=81100351513&CFID=105750247&CFTOKEN=50542134">Andrew Selle</a>, 
                        <a href="author_page.cfm?id=81487655635&CFID=105750247&CFTOKEN=50542134">Mark Empey</a>, 
                        <a href="author_page.cfm?id=81100289069&CFID=105750247&CFTOKEN=50542134">Rasmus Tamstorf</a>, 
                        <a href="author_page.cfm?id=81100222891&CFID=105750247&CFTOKEN=50542134">Joseph Teran</a>, 
                        <a href="author_page.cfm?id=81409594691&CFID=105750247&CFTOKEN=50542134">Eftychios Sifakis</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 37</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964932" title="DOI">10.1145/1964921.1964932</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964932&ftid=1006131&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow15" style="display:inline;"><br /><div style="display:inline">We present a new algorithm for near-interactive simulation of skeleton driven, high resolution elasticity models. Our methodology is used for soft tissue deformation in character animation. The algorithm is based on a novel discretization of corotational ...</div></span>
          <span id="toHide15" style="display:none;"><br /><div style="display:inline"><p>We present a new algorithm for near-interactive simulation of skeleton driven, high resolution elasticity models. Our methodology is used for soft tissue deformation in character animation. The algorithm is based on a novel discretization of corotational elasticity over a hexahedral lattice. Within this framework we enforce positive definiteness of the stiffness matrix to allow efficient quasistatics and dynamics. In addition, we present a multigrid method that converges with very high efficiency. Our design targets performance through parallelism using a fully vectorized and branch-free SVD algorithm as well as a stable one-point quadrature scheme. Since body collisions, self collisions and soft-constraints are necessary for real-world examples, we present a simple framework for enforcing them. The whole approach is demonstrated in an end-to-end production-level character skinning system.</p></div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964933&CFID=105750247&CFTOKEN=50542134">Toward high-quality modal contact sound</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414596051&CFID=105750247&CFTOKEN=50542134">Changxi Zheng</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=105750247&CFTOKEN=50542134">Doug L. James</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 38</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964933" title="DOI">10.1145/1964921.1964933</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964933&ftid=1006132&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964933&ftid=1074003&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow16" style="display:inline;"><br /><div style="display:inline">Contact sound models based on linear modal analysis are commonly used with rigid body dynamics. Unfortunately, treating vibrating objects as "rigid" during collision and contact processing fundamentally limits the range of sounds that can be computed, ...</div></span>
          <span id="toHide16" style="display:none;"><br /><div style="display:inline"><p>Contact sound models based on linear modal analysis are commonly used with rigid body dynamics. Unfortunately, treating vibrating objects as "rigid" during collision and contact processing fundamentally limits the range of sounds that can be computed, and contact solvers for rigid body animation can be ill-suited for modal contact sound synthesis, producing various sound artifacts. In this paper, we resolve modal vibrations in both collision and frictional contact processing stages, thereby enabling non-rigid sound phenomena such as micro-collisions, vibrational energy exchange, and chattering. We propose a frictional multibody contact formulation and modified Staggered Projections solver which is well-suited to sound rendering and avoids noise artifacts associated with spatial and temporal contact-force fluctuations which plague prior methods. To enable practical animation and sound synthesis of numerous bodies with many coupled modes, we propose a novel asynchronous integrator with model-level adaptivity built into the frictional contact solver. Vibrational contact damping is modeled to approximate contact-dependent sound dissipation. Results are provided that demonstrate high-quality contact resolution with sound.</p></div></span> <a id="expcoll16" href="JavaScript: expandcollapse('expcoll16',16)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964934&CFID=105750247&CFTOKEN=50542134">Large-scale dynamic simulation of highly constrained strands</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335498230&CFID=105750247&CFTOKEN=50542134">Shinjiro Sueda</a>, 
                        <a href="author_page.cfm?id=81487651368&CFID=105750247&CFTOKEN=50542134">Garrett L. Jones</a>, 
                        <a href="author_page.cfm?id=81466645026&CFID=105750247&CFTOKEN=50542134">David I. W. Levin</a>, 
                        <a href="author_page.cfm?id=81100642559&CFID=105750247&CFTOKEN=50542134">Dinesh K. Pai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 39</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964934" title="DOI">10.1145/1964921.1964934</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964934&ftid=1006133&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964934&ftid=1074008&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow17" style="display:inline;"><br /><div style="display:inline">A significant challenge in applications of computer animation is the simulation of ropes, cables, and other highly constrained strandlike physical curves. Such scenarios occur frequently, for instance, when a strand wraps around rigid bodies or passes ...</div></span>
          <span id="toHide17" style="display:none;"><br /><div style="display:inline"><p>A significant challenge in applications of computer animation is the simulation of ropes, cables, and other highly constrained strandlike physical curves. Such scenarios occur frequently, for instance, when a strand wraps around rigid bodies or passes through narrow sheaths. Purely Lagrangian methods designed for less constrained applications such as hair simulation suffer from difficulties in these important cases. To overcome this, we introduce a new framework that combines Lagrangian and Eulerian approaches. The two key contributions are the <i>reduced node</i>, whose degrees of freedom precisely match the constraint, and the <i>Eulerian node</i>, which allows constraint handling that is independent of the initial discretization of the strand. The resulting system generates robust, efficient, and accurate simulations of massively constrained systems of rigid bodies and strands.</p></div></span> <a id="expcoll17" href="JavaScript: expandcollapse('expcoll17',17)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Tone editing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Karol Myszkowski 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964935&CFID=105750247&CFTOKEN=50542134">HDR-VDP-2: a calibrated visual metric for visibility and quality predictions in all luminance conditions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487643988&CFID=105750247&CFTOKEN=50542134">Rafat Mantiuk</a>, 
                        <a href="author_page.cfm?id=81487652020&CFID=105750247&CFTOKEN=50542134">Kil Joong Kim</a>, 
                        <a href="author_page.cfm?id=81335496600&CFID=105750247&CFTOKEN=50542134">Allan G. Rempel</a>, 
                        <a href="author_page.cfm?id=81100644737&CFID=105750247&CFTOKEN=50542134">Wolfgang Heidrich</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 40</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964935" title="DOI">10.1145/1964921.1964935</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964935&ftid=1006134&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964935&ftid=1074004&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow19" style="display:inline;"><br /><div style="display:inline">Visual metrics can play an important role in the evaluation of novel lighting, rendering, and imaging algorithms. Unfortunately, current metrics only work well for narrow intensity ranges, and do not correlate well with experimental data outside these ...</div></span>
          <span id="toHide19" style="display:none;"><br /><div style="display:inline"><p>Visual metrics can play an important role in the evaluation of novel lighting, rendering, and imaging algorithms. Unfortunately, current metrics only work well for narrow intensity ranges, and do not correlate well with experimental data outside these ranges. To address these issues, we propose a visual metric for predicting visibility (discrimination) and quality (mean-opinion-score). The metric is based on a new visual model for all luminance conditions, which has been derived from new contrast sensitivity measurements. The model is calibrated and validated against several contrast discrimination data sets, and image quality databases (LIVE and TID2008). The visibility metric is shown to provide much improved predictions as compared to the original HDR-VDP and VDP metrics, especially for low luminance conditions. The image quality predictions are comparable to or better than for the MS-SSIM, which is considered one of the most successful quality metrics. The code of the proposed metric is available on-line.</p></div></span> <a id="expcoll19" href="JavaScript: expandcollapse('expcoll19',19)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964936&CFID=105750247&CFTOKEN=50542134">A versatile HDR video production system</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487643279&CFID=105750247&CFTOKEN=50542134">Michael D. Tocci</a>, 
                        <a href="author_page.cfm?id=81487652768&CFID=105750247&CFTOKEN=50542134">Chris Kiser</a>, 
                        <a href="author_page.cfm?id=81487654941&CFID=105750247&CFTOKEN=50542134">Nora Tocci</a>, 
                        <a href="author_page.cfm?id=81100399113&CFID=105750247&CFTOKEN=50542134">Pradeep Sen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 41</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964936" title="DOI">10.1145/1964921.1964936</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964936&ftid=1006135&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964936&ftid=1074005&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow20" style="display:inline;"><br /><div style="display:inline">Although High Dynamic Range (HDR) imaging has been the subject of significant research over the past fifteen years, the goal of acquiring cinema-quality HDR images of fast-moving scenes using available components has not yet been achieved. In this work, ...</div></span>
          <span id="toHide20" style="display:none;"><br /><div style="display:inline"><p>Although High Dynamic Range (HDR) imaging has been the subject of significant research over the past fifteen years, the goal of acquiring cinema-quality HDR images of fast-moving scenes using available components has not yet been achieved. In this work, we present an optical architecture for HDR imaging that allows simultaneous capture of high, medium, and low-exposure images on three sensors at high fidelity with efficient use of the available light. We also present an HDR merging algorithm to complement this architecture, which avoids undesired artifacts when there is a large exposure difference between the images. We implemented a prototype high-definition HDR-video system and we present still frames from the acquired HDR video, tonemapped with various techniques.</p></div></span> <a id="expcoll20" href="JavaScript: expandcollapse('expcoll20',20)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964937&CFID=105750247&CFTOKEN=50542134">Perceptually based tone mapping for low-light conditions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100166834&CFID=105750247&CFTOKEN=50542134">Adam G. Kirk</a>, 
                        <a href="author_page.cfm?id=81100311781&CFID=105750247&CFTOKEN=50542134">James F. O'Brien</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 42</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964937" title="DOI">10.1145/1964921.1964937</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964937&ftid=1016539&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964937&ftid=1074006&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow21" style="display:inline;"><br /><div style="display:inline">In this paper we present a perceptually based algorithm for modeling the color shift that occurs for human viewers in low-light scenes. Known as the Purkinje effect, this color shift occurs as the eye transitions from photopic, cone-mediated vision in ...</div></span>
          <span id="toHide21" style="display:none;"><br /><div style="display:inline"><p>In this paper we present a perceptually based algorithm for modeling the color shift that occurs for human viewers in low-light scenes. Known as the Purkinje effect, this color shift occurs as the eye transitions from photopic, cone-mediated vision in well-lit scenes to scotopic, rod-mediated vision in dark scenes. At intermediate light levels vision is mesopic with both the rods and cones active. Although the rods have a spectral response distinct from the cones, they still share the same neural pathways. As light levels decrease and the rods become increasingly active they cause a perceived shift in color. We model this process so that we can compute perceived colors for mesopic and scotopic scenes from spectral image data. We also describe how the effect can be approximated from standard high dynamic range RGB images. Once we have determined rod and cone responses, we map them to RGB values that can be displayed on a standard monitor to elicit the intended color perception when viewed photopically. Our method focuses on computing the color shift associated with low-light conditions and leverages current HDR techniques to control the image's dynamic range. We include results generated from both spectral and RGB input images.</p></div></span> <a id="expcoll21" href="JavaScript: expandcollapse('expcoll21',21)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964938&CFID=105750247&CFTOKEN=50542134">Illumination decomposition for material recoloring with consistent interreflections</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100112519&CFID=105750247&CFTOKEN=50542134">Robert Carroll</a>, 
                        <a href="author_page.cfm?id=81100019585&CFID=105750247&CFTOKEN=50542134">Ravi Ramamoorthi</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=105750247&CFTOKEN=50542134">Maneesh Agrawala</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 43</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964938" title="DOI">10.1145/1964921.1964938</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964938&ftid=1006137&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964938&ftid=1074007&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow22" style="display:inline;"><br /><div style="display:inline">Changing the color of an object is a basic image editing operation, but a high quality result must also preserve natural shading. A common approach is to first compute reflectance and illumination intrinsic images. Reflectances can then be edited independently, ...</div></span>
          <span id="toHide22" style="display:none;"><br /><div style="display:inline"><p>Changing the color of an object is a basic image editing operation, but a high quality result must also preserve natural shading. A common approach is to first compute reflectance and illumination intrinsic images. Reflectances can then be edited independently, and recomposed with the illumination. However, manipulating only the reflectance color does not account for diffuse interreflections, and can result in inconsistent shading in the edited image. We propose an approach for further decomposing illumination into direct lighting, and indirect diffuse illumination from each material. This decomposition allows us to change indirect illumination from an individual material independently, so it matches the modified reflectance color. To address the underconstrained problem of decomposing illumination into multiple components, we take advantage of its smooth nature, as well as user-provided constraints. We demonstrate our approach on a number of examples, where we consistently edit material colors and the associated interreflections.</p></div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Capturing geometry & appearance</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Mark Levoy 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964939&CFID=105750247&CFTOKEN=50542134">Building volumetric appearance models of fabric using micro CT imaging</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440593109&CFID=105750247&CFTOKEN=50542134">Shuang Zhao</a>, 
                        <a href="author_page.cfm?id=81448598202&CFID=105750247&CFTOKEN=50542134">Wenzel Jakob</a>, 
                        <a href="author_page.cfm?id=81100238316&CFID=105750247&CFTOKEN=50542134">Steve Marschner</a>, 
                        <a href="author_page.cfm?id=81100081277&CFID=105750247&CFTOKEN=50542134">Kavita Bala</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 44</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964939" title="DOI">10.1145/1964921.1964939</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964939&ftid=1006138&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964939&ftid=1074009&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow24" style="display:inline;"><br /><div style="display:inline">The appearance of complex, thick materials like textiles is determined by their 3D structure, and they are incompletely described by surface reflection models alone. While volume scattering can produce highly realistic images of such materials, creating ...</div></span>
          <span id="toHide24" style="display:none;"><br /><div style="display:inline"><p>The appearance of complex, thick materials like textiles is determined by their 3D structure, and they are incompletely described by surface reflection models alone. While volume scattering can produce highly realistic images of such materials, creating the required volume density models is difficult. Procedural approaches require significant programmer effort and intuition to design specialpurpose algorithms for each material. Further, the resulting models lack the visual complexity of real materials with their naturally-arising irregularities.</p> <p>This paper proposes a new approach to acquiring volume models, based on density data from X-ray computed tomography (CT) scans and appearance data from photographs under uncontrolled illumination. To model a material, a CT scan is made, resulting in a scalar density volume. This 3D data is processed to extract orientation information and remove noise. The resulting density and orientation fields are used in an appearance matching procedure to define scattering properties in the volume that, when rendered, produce images with texture statistics that match the photographs. As our results show, this approach can easily produce volume appearance models with extreme detail, and at larger scales the distinctive textures and highlights of a range of very different fabrics like satin and velvet emerge automatically---all based simply on having accurate mesoscale geometry.</p></div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964940&CFID=105750247&CFTOKEN=50542134">Pocket reflectometry</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100597775&CFID=105750247&CFTOKEN=50542134">Peiran Ren</a>, 
                        <a href="author_page.cfm?id=81100233349&CFID=105750247&CFTOKEN=50542134">Jiaping Wang</a>, 
                        <a href="author_page.cfm?id=81100167784&CFID=105750247&CFTOKEN=50542134">John Snyder</a>, 
                        <a href="author_page.cfm?id=81314492380&CFID=105750247&CFTOKEN=50542134">Xin Tong</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=105750247&CFTOKEN=50542134">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 45</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964940" title="DOI">10.1145/1964921.1964940</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964940&ftid=1006139&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964940&ftid=1074010&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow25" style="display:inline;"><br /><div style="display:inline">We present a simple, fast solution for reflectance acquisition using tools that fit into a pocket. Our method captures video of a flat target surface from a fixed video camera lit by a hand-held, moving, linear light source. After processing, we obtain ...</div></span>
          <span id="toHide25" style="display:none;"><br /><div style="display:inline"><p>We present a simple, fast solution for reflectance acquisition using tools that fit into a pocket. Our method captures video of a flat target surface from a fixed video camera lit by a hand-held, moving, linear light source. After processing, we obtain an SVBRDF.</p> <p>We introduce a <i>BRDF chart</i>, analogous to a color "checker" chart, which arranges a set of known-BRDF reference tiles over a small card. A sequence of light responses from the chart tiles as well as from points on the target is captured and matched to reconstruct the target's appearance.</p> <p>We develop a new algorithm for BRDF reconstruction which works directly on these LDR responses, without knowing the light or camera position, or acquiring HDR lighting. It compensates for spatial variation caused by the local (finite distance) camera and light position by warping responses over time to align them to a specular reference. After alignment, we find an optimal linear combination of the Lambertian and purely specular reference responses to match each target point's response. The same weights are then applied to the corresponding (known) reference BRDFs to reconstruct the target point's BRDF. We extend the basic algorithm to also recover varying surface normals by adding two spherical caps for diffuse and specular references to the BRDF chart.</p> <p>We demonstrate convincing results obtained after less than 30 seconds of data capture, using commercial mobile phone cameras in a casual environment.</p></div></span> <a id="expcoll25" href="JavaScript: expandcollapse('expcoll25',25)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964941&CFID=105750247&CFTOKEN=50542134">Microgeometry capture using an elastomeric sensor</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442593869&CFID=105750247&CFTOKEN=50542134">Micah K. Johnson</a>, 
                        <a href="author_page.cfm?id=81351604051&CFID=105750247&CFTOKEN=50542134">Forrester Cole</a>, 
                        <a href="author_page.cfm?id=81442599480&CFID=105750247&CFTOKEN=50542134">Alvin Raj</a>, 
                        <a href="author_page.cfm?id=81100466478&CFID=105750247&CFTOKEN=50542134">Edward H. Adelson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 46</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964941" title="DOI">10.1145/1964921.1964941</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964941&ftid=1006140&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964941&ftid=1074011&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow26" style="display:inline;"><br /><div style="display:inline">We describe a system for capturing microscopic surface geometry. The system extends the retrographic sensor [Johnson and Adelson 2009] to the microscopic domain, demonstrating spatial resolution as small as 2 microns. In contrast to existing microgeometry ...</div></span>
          <span id="toHide26" style="display:none;"><br /><div style="display:inline"><p>We describe a system for capturing microscopic surface geometry. The system extends the retrographic sensor [Johnson and Adelson 2009] to the microscopic domain, demonstrating spatial resolution as small as 2 microns. In contrast to existing microgeometry capture techniques, the system is not affected by the optical characteristics of the surface being measured---it captures the same geometry whether the object is matte, glossy, or transparent. In addition, the hardware design allows for a variety of form factors, including a hand-held device that can be used to capture high-resolution surface geometry in the field. We achieve these results with a combination of improved sensor materials, illumination design, and reconstruction algorithm, as compared to the original sensor of Johnson and Adelson [2009].</p></div></span> <a id="expcoll26" href="JavaScript: expandcollapse('expcoll26',26)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964942&CFID=105750247&CFTOKEN=50542134">CATRA: interactive measuring and modeling of cataracts</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442619125&CFID=105750247&CFTOKEN=50542134">Vitor F. Pamplona</a>, 
                        <a href="author_page.cfm?id=81453624435&CFID=105750247&CFTOKEN=50542134">Erick B. Passos</a>, 
                        <a href="author_page.cfm?id=81100422084&CFID=105750247&CFTOKEN=50542134">Jan Zizka</a>, 
                        <a href="author_page.cfm?id=81100516478&CFID=105750247&CFTOKEN=50542134">Manuel M. Oliveira</a>, 
                        <a href="author_page.cfm?id=81487645512&CFID=105750247&CFTOKEN=50542134">Everett Lawson</a>, 
                        <a href="author_page.cfm?id=81339494999&CFID=105750247&CFTOKEN=50542134">Esteban Clua</a>, 
                        <a href="author_page.cfm?id=81100022847&CFID=105750247&CFTOKEN=50542134">Ramesh Raskar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 47</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964942" title="DOI">10.1145/1964921.1964942</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964942&ftid=1006141&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964942&ftid=1074012&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow27" style="display:inline;"><br /><div style="display:inline">We introduce an interactive method to assess cataracts in the human eye by crafting an optical solution that measures the perceptual impact of forward scattering on the foveal region. Current solutions rely on highly-trained clinicians to check the back ...</div></span>
          <span id="toHide27" style="display:none;"><br /><div style="display:inline"><p>We introduce an interactive method to assess cataracts in the human eye by crafting an optical solution that measures the perceptual impact of forward scattering on the foveal region. Current solutions rely on highly-trained clinicians to check the back scattering in the crystallin lens and test their predictions on visual acuity tests. Close-range parallax barriers create collimated beams of light to scan through sub-apertures, scattering light as it strikes a cataract. User feedback generates maps for opacity, attenuation, contrast and sub-aperture point-spread functions. The goal is to allow a general audience to operate a portable high-contrast light-field display to gain a meaningful understanding of their own visual conditions. User evaluations and validation with modified camera optics are performed. Compiled data is used to reconstruct the individual's cataract-affected view, offering a novel approach for capturing information for screening, diagnostic, and clinical analysis.</p></div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Sampling & noise</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Sylvain Lefebvre 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964943&CFID=105750247&CFTOKEN=50542134">Blue-noise point sampling using kernel density model</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100376142&CFID=105750247&CFTOKEN=50542134">Raanan Fattal</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 48</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964943" title="DOI">10.1145/1964921.1964943</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964943&ftid=1006142&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964943&ftid=1074013&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow29" style="display:inline;"><br /><div style="display:inline">Stochastic point distributions with blue-noise spectrum are used extensively in computer graphics for various applications such as avoiding aliasing artifacts in ray tracing, halftoning, stippling, etc. In this paper we present a new approach for generating ...</div></span>
          <span id="toHide29" style="display:none;"><br /><div style="display:inline"><p>Stochastic point distributions with blue-noise spectrum are used extensively in computer graphics for various applications such as avoiding aliasing artifacts in ray tracing, halftoning, stippling, etc. In this paper we present a new approach for generating point sets with high-quality blue noise properties that formulates the problem using a statistical mechanics interacting particle model. Points distributions are generated by sampling this model. This new formulation of the problem unifies randomness with the requirement for equidistant point spacing, responsible for the enhanced blue noise spectral properties. We derive a highly efficient multi-scale sampling scheme for drawing random point distributions from this model. The new scheme avoids the <i>critical slowing down</i> phenomena that plagues this type of models. This derivation is accompanied by a model-specific analysis.</p> <p>Altogether, our approach generates high-quality point distributions, supports spatially-varying spatial point density, and runs in time that is linear in the number of points generated.</p></div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964944&CFID=105750247&CFTOKEN=50542134">Efficient maximal poisson-disk sampling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440623254&CFID=105750247&CFTOKEN=50542134">Mohamed S. Ebeida</a>, 
                        <a href="author_page.cfm?id=81100099492&CFID=105750247&CFTOKEN=50542134">Andrew A. Davidson</a>, 
                        <a href="author_page.cfm?id=81385599174&CFID=105750247&CFTOKEN=50542134">Anjul Patney</a>, 
                        <a href="author_page.cfm?id=81100540441&CFID=105750247&CFTOKEN=50542134">Patrick M. Knupp</a>, 
                        <a href="author_page.cfm?id=81100359819&CFID=105750247&CFTOKEN=50542134">Scott A. Mitchell</a>, 
                        <a href="author_page.cfm?id=81100458295&CFID=105750247&CFTOKEN=50542134">John D. Owens</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 49</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964944" title="DOI">10.1145/1964921.1964944</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964944&ftid=1006143&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964944&ftid=1074014&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow30" style="display:inline;"><br /><div style="display:inline">We solve the problem of generating a uniform Poisson-disk sampling that is both maximal and unbiased over bounded non-convex domains. To our knowledge this is the first provably correct algorithm with time and space dependent only on the ...</div></span>
          <span id="toHide30" style="display:none;"><br /><div style="display:inline"><p>We solve the problem of generating a uniform Poisson-disk sampling that is both <b>maximal</b> and <b>unbiased</b> over bounded non-convex domains. To our knowledge this is the first provably correct algorithm with time and space dependent only on the number of points produced. Our method has two phases, both based on classical dart-throwing. The first phase uses a background grid of square cells to rapidly create an unbiased, near-maximal covering of the domain. The second phase completes the maximal covering by calculating the connected components of the remaining uncovered voids, and by using their geometry to efficiently place unbiased samples that cover them. The second phase converges quickly, overcoming a common difficulty in dart-throwing methods. The deterministic memory is <i>O</i>(<i>n</i>) and the expected running time is <i>O</i>(<i>n</i> log <i>n</i>), where <i>n</i> is the output size, the number of points in the final sample. Our serial implementation verifies that the log <i>n</i> dependence is minor, and nearly <i>O</i>(<i>n</i>) performance for both time and memory is achieved in practice. We also present a parallel implementation on GPUs to demonstrate the parallel-friendly nature of our method, which achieves 2.4x the performance of our serial version.</p></div></span> <a id="expcoll30" href="JavaScript: expandcollapse('expcoll30',30)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964945&CFID=105750247&CFTOKEN=50542134">Differential domain analysis for non-uniform sampling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81452594229&CFID=105750247&CFTOKEN=50542134">Li-Yi Wei</a>, 
                        <a href="author_page.cfm?id=81408591714&CFID=105750247&CFTOKEN=50542134">Rui Wang</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 50</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964945" title="DOI">10.1145/1964921.1964945</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964945&ftid=1006144&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964945&ftid=1074015&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow31" style="display:inline;"><br /><div style="display:inline">Sampling is a core component for many graphics applications including rendering, imaging, animation, and geometry processing. The efficacy of these applications often crucially depends upon the distribution quality of the underlying samples. While uniform ...</div></span>
          <span id="toHide31" style="display:none;"><br /><div style="display:inline"><p>Sampling is a core component for many graphics applications including rendering, imaging, animation, and geometry processing. The efficacy of these applications often crucially depends upon the distribution quality of the underlying samples. While uniform sampling can be analyzed by using existing spatial and spectral methods, these cannot be easily extended to general non-uniform settings, such as adaptive, anisotropic, or non-Euclidean domains.</p> <p>We present new methods for analyzing non-uniform sample distributions. Our key insight is that standard Fourier analysis, which depends on samples' spatial locations, can be reformulated into an equivalent form that depends only on the distribution of their location <i>differentials</i>. We call this differential domain analysis. The main benefit of this reformulation is that it bridges the fundamental connection between the samples' spatial statistics and their spectral properties. In addition, it allows us to generalize our method with different computation kernels and differential measurements. Using this analysis, we can quantitatively measure the spatial and spectral properties of various non-uniform sample distributions, including adaptive, anisotropic, and non-Euclidean domains.</p></div></span> <a id="expcoll31" href="JavaScript: expandcollapse('expcoll31',31)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964946&CFID=105750247&CFTOKEN=50542134">Filtering solid Gabor noise</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81300379401&CFID=105750247&CFTOKEN=50542134">Ares Lagae</a>, 
                        <a href="author_page.cfm?id=81100408270&CFID=105750247&CFTOKEN=50542134">George Drettakis</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 51</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964946" title="DOI">10.1145/1964921.1964946</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964946&ftid=1006145&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964946&ftid=1074016&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow32" style="display:inline;"><br /><div style="display:inline">Solid noise is a fundamental tool in computer graphics. Surprisingly, no existing noise function supports both high-quality antialiasing and continuity across sharp edges. In this paper we show that a slicing approach is required to preserve continuity ...</div></span>
          <span id="toHide32" style="display:none;"><br /><div style="display:inline"><p>Solid noise is a fundamental tool in computer graphics. Surprisingly, no existing noise function supports both high-quality antialiasing and continuity across sharp edges. In this paper we show that a slicing approach is required to preserve continuity across sharp edges, and we present a new noise function that supports anisotropic filtering of sliced solid noise. This is made possible by individually filtering the slices of Gabor kernels, which requires the proper treatment of phase. This in turn leads to the introduction of the phase-augmented Gabor kernel and random-phase Gabor noise, our new noise function. We demonstrate that our new noise function supports both high-quality anti-aliasing and continuity across sharp edges, as well as anisotropy.</p></div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Geometry Acquisition</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Paolo Cignoni 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964947&CFID=105750247&CFTOKEN=50542134">GlobFit: consistently fitting primitives by discovering global relations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466641543&CFID=105750247&CFTOKEN=50542134">Yangyan Li</a>, 
                        <a href="author_page.cfm?id=81487651262&CFID=105750247&CFTOKEN=50542134">Xiaokun Wu</a>, 
                        <a href="author_page.cfm?id=81487654200&CFID=105750247&CFTOKEN=50542134">Yiorgos Chrysathou</a>, 
                        <a href="author_page.cfm?id=81100404504&CFID=105750247&CFTOKEN=50542134">Andrei Sharf</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105750247&CFTOKEN=50542134">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=105750247&CFTOKEN=50542134">Niloy J. Mitra</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 52</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964947" title="DOI">10.1145/1964921.1964947</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964947&ftid=1006146&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964947&ftid=1074017&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow34" style="display:inline;"><br /><div style="display:inline">Given a noisy and incomplete point set, we introduce a method that simultaneously recovers a set of locally fitted primitives along with their global mutual relations. We operate under the assumption that the data corresponds to a man-made engineering ...</div></span>
          <span id="toHide34" style="display:none;"><br /><div style="display:inline"><p>Given a noisy and incomplete point set, we introduce a method that simultaneously recovers a set of locally fitted primitives along with their global mutual relations. We operate under the assumption that the data corresponds to a man-made engineering object consisting of basic primitives, possibly repeated and globally aligned under common relations. We introduce an algorithm to directly couple the local and global aspects of the problem. The local fit of the model is determined by how well the inferred model agrees to the observed data, while the global relations are iteratively learned and enforced through a constrained optimization. Starting with a set of initial RANSAC based locally fitted primitives, relations across the primitives such as orientation, placement, and equality are progressively learned and conformed to. In each stage, a set of feasible relations are extracted among the candidate relations, and then aligned to, while best fitting to the input data. The global coupling corrects the primitives obtained in the local RANSAC stage, and brings them to precise global alignment. We test the robustness of our algorithm on a range of synthesized and scanned data, with varying amounts of noise, outliers, and non-uniform sampling, and validate the results against ground truth, where available.</p></div></span> <a id="expcoll34" href="JavaScript: expandcollapse('expcoll34',34)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964948&CFID=105750247&CFTOKEN=50542134">Texture-lobes for tree modelling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81351605108&CFID=105750247&CFTOKEN=50542134">Yotam Livny</a>, 
                        <a href="author_page.cfm?id=81487654852&CFID=105750247&CFTOKEN=50542134">Soeren Pirk</a>, 
                        <a href="author_page.cfm?id=81487651018&CFID=105750247&CFTOKEN=50542134">Zhanglin Cheng</a>, 
                        <a href="author_page.cfm?id=81339538120&CFID=105750247&CFTOKEN=50542134">Feilong Yan</a>, 
                        <a href="author_page.cfm?id=81100092246&CFID=105750247&CFTOKEN=50542134">Oliver Deussen</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105750247&CFTOKEN=50542134">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81100108037&CFID=105750247&CFTOKEN=50542134">Baoquan Chen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 53</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964948" title="DOI">10.1145/1964921.1964948</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964948&ftid=1006147&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964948&ftid=1074020&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow35" style="display:inline;"><br /><div style="display:inline">We present a lobe-based tree representation for modeling trees. The new representation is based on the observation that the tree's foliage details can be abstracted into canonical geometry structures, termed lobe-textures. We introduce techniques to ...</div></span>
          <span id="toHide35" style="display:none;"><br /><div style="display:inline"><p>We present a lobe-based tree representation for modeling trees. The new representation is based on the observation that the tree's foliage details can be abstracted into canonical geometry structures, termed lobe-textures. We introduce techniques to (i) approximate the geometry of given tree data and encode it into a lobe-based representation, (ii) decode the representation and synthesize a fully detailed tree model that visually resembles the input. The encoded tree serves as a light intermediate representation, which facilitates efficient storage and transmission of massive amounts of trees, e.g., from a server to clients for interactive applications in urban environments. The method is evaluated by both reconstructing laser scanned trees (given as point sets) as well as re-representing existing tree models (given as polygons).</p></div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Stochastic rendering & visibility</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Elmar Eisemann 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964949&CFID=105750247&CFTOKEN=50542134">High-quality spatio-temporal rendering using semi-analytical visibility</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81477643791&CFID=105750247&CFTOKEN=50542134">Carl Johan Gribel</a>, 
                        <a href="author_page.cfm?id=81487654645&CFID=105750247&CFTOKEN=50542134">Rasmus Barringer</a>, 
                        <a href="author_page.cfm?id=81487648063&CFID=105750247&CFTOKEN=50542134">Tomas Akenine-M&#246;ller</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 54</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964949" title="DOI">10.1145/1964921.1964949</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964949&ftid=1006148&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964949&ftid=1074018&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow37" style="display:inline;"><br /><div style="display:inline">We present a novel visibility algorithm for rendering motion blur with per-pixel anti-aliasing. Our algorithm uses a number of line samples over a rectangular group of pixels, and together with the time dimension, a two-dimensional spatio-temporal visibility ...</div></span>
          <span id="toHide37" style="display:none;"><br /><div style="display:inline"><p>We present a novel visibility algorithm for rendering motion blur with per-pixel anti-aliasing. Our algorithm uses a number of line samples over a rectangular group of pixels, and together with the time dimension, a two-dimensional spatio-temporal visibility problem needs to be solved per line sample. In a coarse culling step, our algorithm first uses a bounding volume hierarchy to rapidly remove geometry that does not overlap with the current line sample. For the remaining triangles, we approximate each triangle's depth function, along the line and along the time dimension, with a number of patch triangles. We resolve for the final color using an analytical visibility algorithm with depth sorting, simple occlusion culling, and clipping. Shading is decoupled from visibility, and we use a shading cache for efficient reuse of shaded values. In our results, we show practically noise-free renderings of motion blur with high-quality spatial anti-aliasing and with competitive rendering times. We also demonstrate that our algorithm, with some adjustments, can be used to accurately compute motion blurred ambient occlusion.</p></div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964950&CFID=105750247&CFTOKEN=50542134">Temporal light field reconstruction for rendering distribution effects</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81339512060&CFID=105750247&CFTOKEN=50542134">Jaakko Lehtinen</a>, 
                        <a href="author_page.cfm?id=81100649025&CFID=105750247&CFTOKEN=50542134">Timo Aila</a>, 
                        <a href="author_page.cfm?id=81340488498&CFID=105750247&CFTOKEN=50542134">Jiawen Chen</a>, 
                        <a href="author_page.cfm?id=81100622664&CFID=105750247&CFTOKEN=50542134">Samuli Laine</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=105750247&CFTOKEN=50542134">Fr&#233;do Durand</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 55</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964950" title="DOI">10.1145/1964921.1964950</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964950&ftid=1006149&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964950&ftid=1074019&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow38" style="display:inline;"><br /><div style="display:inline">Traditionally, effects that require evaluating multidimensional integrals for each pixel, such as motion blur, depth of field, and soft shadows, suffer from noise due to the variance of the high-dimensional integrand. In this paper, we describe a general ...</div></span>
          <span id="toHide38" style="display:none;"><br /><div style="display:inline"><p>Traditionally, effects that require evaluating multidimensional integrals for each pixel, such as motion blur, depth of field, and soft shadows, suffer from noise due to the variance of the high-dimensional integrand. In this paper, we describe a general reconstruction technique that exploits the anisotropy in the temporal light field and permits efficient reuse of samples between pixels, multiplying the effective sampling rate by a large factor. We show that our technique can be applied in situations that are challenging or impossible for previous anisotropic reconstruction methods, and that it can yield good results with very sparse inputs. We demonstrate our method for simultaneous motion blur, depth of field, and soft shadows.</p></div></span> <a id="expcoll38" href="JavaScript: expandcollapse('expcoll38',38)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Volumes & photons</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jaakko Lehtinen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964951&CFID=105750247&CFTOKEN=50542134">A quantized-diffusion model for rendering translucent materials</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335489650&CFID=105750247&CFTOKEN=50542134">Eugene D'Eon</a>, 
                        <a href="author_page.cfm?id=81100569226&CFID=105750247&CFTOKEN=50542134">Geoffrey Irving</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 56</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964951" title="DOI">10.1145/1964921.1964951</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964951&ftid=1006150&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964951&ftid=1074021&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow40" style="display:inline;"><br /><div style="display:inline">We present a new BSSRDF for rendering images of translucent materials. Previous diffusion BSSRDFs are limited by the accuracy of classical diffusion theory. We introduce a modified diffusion theory that is more accurate for highly absorbing materials ...</div></span>
          <span id="toHide40" style="display:none;"><br /><div style="display:inline"><p>We present a new BSSRDF for rendering images of translucent materials. Previous diffusion BSSRDFs are limited by the accuracy of classical diffusion theory. We introduce a modified diffusion theory that is more accurate for highly absorbing materials and near the point of illumination. The new diffusion solution accurately decouples single and multiple scattering. We then derive a novel, analytic, extended-source solution to the multilayer search-light problem by quantizing the diffusion Green's function. This allows the application of the diffusion multipole model to material layers several orders of magnitude thinner than previously possible and creates accurate results under high-frequency illumination. Quantized diffusion provides both a new physical foundation and a variable-accuracy construction method for sum-of-Gaussians BSSRDFs, which have many useful properties for efficient rendering and appearance capture. Our BSSRDF maps directly to previous real-time rendering algorithms. For film production rendering, we propose several improvements to previous hierarchical point cloud algorithms by introducing a new radial-binning data structure and a doubly-adaptive traversal strategy.</p></div></span> <a id="expcoll40" href="JavaScript: expandcollapse('expcoll40',40)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Geometry processing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Scott Schaefer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964952&CFID=105750247&CFTOKEN=50542134">Interactive and anisotropic geometry processing using the screened Poisson equation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100637062&CFID=105750247&CFTOKEN=50542134">Ming Chuang</a>, 
                        <a href="author_page.cfm?id=81100017967&CFID=105750247&CFTOKEN=50542134">Michael Kazhdan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 57</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964952" title="DOI">10.1145/1964921.1964952</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964952&ftid=1006151&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964952&ftid=1074022&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow42" style="display:inline;"><br /><div style="display:inline">We present a general framework for performing geometry filtering through the solution of a screened Poisson equation. We show that this framework can be efficiently adapted to a changing Riemannian metric to support curvature-aware filtering and describe ...</div></span>
          <span id="toHide42" style="display:none;"><br /><div style="display:inline"><p>We present a general framework for performing geometry filtering through the solution of a screened Poisson equation. We show that this framework can be efficiently adapted to a changing Riemannian metric to support curvature-aware filtering and describe a parallel and streaming multigrid implementation for solving the system. We demonstrate the practicality of our approach by developing an interactive system for mesh editing that allows for exploration of a large family of curvature-guided, anisotropic filters.</p></div></span> <a id="expcoll42" href="JavaScript: expandcollapse('expcoll42',42)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Call animal control!</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          KangKang Yin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964953&CFID=105750247&CFTOKEN=50542134">Articulated swimming creatures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81486651856&CFID=105750247&CFTOKEN=50542134">Jie Tan</a>, 
                        <a href="author_page.cfm?id=81487646830&CFID=105750247&CFTOKEN=50542134">Yuting Gu</a>, 
                        <a href="author_page.cfm?id=81100457973&CFID=105750247&CFTOKEN=50542134">Greg Turk</a>, 
                        <a href="author_page.cfm?id=81452598193&CFID=105750247&CFTOKEN=50542134">C. Karen Liu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 58</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964953" title="DOI">10.1145/1964921.1964953</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964953&ftid=1006152&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964953&ftid=1074023&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow44" style="display:inline;"><br /><div style="display:inline">We present a general approach to creating realistic swimming behavior for a given articulated creature body. The two main components of our method are creature/fluid simulation and the optimization of the creature motion parameters. We simulate two-way ...</div></span>
          <span id="toHide44" style="display:none;"><br /><div style="display:inline"><p>We present a general approach to creating realistic swimming behavior for a given articulated creature body. The two main components of our method are creature/fluid simulation and the optimization of the creature motion parameters. We simulate two-way coupling between the fluid and the articulated body by solving a linear system that matches acceleration at fluid/solid boundaries and that also enforces fluid incompressibility. The swimming motion of a given creature is described as a set of periodic functions, one for each joint degree of freedom. We optimize over the space of these functions in order to find a motion that causes the creature to swim straight and stay within a given energy budget. Our creatures can perform path following by first training appropriate turning maneuvers through offline optimization and then selecting between these motions to track the given path. We present results for a clownfish, an eel, a sea turtle, a manta ray and a frog, and in each case the resulting motion is a good match to the real-world animals. We also demonstrate a plausible swimming gait for a fictional creature that has no real-world counterpart.</p></div></span> <a id="expcoll44" href="JavaScript: expandcollapse('expcoll44',44)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964954&CFID=105750247&CFTOKEN=50542134">Locomotion skills for simulated quadrupeds</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81320488815&CFID=105750247&CFTOKEN=50542134">Stelian Coros</a>, 
                        <a href="author_page.cfm?id=81487652688&CFID=105750247&CFTOKEN=50542134">Andrej Karpathy</a>, 
                        <a href="author_page.cfm?id=81487647543&CFID=105750247&CFTOKEN=50542134">Ben Jones</a>, 
                        <a href="author_page.cfm?id=81100400947&CFID=105750247&CFTOKEN=50542134">Lionel Reveret</a>, 
                        <a href="author_page.cfm?id=81319502903&CFID=105750247&CFTOKEN=50542134">Michiel van de Panne</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 59</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964954" title="DOI">10.1145/1964921.1964954</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964954&ftid=1006153&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964954&ftid=1074024&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow45" style="display:inline;"><br /><div style="display:inline">We develop an integrated set of gaits and skills for a physics-based simulation of a quadruped. The motion repertoire for our simulated dog includes walk, trot, pace, canter, transverse gallop, rotary gallop, leaps capable of jumping on-and-off platforms ...</div></span>
          <span id="toHide45" style="display:none;"><br /><div style="display:inline"><p>We develop an integrated set of gaits and skills for a physics-based simulation of a quadruped. The motion repertoire for our simulated dog includes walk, trot, pace, canter, transverse gallop, rotary gallop, leaps capable of jumping on-and-off platforms and over obstacles, sitting, lying down, standing up, and getting up from a fall. The controllers use a representation based on gait graphs, a dual leg frame model, a flexible spine model, and the extensive use of internal virtual forces applied via the Jacobian transpose. Optimizations are applied to these control abstractions in order to achieve robust gaits and leaps with desired motion styles. The resulting gaits are evaluated for robustness with respect to push disturbances and the traversal of variable terrain. The simulated motions are also compared to motion data captured from a filmed dog.</p></div></span> <a id="expcoll45" href="JavaScript: expandcollapse('expcoll45',45)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>By-example image synthesis</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Dan B. Goldman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964955&CFID=105750247&CFTOKEN=50542134">Expression flow for 3D-aware face component transfer</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487641941&CFID=105750247&CFTOKEN=50542134">Fei Yang</a>, 
                        <a href="author_page.cfm?id=81100233470&CFID=105750247&CFTOKEN=50542134">Jue Wang</a>, 
                        <a href="author_page.cfm?id=81100538015&CFID=105750247&CFTOKEN=50542134">Eli Shechtman</a>, 
                        <a href="author_page.cfm?id=81100013722&CFID=105750247&CFTOKEN=50542134">Lubomir Bourdev</a>, 
                        <a href="author_page.cfm?id=81409597622&CFID=105750247&CFTOKEN=50542134">Dimitri Metaxas</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 60</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964955" title="DOI">10.1145/1964921.1964955</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964955&ftid=1006154&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964955&ftid=1074025&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow47" style="display:inline;"><br /><div style="display:inline">We address the problem of correcting an undesirable expression on a face photo by transferring local facial components, such as a smiling mouth, from another face photo of the same person which has the desired expression. Direct copying and blending ...</div></span>
          <span id="toHide47" style="display:none;"><br /><div style="display:inline"><p>We address the problem of correcting an undesirable expression on a face photo by transferring local facial components, such as a smiling mouth, from another face photo of the same person which has the desired expression. Direct copying and blending using existing compositing tools results in semantically unnatural composites, since expression is a global effect and the local component in one expression is often incompatible with the shape and other components of the face in another expression. To solve this problem we present Expression Flow, a 2D flow field which can warp the target face globally in a natural way, so that the warped face is compatible with the new facial component to be copied over. To do this, starting with the two input face photos, we jointly construct a pair of 3D face shapes with the same identity but different expressions. The expression flow is computed by projecting the difference between the two 3D shapes back to 2D. It describes how to warp the target face photo to match the expression of the reference photo. User studies suggest that our system is able to generate face composites with much higher fidelity than existing methods.</p></div></span> <a id="expcoll47" href="JavaScript: expandcollapse('expcoll47',47)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964956&CFID=105750247&CFTOKEN=50542134">Exploring photobios</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81474701471&CFID=105750247&CFTOKEN=50542134">Ira Kemelmacher-Shlizerman</a>, 
                        <a href="author_page.cfm?id=81100538015&CFID=105750247&CFTOKEN=50542134">Eli Shechtman</a>, 
                        <a href="author_page.cfm?id=81100629901&CFID=105750247&CFTOKEN=50542134">Rahul Garg</a>, 
                        <a href="author_page.cfm?id=81407593498&CFID=105750247&CFTOKEN=50542134">Steven M. Seitz</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 61</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964956" title="DOI">10.1145/1964921.1964956</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964956&ftid=1006155&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964956&ftid=1074026&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow48" style="display:inline;"><br /><div style="display:inline">We present an approach for generating face animations from large image collections of the same person. Such collections, which we call photobios, sample the appearance of a person over changes in pose, facial expression, hairstyle, age, and other ...</div></span>
          <span id="toHide48" style="display:none;"><br /><div style="display:inline"><p>We present an approach for generating face animations from large image collections of the same person. Such collections, which we call <i>photobios</i>, sample the appearance of a person over changes in pose, facial expression, hairstyle, age, and other variations. By optimizing the order in which images are displayed and cross-dissolving between them, we control the motion through face space and create compelling animations (e.g., render a smooth transition from frowning to smiling). Used in this context, the <i>cross dissolve</i> produces a very strong motion effect; a key contribution of the paper is to explain this effect and analyze its operating range. The approach operates by creating a graph with faces as nodes, and similarities as edges, and solving for walks and shortest paths on this graph. The processing pipeline involves face detection, locating fiducials (eyes/nose/mouth), solving for pose, warping to frontal views, and image comparison based on Local Binary Patterns. We demonstrate results on a variety of datasets including time-lapse photography, personal photo collections, and images of celebrities downloaded from the Internet. Our approach is the basis for the Face Movies feature in Google's Picasa.</p></div></span> <a id="expcoll48" href="JavaScript: expandcollapse('expcoll48',48)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964957&CFID=105750247&CFTOKEN=50542134">Discrete element textures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448597890&CFID=105750247&CFTOKEN=50542134">Chongyang Ma</a>, 
                        <a href="author_page.cfm?id=81452594229&CFID=105750247&CFTOKEN=50542134">Li-Yi Wei</a>, 
                        <a href="author_page.cfm?id=81314492380&CFID=105750247&CFTOKEN=50542134">Xin Tong</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 62</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964957" title="DOI">10.1145/1964921.1964957</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964957&ftid=1006156&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964957&ftid=1074027&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow49" style="display:inline;"><br /><div style="display:inline">A variety of phenomena can be characterized by repetitive small scale elements within a large scale domain. Examples include a stack of fresh produce, a plate of spaghetti, or a mosaic pattern. Although certain results can be produced via manual placement ...</div></span>
          <span id="toHide49" style="display:none;"><br /><div style="display:inline"><p>A variety of phenomena can be characterized by repetitive small scale elements within a large scale domain. Examples include a stack of fresh produce, a plate of spaghetti, or a mosaic pattern. Although certain results can be produced via manual placement or procedural/physical simulation, these methods can be labor intensive, difficult to control, or limited to specific phenomena.</p> <p>We present discrete element textures, a data-driven method for synthesizing repetitive elements according to a small input exemplar and a large output domain. Our method preserves both individual element properties and their aggregate distributions. It is also general and applicable to a variety of phenomena, including different dimensionalities, different element properties and distributions, and different effects including both artistic and physically realistic ones. We represent each element by one or multiple samples whose positions encode relevant element attributes including position, size, shape, and orientation. We propose a sample-based neighborhood similarity metric and an energy optimization solver to synthesize desired outputs that observe not only input exemplars and output domains but also optional constraints such as physics, orientation fields, and boundary conditions. As a further benefit, our method can also be applied for editing existing element distributions.</p></div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Colorful</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Olga Sorkine 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964958&CFID=105750247&CFTOKEN=50542134">Color compatibility from large datasets</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314491507&CFID=105750247&CFTOKEN=50542134">Peter O'Donovan</a>, 
                        <a href="author_page.cfm?id=81100035467&CFID=105750247&CFTOKEN=50542134">Aseem Agarwala</a>, 
                        <a href="author_page.cfm?id=81100015154&CFID=105750247&CFTOKEN=50542134">Aaron Hertzmann</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 63</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964958" title="DOI">10.1145/1964921.1964958</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964958&ftid=1006157&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964958&ftid=1074028&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow51" style="display:inline;"><br /><div style="display:inline">This paper studies color compatibility theories using large datasets, and develops new tools for choosing colors. There are three parts to this work. First, using on-line datasets, we test new and existing theories of human color preferences. For example, ...</div></span>
          <span id="toHide51" style="display:none;"><br /><div style="display:inline"><p>This paper studies color compatibility theories using large datasets, and develops new tools for choosing colors. There are three parts to this work. First, using on-line datasets, we test new and existing theories of human color preferences. For example, we test whether certain hues or hue templates may be preferred by viewers. Second, we learn quantitative models that score the quality of a five-color set of colors, called a <i>color theme</i>. Such models can be used to rate the quality of a new color theme. Third, we demonstrate simple proto-types that apply a learned model to tasks in color design, including improving existing themes and extracting themes from images.</p></div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964959&CFID=105750247&CFTOKEN=50542134">Example-based image color and tone style enhancement</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81474657665&CFID=105750247&CFTOKEN=50542134">Baoyuan Wang</a>, 
                        <a href="author_page.cfm?id=81100472713&CFID=105750247&CFTOKEN=50542134">Yizhou Yu</a>, 
                        <a href="author_page.cfm?id=81365590697&CFID=105750247&CFTOKEN=50542134">Ying-Qing Xu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 64</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964959" title="DOI">10.1145/1964921.1964959</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964959&ftid=1006158&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964959&ftid=1074031&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow52" style="display:inline;"><br /><div style="display:inline">Color and tone adjustments are among the most frequent image enhancement operations. We define a color and tone style as a set of explicit or implicit rules governing color and tone adjustments. Our goal in this paper is to learn implicit color and tone ...</div></span>
          <span id="toHide52" style="display:none;"><br /><div style="display:inline"><p>Color and tone adjustments are among the most frequent image enhancement operations. We define a color and tone style as a set of explicit or implicit rules governing color and tone adjustments. Our goal in this paper is to learn implicit color and tone adjustment rules from examples. That is, given a set of examples, each of which is a pair of corresponding images before and after adjustments, we would like to discover the underlying mathematical relationships optimally connecting the color and tone of corresponding pixels in all image pairs. We formally define tone and color adjustment rules as mappings, and propose to approximate complicated spatially varying nonlinear mappings in a piecewise manner. The reason behind this is that a very complicated mapping can still be locally approximated with a low-order polynomial model. Parameters within such low-order models are trained using data extracted from example image pairs. We successfully apply our framework in two scenarios, low-quality photo enhancement by transferring the style of a high-end camera, and photo enhancement using styles learned from photographers and designers.</p></div></span> <a id="expcoll52" href="JavaScript: expandcollapse('expcoll52',52)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964960&CFID=105750247&CFTOKEN=50542134">Switchable primaries using shiftable layers of color filter arrays</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414620432&CFID=105750247&CFTOKEN=50542134">Behzad Sajadi</a>, 
                        <a href="author_page.cfm?id=81100150661&CFID=105750247&CFTOKEN=50542134">Aditi Majumder</a>, 
                        <a href="author_page.cfm?id=81392591241&CFID=105750247&CFTOKEN=50542134">Kazuhiro Hiwada</a>, 
                        <a href="author_page.cfm?id=81100566431&CFID=105750247&CFTOKEN=50542134">Atsuto Maki</a>, 
                        <a href="author_page.cfm?id=81100022847&CFID=105750247&CFTOKEN=50542134">Ramesh Raskar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 65</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964960" title="DOI">10.1145/1964921.1964960</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964960&ftid=1006159&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964960&ftid=1074032&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow53" style="display:inline;"><br /><div style="display:inline">We present a camera with switchable primaries using shiftable layers of color filter arrays (CFAs). By layering a pair of CMY CFAs in this novel manner we can switch between multiple sets of color primaries (namely RGB, CMY and RGBCY) in the same camera. ...</div></span>
          <span id="toHide53" style="display:none;"><br /><div style="display:inline"><p>We present a camera with switchable primaries using shiftable layers of color filter arrays (CFAs). By layering a pair of CMY CFAs in this novel manner we can switch between multiple sets of color primaries (namely RGB, CMY and RGBCY) in the same camera. In contrast to fixed color primaries (e.g. RGB or CMY), which cannot provide optimal image quality for all scene conditions, our camera with switchable primaries provides optimal <i>color fidelity</i> and <i>signal to noise ratio</i> for multiple scene conditions.</p> <p>Next, we show that the same concept can be used to layer two RGB CFAs to design a camera with switchable low dynamic range (LDR) and high dynamic range (HDR) modes. Further, we show that such layering can be generalized as a constrained satisfaction problem (CSP) allowing to constrain a large number of parameters (e.g. different operational modes, amount and direction of the shifts, placement of the primaries in the CFA) to provide an optimal solution.</p> <p>We investigate practical design options for shiftable layering of the CFAs. We demonstrate these by building prototype cameras for both switchable primaries and switchable LDR/HDR modes.</p> <p>To the best of our knowledge, we present, for the first time, the concept of shiftable layers of CFAs that provides a new degree of freedom in photography where multiple operational modes are available to the user in a single camera for optimizing the picture quality based on the nature of the scene geometry, color and illumination.</p></div></span> <a id="expcoll53" href="JavaScript: expandcollapse('expcoll53',53)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Surfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Eugene Zhang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964961&CFID=105750247&CFTOKEN=50542134"><i>MeshFlow</i>: interactive visualization of mesh construction sequences</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487654829&CFID=105750247&CFTOKEN=50542134">Jonathan D. Denning</a>, 
                        <a href="author_page.cfm?id=81440603027&CFID=105750247&CFTOKEN=50542134">William B. Kerr</a>, 
                        <a href="author_page.cfm?id=81100112064&CFID=105750247&CFTOKEN=50542134">Fabio Pellacini</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 66</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964961" title="DOI">10.1145/1964921.1964961</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964961&ftid=1006160&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964961&ftid=1074029&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow55" style="display:inline;"><br /><div style="display:inline">The construction of polygonal meshes remains a complex task in Computer Graphics, taking tens of thousands of individual operations over several hours of modeling time. The complexity of modeling in terms of number of operations and time makes it difficult ...</div></span>
          <span id="toHide55" style="display:none;"><br /><div style="display:inline"><p>The construction of polygonal meshes remains a complex task in Computer Graphics, taking tens of thousands of individual operations over several hours of modeling time. The complexity of modeling in terms of number of operations and time makes it difficult for artists to understand all details of how meshes are constructed. We present <i>MeshFlow</i>, an interactive system for visualizing mesh construction sequences. <i>MeshFlow</i> hierarchically clusters mesh editing operations to provide viewers with an overview of the model construction while still allowing them to view more details on demand. We base our clustering on an analysis of the frequency of repeated operations and implement it using substituting regular expressions. By filtering operations based on either their type or which vertices they affect, <i>MeshFlow</i> also ensures that viewers can interactively focus on the relevant parts of the modeling process. Automatically generated graphical annotations visualize the clustered operations. We have tested <i>MeshFlow</i> by visualizing five mesh sequences each taking a few hours to model, and we found it to work well for all. We have also evaluated <i>MeshFlow</i> with a case study using modeling students. We conclude that our system provides useful visualizations that are found to be more helpful than video or document-form instructions in understanding mesh construction.</p></div></span> <a id="expcoll55" href="JavaScript: expandcollapse('expcoll55',55)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964962&CFID=105750247&CFTOKEN=50542134">LR: compact connectivity representation for triangle meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81443598153&CFID=105750247&CFTOKEN=50542134">Topraj Gurung</a>, 
                        <a href="author_page.cfm?id=81487653561&CFID=105750247&CFTOKEN=50542134">Mark Luffel</a>, 
                        <a href="author_page.cfm?id=81100040340&CFID=105750247&CFTOKEN=50542134">Peter Lindstrom</a>, 
                        <a href="author_page.cfm?id=81100166952&CFID=105750247&CFTOKEN=50542134">Jarek Rossignac</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 67</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964962" title="DOI">10.1145/1964921.1964962</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964962&ftid=1006161&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964962&ftid=1074030&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow56" style="display:inline;"><br /><div style="display:inline">We propose LR (Laced Ring)---a simple data structure for representing the connectivity of manifold triangle meshes. LR provides the option to store on average either 1.08 references per triangle or 26.2 bits per triangle. Its construction, from ...</div></span>
          <span id="toHide56" style="display:none;"><br /><div style="display:inline"><p>We propose LR (<i>Laced Ring</i>)---a simple data structure for representing the connectivity of manifold triangle meshes. LR provides the option to store on average either 1.08 references per triangle or 26.2 bits per triangle. Its construction, from an input mesh that supports constant-time adjacency queries, has linear space and time complexity, and involves ordering most vertices along a nearly-Hamiltonian cycle. LR is best suited for applications that process meshes with fixed connectivity, as any changes to the connectivity require the data structure to be rebuilt. We provide an implementation of the set of standard random-access, constant-time operators for traversing a mesh, and show that LR often saves both space and traversal time over competing representations.</p></div></span> <a id="expcoll56" href="JavaScript: expandcollapse('expcoll56',56)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Image processing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Aaron Hertzmann 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964963&CFID=105750247&CFTOKEN=50542134">Local Laplacian filters: edge-aware image processing with a Laplacian pyramid</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100495713&CFID=105750247&CFTOKEN=50542134">Sylvain Paris</a>, 
                        <a href="author_page.cfm?id=81100479713&CFID=105750247&CFTOKEN=50542134">Samuel W. Hasinoff</a>, 
                        <a href="author_page.cfm?id=81100016395&CFID=105750247&CFTOKEN=50542134">Jan Kautz</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 68</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964963" title="DOI">10.1145/1964921.1964963</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964963&ftid=1006162&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964963&ftid=1074033&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow58" style="display:inline;"><br /><div style="display:inline">The Laplacian pyramid is ubiquitous for decomposing images into multiple scales and is widely used for image analysis. However, because it is constructed with spatially invariant Gaussian kernels, the Laplacian pyramid is widely believed as being unable ...</div></span>
          <span id="toHide58" style="display:none;"><br /><div style="display:inline"><p>The Laplacian pyramid is ubiquitous for decomposing images into multiple scales and is widely used for image analysis. However, because it is constructed with spatially invariant Gaussian kernels, the Laplacian pyramid is widely believed as being unable to represent edges well and as being ill-suited for edge-aware operations such as edge-preserving smoothing and tone mapping. To tackle these tasks, a wealth of alternative techniques and representations have been proposed, e.g., anisotropic diffusion, neighborhood filtering, and specialized wavelet bases. While these methods have demonstrated successful results, they come at the price of additional complexity, often accompanied by higher computational cost or the need to post-process the generated results. In this paper, we show state-of-the-art edge-aware processing using standard Laplacian pyramids. We characterize edges with a simple threshold on pixel values that allows us to differentiate large-scale edges from small-scale details. Building upon this result, we propose a set of image filters to achieve edge-preserving smoothing, detail enhancement, tone mapping, and inverse tone mapping. The advantage of our approach is its simplicity and flexibility, relying only on simple point-wise nonlinearities and small Gaussian convolutions; no optimization or post-processing is required. As we demonstrate, our method produces consistently high-quality results, without degrading edges or introducing halos.</p></div></span> <a id="expcoll58" href="JavaScript: expandcollapse('expcoll58',58)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964964&CFID=105750247&CFTOKEN=50542134">Domain transform for edge-aware image and video processing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487655413&CFID=105750247&CFTOKEN=50542134">Eduardo S. L. Gastal</a>, 
                        <a href="author_page.cfm?id=81100516478&CFID=105750247&CFTOKEN=50542134">Manuel M. Oliveira</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 69</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964964" title="DOI">10.1145/1964921.1964964</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964964&ftid=1006163&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964964&ftid=1074034&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow59" style="display:inline;"><br /><div style="display:inline">We present a new approach for performing high-quality edge-preserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform ...</div></span>
          <span id="toHide59" style="display:none;"><br /><div style="display:inline"><p>We present a new approach for performing high-quality edge-preserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform preserves the geodesic distance between points on these curves, adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations of 1D edge-preserving filters, show how to produce high-quality 2D edge-preserving filters by iterating 1D-filtering operations, and empirically analyze the convergence of this process. Our approach has several desirable features: the use of 1D operations leads to considerable speedups over existing techniques and potential memory savings; its computational cost is not affected by the choice of the filter parameters; and it is the first edge-preserving filter to work on color images at arbitrary scales in real time, without resorting to subsampling or quantization. We demonstrate the versatility of our domain transform and edge-preserving filters on several real-time image and video processing tasks including edge-preserving filtering, depth-of-field effects, stylization, recoloring, colorization, detail enhancement, and tone mapping.</p></div></span> <a id="expcoll59" href="JavaScript: expandcollapse('expcoll59',59)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964965&CFID=105750247&CFTOKEN=50542134">Non-rigid dense correspondence with applications for image enhancement</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487654423&CFID=105750247&CFTOKEN=50542134">Yoav HaCohen</a>, 
                        <a href="author_page.cfm?id=81100538015&CFID=105750247&CFTOKEN=50542134">Eli Shechtman</a>, 
                        <a href="author_page.cfm?id=81100026255&CFID=105750247&CFTOKEN=50542134">Dan B. Goldman</a>, 
                        <a href="author_page.cfm?id=81474662083&CFID=105750247&CFTOKEN=50542134">Dani Lischinski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 70</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964965" title="DOI">10.1145/1964921.1964965</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964965&ftid=1006164&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964965&ftid=1074035&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow60" style="display:inline;"><br /><div style="display:inline">This paper presents a new efficient method for recovering reliable local sets of dense correspondences between two images with some shared content. Our method is designed for pairs of images depicting similar regions acquired by different cameras and ...</div></span>
          <span id="toHide60" style="display:none;"><br /><div style="display:inline"><p>This paper presents a new efficient method for recovering reliable local sets of dense correspondences between two images with some shared content. Our method is designed for pairs of images depicting similar regions acquired by different cameras and lenses, under non-rigid transformations, under different lighting, and over different backgrounds. We utilize a new coarse-to-fine scheme in which nearest-neighbor field computations using Generalized PatchMatch [Barnes et al. 2010] are interleaved with fitting a global non-linear parametric color model and aggregating consistent matching regions using locally adaptive constraints. Compared to previous correspondence approaches, our method combines the best of two worlds: It is dense, like optical flow and stereo reconstruction methods, and it is also robust to geometric and photometric variations, like sparse feature matching. We demonstrate the usefulness of our method using three applications for automatic example-based photograph enhancement: adjusting the tonal characteristics of a source image to match a reference, transferring a known mask to a new image, and kernel estimation for image deblurring.</p></div></span> <a id="expcoll60" href="JavaScript: expandcollapse('expcoll60',60)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Example-based simulation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jernej Barbic 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964966&CFID=105750247&CFTOKEN=50542134">Data-driven elastic models for cloth: modeling and measurement</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466648783&CFID=105750247&CFTOKEN=50542134">Huamin Wang</a>, 
                        <a href="author_page.cfm?id=81100311781&CFID=105750247&CFTOKEN=50542134">James F. O'Brien</a>, 
                        <a href="author_page.cfm?id=81100019585&CFID=105750247&CFTOKEN=50542134">Ravi Ramamoorthi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 71</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964966" title="DOI">10.1145/1964921.1964966</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964966&ftid=1016540&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964966&ftid=1074036&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow62" style="display:inline;"><br /><div style="display:inline">Cloth often has complicated nonlinear, anisotropic elastic behavior due to its woven pattern and fiber properties. However, most current cloth simulation techniques simply use linear and isotropic elastic models with manually selected stiffness parameters. ...</div></span>
          <span id="toHide62" style="display:none;"><br /><div style="display:inline"><p>Cloth often has complicated nonlinear, anisotropic elastic behavior due to its woven pattern and fiber properties. However, most current cloth simulation techniques simply use linear and isotropic elastic models with manually selected stiffness parameters. Such simple simulations do not allow differentiating the behavior of distinct cloth materials such as silk or denim, and they cannot model most materials with fidelity to their real-world counterparts. In this paper, we present a data-driven technique to more realistically animate cloth. We propose a piecewise linear elastic model that is a good approximation to nonlinear, anisotropic stretching and bending behaviors of various materials. We develop new measurement techniques for studying the elastic deformations for both stretching and bending in real cloth samples. Our setup is easy and inexpensive to construct, and the parameters of our model can be fit to observed data with a well-posed optimization procedure. We have measured a database of ten different cloth materials, each of which exhibits distinctive elastic behaviors. These measurements can be used in most cloth simulation systems to create natural and realistic clothing wrinkles and shapes, for a range of different materials.</p></div></span> <a id="expcoll62" href="JavaScript: expandcollapse('expcoll62',62)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964967&CFID=105750247&CFTOKEN=50542134">Example-based elastic materials</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81435594668&CFID=105750247&CFTOKEN=50542134">Sebastian Martin</a>, 
                        <a href="author_page.cfm?id=81323496851&CFID=105750247&CFTOKEN=50542134">Bernhard Thomaszewski</a>, 
                        <a href="author_page.cfm?id=81441592259&CFID=105750247&CFTOKEN=50542134">Eitan Grinspun</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105750247&CFTOKEN=50542134">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 72</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964967" title="DOI">10.1145/1964921.1964967</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964967&ftid=1006166&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow63" style="display:inline;"><br /><div style="display:inline">We propose an example-based approach for simulating complex elastic material behavior. Supplied with a few poses that characterize a given object, our system starts by constructing a space of prefered deformations by means of interpolation. During simulation, ...</div></span>
          <span id="toHide63" style="display:none;"><br /><div style="display:inline"><p>We propose an example-based approach for simulating complex elastic material behavior. Supplied with a few poses that characterize a given object, our system starts by constructing a space of prefered deformations by means of interpolation. During simulation, this example manifold then acts as an additional elastic attractor that guides the object towards its space of prefered shapes. Added on top of existing solid simulation codes, this example potential effectively allows us to implement inhomogeneous and anisotropic materials in a direct and intuitive way. Due to its example-based interface, our method promotes an art-directed approach to solid simulation, which we exemplify on a set of practical examples.</p></div></span> <a id="expcoll63" href="JavaScript: expandcollapse('expcoll63',63)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964968&CFID=105750247&CFTOKEN=50542134">Sparse meshless models of complex deformable solids</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100210102&CFID=105750247&CFTOKEN=50542134">Fran&#231;ois Faure</a>, 
                        <a href="author_page.cfm?id=81388599480&CFID=105750247&CFTOKEN=50542134">Benjamin Gilles</a>, 
                        <a href="author_page.cfm?id=81484644569&CFID=105750247&CFTOKEN=50542134">Guillaume Bousquet</a>, 
                        <a href="author_page.cfm?id=81100642559&CFID=105750247&CFTOKEN=50542134">Dinesh K. Pai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 73</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964968" title="DOI">10.1145/1964921.1964968</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964968&ftid=1006167&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964968&ftid=1074037&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow64" style="display:inline;"><br /><div style="display:inline">A new method to simulate deformable objects with heterogeneous material properties and complex geometries is presented. Given a volumetric map of the material properties and an arbitrary number of control nodes, a distribution of the nodes is computed ...</div></span>
          <span id="toHide64" style="display:none;"><br /><div style="display:inline"><p>A new method to simulate deformable objects with heterogeneous material properties and complex geometries is presented. Given a volumetric map of the material properties and an arbitrary number of control nodes, a distribution of the nodes is computed automatically, as well as the associated shape functions. Reference frames attached to the nodes are used to apply skeleton subspace deformation across the volume of the objects. A continuum mechanics formulation is derived from the displacements and the material properties. We introduce novel material-aware shape functions in place of the traditional radial basis functions used in meshless frameworks. In contrast with previous approaches, these allow coarse deformation functions to efficiently resolve non-uniform stiffnesses. Complex models can thus be simulated at high frame rates using a small number of control nodes.</p></div></span> <a id="expcoll64" href="JavaScript: expandcollapse('expcoll64',64)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Facial animation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Okan Arikan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964969&CFID=105750247&CFTOKEN=50542134">Leveraging motion capture and 3D scanning for high-fidelity facial performance acquisition</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487648312&CFID=105750247&CFTOKEN=50542134">Haoda Huang</a>, 
                        <a href="author_page.cfm?id=81100205074&CFID=105750247&CFTOKEN=50542134">Jinxiang Chai</a>, 
                        <a href="author_page.cfm?id=81314492380&CFID=105750247&CFTOKEN=50542134">Xin Tong</a>, 
                        <a href="author_page.cfm?id=81487650131&CFID=105750247&CFTOKEN=50542134">Hsiang-Tao Wu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 74</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964969" title="DOI">10.1145/1964921.1964969</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964969&ftid=1006168&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964969&ftid=1074038&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow66" style="display:inline;"><br /><div style="display:inline">This paper introduces a new approach for acquiring high-fidelity 3D facial performances with realistic dynamic wrinkles and fine-scale facial details. Our approach leverages state-of-the-art motion capture technology and advanced 3D scanning technology ...</div></span>
          <span id="toHide66" style="display:none;"><br /><div style="display:inline"><p>This paper introduces a new approach for acquiring high-fidelity 3D facial performances with realistic dynamic wrinkles and fine-scale facial details. Our approach leverages state-of-the-art motion capture technology and advanced 3D scanning technology for facial performance acquisition. We start the process by recording 3D facial performances of an actor using a marker-based motion capture system and perform facial analysis on the captured data, thereby determining a minimal set of face scans required for accurate facial reconstruction. We introduce a two-step registration process to efficiently build dense consistent surface correspondences across all the face scans. We reconstruct high-fidelity 3D facial performances by combining motion capture data with the minimal set of face scans in the blendshape interpolation framework. We have evaluated the performance of our system on both real and synthetic data. Our results show that the system can capture facial performances that match both the spatial resolution of static face scans and the acquisition speed of motion capture systems.</p></div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964970&CFID=105750247&CFTOKEN=50542134">High-quality passive facial performance capture using anchor frames</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466647897&CFID=105750247&CFTOKEN=50542134">Thabo Beeler</a>, 
                        <a href="author_page.cfm?id=81487642105&CFID=105750247&CFTOKEN=50542134">Fabian Hahn</a>, 
                        <a href="author_page.cfm?id=81319488885&CFID=105750247&CFTOKEN=50542134">Derek Bradley</a>, 
                        <a href="author_page.cfm?id=81314493860&CFID=105750247&CFTOKEN=50542134">Bernd Bickel</a>, 
                        <a href="author_page.cfm?id=81100489358&CFID=105750247&CFTOKEN=50542134">Paul Beardsley</a>, 
                        <a href="author_page.cfm?id=81100294813&CFID=105750247&CFTOKEN=50542134">Craig Gotsman</a>, 
                        <a href="author_page.cfm?id=81100099182&CFID=105750247&CFTOKEN=50542134">Robert W. Sumner</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105750247&CFTOKEN=50542134">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 75</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964970" title="DOI">10.1145/1964921.1964970</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964970&ftid=1006169&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow67" style="display:inline;"><br /><div style="display:inline">We present a new technique for passive and markerless facial performance capture based on anchor frames. Our method starts with high resolution per-frame geometry acquisition using state-of-the-art stereo reconstruction, and proceeds to establish ...</div></span>
          <span id="toHide67" style="display:none;"><br /><div style="display:inline"><p>We present a new technique for passive and markerless facial performance capture based on <i>anchor frames</i>. Our method starts with high resolution per-frame geometry acquisition using state-of-the-art stereo reconstruction, and proceeds to establish a single triangle mesh that is propagated through the entire performance. Leveraging the fact that facial performances often contain repetitive subsequences, we identify <i>anchor frames</i> as those which contain similar facial expressions to a manually chosen reference expression. Anchor frames are automatically computed over one or even multiple performances. We introduce a robust image-space tracking method that computes pixel matches directly from the reference frame to all anchor frames, and thereby to the remaining frames in the sequence via sequential matching. This allows us to propagate one reconstructed frame to an entire sequence in parallel, in contrast to previous sequential methods. Our anchored reconstruction approach also limits tracker drift and robustly handles occlusions and motion blur. The parallel tracking and mesh propagation offer low computation times. Our technique will even automatically match anchor frames across different sequences captured on different occasions, propagating a single mesh to all performances.</p></div></span> <a id="expcoll67" href="JavaScript: expandcollapse('expcoll67',67)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964971&CFID=105750247&CFTOKEN=50542134">Interactive region-based linear 3D face models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487642212&CFID=105750247&CFTOKEN=50542134">J. Rafael Tena</a>, 
                        <a href="author_page.cfm?id=81100338725&CFID=105750247&CFTOKEN=50542134">Fernando De la Torre</a>, 
                        <a href="author_page.cfm?id=81100545736&CFID=105750247&CFTOKEN=50542134">Iain Matthews</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 76</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964971" title="DOI">10.1145/1964921.1964971</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964971&ftid=1006170&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow68" style="display:inline;"><br /><div style="display:inline">Linear models, particularly those based on principal component analysis (PCA), have been used successfully on a broad range of human face-related applications. Although PCA models achieve high compression, they have not been widely used for animation ...</div></span>
          <span id="toHide68" style="display:none;"><br /><div style="display:inline"><p>Linear models, particularly those based on principal component analysis (PCA), have been used successfully on a broad range of human face-related applications. Although PCA models achieve high compression, they have not been widely used for animation in a production environment because their bases lack a semantic interpretation. Their parameters are not an intuitive set for animators to work with. In this paper we present a linear face modelling approach that generalises to unseen data better than the traditional holistic approach while also allowing <i>click-and-drag</i> interaction for animation. Our model is composed of a collection of PCA sub-models that are independently trained but share boundaries. Boundary consistency and user-given constraints are enforced in a soft least mean squares sense to give flexibility to the model while maintaining coherence. Our results show that the region-based model generalises better than its holistic counterpart when describing previously unseen motion capture data from multiple subjects. The decomposition of the face into several regions, which we determine automatically from training data, gives the user localised manipulation control. This feature allows to use the model for face posing and animation in an intuitive style.</p></div></span> <a id="expcoll68" href="JavaScript: expandcollapse('expcoll68',68)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964972&CFID=105750247&CFTOKEN=50542134">Realtime performance-based facial animation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442612832&CFID=105750247&CFTOKEN=50542134">Thibaut Weise</a>, 
                        <a href="author_page.cfm?id=81487643175&CFID=105750247&CFTOKEN=50542134">Sofien Bouaziz</a>, 
                        <a href="author_page.cfm?id=81442610499&CFID=105750247&CFTOKEN=50542134">Hao Li</a>, 
                        <a href="author_page.cfm?id=81100582775&CFID=105750247&CFTOKEN=50542134">Mark Pauly</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 77</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964972" title="DOI">10.1145/1964921.1964972</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964972&ftid=1006171&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964972&ftid=1074039&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow69" style="display:inline;"><br /><div style="display:inline">This paper presents a system for performance-based character animation that enables any user to control the facial expressions of a digital avatar in realtime. The user is recorded in a natural environment using a non-intrusive, commercially available ...</div></span>
          <span id="toHide69" style="display:none;"><br /><div style="display:inline"><p>This paper presents a system for performance-based character animation that enables any user to control the facial expressions of a digital avatar in realtime. The user is recorded in a natural environment using a non-intrusive, commercially available 3D sensor. The simplicity of this acquisition device comes at the cost of high noise levels in the acquired data. To effectively map low-quality 2D images and 3D depth maps to realistic facial expressions, we introduce a novel face tracking algorithm that combines geometry and texture registration with pre-recorded animation priors in a single optimization. Formulated as a maximum a posteriori estimation in a reduced parameter space, our method implicitly exploits temporal coherence to stabilize the tracking. We demonstrate that compelling 3D facial dynamics can be reconstructed in realtime without the use of face markers, intrusive lighting, or complex scanning hardware. This makes our system easy to deploy and facilitates a range of new applications, e.g. in digital gameplay or social interactions.</p></div></span> <a id="expcoll69" href="JavaScript: expandcollapse('expcoll69',69)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Mapping & warping shapes</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Mathieu Desbrun 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964973&CFID=105750247&CFTOKEN=50542134">Bounded biharmonic weights for real-time deformation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487642912&CFID=105750247&CFTOKEN=50542134">Alec Jacobson</a>, 
                        <a href="author_page.cfm?id=81100129752&CFID=105750247&CFTOKEN=50542134">Ilya Baran</a>, 
                        <a href="author_page.cfm?id=81100620337&CFID=105750247&CFTOKEN=50542134">Jovan Popovi&#263;</a>, 
                        <a href="author_page.cfm?id=81100036540&CFID=105750247&CFTOKEN=50542134">Olga Sorkine</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 78</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964973" title="DOI">10.1145/1964921.1964973</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964973&ftid=1006172&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow71" style="display:inline;"><br /><div style="display:inline">Object deformation with linear blending dominates practical use as the fastest approach for transforming raster images, vector graphics, geometric models and animated characters. Unfortunately, linear blending schemes for skeletons or cages are not always ...</div></span>
          <span id="toHide71" style="display:none;"><br /><div style="display:inline"><p>Object deformation with linear blending dominates practical use as the fastest approach for transforming raster images, vector graphics, geometric models and animated characters. Unfortunately, linear blending schemes for skeletons or cages are not always easy to use because they may require manual weight painting or modeling closed polyhedral envelopes around objects. Our goal is to make the design and control of deformations simpler by allowing the user to work freely with the most convenient combination of handle types. We develop linear blending weights that produce smooth and intuitive deformations for points, bones and cages of arbitrary topology. Our weights, called bounded biharmonic weights, minimize the Laplacian energy subject to bound constraints. Doing so spreads the influences of the controls in a shape-aware and localized manner, even for objects with complex and concave boundaries. The variational weight optimization also makes it possible to customize the weights so that they preserve the shape of specified essential object features. We demonstrate successful use of our blending weights for real-time deformation of 2D and 3D shapes.</p></div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964974&CFID=105750247&CFTOKEN=50542134">Blended intrinsic maps</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100654133&CFID=105750247&CFTOKEN=50542134">Vladimir G. Kim</a>, 
                        <a href="author_page.cfm?id=81100456149&CFID=105750247&CFTOKEN=50542134">Yaron Lipman</a>, 
                        <a href="author_page.cfm?id=81100182132&CFID=105750247&CFTOKEN=50542134">Thomas Funkhouser</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 79</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964974" title="DOI">10.1145/1964921.1964974</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964974&ftid=1006173&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964974&ftid=1074157&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow72" style="display:inline;"><br /><div style="display:inline">This paper describes a fully automatic pipeline for finding an intrinsic map between two non-isometric, genus zero surfaces. Our approach is based on the observation that efficient methods exist to search for nearly isometric maps (e.g., M&ouml;bius ...</div></span>
          <span id="toHide72" style="display:none;"><br /><div style="display:inline"><p>This paper describes a fully automatic pipeline for finding an intrinsic map between two non-isometric, genus zero surfaces. Our approach is based on the observation that efficient methods exist to search for nearly isometric maps (e.g., M&ouml;bius Voting or Heat Kernel Maps), but no single solution found with these methods provides low-distortion everywhere for pairs of surfaces differing by large deformations. To address this problem, we suggest using a weighted combination of these maps to produce a "blended map." This approach enables algorithms that leverage efficient search procedures, yet can provide the flexibility to handle large deformations.</p> <p>The main challenges of this approach lie in finding a set of candidate maps {<i>m</i><sub><i>i</i></sub>} and their associated blending weights {<i>b</i><sub><i>i</i></sub>(<i>p</i>)} for every point <i>p</i> on the surface. We address these challenges specifically for conformal maps by making the following contributions. First, we provide a way to blend maps, defining the image of <i>p</i> as the weighted geodesic centroid of <i>m</i><sub><i>i</i></sub>(<i>p</i>). Second, we provide a definition for smooth blending weights at every point <i>p</i> that are proportional to the area preservation of <i>m</i><sub><i>i</i></sub> at <i>p</i>. Third, we solve a global optimization problem that selects candidate maps based both on their area preservation and consistency with other selected maps. During experiments with these methods, we find that our algorithm produces blended maps that align semantic features better than alternative approaches over a variety of data sets.</p></div></span> <a id="expcoll72" href="JavaScript: expandcollapse('expcoll72',72)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964975&CFID=105750247&CFTOKEN=50542134">Photo-inspired model-driven 3D object modeling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81320496812&CFID=105750247&CFTOKEN=50542134">Kai Xu</a>, 
                        <a href="author_page.cfm?id=81474690309&CFID=105750247&CFTOKEN=50542134">Hanlin Zheng</a>, 
                        <a href="author_page.cfm?id=81336494344&CFID=105750247&CFTOKEN=50542134">Hao Zhang</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105750247&CFTOKEN=50542134">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81335493715&CFID=105750247&CFTOKEN=50542134">Ligang Liu</a>, 
                        <a href="author_page.cfm?id=81320496621&CFID=105750247&CFTOKEN=50542134">Yueshan Xiong</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 80</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964975" title="DOI">10.1145/1964921.1964975</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964975&ftid=1006174&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964975&ftid=1074040&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow73" style="display:inline;"><br /><div style="display:inline">We introduce an algorithm for 3D object modeling where the user draws creative inspiration from an object captured in a single photograph. Our method leverages the rich source of photographs for creative 3D modeling. However, with only a photo as a guide, ...</div></span>
          <span id="toHide73" style="display:none;"><br /><div style="display:inline"><p>We introduce an algorithm for 3D object modeling where the user draws creative inspiration from an object captured in a single photograph. Our method leverages the rich source of photographs for creative 3D modeling. However, with only a photo as a guide, creating a 3D model from scratch is a daunting task. We support the modeling process by utilizing an available set of 3D candidate models. Specifically, the user creates a digital 3D model as a geometric variation from a 3D candidate. Our modeling technique consists of two major steps. The first step is a user-guided image-space object segmentation to reveal the structure of the photographed object. The core step is the second one, in which a 3D candidate is automatically deformed to fit the photographed target under the guidance of silhouette correspondence. The set of candidate models have been pre-analyzed to possess useful high-level structural information, which is heavily utilized in both steps to compensate for the ill-posedness of the analysis and modeling problems based only on content in a single image. Equally important, the structural information is preserved by the geometric variation so that the final product is coherent with its inherited structural information readily usable for subsequent model refinement or processing.</p></div></span> <a id="expcoll73" href="JavaScript: expandcollapse('expcoll73',73)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Fluid simulation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Nils Thuerey 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964976&CFID=105750247&CFTOKEN=50542134">Two-scale particle simulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100111111&CFID=105750247&CFTOKEN=50542134">Barbara Solenthaler</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105750247&CFTOKEN=50542134">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 81</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964976" title="DOI">10.1145/1964921.1964976</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964976&ftid=1006175&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964976&ftid=1074044&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow75" style="display:inline;"><br /><div style="display:inline">We propose a two-scale method for particle-based fluids that allocates computing resources to regions of the fluid where complex flow behavior emerges. Our method uses a low- and a high-resolution simulation that run at the same time. While in the coarse ...</div></span>
          <span id="toHide75" style="display:none;"><br /><div style="display:inline"><p>We propose a two-scale method for particle-based fluids that allocates computing resources to regions of the fluid where complex flow behavior emerges. Our method uses a low- and a high-resolution simulation that run at the same time. While in the coarse simulation the whole fluid is represented by large particles, the fine level simulates only a subset of the fluid with small particles. The subset can be arbitrarily defined and also dynamically change over time to capture complex flows and small-scale surface details. The low- and high-resolution simulations are coupled by including feedback forces and defining appropriate boundary conditions. Our method offers the benefit that particles are of the same size within each simulation level. This avoids particle splitting and merging processes, and allows the simulation of very large resolution differences without any stability problems. The model is easy to implement, and we show how it can be integrated into a standard SPH simulation as well as into the incompressible PCISPH solver. Compared to the single-resolution simulation, our method produces similar surface details while improving the efficiency linearly to the achieved reduction rate of the particle number.</p></div></span> <a id="expcoll75" href="JavaScript: expandcollapse('expcoll75',75)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964977&CFID=105750247&CFTOKEN=50542134">Real-time Eulerian water simulation using a restricted tall cell grid</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314493444&CFID=105750247&CFTOKEN=50542134">Nuttapong Chentanez</a>, 
                        <a href="author_page.cfm?id=81100615490&CFID=105750247&CFTOKEN=50542134">Matthias M&#252;ller</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 82</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964977" title="DOI">10.1145/1964921.1964977</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964977&ftid=1006176&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964977&ftid=1074045&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow76" style="display:inline;"><br /><div style="display:inline">We present a new Eulerian fluid simulation method, which allows real-time simulations of large scale three dimensional liquids. Such scenarios have hitherto been restricted to the domain of off-line computation. To reduce computation time we use a hybrid ...</div></span>
          <span id="toHide76" style="display:none;"><br /><div style="display:inline"><p>We present a new Eulerian fluid simulation method, which allows real-time simulations of large scale three dimensional liquids. Such scenarios have hitherto been restricted to the domain of off-line computation. To reduce computation time we use a hybrid grid representation composed of regular cubic cells on top of a layer of tall cells. With this layout water above an arbitrary terrain can be represented without consuming an excessive amount of memory and compute power, while focusing effort on the area near the surface where it most matters. Additionally, we optimized the grid representation for a GPU implementation of the fluid solver. To further accelerate the simulation, we introduce a specialized multi-grid algorithm for solving the Poisson equation and propose solver modifications to keep the simulation stable for large time steps. We demonstrate the efficiency of our approach in several real-world scenarios, all running above 30 frames per second on a modern GPU. Some scenes include additional features such as two-way rigid body coupling as well as particle representations of sub-grid detail.</p></div></span> <a id="expcoll76" href="JavaScript: expandcollapse('expcoll76',76)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964978&CFID=105750247&CFTOKEN=50542134">Guide shapes for high resolution naturalistic liquid simulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100583432&CFID=105750247&CFTOKEN=50542134">Michael B. Nielsen</a>, 
                        <a href="author_page.cfm?id=81441592258&CFID=105750247&CFTOKEN=50542134">Robert Bridson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 83</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964978" title="DOI">10.1145/1964921.1964978</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964978&ftid=1006177&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964978&ftid=1074046&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow77" style="display:inline;"><br /><div style="display:inline">Art direction of high resolution naturalistic liquid simulations is notoriously hard, due to both the chaotic nature of the physics and the computational resources required. Resimulating a scene at higher resolution often produces very different results, ...</div></span>
          <span id="toHide77" style="display:none;"><br /><div style="display:inline"><p>Art direction of high resolution naturalistic liquid simulations is notoriously hard, due to both the chaotic nature of the physics and the computational resources required. Resimulating a scene at higher resolution often produces very different results, and is too expensive to allow many design cycles. We present a method of constraining or <i>guiding</i> a high resolution liquid simulation to stay close to a finalized low resolution version (either simulated or directly animated), restricting the solve to a thin outer shell of liquid around a <i>guide shape</i>. Our method is generally faster than an unconstrained simulation and can be integrated with a standard fluid simulator. We demonstrate several applications, with both simulated and hand-animated inputs.</p></div></span> <a id="expcoll77" href="JavaScript: expandcollapse('expcoll77',77)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964979&CFID=105750247&CFTOKEN=50542134">Animating fire with sound</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81448594205&CFID=105750247&CFTOKEN=50542134">Jeffrey N. Chadwick</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=105750247&CFTOKEN=50542134">Doug L. James</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 84</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964979" title="DOI">10.1145/1964921.1964979</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964979&ftid=1006178&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964979&ftid=1074047&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow78" style="display:inline;"><br /><div style="display:inline">We propose a practical method for synthesizing plausible fire sounds that are synchronized with physically based fire animations. To enable synthesis of combustion sounds without incurring the cost of time-stepping fluid simulations at audio rates, we ...</div></span>
          <span id="toHide78" style="display:none;"><br /><div style="display:inline"><p>We propose a practical method for synthesizing plausible fire sounds that are synchronized with physically based fire animations. To enable synthesis of combustion sounds without incurring the cost of time-stepping fluid simulations at audio rates, we decompose our synthesis procedure into two components. First, a low-frequency flame sound is synthesized using a physically based combustion sound model driven with data from a visual flame simulation run at a relatively low temporal sampling rate. Second, we propose two bandwidth extension methods for synthesizing additional high-frequency flame sound content: (1) spectral bandwidth extension which synthesizes higher-frequency noise matching combustion sound spectra from theory and experiment; and (2) data-driven texture synthesis to synthesize high-frequency content based on input flame sound recordings. Various examples and comparisons are presented demonstrating plausible flame sounds, from small candle flames to large flame jets.</p></div></span> <a id="expcoll78" href="JavaScript: expandcollapse('expcoll78',78)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Procedural & interactive modeling</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Niloy Mitra 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964980&CFID=105750247&CFTOKEN=50542134">Converting 3D furniture models to fabricatable parts and connectors</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100206137&CFID=105750247&CFTOKEN=50542134">Manfred Lau</a>, 
                        <a href="author_page.cfm?id=81487654944&CFID=105750247&CFTOKEN=50542134">Akira Ohgawara</a>, 
                        <a href="author_page.cfm?id=81100209891&CFID=105750247&CFTOKEN=50542134">Jun Mitani</a>, 
                        <a href="author_page.cfm?id=81100444444&CFID=105750247&CFTOKEN=50542134">Takeo Igarashi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 85</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964980" title="DOI">10.1145/1964921.1964980</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964980&ftid=1006179&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964980&ftid=1074041&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow80" style="display:inline;"><br /><div style="display:inline">Although there is an abundance of 3D models available, most of them exist only in virtual simulation and are not immediately usable as physical objects in the real world. We solve the problem of taking as input a 3D model of a man-made object, and automatically ...</div></span>
          <span id="toHide80" style="display:none;"><br /><div style="display:inline"><p>Although there is an abundance of 3D models available, most of them exist only in virtual simulation and are not immediately usable as physical objects in the real world. We solve the problem of taking as input a 3D model of a man-made object, and automatically generating the parts and connectors needed to build the corresponding physical object. We focus on furniture models, and we define formal grammars for IKEA cabinets and tables. We perform lexical analysis to identify the primitive parts of the 3D model. Structural analysis then gives structural information to these parts, and generates the connectors (i.e. nails, screws) needed to attach the parts together. We demonstrate our approach with arbitrary 3D models of cabinets and tables available online.</p></div></span> <a id="expcoll80" href="JavaScript: expandcollapse('expcoll80',80)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964981&CFID=105750247&CFTOKEN=50542134">Make it home: automatic optimization of furniture arrangement</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487650310&CFID=105750247&CFTOKEN=50542134">Lap-Fai Yu</a>, 
                        <a href="author_page.cfm?id=81322510441&CFID=105750247&CFTOKEN=50542134">Sai-Kit Yeung</a>, 
                        <a href="author_page.cfm?id=81100641929&CFID=105750247&CFTOKEN=50542134">Chi-Keung Tang</a>, 
                        <a href="author_page.cfm?id=81100294834&CFID=105750247&CFTOKEN=50542134">Demetri Terzopoulos</a>, 
                        <a href="author_page.cfm?id=81100178322&CFID=105750247&CFTOKEN=50542134">Tony F. Chan</a>, 
                        <a href="author_page.cfm?id=81100319117&CFID=105750247&CFTOKEN=50542134">Stanley J. Osher</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 86</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964981" title="DOI">10.1145/1964921.1964981</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964981&ftid=1006180&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964981&ftid=1074042&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow81" style="display:inline;"><br /><div style="display:inline">We present a system that automatically synthesizes indoor scenes realistically populated by a variety of furniture objects. Given examples of sensibly furnished indoor scenes, our system extracts, in advance, hierarchical and spatial relationships for ...</div></span>
          <span id="toHide81" style="display:none;"><br /><div style="display:inline"><p>We present a system that automatically synthesizes indoor scenes realistically populated by a variety of furniture objects. Given examples of sensibly furnished indoor scenes, our system extracts, in advance, hierarchical and spatial relationships for various furniture objects, encoding them into priors associated with ergonomic factors, such as visibility and accessibility, which are assembled into a cost function whose optimization yields realistic furniture arrangements. To deal with the prohibitively large search space, the cost function is optimized by simulated annealing using a Metropolis-Hastings state search step. We demonstrate that our system can synthesize multiple realistic furniture arrangements and, through a perceptual study, investigate whether there is a significant difference in the perceived functionality of the automatically synthesized results relative to furniture arrangements produced by human designers.</p></div></span> <a id="expcoll81" href="JavaScript: expandcollapse('expcoll81',81)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964982&CFID=105750247&CFTOKEN=50542134">Interactive furniture layout using interior design guidelines</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81385593374&CFID=105750247&CFTOKEN=50542134">Paul Merrell</a>, 
                        <a href="author_page.cfm?id=81388601846&CFID=105750247&CFTOKEN=50542134">Eric Schkufza</a>, 
                        <a href="author_page.cfm?id=81485641976&CFID=105750247&CFTOKEN=50542134">Zeyang Li</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=105750247&CFTOKEN=50542134">Maneesh Agrawala</a>, 
                        <a href="author_page.cfm?id=81100662243&CFID=105750247&CFTOKEN=50542134">Vladlen Koltun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 87</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964982" title="DOI">10.1145/1964921.1964982</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964982&ftid=1006181&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964982&ftid=1074043&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow82" style="display:inline;"><br /><div style="display:inline">We present an interactive furniture layout system that assists users by suggesting furniture arrangements that are based on interior design guidelines. Our system incorporates the layout guidelines as terms in a density function and generates layout ...</div></span>
          <span id="toHide82" style="display:none;"><br /><div style="display:inline"><p>We present an interactive furniture layout system that assists users by suggesting furniture arrangements that are based on interior design guidelines. Our system incorporates the layout guidelines as terms in a density function and generates layout suggestions by rapidly sampling the density function using a hardware-accelerated Monte Carlo sampler. Our results demonstrate that the suggestion generation functionality measurably increases the quality of furniture arrangements produced by participants with no prior training in interior design.</p></div></span> <a id="expcoll82" href="JavaScript: expandcollapse('expcoll82',82)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Video resizing & stabilization</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Wolfgang Heidrich 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964983&CFID=105750247&CFTOKEN=50542134">Scalable and coherent video resizing with per-frame optimization</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81318496997&CFID=105750247&CFTOKEN=50542134">Yu-Shuen Wang</a>, 
                        <a href="author_page.cfm?id=81487650744&CFID=105750247&CFTOKEN=50542134">Jen-Hung Hsiao</a>, 
                        <a href="author_page.cfm?id=81100036540&CFID=105750247&CFTOKEN=50542134">Olga Sorkine</a>, 
                        <a href="author_page.cfm?id=81409592133&CFID=105750247&CFTOKEN=50542134">Tong-Yee Lee</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 88</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964983" title="DOI">10.1145/1964921.1964983</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964983&ftid=1006182&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964983&ftid=1074048&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow84" style="display:inline;"><br /><div style="display:inline">The key to high-quality video resizing is preserving the shape and motion of visually salient objects while remaining temporally-coherent. These spatial and temporal requirements are difficult to reconcile, typically leading existing video retargeting ...</div></span>
          <span id="toHide84" style="display:none;"><br /><div style="display:inline"><p>The key to high-quality video resizing is preserving the shape and motion of visually salient objects while remaining temporally-coherent. These spatial and temporal requirements are difficult to reconcile, typically leading existing video retargeting methods to sacrifice one of them and causing distortion or waving artifacts. Recent work enforces temporal coherence of content-aware video warping by solving a global optimization problem over the entire video cube. This significantly improves the results but does not scale well with the resolution and length of the input video and quickly becomes intractable. We propose a new method that solves the scalability problem without compromising the resizing quality. Our method factors the problem into spatial and time/motion components: we first resize each frame independently to preserve the shape of salient regions, and then we optimize their motion using a reduced model for each pathline of the optical flow. This factorization decomposes the optimization of the video cube into sets of sub-problems whose size is proportional to a single frame's resolution and which can be solved in parallel. We also show how to incorporate cropping into our optimization, which is useful for scenes with numerous salient objects where warping alone would degenerate to linear scaling. Our results match the quality of state-of-the-art retargeting methods while dramatically reducing the computation time and memory consumption, making content-aware video resizing scalable and practical.</p></div></span> <a id="expcoll84" href="JavaScript: expandcollapse('expcoll84',84)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964984&CFID=105750247&CFTOKEN=50542134">Tonal stabilization of video</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365591397&CFID=105750247&CFTOKEN=50542134">Zeev Farbman</a>, 
                        <a href="author_page.cfm?id=81474662083&CFID=105750247&CFTOKEN=50542134">Dani Lischinski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 89</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964984" title="DOI">10.1145/1964921.1964984</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964984&ftid=1006183&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964984&ftid=1074049&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow85" style="display:inline;"><br /><div style="display:inline">This paper presents a method for reducing undesirable tonal fluctuations in video: minute changes in tonal characteristics, such as exposure, color temperature, brightness and contrast in a sequence of frames, which are easily noticeable when the sequence ...</div></span>
          <span id="toHide85" style="display:none;"><br /><div style="display:inline"><p>This paper presents a method for reducing undesirable tonal fluctuations in video: minute changes in tonal characteristics, such as exposure, color temperature, brightness and contrast in a sequence of frames, which are easily noticeable when the sequence is viewed. These fluctuations are typically caused by the camera's automatic adjustment of its tonal settings while shooting.</p> <p>Our approach operates on a continuous video shot by first designating one or more frames as <i>anchors</i>. We then <i>tonally align</i> a sequence of frames with each anchor: for each frame, we compute an adjustment map that indicates how each of its pixels should be modified in order to appear as if it was captured with the tonal settings of the anchor. The adjustment map is efficiently updated between successive frames by taking advantage of temporal video coherence and the global nature of the tonal fluctuations. Once a sequence has been aligned, it is possible to generate smooth tonal transitions between anchors, and also further control its tonal characteristics in a consistent and principled manner, which is difficult to do without incurring strong artifacts when operating on unstable sequences. We demonstrate the utility of our method using a number of clips captured with a variety of video cameras, and believe that it is well-suited for integration into today's non-linear video editing tools.</p></div></span> <a id="expcoll85" href="JavaScript: expandcollapse('expcoll85',85)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Fast simulation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Mark Meyer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964985&CFID=105750247&CFTOKEN=50542134">Sensitive couture for interactive garment modeling and editing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81487655259&CFID=105750247&CFTOKEN=50542134">Nobuyuki Umetani</a>, 
                        <a href="author_page.cfm?id=81100224608&CFID=105750247&CFTOKEN=50542134">Danny M. Kaufman</a>, 
                        <a href="author_page.cfm?id=81100444444&CFID=105750247&CFTOKEN=50542134">Takeo Igarashi</a>, 
                        <a href="author_page.cfm?id=81320489894&CFID=105750247&CFTOKEN=50542134">Eitan Grinspun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 90</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964985" title="DOI">10.1145/1964921.1964985</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964985&ftid=1006184&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964985&ftid=1074050&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow87" style="display:inline;"><br /><div style="display:inline">We present a novel interactive tool for garment design that enables, for the first time, interactive bidirectional editing between 2D patterns and 3D high-fidelity simulated draped forms. This provides a continuous, interactive, and natural design modality ...</div></span>
          <span id="toHide87" style="display:none;"><br /><div style="display:inline"><p>We present a novel interactive tool for garment design that enables, for the first time, interactive bidirectional editing between 2D patterns and 3D high-fidelity simulated draped forms. This provides a continuous, interactive, and natural design modality in which 2D and 3D representations are simultaneously visible and seamlessly maintain correspondence. Artists can now interactively edit 2D pattern designs and immediately obtain stable accurate feedback online, thus enabling rapid prototyping and an intuitive understanding of complex drape form.</p></div></span> <a id="expcoll87" href="JavaScript: expandcollapse('expcoll87',87)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964986&CFID=105750247&CFTOKEN=50542134">Real-time large-deformation substructuring</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100158368&CFID=105750247&CFTOKEN=50542134">Jernej Barbi&#269;</a>, 
                        <a href="author_page.cfm?id=81487651484&CFID=105750247&CFTOKEN=50542134">Yili Zhao</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 91</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964986" title="DOI">10.1145/1964921.1964986</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964986&ftid=1006185&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964986&ftid=1074051&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow88" style="display:inline;"><br /><div style="display:inline">This paper shows a method to extend 3D nonlinear elasticity model reduction to open-loop multi-level reduced deformable structures. Given a volumetric mesh, we decompose the mesh into several subdomains, build a reduced deformable model for each domain, ...</div></span>
          <span id="toHide88" style="display:none;"><br /><div style="display:inline"><p>This paper shows a method to extend 3D nonlinear elasticity model reduction to open-loop multi-level reduced deformable structures. Given a volumetric mesh, we decompose the mesh into several subdomains, build a reduced deformable model for each domain, and connect the domains using inertia coupling. This makes model reduction deformable simulations much more versatile: localized deformations can be supported without prohibitive computational costs, parts can be re-used and precomputation times shortened. Our method does not use constraints, and can handle large domain rigid body motion in addition to large deformations, due to our derivation of the gradient and Hessian of the rotation matrix in polar decomposition. We show real-time examples with multi-level domain hierarchies and hundreds of reduced degrees of freedom.</p></div></span> <a id="expcoll88" href="JavaScript: expandcollapse('expcoll88',88)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964987&CFID=105750247&CFTOKEN=50542134">Solid simulation with oriented particles</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100615490&CFID=105750247&CFTOKEN=50542134">Matthias M&#252;ller</a>, 
                        <a href="author_page.cfm?id=81314493444&CFID=105750247&CFTOKEN=50542134">Nuttapong Chentanez</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 92</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964987" title="DOI">10.1145/1964921.1964987</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964987&ftid=1006186&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964987&ftid=1074052&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow89" style="display:inline;"><br /><div style="display:inline">We propose a new fast and robust method to simulate various types of solid including rigid, plastic and soft bodies as well as one, two and three dimensional structures such as ropes, cloth and volumetric objects. The underlying idea is to use oriented ...</div></span>
          <span id="toHide89" style="display:none;"><br /><div style="display:inline"><p>We propose a new fast and robust method to simulate various types of solid including rigid, plastic and soft bodies as well as one, two and three dimensional structures such as ropes, cloth and volumetric objects. The underlying idea is to use oriented particles that store rotation and spin, along with the usual linear attributes, i.e. position and velocity. This additional information adds substantially to traditional particle methods. First, particles can be represented by anisotropic shapes such as ellipsoids, which approximate surfaces more accurately than spheres. Second, shape matching becomes robust for sparse structures such as chains of particles or even single particles because the undefined degrees of freedom are captured in the rotational states of the particles. Third, the full transformation stored in the particles, including translation and rotation, can be used for robust skinning of graphical meshes and for transforming plastic deformations back into the rest state.</p></div></span> <a id="expcoll89" href="JavaScript: expandcollapse('expcoll89',89)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964988&CFID=105750247&CFTOKEN=50542134">Physics-inspired upsampling for cloth simulation in games</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100550151&CFID=105750247&CFTOKEN=50542134">Ladislav Kavan</a>, 
                        <a href="author_page.cfm?id=81442618802&CFID=105750247&CFTOKEN=50542134">Dan Gerszewski</a>, 
                        <a href="author_page.cfm?id=81100355860&CFID=105750247&CFTOKEN=50542134">Adam W. Bargteil</a>, 
                        <a href="author_page.cfm?id=81100524617&CFID=105750247&CFTOKEN=50542134">Peter-Pike Sloan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 93</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964988" title="DOI">10.1145/1964921.1964988</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964988&ftid=1006187&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow90" style="display:inline;"><br /><div style="display:inline">We propose a method for learning linear upsampling operators for physically-based cloth simulation, allowing us to enrich coarse meshes with mid-scale details in minimal time and memory budgets, as required in computer games. In contrast to classical ...</div></span>
          <span id="toHide90" style="display:none;"><br /><div style="display:inline"><p>We propose a method for learning linear upsampling operators for physically-based cloth simulation, allowing us to enrich coarse meshes with mid-scale details in minimal time and memory budgets, as required in computer games. In contrast to classical subdivision schemes, our operators adapt to a specific context (e.g. a flag flapping in the wind or a skirt worn by a character), which allows them to achieve higher detail. Our method starts by pre-computing a pair of coarse and fine training simulations aligned with <i>tracking constraints</i> using harmonic test functions. Next, we train the upsampling operators with a new regularization method that enables us to learn mid-scale details without overfitting. We demonstrate generalizability to unseen conditions such as different wind velocities or novel character motions. Finally, we discuss how to re-introduce high frequency details not explainable by the coarse mesh alone using <i>oscillatory modes</i>.</p></div></span> <a id="expcoll90" href="JavaScript: expandcollapse('expcoll90',90)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Stereo & disparity</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Kari Pulli 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964989&CFID=105750247&CFTOKEN=50542134">Computational stereo camera system with programmable control loop</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81375601375&CFID=105750247&CFTOKEN=50542134">Simon Heinzle</a>, 
                        <a href="author_page.cfm?id=81470655188&CFID=105750247&CFTOKEN=50542134">Pierre Greisen</a>, 
                        <a href="author_page.cfm?id=81487642359&CFID=105750247&CFTOKEN=50542134">David Gallup</a>, 
                        <a href="author_page.cfm?id=81487645044&CFID=105750247&CFTOKEN=50542134">Christine Chen</a>, 
                        <a href="author_page.cfm?id=81487655224&CFID=105750247&CFTOKEN=50542134">Daniel Saner</a>, 
                        <a href="author_page.cfm?id=81100168168&CFID=105750247&CFTOKEN=50542134">Aljoscha Smolic</a>, 
                        <a href="author_page.cfm?id=81313482009&CFID=105750247&CFTOKEN=50542134">Andreas Burg</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=105750247&CFTOKEN=50542134">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=105750247&CFTOKEN=50542134">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 94</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964989" title="DOI">10.1145/1964921.1964989</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964989&ftid=1006188&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow92" style="display:inline;"><br /><div style="display:inline">Stereoscopic 3D has gained significant importance in the entertainment industry. However, production of high quality stereoscopic content is still a challenging art that requires mastering the complex interplay of human perception, 3D display properties, ...</div></span>
          <span id="toHide92" style="display:none;"><br /><div style="display:inline"><p>Stereoscopic 3D has gained significant importance in the entertainment industry. However, production of high quality stereoscopic content is still a challenging art that requires mastering the complex interplay of human perception, 3D display properties, and artistic intent. In this paper, we present a computational stereo camera system that closes the control loop from capture and analysis to automatic adjustment of physical parameters. Intuitive interaction metaphors are developed that replace cumbersome handling of rig parameters using a touch screen interface with 3D visualization. Our system is designed to make stereoscopic 3D production as easy, intuitive, flexible, and reliable as possible. Captured signals are processed and analyzed in real-time on a stream processor. Stereoscopy and user settings define programmable control functionalities, which are executed in real-time on a control processor. Computational power and flexibility is enabled by a dedicated software and hardware architecture. We show that even traditionally difficult shots can be easily captured using our system.</p></div></span> <a id="expcoll92" href="JavaScript: expandcollapse('expcoll92',92)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964990&CFID=105750247&CFTOKEN=50542134">Layered 3D: tomographic image synthesis for attenuation-based light field and high dynamic range displays</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335499586&CFID=105750247&CFTOKEN=50542134">Gordon Wetzstein</a>, 
                        <a href="author_page.cfm?id=81319495323&CFID=105750247&CFTOKEN=50542134">Douglas Lanman</a>, 
                        <a href="author_page.cfm?id=81100644737&CFID=105750247&CFTOKEN=50542134">Wolfgang Heidrich</a>, 
                        <a href="author_page.cfm?id=81100022847&CFID=105750247&CFTOKEN=50542134">Ramesh Raskar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 95</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964990" title="DOI">10.1145/1964921.1964990</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964990&ftid=1006189&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964990&ftid=1074053&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow93" style="display:inline;"><br /><div style="display:inline">We develop tomographic techniques for image synthesis on displays composed of compact volumes of light-attenuating material. Such volumetric attenuators recreate a 4D light field or high-contrast 2D image when illuminated by a uniform backlight. Since ...</div></span>
          <span id="toHide93" style="display:none;"><br /><div style="display:inline"><p>We develop tomographic techniques for image synthesis on displays composed of compact volumes of light-attenuating material. Such volumetric attenuators recreate a 4D light field or high-contrast 2D image when illuminated by a uniform backlight. Since arbitrary oblique views may be inconsistent with any single attenuator, iterative tomographic reconstruction minimizes the difference between the emitted and target light fields, subject to physical constraints on attenuation. As multi-layer generalizations of conventional parallax barriers, such displays are shown, both by theory and experiment, to exceed the performance of existing dual-layer architectures. For 3D display, spatial resolution, depth of field, and brightness are increased, compared to parallax barriers. For a plane at a fixed depth, our optimization also allows optimal construction of high dynamic range displays, confirming existing heuristics and providing the first extension to multiple, disjoint layers. We conclude by demonstrating the benefits and limitations of attenuation-based light field displays using an inexpensive fabrication method: separating multiple printed transparencies with acrylic sheets.</p></div></span> <a id="expcoll93" href="JavaScript: expandcollapse('expcoll93',93)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964991&CFID=105750247&CFTOKEN=50542134">A perceptual model for disparity</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466647837&CFID=105750247&CFTOKEN=50542134">Piotr Didyk</a>, 
                        <a href="author_page.cfm?id=81351607404&CFID=105750247&CFTOKEN=50542134">Tobias Ritschel</a>, 
                        <a href="author_page.cfm?id=81310501633&CFID=105750247&CFTOKEN=50542134">Elmar Eisemann</a>, 
                        <a href="author_page.cfm?id=81332517742&CFID=105750247&CFTOKEN=50542134">Karol Myszkowski</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105750247&CFTOKEN=50542134">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 96</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964991" title="DOI">10.1145/1964921.1964991</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964991&ftid=1006190&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964991&ftid=1074054&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow94" style="display:inline;"><br /><div style="display:inline">Binocular disparity is an important cue for the human visual system to recognize spatial layout, both in reality and simulated virtual worlds. This paper introduces a perceptual model of disparity for computer graphics that is used to define a metric ...</div></span>
          <span id="toHide94" style="display:none;"><br /><div style="display:inline"><p>Binocular disparity is an important cue for the human visual system to recognize spatial layout, both in reality and simulated virtual worlds. This paper introduces a perceptual model of disparity for computer graphics that is used to define a metric to compare a stereo image to an alternative stereo image and to estimate the magnitude of the perceived disparity change. Our model can be used to assess the effect of disparity to control the level of undesirable distortions or enhancements (introduced on purpose). A number of psycho-visual experiments are conducted to quantify the mutual effect of disparity magnitude and frequency to derive the model. Besides difference prediction, other applications include compression, and re-targeting. We also present novel applications in form of hybrid stereo images and backward-compatible stereo. The latter minimizes disparity in order to convey a stereo impression if special equipment is used but produces images that appear almost ordinary to the naked eye. The validity of our model and difference metric is again confirmed in a study.</p></div></span> <a id="expcoll94" href="JavaScript: expandcollapse('expcoll94',94)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Fun with shapes</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Eitan Grinspun 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964992&CFID=105750247&CFTOKEN=50542134">Making burr puzzles from 3D models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414607055&CFID=105750247&CFTOKEN=50542134">Shiqing Xin</a>, 
                        <a href="author_page.cfm?id=81466646914&CFID=105750247&CFTOKEN=50542134">Chi-Fu Lai</a>, 
                        <a href="author_page.cfm?id=81100244740&CFID=105750247&CFTOKEN=50542134">Chi-Wing Fu</a>, 
                        <a href="author_page.cfm?id=81343509200&CFID=105750247&CFTOKEN=50542134">Tien-Tsin Wong</a>, 
                        <a href="author_page.cfm?id=81100331607&CFID=105750247&CFTOKEN=50542134">Ying He</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=105750247&CFTOKEN=50542134">Daniel Cohen-Or</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 97</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964992" title="DOI">10.1145/1964921.1964992</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964992&ftid=1006191&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964992&ftid=1074055&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow96" style="display:inline;"><br /><div style="display:inline">A 3D burr puzzle is a 3D model that consists of interlocking pieces with a single-key property. That is, when the puzzle is assembled, all the pieces are notched except one single key component which remains mobile. The intriguing property of the assembled ...</div></span>
          <span id="toHide96" style="display:none;"><br /><div style="display:inline"><p>A 3D burr puzzle is a 3D model that consists of interlocking pieces with a single-key property. That is, when the puzzle is assembled, all the pieces are notched except one single key component which remains mobile. The intriguing property of the assembled burr puzzle is that it is stable, perfectly interlocked, without glue or screws, etc. Moreover, a burr puzzle consisting of a small number of pieces is still rather difficult to solve since the assembly must follow certain orders while the combinatorial complexity of the puzzle's piece arrangements is extremely high.</p> <p>In this paper, we generalize the 6-piece orthogonal burr puzzle (a knot) to design and model burr puzzles from 3D models. Given a 3D input model, we first interactively embed a network of knots into the 3D shape. Our method automatically optimizes and arranges the orientation of each knot, and modifies pieces of adjacent knots with an appropriate connection type. Then, following the geometry of the embedded pieces, the entire 3D model is partitioned by splitting the solid while respecting the assembly motion of embedded pieces. The main technical challenge is to enforce the single-key property and ensure the assembly/disassembly remains feasible, as the puzzle pieces in a network of knots are highly interlocked. Lastly, we also present an automated approach to generate the visualizations of the puzzle assembly process.</p></div></span> <a id="expcoll96" href="JavaScript: expandcollapse('expcoll96',96)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964993&CFID=105750247&CFTOKEN=50542134">A geometric study of v-style pop-ups: theories and algorithms</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81466646757&CFID=105750247&CFTOKEN=50542134">Xian-Ying Li</a>, 
                        <a href="author_page.cfm?id=81100098726&CFID=105750247&CFTOKEN=50542134">Tao Ju</a>, 
                        <a href="author_page.cfm?id=81487646831&CFID=105750247&CFTOKEN=50542134">Yan Gu</a>, 
                        <a href="author_page.cfm?id=81100254073&CFID=105750247&CFTOKEN=50542134">Shi-Min Hu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 98</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964993" title="DOI">10.1145/1964921.1964993</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964993&ftid=1006192&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964993&ftid=1074056&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow97" style="display:inline;"><br /><div style="display:inline">Pop-up books are a fascinating form of paper art with intriguing geometric properties. In this paper, we present a systematic study of a simple but common class of pop-ups consisting of patches falling into four parallel groups, which we call v-style ...</div></span>
          <span id="toHide97" style="display:none;"><br /><div style="display:inline"><p>Pop-up books are a fascinating form of paper art with intriguing geometric properties. In this paper, we present a systematic study of a simple but common class of pop-ups consisting of patches falling into four parallel groups, which we call v-style pop-ups. We give sufficient conditions for a v-style paper structure to be pop-uppable. That is, it can be closed flat while maintaining the rigidity of the patches, the closing and opening do not need extra force besides holding two patches and are free of intersections, and the closed paper is contained within the page border. These conditions allow us to identify novel mechanisms for making pop-ups. Based on the theory and mechanisms, we developed an interactive tool for designing v-style pop-ups and an automated construction algorithm from a given geometry, both of which guaranteeing the pop-uppability of the results.</p></div></span> <a id="expcoll97" href="JavaScript: expandcollapse('expcoll97',97)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964994&CFID=105750247&CFTOKEN=50542134">Depixelizing pixel art</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335493017&CFID=105750247&CFTOKEN=50542134">Johannes Kopf</a>, 
                        <a href="author_page.cfm?id=81474662083&CFID=105750247&CFTOKEN=50542134">Dani Lischinski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 99</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964994" title="DOI">10.1145/1964921.1964994</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964994&ftid=1006193&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964994&ftid=1074057&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow98" style="display:inline;"><br /><div style="display:inline">We describe a novel algorithm for extracting a resolution-independent vector representation from pixel art images, which enables magnifying the results by an arbitrary amount without image degradation. Our algorithm resolves pixel-scale features ...</div></span>
          <span id="toHide98" style="display:none;"><br /><div style="display:inline"><p>We describe a novel algorithm for extracting a resolution-independent vector representation from <i>pixel art</i> images, which enables magnifying the results by an arbitrary amount without image degradation. Our algorithm resolves pixel-scale features in the input and converts them into regions with smoothly varying shading that are crisply separated by piecewise-smooth contour curves. In the original image, pixels are represented on a square pixel lattice, where diagonal neighbors are only connected through a single point. This causes thin features to become visually disconnected under magnification by conventional means, and creates ambiguities in the connectedness and separation of diagonal neighbors. The key to our algorithm is in resolving these ambiguities. This enables us to reshape the pixel cells so that neighboring pixels belonging to the same feature are connected through edges, thereby preserving the feature connectivity under magnification. We reduce pixel aliasing artifacts and improve smoothness by fitting spline curves to contours in the image and optimizing their control points.</p></div></span> <a id="expcoll98" href="JavaScript: expandcollapse('expcoll98',98)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964995&CFID=105750247&CFTOKEN=50542134">Digital micrography</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81485645972&CFID=105750247&CFTOKEN=50542134">Ron Maharik</a>, 
                        <a href="author_page.cfm?id=81487647452&CFID=105750247&CFTOKEN=50542134">Mikhail Bessmeltsev</a>, 
                        <a href="author_page.cfm?id=81100389496&CFID=105750247&CFTOKEN=50542134">Alla Sheffer</a>, 
                        <a href="author_page.cfm?id=81100081895&CFID=105750247&CFTOKEN=50542134">Ariel Shamir</a>, 
                        <a href="author_page.cfm?id=81452610865&CFID=105750247&CFTOKEN=50542134">Nathan Carr</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 100</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964995" title="DOI">10.1145/1964921.1964995</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964995&ftid=1006194&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964995&ftid=1074058&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow99" style="display:inline;"><br /><div style="display:inline">We present an algorithm for creating digital micrography images, or micrograms, a special type of calligrams created from minuscule text. These attractive text-art works successfully combine beautiful images with readable meaningful text. Traditional ...</div></span>
          <span id="toHide99" style="display:none;"><br /><div style="display:inline"><p>We present an algorithm for creating digital micrography images, or <i>micrograms</i>, a special type of calligrams created from minuscule text. These attractive text-art works successfully combine beautiful images with readable meaningful text. Traditional micrograms are created by highly skilled artists and involve a huge amount of tedious manual work. We aim to simplify this process by providing a computerized digital micrography design tool. The main challenge in creating digital micrograms is designing textual layouts that simultaneously convey the input image, are readable and appealing. To generate such layout we use the streamlines of singularity free, low curvature, smooth vector fields, especially designed for our needs. The vector fields are computed using a new approach which controls field properties via <i>a priori</i> boundary condition design that balances the different requirements we aim to satisfy. The optimal boundary conditions are computed using a graph-cut approach balancing local and global design considerations. The generated layouts are further processed to obtain the final micrograms. Our method automatically generates engaging, readable micrograms starting from a vector image and an input text while providing a variety of optional high-level controls to the user.</p></div></span> <a id="expcoll99" href="JavaScript: expandcollapse('expcoll99',99)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Discrete differential geometry</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Yaron Lipman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964996&CFID=105750247&CFTOKEN=50542134">Circular arc structures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365596214&CFID=105750247&CFTOKEN=50542134">Pengbo Bo</a>, 
                        <a href="author_page.cfm?id=81100537406&CFID=105750247&CFTOKEN=50542134">Helmut Pottmann</a>, 
                        <a href="author_page.cfm?id=81365594691&CFID=105750247&CFTOKEN=50542134">Martin Kilian</a>, 
                        <a href="author_page.cfm?id=81451595839&CFID=105750247&CFTOKEN=50542134">Wenping Wang</a>, 
                        <a href="author_page.cfm?id=81100493818&CFID=105750247&CFTOKEN=50542134">Johannes Wallner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 101</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964996" title="DOI">10.1145/1964921.1964996</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964996&ftid=1006195&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964996&ftid=1074059&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow101" style="display:inline;"><br /><div style="display:inline">The most important guiding principle in computational methods for freeform architecture is the balance between cost efficiency on the one hand, and adherence to the design intent on the other. Key issues are the simplicity of supporting and connecting ...</div></span>
          <span id="toHide101" style="display:none;"><br /><div style="display:inline"><p>The most important guiding principle in computational methods for freeform architecture is the balance between cost efficiency on the one hand, and adherence to the design intent on the other. Key issues are the simplicity of supporting and connecting elements as well as repetition of costly parts. This paper proposes so-called circular arc structures as a means to faithfully realize freeform designs without giving up smooth appearance. In contrast to non-smooth meshes with straight edges where geometric complexity is concentrated in the nodes, we stay with smooth surfaces and rather distribute complexity in a uniform way by allowing edges in the shape of circular arcs. We are able to achieve the simplest possible shape of nodes without interfering with known panel optimization algorithms. We study remarkable special cases of circular arc structures which possess simple supporting elements or repetitive edges, we present the first global approximation method for principal patches, and we show an extension to volumetric structures for truly three-dimensional designs.</p></div></span> <a id="expcoll101" href="JavaScript: expandcollapse('expcoll101',101)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964997&CFID=105750247&CFTOKEN=50542134">Discrete Laplacians on general polygonal meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100235480&CFID=105750247&CFTOKEN=50542134">Marc Alexa</a>, 
                        <a href="author_page.cfm?id=81320496298&CFID=105750247&CFTOKEN=50542134">Max Wardetzky</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 102</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964997" title="DOI">10.1145/1964921.1964997</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964997&ftid=1006196&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964997&ftid=1074060&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow102" style="display:inline;"><br /><div style="display:inline">While the theory and applications of discrete Laplacians on triangulated surfaces are well developed, far less is known about the general polygonal case. We present here a principled approach for constructing geometric discrete Laplacians ...</div></span>
          <span id="toHide102" style="display:none;"><br /><div style="display:inline"><p>While the theory and applications of discrete Laplacians on <i>triangulated</i> surfaces are well developed, far less is known about the general <i>polygonal</i> case. We present here a principled approach for constructing geometric discrete Laplacians on surfaces with arbitrary polygonal faces, encompassing non-planar and non-convex polygons. Our construction is guided by closely mimicking structural properties of the smooth Laplace--Beltrami operator. Among other features, our construction leads to an extension of the widely employed cotan formula from triangles to polygons. Besides carefully laying out theoretical aspects, we demonstrate the versatility of our approach for a variety of geometry processing applications, embarking on situations that would have been more difficult to achieve based on geometric Laplacians for simplicial meshes or purely combinatorial Laplacians for general meshes.</p></div></span> <a id="expcoll102" href="JavaScript: expandcollapse('expcoll102',102)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964998&CFID=105750247&CFTOKEN=50542134">HOT: Hodge-optimized triangulations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100472126&CFID=105750247&CFTOKEN=50542134">Patrick Mullen</a>, 
                        <a href="author_page.cfm?id=81335494573&CFID=105750247&CFTOKEN=50542134">Pooran Memari</a>, 
                        <a href="author_page.cfm?id=81319490357&CFID=105750247&CFTOKEN=50542134">Fernando de Goes</a>, 
                        <a href="author_page.cfm?id=81100041821&CFID=105750247&CFTOKEN=50542134">Mathieu Desbrun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 103</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964998" title="DOI">10.1145/1964921.1964998</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964998&ftid=1006197&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964998&ftid=1074061&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow103" style="display:inline;"><br /><div style="display:inline">We introduce Hodge-optimized triangulations (HOT), a family of well-shaped primal-dual pairs of complexes designed for fast and accurate computations in computer graphics. Previous work most commonly employs barycentric or circumcentric duals; while ...</div></span>
          <span id="toHide103" style="display:none;"><br /><div style="display:inline"><p>We introduce Hodge-optimized triangulations (HOT), a family of well-shaped primal-dual pairs of complexes designed for fast and accurate computations in computer graphics. Previous work most commonly employs barycentric or circumcentric duals; while barycentric duals guarantee that the dual of each simplex lies within the simplex, circumcentric duals are often preferred due to the induced orthogonality between primal and dual complexes. We instead promote the use of weighted duals ("power diagrams"). They allow greater flexibility in the location of dual vertices while keeping primal-dual orthogonality, thus providing a valuable extension to the usual choices of dual by only adding one additional scalar per primal vertex. Furthermore, we introduce a family of functionals on pairs of complexes that we derive from bounds on the errors induced by diagonal Hodge stars, commonly used in discrete computations. The minimizers of these functionals, called HOT meshes, are shown to be generalizations of Centroidal Voronoi Tesselations and Optimal Delaunay Triangulations, and to provide increased accuracy and flexibility for a variety of computational purposes.</p></div></span> <a id="expcoll103" href="JavaScript: expandcollapse('expcoll103',103)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1964999&CFID=105750247&CFTOKEN=50542134">Spin transformations of discrete surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81315488302&CFID=105750247&CFTOKEN=50542134">Keenan Crane</a>, 
                        <a href="author_page.cfm?id=81365591193&CFID=105750247&CFTOKEN=50542134">Ulrich Pinkall</a>, 
                        <a href="author_page.cfm?id=81100117380&CFID=105750247&CFTOKEN=50542134">Peter Schr&#246;der</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 104</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1964999" title="DOI">10.1145/1964921.1964999</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1964999&ftid=1006198&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1964999&ftid=1074062&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow104" style="display:inline;"><br /><div style="display:inline">We introduce a new method for computing conformal transformations of triangle meshes in R3. Conformal maps are desirable in digital geometry processing because they do not exhibit shear, and therefore preserve texture fidelity as well ...</div></span>
          <span id="toHide104" style="display:none;"><br /><div style="display:inline"><p>We introduce a new method for computing conformal transformations of triangle meshes in R<sup>3</sup>. Conformal maps are desirable in digital geometry processing because they do not exhibit <i>shear</i>, and therefore preserve texture fidelity as well as the quality of the mesh itself. Traditional discretizations consider maps into the complex plane, which are useful only for problems such as surface parameterization and planar shape deformation where the target surface is flat. We instead consider maps into the <i>quaternions</i> H, which allows us to work directly with surfaces sitting in R<sup>3</sup>. In particular, we introduce a <i>quaternionic Dirac operator</i> and use it to develop a novel integrability condition on conformal deformations. Our discretization of this condition results in a sparse linear system that is simple to build and can be used to efficiently edit surfaces by manipulating curvature and boundary data, as demonstrated via several mesh processing applications.</p></div></span> <a id="expcoll104" href="JavaScript: expandcollapse('expcoll104',104)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Interactive image editing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Ariel Shamir 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1965000&CFID=105750247&CFTOKEN=50542134">Nonlinear revision control for images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100114673&CFID=105750247&CFTOKEN=50542134">Hsiang-Ting Chen</a>, 
                        <a href="author_page.cfm?id=81452594229&CFID=105750247&CFTOKEN=50542134">Li-Yi Wei</a>, 
                        <a href="author_page.cfm?id=81332492414&CFID=105750247&CFTOKEN=50542134">Chun-Fa Chang</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 105</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1965000" title="DOI">10.1145/1964921.1965000</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1965000&ftid=1006199&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1965000&ftid=1074063&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow106" style="display:inline;"><br /><div style="display:inline">Revision control is a vital component of digital project management and has been widely deployed for text files. Binary files, on the other hand, have received relatively less attention. This can be inconvenient for graphics applications that use a significant ...</div></span>
          <span id="toHide106" style="display:none;"><br /><div style="display:inline"><p>Revision control is a vital component of digital project management and has been widely deployed for text files. Binary files, on the other hand, have received relatively less attention. This can be inconvenient for graphics applications that use a significant amount of binary data, such as images, videos, meshes, and animations. Existing strategies such as storing whole files for individual revisions or simple binary deltas could consume significant storage and obscure vital semantic information. We present a nonlinear revision control system for images, designed with the common digital editing and sketching workflows in mind. We use DAG (directed acyclic graph) as the core structure, with DAG nodes representing editing operations and DAG edges the corresponding spatial, temporal and semantic relationships. We visualize our DAG in RevG (revision graph), which provides not only as a meaningful display of the revision history but also an intuitive interface for common revision control operations such as review, replay, diff, addition, branching, merging, and conflict resolving. Beyond revision control, our system also facilitates artistic creation processes in common image editing and digital painting workflows. We have built a prototype system upon GIMP, an open source image editor, and demonstrate its effectiveness through formative user study and comparisons with alternative revision control systems.</p></div></span> <a id="expcoll106" href="JavaScript: expandcollapse('expcoll106',106)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Real-time rendering hardware</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Bill Mark 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1965001&CFID=105750247&CFTOKEN=50542134">Clipless dual-space bounds for faster stochastic rasterization</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100622664&CFID=105750247&CFTOKEN=50542134">Samuli Laine</a>, 
                        <a href="author_page.cfm?id=81100649025&CFID=105750247&CFTOKEN=50542134">Timo Aila</a>, 
                        <a href="author_page.cfm?id=81456614249&CFID=105750247&CFTOKEN=50542134">Tero Karras</a>, 
                        <a href="author_page.cfm?id=81339512060&CFID=105750247&CFTOKEN=50542134">Jaakko Lehtinen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 106</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1965001" title="DOI">10.1145/1964921.1965001</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1965001&ftid=1006200&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1965001&ftid=1074064&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow108" style="display:inline;"><br /><div style="display:inline">We present a novel method for increasing the efficiency of stochastic rasterization of motion and defocus blur. Contrary to earlier approaches, our method is efficient even with the low sampling densities commonly encountered in realtime rendering, while ...</div></span>
          <span id="toHide108" style="display:none;"><br /><div style="display:inline"><p>We present a novel method for increasing the efficiency of stochastic rasterization of motion and defocus blur. Contrary to earlier approaches, our method is efficient even with the low sampling densities commonly encountered in realtime rendering, while allowing the use of arbitrary sampling patterns for maximal image quality. Our clipless dual-space formulation avoids problems with triangles that cross the camera plane during the shutter interval. The method is also simple to plug into existing rendering systems.</p></div></span> <a id="expcoll108" href="JavaScript: expandcollapse('expcoll108',108)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1965002&CFID=105750247&CFTOKEN=50542134">Spark: modular, composable shaders for graphics hardware</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81332498769&CFID=105750247&CFTOKEN=50542134">Tim Foley</a>, 
                        <a href="author_page.cfm?id=81100482576&CFID=105750247&CFTOKEN=50542134">Pat Hanrahan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 107</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1965002" title="DOI">10.1145/1964921.1965002</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1965002&ftid=1006201&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1965002&ftid=1074065&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow109" style="display:inline;"><br /><div style="display:inline">In creating complex real-time shaders, programmers should be able to decompose code into independent, localized modules of their choosing. Current real-time shading languages, however, enforce a fixed decomposition into per-pipeline-stage procedures. ...</div></span>
          <span id="toHide109" style="display:none;"><br /><div style="display:inline"><p>In creating complex real-time shaders, programmers should be able to decompose code into independent, localized modules of their choosing. Current real-time shading languages, however, enforce a fixed decomposition into per-pipeline-stage procedures. Program concerns at other scales -- including those that <i>cross-cut</i> multiple pipeline stages -- cannot be expressed as reusable modules.</p> <p>We present a shading language, Spark, and its implementation for modern graphics hardware that improves support for separation of concerns into modules. A Spark <i>shader class</i> can encapsulate code that maps to more than one pipeline stage, and can be extended and composed using object-oriented inheritance. In our tests, shaders written in Spark achieve performance within 2% of HLSL.</p></div></span> <a id="expcoll109" href="JavaScript: expandcollapse('expcoll109',109)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1965003&CFID=105750247&CFTOKEN=50542134">Physically-based real-time lens flare rendering</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365598554&CFID=105750247&CFTOKEN=50542134">Matthias Hullin</a>, 
                        <a href="author_page.cfm?id=81310501633&CFID=105750247&CFTOKEN=50542134">Elmar Eisemann</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=105750247&CFTOKEN=50542134">Hans-Peter Seidel</a>, 
                        <a href="author_page.cfm?id=81448593503&CFID=105750247&CFTOKEN=50542134">Sungkil Lee</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 108</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1964921.1965003" title="DOI">10.1145/1964921.1965003</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1965003&ftid=1006202&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1965003&ftid=1074066&dwn=1&CFID=105750247&CFTOKEN=50542134" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow110" style="display:inline;"><br /><div style="display:inline">Lens flare is caused by light passing through a photographic lens system in an unintended way. Often considered a degrading artifact, it has become a crucial component for realistic imagery and an artistic means that can even lead to an increased perceived ...</div></span>
          <span id="toHide110" style="display:none;"><br /><div style="display:inline"><p>Lens flare is caused by light passing through a photographic lens system in an unintended way. Often considered a degrading artifact, it has become a crucial component for realistic imagery and an artistic means that can even lead to an increased perceived brightness. So far, only costly offline processes allowed for convincing simulations of the complex light interactions. In this paper, we present a novel method to interactively compute physically-plausible flare renderings for photographic lenses. The underlying model covers many components that are important for realism, such as imperfections, chromatic and geometric lens aberrations, and antireflective lens coatings. Various acceleration strategies allow for a performance/quality tradeoff, making our technique applicable both in real-time applications and in high-quality production rendering. We further outline artistic extensions to our system.</p></div></span> <a id="expcoll110" href="JavaScript: expandcollapse('expcoll110',110)">expand</a>
          </div>
		  </td>
          </tr>          
          
</table>


</div> 
</div>


 <p class="small-text" align="center">Powered by <a id="theguide" name="theguide" href="javascript:ColdFusion.Window.show('theguide')"><img src="img/poweredbyacm.jpg" width="336" height="11" alt="The ACM Guide to Computing Literature" border="0" /></a></p>



 <br />
<div class="footerbody" align="center" >
	

	The ACM Digital Library is published by the Association for Computing Machinery. Copyright &copy; 2012 ACM, Inc.<br />
	<a href="http://www.acm.org/publications/policies/usage">Terms of Usage</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/privacy-policy">Privacy Policy</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/code-of-ethics">Code of Ethics</a>&nbsp;&nbsp;	  
	<a href="http://www.acm.org/about/contact-us">Contact Us</a>

<br /><br />
Useful downloads: 
<a href="http://www.adobe.com/products/acrobat/readstep2.html"><img src="http://dl.acm.org/images/pdf_logo.gif" width="16" height="16" alt="" border="0" /> Adobe Acrobat</a>
&nbsp;&nbsp;
<a href="http://www.apple.com/quicktime/download/" target="_blank"><img src="http://dl.acm.org/images/qtlogo.gif" width="16" height="16" alt="" border="0" /> QuickTime</a>
&nbsp;&nbsp;
<a href="http://www.microsoft.com/windows/windowsmedia/download/default.asp" target="_blank"><img src="http://dl.acm.org/images/wmv.gif" width="16" height="15" alt="" border="0" /> Windows Media Player</a>
&nbsp;&nbsp;
<a href="http://www.real.com/" target="_blank"><img src="http://dl.acm.org/images/realplayer.gif" width="20" height="18" alt="" border="0" /> Real Player</a>

</div> 



<div  id="cf_window1338240864385" class="yuiextdlg">
	
	<div  id="theguide_title" class="x-dlg-hd">
		The ACM Guide to Computing Literature
	 </div>
	<div  id="theguide_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240864388" class="yuiextdlg">
	
	<div  id="thetags_title" class="x-dlg-hd">
		All Tags
	 </div>
	<div  id="thetags_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240864391" class="yuiextdlg">
	
	<div  id="theformats_title" class="x-dlg-hd">
		Export Formats
	 </div>
	<div  id="theformats_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240864393" class="yuiextdlg">
	
	<div  id="theexplaination_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theexplaination_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240864395" class="yuiextdlg">
	
	<div  id="theservices_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theservices_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240864397" class="yuiextdlg">
	
	<div  id="savetobinder_title" class="x-dlg-hd">
		Save to Binder
	 </div>
	<div  id="savetobinder_body" class="x-dlg-bd">
		
		
	 </div>
 </div> 

</body>
</html>