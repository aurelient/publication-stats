


<!doctype html>


<head><script type="text/javascript">_cf_loadingtexthtml="<img alt=' ' src='/CFIDE/scripts/ajax/resources/cf/images/loading.gif'/>";
_cf_contextpath="";
_cf_ajaxscriptsrc="/CFIDE/scripts/ajax";
_cf_jsonprefix='//';
_cf_clientid='C644CB9544CFF926E716B8691EEEF3A4';</script><script type="text/javascript" src="/CFIDE/scripts/ajax/messages/cfmessage.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfajax.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfform.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/masks.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfformhistory.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfrichtexteditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/FCKeditor/fckeditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/yahoo-dom-event/yahoo-dom-event.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/animation/animation-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/adapter/yui/ext-yui-adapter.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/ext-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/resizable.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dragdrop/dragdrop.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/util.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/build/state/State-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/widget-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dialog/dialogs.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfwindow.js"></script>
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/ext/css/ext-all.css" />
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/cf/cf.css" />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="css/dl.css" />



<title>ACM SIGGRAPH 2005 Papers</title>
<style type="text/css"><!--
    body {margin-left: 0em; margin-top: 0}
    a:link {text-decoration: underline; 	Color: #1d4d0f;}
    a:visited  { color: #990033; text-decoration: underline;}
    a:hover {color: red; text-decoration: none}
    a.dLink1:link {color:#336699}
    a.dLink1:visited {color:#666666}
	a.isblack:link {text-decoration: underline; 	Color: #000000;}
    a.isblack:visited  { color: #000000; text-decoration: underline;}
    a.isblack:hover {color: #000000; text-decoration: none}
    h1 {font-size: 140%; margin-bottom: 0}
	ul {margin-top: .25em; list-style-type: disc}
	ol {margin-top: .25em;}
	li {padding-bottom: .25em}
    h2 {color: white; background-color: #069; 
        font-size: 100%; padding-left: 1em;
		margin: 0}
	h3 {color: black; background-color: yellow; 
    	font-size: 100%;
		margin: 0}
	 h4 {color: black; background-color: #99c5e8; 
        font-size: 100%;
		margin: 0}
    hr {color: #39176d;}
    form {margin-top: 10}
    form.xrs {margin-top: 0}
	
	a {text-decoration: none; }
	
	input {font-size: 1em;}
	.chevron {color: #ff0000;}
	.light-blue {color:#336699;}
	.black {color:#000000;}
	
	/* ### standard text styles, smallest to largest ### */
	
	.footer-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .75em; line-height: 1.33em;
		text-indent: -.75 em; margin-left: 2em; margin-right: .75em;}
		
	.footer-copy-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em; line-height: 1.3em;
		margin-left: .75em; margin-right: .75em;}
		
	.small-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; padding-bottom : 2px;
	  	padding-top : 2px;}

	.smallerer-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .65em;}
	.smaller-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em;}		
	.small-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em;}
	.small-textb {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; font-weight: bold;}
	.medium-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em;}
	.mediumb-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em; font-weight: bold;}
	.large-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1.3em;}		
	.instr-text {font-family: Arial, Helvetica, sans-serif;
		color:#666666; font-size: .83em;}
		
	.list-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .83em; line-height: 1.3em;}
	.list-link-btext {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; line-height: 1.3em;}
	
	.searchbox-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;}
	.footer-header-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;
		margin-left: .75em; margin-right: .75em;}
	.medium-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold; line-height: 1em;
		text-indent: -1.25em; margin-left: 2em; margin-right: .75em;}
	
	.text16 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 16px;}
		
	.text14 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 14px;}
	
	.text12 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 12px;}
		
	.text10 {font-family: Arial, Helvetica, sans-serif;
	    color:#000000; font-size: 12px;}
		
	.text9 {font-family: Arial, Helvetica, sans-serif;
	   color:#000000; font-size: 12px;}
	
	.error-text {color:red;}
	
	.small-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: .75em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}

	.medium-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1.3em; line-height: 1.5em;
		margin-left: .75em; margin-right: .75em;}
	
	.medium-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1.5em;
		margin-left: .75em; margin-right: .75em;}

		#side {
			width: 10px;
			float: left;
			margin-left: -1px;
			padding: 2px;
			}
							
		#content {
			padding: 2px;
			margin-left: 25px;
			
		        
		        }
	 .fulltext_lnk {border:0px;
	 				 margin-right: 2px;
					 vertical-align:baseline;
	 				}
	 
	  .leftcoltab { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:530px;  /* for IE5/WIN */
		  width:520px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	  .rightcoltab {
    float: right;
    margin: 0;
    padding: 5px;
    position: relative;
    right: 50px;
    top: 25px;
    width: 350px;
    z-index: 99;
}
	  .centercoltab {
		  position:absolute;
		  padding:0 0px;
		  }
	  .alt {
		background: #ece9d8;
		margin: 0;
		padding: 1px;
		}
		.leftcolc { 
	position:relative;
	top:5px;
	left:5px;
	float:left;
	width:420px;  /* for IE5/WIN */
	width:400px; /* actual value */
	margin:0 0 0px 0;
	padding:5px;
	z-index:100;
	}
.rightcolc {
	position:relative;
	top:0px;
	right:0px;
	float:right;
	margin:0 0px;
	padding:0px;
	width:500px;
	z-index:99;
	}
.centercolc {
	position:absolute;
	padding:0 0px;
	}
	
	.leftcoltabv { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:460px;  /* for IE5/WIN */
		  width:350px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	.rightcoltabv {
		position:relative;
		top:5px;
		right:0px;
		float:right;
		margin:0 0px 0 0;
		padding:15px;
		width:480px;
		z-index:99;
		}
	
  --></style>
 


<script type="text/javascript" src="cfformprotect/js/cffp.js"></script>


<script type="text/javascript">
 function expandcollapse(anchor,whichone) {
	 var inner = document.getElementById(anchor);
	 var theshow = "toShow" + whichone;
 	 var thehide = "toHide" + whichone;
	 var span = document.getElementById(theshow);
     span.style.display = (span.style.display=='inline')?'none':'inline';
     var span = document.getElementById(thehide);
     span.style.display = (span.style.display=='none')?'inline':'none';
     inner.innerHTML = (inner.innerHTML=='collapse')?'expand':'collapse';
    }

  function setDiv() {
	var m = document.getElementById('divmain');
	var mh = m.offsetHeight;
	var t = document.getElementById('divtools');
	var th = t.offsetHeight;
	var tg = document.getElementById('divtags');
	var tgh = tg.offsetHeight;
	var calcheight = mh - th;
	if (tgh > calcheight  ){
	  var x = (th + tgh) - mh;
	  if ( (th + tgh) - mh < 65) {
	  }
	  else {
		 document.getElementById('divtags').innerHTML = ""; 
		 var tg = document.getElementById('divtags');
		 var tgh = tg.offsetHeight;
		 tg.style.height = tgh  + 'px';
	  }
	}
	else {
		tg.style.height = calcheight + 'px';
		document.getElementById('divtags').innerHTML = "";
	}

//  do I need to check after I resize to be sure I didn't go too big?
//	var tg2 = document.getElementById('divtags');
//	var tgh2 = tg.offsetHeight;	
//	if (tgh2 > mh + 65) {
//	  var y = mh + 65;
//	  alert('expanded too much ' + tgh2 + ' should be at most ' + y);
//	  tg.style.height = y + 'px';
//	  document.getElementById('divtags').innerHTML = "";
//	}

  }
</script>

<script type="text/javascript">
 /* <!-- Begin
	if(document.layers || document.all) {
	a = 1;
	setInterval("Jump()", 10);
	}
	function Jump() {
	a = a + 1;
	//self.moveBy((Math.random() * a * 2 - a), (Math.random() * a * 2) - a);
	}
//  End --> */
</script>



<meta name="citation_publisher" content="ACM"> <meta name="citation_authors" content="Gross, Markus"> <meta name="citation_title" content="ACM SIGGRAPH 2005 Papers"> <meta name="citation_date" content="07/31/2005"> <meta name="citation_abstract_html_url" content="http://dl.acm.org/citation.cfm?id=1186822"> 



<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFAJAXPROXY');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFFORM');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFDIV');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFTEXTAREA');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFWINDOW');
</script>

<script type="text/javascript">
	var _cf_window_init_1338239898044=function()
	{
		_cf_bind_init_1338239898045=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'theguide_body','bindExpr':['whatisguide.cfm']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338239898045);var _cf_window=ColdFusion.Window.create('theguide','The ACM Guide to Computing Literature','whatisguide.cfm',{ modal:false, closable:true, divid:'cf_window1338239898043', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338239898044);
</script>

<script type="text/javascript">
	var _cf_window_init_1338239898047=function()
	{
		_cf_bind_init_1338239898048=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'thetags_body','bindExpr':['showthetags.cfm?id=1186822']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338239898048);var _cf_window=ColdFusion.Window.create('thetags','All Tags','showthetags.cfm?id=1186822',{ modal:false, closable:true, divid:'cf_window1338239898046', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338239898047);
</script>

<script type="text/javascript">
	var _cf_window_init_1338239898050=function()
	{
		var _cf_window=ColdFusion.Window.create('theformats','Export Formats','',{ modal:false, closable:true, divid:'cf_window1338239898049', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:250, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338239898050);
</script>

<script type="text/javascript">
	var _cf_window_init_1338239898052=function()
	{
		var _cf_window=ColdFusion.Window.create('theexplaination','','',{ modal:false, closable:true, divid:'cf_window1338239898051', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338239898052);
</script>

<script type="text/javascript">
	var _cf_window_init_1338239898054=function()
	{
		var _cf_window=ColdFusion.Window.create('theservices','','',{ modal:false, closable:true, divid:'cf_window1338239898053', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338239898054);
</script>

<script type="text/javascript">
	var _cf_window_init_1338239898056=function()
	{
		_cf_bind_init_1338239898057=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'savetobinder_body','bindExpr':['savetobinder.cfm?id=1186822']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338239898057);var _cf_window=ColdFusion.Window.create('savetobinder','Save to Binder','savetobinder.cfm?id=1186822',{ modal:false, closable:true, divid:'cf_window1338239898055', draggable:true, resizable:true, fixedcenter:true, width:600, height:600, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false, _cf_refreshOnShow:true});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338239898056);
</script>
</head>

<body style="text-align:center" onLoad="window.focus();">

<script type="text/javascript">
						addthis_pub             = 'acm'; 
						//addthis_logo            = 'http://www.addthis.com/images/yourlogo.png';
						addthis_logo            = 'http://dl.acm.org/images/ACM_transparent.png';
						addthis_logo_background = 'c2d5fc';
						addthis_logo_color      = '000000';
						addthis_brand           = 'Citation Page';
						addthis_options         = 'favorites, email, slashdot, citeulike, digg, delicious, twitter, myspace, facebook, google, more';
						</script>
                        
<script src='AC_RunActiveContent.js' type="text/javascript"></script>




<div style="width:940px; margin-left: auto; margin-right: auto; text-align:left">
<a id="CIT"></a>



<table style="table-layout:fixed; margin-top: 5px; margin-bottom: 10px; border:0px; width:100%; border-collapse:collapse;">
	
    <tr style="vertical-align:top">
		
		<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; width:300px" class="small-link-text"  ><img src="http://dl.acm.org/images/ACMDL_Logo.jpg" alt="ACM DL" style="border:0px" usemap="#port" />
		</td>
        
        <td style="padding-left: 5px; padding-right:10px; padding-bottom:0px;" class="small-link-text">
        	<table style="width:100%; border-collapse:collapse; padding:0px">
			<tr><td style="text-align:center">
				
                            <div style="margin:0px auto;color:#356b20;font-size:10pt;line-height:10%;"> </div>
                    
					</td>		
			</tr>
			</table> 
        </td>
		<td style="padding-top: 0px; padding-left: 0px; padding-bottom:0px; text-align:right;" class="small-link-text">
			 <p style="margin-top:0px; margin-bottom:10px;">
					
                            <a href="https://dl.acm.org/signin.cfm?cfid=85074218&amp;cftoken=62570672" class="small-link-text" title="Sign in to personalize your Digital Library experience">SIGN IN</a>
                            &nbsp;&nbsp;<a href="https://dl.acm.org/signin.cfm?cfid=85074218&amp;cftoken=62570672"  class="small-link-text" title="Sign up to personalize your Digital Library experience">SIGN UP</a>
						
			 </p>
            
			<table style="padding: 5px; border-collapse:collapse; float:right">
				
				
                            
                            <tr>
                            <td class="small-link-text" style="text-align:right">
                            <form name="qiksearch" action="results.cfm?h=1&amp;cfid=85074218&amp;cftoken=62570672" method="post">
                           
                           
                            
                                     
                                    <span style="margin-left:0px"><label><input type="text" name="query" size="34" value=" " /></label>&nbsp;
                                    <input style="vertical-align:top;" type="image" alt="Search" name="Go" src="http://dl.acm.org/images/search_small.jpg" />
                                    
                                    </span>
							  </form>
                                </td>
                            </tr>
                          
				  
			</table>

			
			
		</td>

	</tr>
    
    
    <tr><td colspan="3" class="small-link-text" style="padding-bottom:5px; padding-top:0px; text-align:center">
		<div style="margin:0px auto;color:#356b20;line-height:10%;"> </div>
         
         </td>
    </tr>
    </table>
	
<map name="port" id="port" > 
  <area shape="rect" coords="1,1,60,50" href="http://www.acm.org/" alt="ACM Home Page" />
  <area shape="rect" coords="65,1,275,68" href="http://dl.acm.org/dl.cfm?CFID=85074218&CFTOKEN=62570672" alt="ACM Digital Library Home Page" />
</map>

<table style="table-layout:fixed; padding-bottom:10px; width:100%; padding:0px;">
	<tr style="vertical-align:top">
		<td style="padding-right:10px; text-align:left" class="small-link-text">
        	<div id="divmain" style="border:1px solid #356b20;">
				 
				<div class="large-text" style="text-align:left; margin-left:2px;margin-bottom:5px;">
					
                    	<h1 class="mediumb-text" style="margin-top:0px; margin-bottom:0px;"><strong>ACM SIGGRAPH 2005 Papers</strong></h1>
                        
                </div>
                
                  

<table class="medium-text" style="border-collapse:collapse; padding:0px;">

<col style="width:540px" />

<tr style="vertical-align:top">
  <td>
    <table style="border-collapse:collapse; padding:2px;" class="medium-text">
      <col style="width:80px;" />
      <col style="width:auto" />
      <tr style="vertical-align:top">
        
      </tr>
    </table>

	
        <table style="margin-top: 10px; border-collapse:collapse; padding:2px;" class="medium-text">
            <col style="width:80px" />
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             Editor:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100260276&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=85074218&amp;cftoken=62570672" title="Author Profile Page" target="_self">Markus Gross</a>
                
            </td>
            <td valign="bottom">
                
                        <a href="inst_page.cfm?id=1031966&CFID=85074218&CFTOKEN=62570672" title="Institutional Profile Page"><small>Eidgen&#246;ssische Technische Hochschule Z&#252;rich</small></a>
                      	
            </td>
            </tr>
            
        </table>
    
        <table style="margin-top: 10px" border="0" class="medium-text" cellpadding="2" cellspacing="0">
            <tr><td><table border="0" class="medium-text" cellpadding="1" cellspacing="0">

<tr valign="top">
    <td rowspan="20" nowrap="nowrap" align="center" style="padding-top:0px;">Publication of:<br />
     
                    	
					<a href="http://www.siggraph.org/s2005/" title="Conference Website" target="_blank"><img style="margin-top:5px; border-width:1px; border-color:black" src="http://portalparts.acm.org/conference_logos/s2005.jpg" height="44"  width="79" alt="Cover Image" /></a><br />
					
                    
    </td>
</tr>
<tr><td>&nbsp;</td></tr>
 
	<tr valign="top">
    	<td nowrap="nowrap" style="padding-bottom:0px">&middot;&nbsp;Conference</td>
	</tr>
    <tr valign="top">
	    <td style="padding-left:10px;">
		   <a href="http://www.siggraph.org/s2005/" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '05</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    
    <tr valign="top">
	    <td style="padding-left:10px; padding-bottom:10px"> Los Angeles, CA, USA &mdash; July 31 - August 04, 2005
                    
                  <br />
                    
                  <a href="http://www.acm.org/publications" class="small-link-text" title="ACM">ACM</a> <span class="small-link-text">New York, NY</span><span class="small-link-text">, USA</span> <span class="small-link-text">  &copy;2005</span> 
                  <br />           
                  
      </td>
	</tr>
	 

</table></td></tr>
        </table>
    

  </td>

  <td rowspan="20" nowrap="nowrap">
	<table border="0" class="medium-text" cellpadding="0" cellspacing="0">
		<tr>
        	<td align="center" style="padding-bottom: 5px;">
			  
               
              </td>
              <td valign="top" align="left" nowrap="nowrap">
	             <img src="images/acm_mini.jpg" title="Published by ACM" alt="Published by ACM" /> 2005 Proceeding<br />
                 
        	 </td>
        </tr>
        
        <tr>
        	<td colspan="2" valign="baseline" style="padding-bottom:5px;">
            <img src="img/stats.jpg" alt="Bibliometrics Data" />&nbsp;
            <a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a>
            </td>
         </tr>
         <tr>
            <td  class="small-text" colspan="2" valign="top" style="padding-left:30px;">
				
	                    	&middot;&nbsp;Downloads (6 Weeks): 1,859<br />
    	                    &middot;&nbsp;Downloads (12 Months): 12,763<br />
                          
                        &middot;&nbsp;Citation Count: 3,356 
			</td>
         </tr>

	</table>
  </td>
</tr>
</table>

<br clear="all" />

                  
                 <br clear="all" />
			</div>
			
		</td>
		<td style="padding-left: 5px; vertical-align:top; text-align:left; width:170px" class="small-link-text">
	
            <div id="divtools" style="background-color:#ece9d8; text-align:left; padding-top:5px; padding-bottom:5px; ">
              <div class="medium-text" style="margin-left:3px; margin-top:10px;"><h1 class="mediumb-text" style="margin-top:-15px;"><strong>Tools and Resources</strong></h1></div>


<ul title="Tools and Resources" style="list-style: none; list-style-position:inside;
margin-left: 0px;
padding-left: 0em;
text-indent: 5px;
margin-bottom: 0px;">


<li style="list-style-image:url(img/toc_small.gif);margin-top:10px;"><span style="margin-left:6px;">
   <span class="small-link-text">TOC Service:</span>
   	  
	  <img src="http://dl.acm.org/images/blanks.gif" border="0" alt="Spacer Image reserves space for checkmark when TOC Service is updated" name="saved" />
      <ul style="margin-left: 0; padding-left: 0; display:inline;">
      	
        <li style="list-style:none; display:inline"><br /><img src="img/email_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Email</a></li>
        <li style="list-style:none; display:inline"><img src="img/rss_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');"  class="small-link-text">RSS</a></li>
		        
      </ul>
    </span>
</li>

        <li style="list-style-image:url(img/binder.gif);margin-top:10px;"><span style="margin-left:6px;">
        <a href="citation.cfm?id=1186822&preflayout=flat#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Save to Binder</a>
         </span></li>
    




<li style="list-style-image:url(img/binder_green.gif);margin-top:10px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Export Formats:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1186822&expformat=bibtex','theformats');" class="small-link-text">BibTeX</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1186822&expformat=endnotes','theformats');" class="small-link-text">EndNote</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1186822&expformat=acmref','theformats');" class="small-link-text">ACM&nbsp;Ref</a></li>
      </ul>
    </span>
</li>



 
   <li style="list-style-image:url(img/calbullet.jpg);margin-top:15px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Upcoming Conference:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px; margin-left:25px;"><a href="http://www.siggraph.org" title="Special Interest Group on Computer Graphics and Interactive Techniques Conference" class="small-link-text">SIGGRAPH '12</a></li>
      </ul>
    </span>
	</li>
    


</ul>           

  <!-- ADDTHIS BUTTON BEGIN -->
  
  <!-- ADDTHIS BUTTON END -->

<p class="small-link-text" style="padding-top: 0px; margin-left:6px; margin-bottom:0px">Share:</p>
  <!-- AddThis Button BEGIN -->



<!-- AddThis Button BEGIN -->
<div style="margin-left:5px;" class="addthis_toolbox addthis_default_style">
<a class="addthis_button_email"></a>
<a class="addthis_button_facebook"></a>
<a class="addthis_button_google"></a>
<a class="addthis_button_twitter"></a>
<a class="addthis_button_slashdot"></a>
<a class="addthis_button_reddit"></a>


<span class="addthis_separator">|</span>
<a href="http://www.addthis.com/bookmark.php?v=250&amp;username=acm" class="addthis_button_expanded" title="more"></a>
</div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=acm"></script>
<!-- AddThis Button END -->

  
 

  
  
            </div>
            
		</td>
	</tr>
    
</table>



</div>


<div class="layout" style="width:940px; margin-left: auto; margin-right: auto; text-align:left">




<div id="fback" style="text-align:left; padding-top:10px; padding-bottom:20px">
<span class="small-text" style="padding-right:10px; margin-bottom:0px;">
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design" style=" vertical-align:middle"><img src="img/feedbackg.gif" width="20" height="19" alt="feedback" border="0" /></a>
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design"><strong>Feedback</strong></a>

<span style="padding:10px;">|</span>




<span>Switch to <a href="citation.cfm?id=1186822&amp;preflayout=tabs">tabbed view</a> <noscript> (javascript required)</noscript></span>


</span>

 
<div class="small-text" style="margin-top:10px; margin-bottom:5px;"> 
<br />

    <a href="#abstract"  title="Abstract" style="padding:5px"><span>Abstract</span></a> |
    
    <a href="#authors"  title="Authors" style="padding:5px"><span>Authors</span></a> |
    <a href="#references"  title="References" style="padding:5px"><span style='color:#999999'>References</span></a> |
    <a href="#citedby"  title="Cited By" style="padding:5px"><span style='color:#999999'>Cited By</span></a> |
    <a href="#indexterms"  title="Index Terms" style="padding:5px"><span style='color:#999999'>Index Terms</span></a> |
    <a href="#source"  title="Publication" style="padding:5px"><span>Publication</span></a> |
    <a href="#revs"  title="Reviews" style="padding:5px"><span style='color:#999999'>Reviews</span></a> |               
	<a href="#comments"  title="Comments" style="padding:5px"><span>Comments</span></a>
	
     |               
	<a href="#prox"  title="Table of Contents" style="padding:5px"><span>Table of Contents</span></a>
    
</div>
    
<div style="right: 0pt; border-top:1px solid #356b20; font-size:1px; margin-bottom:20px;"/>



</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="abstract" class="small-text">ABSTRACT</A></h1>
       	
			<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

			

		
			
           
			
				
				<p>
					<div style="display:inline">Experience the highest standard of research excellence. In SIGGRAPH 2005 Papers, internationally renowned researchers challenge conventional wisdom and establish new paradigms for future inquiry. No other conference presents the full range of the world's most significant achievements in computer graphics and interactive techniques.</div>
				</p>
   				
           	</div>
			
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="authors" class="small-text"><SPAN class="heading">AUTHORS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<dl title="Authors" style="margin-top:0px">




<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 Editor 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Markus Gross" href="author_page.cfm?id=81100260276&CFID=85074218&CFTOKEN=62570672">Markus Gross</a></strong><br /></span>
	
	<span class="small-text"><br />&nbsp;<a href="http://www.graphics.ethz.ch">homepage</a></span>
	
	<div style="margin-top: 6px" class="small-text">&nbsp;grossm<img src="gifs/at.gif" width="12" height="12" alt="at" />inf.ethz.ch</div>
	
	
	
	<span class="small-text">
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1991-2011</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">145</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">2,074</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">83</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">1,574</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">15,090</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Markus Gross" href="author_page.cfm?id=81100260276&amp;dsp=coll&amp;trk=1&amp;CFID=85074218&CFTOKEN=62570672" target="_self">View colleagues</a> of Markus Gross
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              

</dl>
</div>

		  
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="references" class="small-text"><SPAN class="heading">REFERENCES</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	References are not available

</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="citedby" class="small-text"><SPAN class="heading">CITED BY</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	Citings are not available
		
 </div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="indexterms" class="small-text"><SPAN class="heading">INDEX TERMS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

Index Terms are not available


</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="source" class="small-text"><SPAN class="heading">PUBLICATION</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">



<table border="0" class="medium-text" cellpadding="0" cellspacing="5">



    <tr valign="top">
    	<td>Title</td> 
	    <td>
		   <a href="http://www.siggraph.org/s2005/" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '05</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    <tr><td></td><td>Los Angeles, CA, USA &mdash; July 31 - August 04, 2005</td></tr> 
                 <tr>
                 
                     <td>Sponsor</td>
                    
                  <td>
                  <a href="sig.cfm?id=SP932&CFID=85074218&CFTOKEN=62570672"> SIGGRAPH</a> ACM Special Interest Group on Computer Graphics and Interactive Techniques
                  </td>
                  </tr>
              
                  <tr><td>Publisher</td><td><a href="http://www.acm.org/publications">ACM</a> New York, NY, USA</td>
				  </tr>
             
			<tr valign="top">
        	<td>Conference</td>
            <td valign="top" align="left"  style="padding-bottom: 25px;">
	            <strong style="padding-right:10px">GRAPH</strong><a href="event.cfm?id=RE214&CFID=85074218&CFTOKEN=62570672" title="International Conference on Computer Graphics and Interactive Techniques">International Conference on Computer Graphics and Interactive Techniques</a>
                
                       
                        <a href="event.cfm?id=RE214&CFID=85074218&CFTOKEN=62570672" title="International Conference on Computer Graphics and Interactive Techniques"><img border="0" src="http://portalparts.acm.org/event_logos/382/382.jpg" title="GRAPH logo" height="100"  width="100" ALT="GRAPH logo" style="vertical-align:top"></a>
						 

        	 </td>
            </tr>
		    <tr><td colspan="2">Paper Acceptance Rate 98 of 461 submissions, 21%</td></tr> <tr valign="top"><td style="pading-top:20px;" colspan="2">Overall Acceptance Rate 2,079 of 8,858 submissions, 23%</td></tr>
                       <tr valign="top">
                        <td colspan="2" style="padding-left:25px;">
                        	<table>
                            	<tr><td>
                                        <!-- WebCharts3D v5.1(2077) -->
<IMG SRC="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=Images/792072730583928.JPG" id="Images_792072730583928_JPG" name="Images_792072730583928_JPG" usemap="#Images_792072730583928_JPG_map" border="0"/>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAB' id='GP1338239898452AAAB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>120</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAC' id='GP1338239898452AAAC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>64</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAD' id='GP1338239898452AAAD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>110</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAE' id='GP1338239898452AAAE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAF' id='GP1338239898452AAAF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAG' id='GP1338239898452AAAG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAH' id='GP1338239898452AAAH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>132</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAI' id='GP1338239898452AAAI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAJ' id='GP1338239898452AAAJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>118</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAK' id='GP1338239898452AAAK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>41</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAL' id='GP1338239898452AAAL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>175</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAM' id='GP1338239898452AAAM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>35</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAN' id='GP1338239898452AAAN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAO' id='GP1338239898452AAAO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>33</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAP' id='GP1338239898452AAAP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>161</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAQ' id='GP1338239898452AAAQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>34</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAR' id='GP1338239898452AAAR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>190</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAS' id='GP1338239898452AAAS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAT' id='GP1338239898452AAAT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>210</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAU' id='GP1338239898452AAAU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAV' id='GP1338239898452AAAV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>213</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAW' id='GP1338239898452AAAW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAX' id='GP1338239898452AAAX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>225</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAY' id='GP1338239898452AAAY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>46</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AAAZ' id='GP1338239898452AAAZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>242</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABA' id='GP1338239898452AABA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>57</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABB' id='GP1338239898452AABB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABC' id='GP1338239898452AABC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>56</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABD' id='GP1338239898452AABD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>247</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABE' id='GP1338239898452AABE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABF' id='GP1338239898452AABF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>265</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABG' id='GP1338239898452AABG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>48</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABH' id='GP1338239898452AABH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>303</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABI' id='GP1338239898452AABI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABJ' id='GP1338239898452AABJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>320</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABK' id='GP1338239898452AABK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABL' id='GP1338239898452AABL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>304</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABM' id='GP1338239898452AABM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>59</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABN' id='GP1338239898452AABN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>300</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABO' id='GP1338239898452AABO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>65</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABP' id='GP1338239898452AABP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABQ' id='GP1338239898452AABQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABR' id='GP1338239898452AABR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>424</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABS' id='GP1338239898452AABS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>81</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABT' id='GP1338239898452AABT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>478</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABU' id='GP1338239898452AABU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>83</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABV' id='GP1338239898452AABV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>461</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABW' id='GP1338239898452AABW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>98</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABX' id='GP1338239898452AABX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>474</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABY' id='GP1338239898452AABY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>86</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AABZ' id='GP1338239898452AABZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>455</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACA' id='GP1338239898452AACA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>108</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACB' id='GP1338239898452AACB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>518</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACC' id='GP1338239898452AACC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>90</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACD' id='GP1338239898452AACD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>439</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACE' id='GP1338239898452AACE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>78</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACF' id='GP1338239898452AACF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>390</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACG' id='GP1338239898452AACG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>103</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACH' id='GP1338239898452AACH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>432</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338239898452AACI' id='GP1338239898452AACI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>82</td></tr></table>
<MAP name='Images_792072730583928_JPG_map'>
<AREA shape='rect' coords='0,0,1,1'/>
<AREA shape="rect" coords="287,179,290,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACI",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACI",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACI",event)'/>
<AREA shape="rect" coords="284,92,287,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACH",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACH",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACH",event)'/>
<AREA shape="rect" coords="278,174,281,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACG",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACG",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACG",event)'/>
<AREA shape="rect" coords="275,103,278,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACF",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACF",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACF",event)'/>
<AREA shape="rect" coords="270,180,273,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACE",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACE",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACE",event)'/>
<AREA shape="rect" coords="267,90,270,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACD",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACD",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACD",event)'/>
<AREA shape="rect" coords="261,177,264,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACC",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACC",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACC",event)'/>
<AREA shape="rect" coords="258,71,261,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACB",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACB",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACB",event)'/>
<AREA shape="rect" coords="253,173,256,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACA",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AACA",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AACA",event)'/>
<AREA shape="rect" coords="250,87,253,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABZ",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABZ",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABZ",event)'/>
<AREA shape="rect" coords="244,178,247,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABY",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABY",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABY",event)'/>
<AREA shape="rect" coords="241,82,244,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABX",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABX",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABX",event)'/>
<AREA shape="rect" coords="235,175,238,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABW",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABW",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABW",event)'/>
<AREA shape="rect" coords="232,85,235,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABV",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABV",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABV",event)'/>
<AREA shape="rect" coords="227,179,230,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABU",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABU",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABU",event)'/>
<AREA shape="rect" coords="224,81,227,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABT",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABT",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABT",event)'/>
<AREA shape="rect" coords="218,179,221,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABS",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABS",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABS",event)'/>
<AREA shape="rect" coords="215,94,218,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABR",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABR",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABR",event)'/>
<AREA shape="rect" coords="210,136,213,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABQ",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABQ",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABQ",event)'/>
<AREA shape="rect" coords="207,136,210,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABP",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABP",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABP",event)'/>
<AREA shape="rect" coords="201,183,204,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABO",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABO",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABO",event)'/>
<AREA shape="rect" coords="198,125,201,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABN",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABN",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABN",event)'/>
<AREA shape="rect" coords="192,185,195,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABM",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABM",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABM",event)'/>
<AREA shape="rect" coords="189,124,192,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABL",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABL",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABL",event)'/>
<AREA shape="rect" coords="184,187,187,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABK",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABK",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABK",event)'/>
<AREA shape="rect" coords="181,120,184,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABJ",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABJ",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABJ",event)'/>
<AREA shape="rect" coords="175,188,178,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABI",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABI",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABI",event)'/>
<AREA shape="rect" coords="172,124,175,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABH",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABH",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABH",event)'/>
<AREA shape="rect" coords="167,188,170,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABG",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABG",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABG",event)'/>
<AREA shape="rect" coords="164,134,167,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABF",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABF",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABF",event)'/>
<AREA shape="rect" coords="158,187,161,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABE",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABE",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABE",event)'/>
<AREA shape="rect" coords="155,138,158,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABD",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABD",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABD",event)'/>
<AREA shape="rect" coords="149,186,152,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABC",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABC",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABC",event)'/>
<AREA shape="rect" coords="146,136,149,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABB",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABB",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABB",event)'/>
<AREA shape="rect" coords="141,185,144,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABA",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AABA",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AABA",event)'/>
<AREA shape="rect" coords="138,139,141,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAZ",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAZ",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAZ",event)'/>
<AREA shape="rect" coords="132,188,135,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAY",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAY",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAY",event)'/>
<AREA shape="rect" coords="129,144,132,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAX",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAX",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAX",event)'/>
<AREA shape="rect" coords="124,188,127,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAW",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAW",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAW",event)'/>
<AREA shape="rect" coords="121,147,124,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAV",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAV",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAV",event)'/>
<AREA shape="rect" coords="115,189,118,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAU",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAU",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAU",event)'/>
<AREA shape="rect" coords="112,147,115,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAT",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAT",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAT",event)'/>
<AREA shape="rect" coords="106,190,109,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAS",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAS",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAS",event)'/>
<AREA shape="rect" coords="103,152,106,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAR",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAR",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAR",event)'/>
<AREA shape="rect" coords="98,191,101,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAQ",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAQ",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAQ",event)'/>
<AREA shape="rect" coords="95,160,98,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAP",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAP",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAP",event)'/>
<AREA shape="rect" coords="89,191,92,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAO",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAO",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAO",event)'/>
<AREA shape="rect" coords="86,165,89,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAN",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAN",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAN",event)'/>
<AREA shape="rect" coords="81,191,84,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAM",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAM",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAM",event)'/>
<AREA shape="rect" coords="78,156,81,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAL",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAL",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAL",event)'/>
<AREA shape="rect" coords="72,189,75,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAK",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAK",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAK",event)'/>
<AREA shape="rect" coords="69,170,72,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAJ",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAJ",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAJ",event)'/>
<AREA shape="rect" coords="63,190,66,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAI",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAI",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAI",event)'/>
<AREA shape="rect" coords="60,167,63,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAH",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAH",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAH",event)'/>
<AREA shape="rect" coords="55,187,58,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAG",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAG",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAG",event)'/>
<AREA shape="rect" coords="52,165,55,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAF",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAF",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAF",event)'/>
<AREA shape="rect" coords="46,189,49,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAE",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAE",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAE",event)'/>
<AREA shape="rect" coords="43,172,46,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAD",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAD",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAD",event)'/>
<AREA shape="rect" coords="38,184,41,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAC",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAC",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAC",event)'/>
<AREA shape="rect" coords="35,170,38,199" onMouseover='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAB",event,true)' onMouseout='xx_set_visible("Images_792072730583928_JPG","GP1338239898452AAAB",event,false)' onMousemove='xx_move_tag("Images_792072730583928_JPG","GP1338239898452AAAB",event)'/>
<AREA shape="rect" coords="160,13,227,27"/>
<AREA shape="rect" coords="89,13,160,27"/>
</MAP>

<script language="javascript" src="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=script.js"></script>

                                      </td>
                                      <td style="padding-left:20px;">
                                             <table style="border-width: 1px; border-style: solid; width:100%;  border-spacing: 6px;" class="text12">
                                                <tr bgcolor="#ffffff">
                                                  <th style="width:50%">Year</th>
                                                  <th  align="right" style="width:15%">Submitted</th>
                                                  <th  align="right" style="width:15%">Accepted</th>
                                                  <th  align="center">Rate</th>
                                                </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '78</td>
                                                            <td align="right">120</td>
                                                            <td align="right">64</td>
                                                            <td align="center">53%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '79</td>
                                                            <td align="right">110</td>
                                                            <td align="right">43</td>
                                                            <td align="center">39%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '80</td>
                                                            <td align="right">140</td>
                                                            <td align="right">52</td>
                                                            <td align="center">37%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '81</td>
                                                            <td align="right">132</td>
                                                            <td align="right">38</td>
                                                            <td align="center">29%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '84</td>
                                                            <td align="right">118</td>
                                                            <td align="right">41</td>
                                                            <td align="center">35%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '85</td>
                                                            <td align="right">175</td>
                                                            <td align="right">35</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '87</td>
                                                            <td align="right">140</td>
                                                            <td align="right">33</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '88</td>
                                                            <td align="right">161</td>
                                                            <td align="right">34</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '89</td>
                                                            <td align="right">190</td>
                                                            <td align="right">38</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '90</td>
                                                            <td align="right">210</td>
                                                            <td align="right">43</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '92</td>
                                                            <td align="right">213</td>
                                                            <td align="right">45</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '93</td>
                                                            <td align="right">225</td>
                                                            <td align="right">46</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '94</td>
                                                            <td align="right">242</td>
                                                            <td align="right">57</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '95</td>
                                                            <td align="right">257</td>
                                                            <td align="right">56</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '96</td>
                                                            <td align="right">247</td>
                                                            <td align="right">52</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '97</td>
                                                            <td align="right">265</td>
                                                            <td align="right">48</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '98</td>
                                                            <td align="right">303</td>
                                                            <td align="right">45</td>
                                                            <td align="center">15%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '99</td>
                                                            <td align="right">320</td>
                                                            <td align="right">52</td>
                                                            <td align="center">16%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '00</td>
                                                            <td align="right">304</td>
                                                            <td align="right">59</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '01</td>
                                                            <td align="right">300</td>
                                                            <td align="right">65</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">358</td>
                                                            <td align="right">67</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">257</td>
                                                            <td align="right">257</td>
                                                            <td align="center">100%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '03</td>
                                                            <td align="right">424</td>
                                                            <td align="right">81</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '04</td>
                                                            <td align="right">478</td>
                                                            <td align="right">83</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '05</td>
                                                            <td align="right">461</td>
                                                            <td align="right">98</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '06</td>
                                                            <td align="right">474</td>
                                                            <td align="right">86</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '07</td>
                                                            <td align="right">455</td>
                                                            <td align="right">108</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '08</td>
                                                            <td align="right">518</td>
                                                            <td align="right">90</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '09</td>
                                                            <td align="right">439</td>
                                                            <td align="right">78</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '10</td>
                                                            <td align="right">390</td>
                                                            <td align="right">103</td>
                                                            <td align="center">26%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '11</td>
                                                            <td align="right">432</td>
                                                            <td align="right">82</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                 <tr bgcolor="#ffffff">
                                                    <td><strong>Overall</strong></td>
                                                    <td align="right">8,858</td>
                                                    <td align="right">2,079</td>
                                                    <td align="center">23%</td>
                                                  </tr>
                                                </table>
                                       </td>
                                     </tr>
                               </table>
                        </td>
                    </tr>
                     
                     
            
</table>


</table>




</div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="revs" class="small-text"><SPAN class="heading">REVIEWS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	<br />Reviews are not available for this item
        
        <div align="left" style="margin-top:30px">
					<a title="Computing Reviews" href="ocr_review_main.cfm?CFID=85074218&CFTOKEN=62570672">
                 <img src="http://dl.acm.org/images/ocrs-s.jpg" alt="Computing Reviews logo" border="0" style="vertical-align:middle"></a>
        
        
       		<ul style="list-style:disc; display:inline-block">
	            <li>Access <a href="ocr_review_main.cfm?CFID=85074218&CFTOKEN=62570672" target="_blank">critical reviews</a> of computing literature.</li>
            	<li><a href="http://www.computingreviews.com/Reviewer/"  target="_blank">Become a reviewer</a> for Computing Reviews</li>
            </ul>
        </div>
        
</div>



<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="comments" class="small-text"><SPAN class="heading">COMMENTS</SPAN></A></h1>
         
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<div>
<div>
	
	<p style="margin-left:5px;">
    <strong>Be the first to comment</strong>
    	
          	To Post a comment please <a href="signin.cfm?CFID=85074218&CFTOKEN=62570672">sign in or create</a> a free Web account</a>
        
    
    
	 </p>
	   	
 
</div>


</div>

	
		<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="prox" class="small-text">Table of Contents</A></h1>
        
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" >

<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">ACM SIGGRAPH 2005 Papers</h5>


<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>

<div style="clear:both">
    
        <div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><a href="citation.cfm?id=1198555&picked=prox&CFID=85074218&CFTOKEN=62570672" title="previous: SIGGRAPH '05"><img hspace="5" align="absmiddle" border="0" src="img/prev.gif" width="19" height="11" alt="previous" />previous proceeding</a> <span style="padding-left:5px;padding-right:5px;">|</span><a href="citation.cfm?id=1186954&picked=prox&CFID=85074218&CFTOKEN=62570672" title="Next: SIGGRAPH '05">next proceeding <img align="absmiddle" hspace="5" border="0" src="img/next.gif" width="19" height="11" alt="next" /></a></div>
        
</div>


 
<table class="text12" border="0">

  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=1134781&CFID=85074218&CFTOKEN=62570672">Keynote and Awards presentations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          
                        <a href="author_page.cfm?id=81341494013&CFID=85074218&CFTOKEN=62570672">James L. Mohler</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">Article No.: 0</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1134781" title="DOI">10.1145/1186822.1134781</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:0">
          Full text: <a name="FullTextMp4" title="FullText Mp4" href="ft_gateway.cfm?id=1134781&ftid=979619&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</A>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=1134856&CFID=85074218&CFTOKEN=62570672">Keynote Speech: George Lucas: A keynote Q&amp;A with the father of digital cinema</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          
                        <a href="author_page.cfm?id=81322490480&CFID=85074218&CFTOKEN=62570672">Bruce Carse</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">Article No.: 1</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1134856" title="DOI">10.1145/1186822.1134856</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Skin & faces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Ronen Barzel 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073206&CFID=85074218&CFTOKEN=62570672">Skinning mesh animations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100415142&CFID=85074218&CFTOKEN=62570672">Doug L. James</a>, 
                        <a href="author_page.cfm?id=81100231532&CFID=85074218&CFTOKEN=62570672">Christopher D. Twigg</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 399 - 407</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073206" title="DOI">10.1145/1186822.1073206</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073206&ftid=321862&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow4" style="display:inline;"><br /><div style="display:inline">We extend approaches for skinning characters to the general setting of skinning deformable mesh animations. We provide an automatic algorithm for generating progressive skinning approximations, that is particularly efficient for pseudo-articulated motions. ...</div></span>
          <span id="toHide4" style="display:none;"><br /><div style="display:inline">We extend approaches for skinning characters to the general setting of skinning deformable mesh animations. We provide an automatic algorithm for generating progressive skinning approximations, that is particularly efficient for pseudo-articulated motions. Our contributions include the use of nonparametric mean shift clustering of high-dimensional mesh rotation sequences to automatically identify statistically relevant bones, and robust least squares methods to determine bone transformations, bone-vertex influence sets, and vertex weight values. We use a low-rank data reduction model defined in the undeformed mesh configuration to provide progressive convergence with a fixed number of bones. We show that the resulting skinned animations enable efficient hardware rendering, rest pose editing, and deformable collision detection. Finally, we present numerous examples where skins were automatically generated using a single set of parameter values.</div></span> <a id="expcoll4" href="JavaScript: expandcollapse('expcoll4',4)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073207&CFID=85074218&CFTOKEN=62570672">SCAPE: shape completion and animation of people</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100453443&CFID=85074218&CFTOKEN=62570672">Dragomir Anguelov</a>, 
                        <a href="author_page.cfm?id=81100406602&CFID=85074218&CFTOKEN=62570672">Praveen Srinivasan</a>, 
                        <a href="author_page.cfm?id=81100246010&CFID=85074218&CFTOKEN=62570672">Daphne Koller</a>, 
                        <a href="author_page.cfm?id=81100590972&CFID=85074218&CFTOKEN=62570672">Sebastian Thrun</a>, 
                        <a href="author_page.cfm?id=81100642611&CFID=85074218&CFTOKEN=62570672">Jim Rodgers</a>, 
                        <a href="author_page.cfm?id=81100603625&CFID=85074218&CFTOKEN=62570672">James Davis</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 408 - 416</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073207" title="DOI">10.1145/1186822.1073207</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073207&ftid=321863&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow5" style="display:inline;"><br /><div style="display:inline">We introduce the SCAPE method (Shape Completion and Animation for PEople)---a data-driven method for building a human shape model that spans variation in both subject shape and pose. The method is based on a representation that incorporates both articulated ...</div></span>
          <span id="toHide5" style="display:none;"><br /><div style="display:inline">We introduce the SCAPE method (Shape Completion and Animation for PEople)---a data-driven method for building a human shape model that spans variation in both subject shape and pose. The method is based on a representation that incorporates both articulated and non-rigid deformations. We learn a <i>pose deformation model</i> that derives the non-rigid surface deformation as a function of the pose of the articulated skeleton. We also learn a separate model of variation based on body shape. Our two models can be combined to produce 3D surface models with realistic muscle deformation for different people in different poses, when neither appear in the training set. We show how the model can be used for <i>shape completion</i> --- generating a complete surface mesh given a limited set of markers specifying the target shape. We present applications of shape completion to partial view completion and motion capture animation. In particular, our method is capable of constructing a high-quality animated surface model of a moving person, with realistic muscle deformation, using just a single static scan and a marker motion capture sequence of the person.</div></span> <a id="expcoll5" href="JavaScript: expandcollapse('expcoll5',5)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073208&CFID=85074218&CFTOKEN=62570672">Automatic determination of facial muscle activations from sparse motion capture marker data</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81409594691&CFID=85074218&CFTOKEN=62570672">Eftychios Sifakis</a>, 
                        <a href="author_page.cfm?id=81100148390&CFID=85074218&CFTOKEN=62570672">Igor Neverov</a>, 
                        <a href="author_page.cfm?id=81100612327&CFID=85074218&CFTOKEN=62570672">Ronald Fedkiw</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 417 - 425</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073208" title="DOI">10.1145/1186822.1073208</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073208&ftid=321864&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow6" style="display:inline;"><br /><div style="display:inline">We built an anatomically accurate model of facial musculature, passive tissue and underlying skeletal structure using volumetric data acquired from a living male subject. The tissues are endowed with a highly nonlinear constitutive model including controllable ...</div></span>
          <span id="toHide6" style="display:none;"><br /><div style="display:inline">We built an anatomically accurate model of facial musculature, passive tissue and underlying skeletal structure using volumetric data acquired from a living male subject. The tissues are endowed with a highly nonlinear constitutive model including controllable anisotropic muscle activations based on fiber directions. Detailed models of this sort can be difficult to animate requiring complex coordinated stimulation of the underlying musculature. We propose a solution to this problem automatically determining muscle activations that track a sparse set of surface landmarks, e.g. acquired from motion capture marker data. Since the resulting animation is obtained via a three dimensional nonlinear finite element method, we obtain visually plausible and anatomically correct deformations with spatial and temporal coherence that provides robustness against outliers in the motion capture data. Moreover, the obtained muscle activations can be used in a robust simulation framework including contact and collision of the face with external objects.</div></span> <a id="expcoll6" href="JavaScript: expandcollapse('expcoll6',6)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073209&CFID=85074218&CFTOKEN=62570672">Face transfer with multilinear models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100451297&CFID=85074218&CFTOKEN=62570672">Daniel Vlasic</a>, 
                        <a href="author_page.cfm?id=81406592826&CFID=85074218&CFTOKEN=62570672">Matthew Brand</a>, 
                        <a href="author_page.cfm?id=81100199891&CFID=85074218&CFTOKEN=62570672">Hanspeter Pfister</a>, 
                        <a href="author_page.cfm?id=81100620337&CFID=85074218&CFTOKEN=62570672">Jovan Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 426 - 433</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073209" title="DOI">10.1145/1186822.1073209</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073209&ftid=321865&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow7" style="display:inline;"><br /><div style="display:inline">Face Transfer is a method for mapping videorecorded performances of one individual to facial animations of another. It extracts visemes (speech-related mouth articulations), expressions, and three-dimensional (3D) pose from monocular video or film footage. ...</div></span>
          <span id="toHide7" style="display:none;"><br /><div style="display:inline">Face Transfer is a method for mapping videorecorded performances of one individual to facial animations of another. It extracts visemes (speech-related mouth articulations), expressions, and three-dimensional (3D) pose from monocular video or film footage. These parameters are then used to generate and drive a detailed 3D textured face mesh for a target identity, which can be seamlessly rendered back into target footage. The underlying face model automatically adjusts for how the target performs facial expressions and visemes. The performance data can be easily edited to change the visemes, expressions, pose, or even the identity of the target---the attributes are separably controllable. This supports a wide variety of video rewrite and puppetry applications.Face Transfer is based on a multilinear model of 3D face meshes that separably parameterizes the space of geometric variations due to different attributes (e.g., identity, expression, and viseme). Separability means that each of these attributes can be independently varied. A multilinear model can be estimated from a Cartesian product of examples (identities &times; expressions &times; visemes) with techniques from statistical analysis, but only after careful preprocessing of the geometric data set to secure one-to-one correspondence, to minimize cross-coupling artifacts, and to fill in any missing examples. Face Transfer offers new solutions to these problems and links the estimated model with a face-tracking algorithm to extract pose, expression, and viseme parameters.</div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Hardware rendering</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Hanspeter Pfister 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073211&CFID=85074218&CFTOKEN=62570672">RPU: a programmable ray processing unit for realtime ray tracing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100618274&CFID=85074218&CFTOKEN=62570672">Sven Woop</a>, 
                        <a href="author_page.cfm?id=81100134343&CFID=85074218&CFTOKEN=62570672">J&#246;rg Schmittler</a>, 
                        <a href="author_page.cfm?id=81100159926&CFID=85074218&CFTOKEN=62570672">Philipp Slusallek</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 434 - 444</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073211" title="DOI">10.1145/1186822.1073211</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073211&ftid=321866&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow9" style="display:inline;"><br /><div style="display:inline">Recursive ray tracing is a simple yet powerful and general approach for accurately computing global light transport and rendering high quality images. While recent algorithmic improvements and optimized parallel software implementations have increased ...</div></span>
          <span id="toHide9" style="display:none;"><br /><div style="display:inline">Recursive ray tracing is a simple yet powerful and general approach for accurately computing global light transport and rendering high quality images. While recent algorithmic improvements and optimized parallel software implementations have increased ray tracing performance to realtime levels, no compact and programmable hardware solution has been available yet.This paper describes the architecture and a prototype implementation of a single chip, fully programmable Ray Processing Unit (RPU). It combines the flexibility of general purpose CPUs with the efficiency of current GPUs for data parallel computations. This design allows for realtime ray tracing of dynamic scenes with programmable material, geometry, and illumination shaders.Although, running at only 66 MHz the prototype FPGA implementation already renders images at up to 20 frames per second, which in many cases beats the performance of highly optimized software running on multi-GHz desktop CPUs. The performance and efficiency of the proposed architecture is analyzed using a variety of benchmark scenes.</div></span> <a id="expcoll9" href="JavaScript: expandcollapse('expcoll9',9)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073212&CFID=85074218&CFTOKEN=62570672">User-configurable automatic shader simplification</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100112064&CFID=85074218&CFTOKEN=62570672">Fabio Pellacini</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 445 - 452</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073212" title="DOI">10.1145/1186822.1073212</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073212&ftid=321867&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow10" style="display:inline;"><br /><div style="display:inline">Programmable shading is a fundamental technique for specifying appearance in 3d environments. While shading architectures provides fast execution of shaders, shader evaluation is today a major cost in the rendering process. In the same manner in which ...</div></span>
          <span id="toHide10" style="display:none;"><br /><div style="display:inline">Programmable shading is a fundamental technique for specifying appearance in 3d environments. While shading architectures provides fast execution of shaders, shader evaluation is today a major cost in the rendering process. In the same manner in which geometric simplification lets us deal with large models, it would be beneficial to have an automatic technique that trades off shader quality for speed.This paper presents such a technique by introducing a framework for the automatic simplification of complex procedural shaders, where a sequence of increasingly simplified shaders is generated starting from an original shader together with ranges for all of its input parameters. Our approach works by applying simplification rules to the code of a shader to generate a series of candidates, whose differences from the original one are measured and used to select the candidate with the smallest error. This procedure is repeated until the last shader is a constant. While this automatic procedure generates high quality simplified shaders, the artist might want to emphasize particular aspects of a shader during simplification. Our framework supports this desire by allowing the user to specify additional rules to be considered during simplification. The term <i>user-configurable</i> simplification comes from this feature of our system.We implemented our algorithm to support the simplification of fragment shaders running on graphics hardware. Our results show that automatic simplification of complex procedural shaders is possible with high quality.</div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073213&CFID=85074218&CFTOKEN=62570672">A relational debugging engine for the graphics pipeline</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100047495&CFID=85074218&CFTOKEN=62570672">Nathaniel Duca</a>, 
                        <a href="author_page.cfm?id=81342505984&CFID=85074218&CFTOKEN=62570672">Krzysztof Niski</a>, 
                        <a href="author_page.cfm?id=81100342313&CFID=85074218&CFTOKEN=62570672">Jonathan Bilodeau</a>, 
                        <a href="author_page.cfm?id=81100230414&CFID=85074218&CFTOKEN=62570672">Matthew Bolitho</a>, 
                        <a href="author_page.cfm?id=81408597179&CFID=85074218&CFTOKEN=62570672">Yuan Chen</a>, 
                        <a href="author_page.cfm?id=81452612087&CFID=85074218&CFTOKEN=62570672">Jonathan Cohen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 453 - 463</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073213" title="DOI">10.1145/1186822.1073213</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073213&ftid=321868&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow11" style="display:inline;"><br /><div style="display:inline">We present a new, unified approach to debugging graphics software. We propose a representation of all graphics state over the course of program execution as a relational database, and produce a query-based framework for extracting, manipulating, and ...</div></span>
          <span id="toHide11" style="display:none;"><br /><div style="display:inline">We present a new, unified approach to debugging graphics software. We propose a representation of all graphics state over the course of program execution as a relational database, and produce a query-based framework for extracting, manipulating, and visualizing data from all stages of the graphics pipeline. Using an SQL-based query language, the programmer can establish functional relationships among all the data, linking OpenGL state to primitives to vertices to fragments to pixels. Based on the Chromium library, our approach requires no modification to or recompilation of the program to be debugged, and forms a superset of many existing techniques for debugging graphics software.</div></span> <a id="expcoll11" href="JavaScript: expandcollapse('expcoll11',11)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073214&CFID=85074218&CFTOKEN=62570672">Lpics: a hybrid hardware-accelerated relighting engine for computer cinematography</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100112064&CFID=85074218&CFTOKEN=62570672">Fabio Pellacini</a>, 
                        <a href="author_page.cfm?id=81100046507&CFID=85074218&CFTOKEN=62570672">Kiril Vidim&#269;e</a>, 
                        <a href="author_page.cfm?id=81100460149&CFID=85074218&CFTOKEN=62570672">Aaron Lefohn</a>, 
                        <a href="author_page.cfm?id=81100271934&CFID=85074218&CFTOKEN=62570672">Alex Mohr</a>, 
                        <a href="author_page.cfm?id=81341492819&CFID=85074218&CFTOKEN=62570672">Mark Leone</a>, 
                        <a href="author_page.cfm?id=81342515410&CFID=85074218&CFTOKEN=62570672">John Warren</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 464 - 470</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073214" title="DOI">10.1145/1186822.1073214</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073214&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow12" style="display:inline;"><br /><div style="display:inline">In computer cinematography, the process of lighting design involves placing and configuring lights to define the visual appearance of environments and to enhance story elements. This process is labor intensive and time consuming, primarily because lighting ...</div></span>
          <span id="toHide12" style="display:none;"><br /><div style="display:inline">In computer cinematography, the process of lighting design involves placing and configuring lights to define the visual appearance of environments and to enhance story elements. This process is labor intensive and time consuming, primarily because lighting artists receive poor feedback from existing tools: interactive previews have very poor quality, while final-quality images often take hours to render.This paper presents an interactive cinematic lighting system used in the production of computer-animated feature films containing environments of very high complexity, in which surface and light appearances are described using procedural RenderMan shaders. Our system provides lighting artists with high-quality previews at interactive framerates with only small approximations compared to the final rendered images. This is accomplished by combining numerical estimation of surface response, image-space caching, deferred shading, and the computational power of modern graphics hardware.Our system has been successfully used in the production of two feature-length animated films, dramatically accelerating lighting tasks. In our experience interactivity fundamentally changes an artist's workflow, improving both productivity and artistic expressiveness.</div></span> <a id="expcoll12" href="JavaScript: expandcollapse('expcoll12',12)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Mesh manipulation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Ioana Boier-Martin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073216&CFID=85074218&CFTOKEN=62570672">Meshless deformations based on shape matching</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100615490&CFID=85074218&CFTOKEN=62570672">Matthias M&#252;ller</a>, 
                        <a href="author_page.cfm?id=81100301594&CFID=85074218&CFTOKEN=62570672">Bruno Heidelberger</a>, 
                        <a href="author_page.cfm?id=81100626136&CFID=85074218&CFTOKEN=62570672">Matthias Teschner</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=85074218&CFTOKEN=62570672">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 471 - 478</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073216" title="DOI">10.1145/1186822.1073216</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073216&ftid=321870&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow14" style="display:inline;"><br /><div style="display:inline">We present a new approach for simulating deformable objects. The underlying model is geometrically motivated. It handles pointbased objects and does not need connectivity information. The approach does not require any pre-processing, is simple to compute, ...</div></span>
          <span id="toHide14" style="display:none;"><br /><div style="display:inline">We present a new approach for simulating deformable objects. The underlying model is geometrically motivated. It handles pointbased objects and does not need connectivity information. The approach does not require any pre-processing, is simple to compute, and provides unconditionally stable dynamic simulations.The main idea of our deformable model is to replace energies by geometric constraints and forces by distances of current positions to goal positions. These goal positions are determined via a generalized shape matching of an undeformed rest state with the current deformed state of the point cloud. Since points are always drawn towards well-defined locations, the overshooting problem of explicit integration schemes is eliminated. The versatility of the approach in terms of object representations that can be handled, the efficiency in terms of memory and computational complexity, and the unconditional stability of the dynamic simulation make the approach particularly interesting for games.</div></span> <a id="expcoll14" href="JavaScript: expandcollapse('expcoll14',14)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073217&CFID=85074218&CFTOKEN=62570672">Linear rotation-invariant coordinates for meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100456149&CFID=85074218&CFTOKEN=62570672">Yaron Lipman</a>, 
                        <a href="author_page.cfm?id=81100036540&CFID=85074218&CFTOKEN=62570672">Olga Sorkine</a>, 
                        <a href="author_page.cfm?id=81100404814&CFID=85074218&CFTOKEN=62570672">David Levin</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074218&CFTOKEN=62570672">Daniel Cohen-Or</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 479 - 487</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073217" title="DOI">10.1145/1186822.1073217</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073217&ftid=321871&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow15" style="display:inline;"><br /><div style="display:inline">We introduce a rigid motion invariant mesh representation based on discrete forms defined on the mesh. The reconstruction of mesh geometry from this representation requires solving two sparse linear systems that arise from the discrete forms: the first ...</div></span>
          <span id="toHide15" style="display:none;"><br /><div style="display:inline">We introduce a rigid motion invariant mesh representation based on discrete forms defined on the mesh. The reconstruction of mesh geometry from this representation requires solving two sparse linear systems that arise from the discrete forms: the first system defines the relationship between local frames on the mesh, and the second encodes the position of the vertices via the local frames. The reconstructed geometry is unique up to a rigid transformation of the mesh. We define surface editing operations by placing user-defined constraints on the local frames and the vertex positions. These constraints are incorporated in the two linear reconstruction systems, and their solution produces a deformed surface geometry that preserves the local differential properties in the least-squares sense. Linear combination of shapes expressed with our representation enables linear shape interpolation that correctly handles rotations. We demonstrate the effectiveness of the new representation with various detail-preserving editing operators and shape morphing.</div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073218&CFID=85074218&CFTOKEN=62570672">Mesh-based inverse kinematics</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100099182&CFID=85074218&CFTOKEN=62570672">Robert W. Sumner</a>, 
                        <a href="author_page.cfm?id=81100289561&CFID=85074218&CFTOKEN=62570672">Matthias Zwicker</a>, 
                        <a href="author_page.cfm?id=81100294813&CFID=85074218&CFTOKEN=62570672">Craig Gotsman</a>, 
                        <a href="author_page.cfm?id=81100620337&CFID=85074218&CFTOKEN=62570672">Jovan Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 488 - 495</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073218" title="DOI">10.1145/1186822.1073218</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073218&ftid=321872&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow16" style="display:inline;"><br /><div style="display:inline">The ability to position a small subset of mesh vertices and produce a meaningful overall deformation of the entire mesh is a fundamental task in mesh editing and animation. However, the class of meaningful deformations varies from mesh to mesh ...</div></span>
          <span id="toHide16" style="display:none;"><br /><div style="display:inline">The ability to position a small subset of mesh vertices and produce a <i>meaningful</i> overall deformation of the entire mesh is a fundamental task in mesh editing and animation. However, the class of meaningful deformations varies from mesh to mesh and depends on mesh kinematics, which prescribes valid mesh configurations, and a selection mechanism for choosing among them. Drawing an analogy to the traditional use of skeleton-based inverse kinematics for posing skeletons. we define <i>mesh-based inverse kinematics</i> as the problem of finding meaningful mesh deformations that meet specified vertex constraints.Our solution relies on example meshes to indicate the class of meaningful deformations. Each example is represented with a feature vector of deformation gradients that capture the affine transformations which individual triangles undergo relative to a reference pose. To pose a mesh, our algorithm efficiently searches among all meshes with specified vertex positions to find the one that is closest to some pose in a nonlinear span of the example feature vectors. Since the search is not restricted to the span of example shapes, this produces compelling deformations even when the constraints require poses that are different from those observed in the examples. Furthermore, because the span is formed by a nonlinear blend of the example feature vectors, the blending component of our system may also be used independently to pose meshes by specifying blending weights or to compute multi-way morph sequences.</div></span> <a id="expcoll16" href="JavaScript: expandcollapse('expcoll16',16)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073219&CFID=85074218&CFTOKEN=62570672">Large mesh deformation using the volumetric graph Laplacian</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335500198&CFID=85074218&CFTOKEN=62570672">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81385597791&CFID=85074218&CFTOKEN=62570672">Jin Huang</a>, 
                        <a href="author_page.cfm?id=81100167784&CFID=85074218&CFTOKEN=62570672">John Snyder</a>, 
                        <a href="author_page.cfm?id=81351599319&CFID=85074218&CFTOKEN=62570672">Xinguo Liu</a>, 
                        <a href="author_page.cfm?id=81100451028&CFID=85074218&CFTOKEN=62570672">Hujun Bao</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074218&CFTOKEN=62570672">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 496 - 503</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073219" title="DOI">10.1145/1186822.1073219</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073219&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow17" style="display:inline;"><br /><div style="display:inline">We present a novel technique for large deformations on 3D meshes using the volumetric graph Laplacian. We first construct a graph representing the volume inside the input mesh. The graph need not form a solid meshing of the input mesh's interior; its ...</div></span>
          <span id="toHide17" style="display:none;"><br /><div style="display:inline">We present a novel technique for large deformations on 3D meshes using the volumetric graph Laplacian. We first construct a graph representing the volume inside the input mesh. The graph need not form a solid meshing of the input mesh's interior; its edges simply connect nearby points in the volume. This graph's Laplacian encodes volumetric details as the difference between each point in the graph and the average of its neighbors. Preserving these volumetric details during deformation imposes a volumetric constraint that prevents unnatural changes in volume. We also include in the graph points a short distance outside the mesh to avoid local self-intersections. Volumetric detail preservation is represented by a quadric energy function. Minimizing it preserves details in a least-squares sense, distributing error uniformly over the whole deformed mesh. It can also be combined with conventional constraints involving surface positions, details or smoothness, and efficiently minimized by solving a sparse linear system.We apply this technique in a 2D curve-based deformation system allowing novice users to create pleasing deformations with little effort. A novel application of this system is to apply nonrigid and exaggerated deformations of 2D cartoon characters to 3D meshes. We demonstrate our system's potential with several examples.</div></span> <a id="expcoll17" href="JavaScript: expandcollapse('expcoll17',17)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Illustration and image based modeling</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Fran&#231;ois X. Sillion 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073221&CFID=85074218&CFTOKEN=62570672">MoXi: real-time ink dispersion in absorbent paper</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100141173&CFID=85074218&CFTOKEN=62570672">Nelson S.-H. Chu</a>, 
                        <a href="author_page.cfm?id=81100311561&CFID=85074218&CFTOKEN=62570672">Chiew-Lan Tai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 504 - 511</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073221" title="DOI">10.1145/1186822.1073221</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073221&ftid=321874&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow19" style="display:inline;"><br /><div style="display:inline">This paper presents a physically-based method for simulating ink dispersion in absorbent paper for art creation purposes. We devise a novel fluid flow model based on the lattice Boltzmann equation suitable for simulating percolation in disordered media, ...</div></span>
          <span id="toHide19" style="display:none;"><br /><div style="display:inline">This paper presents a physically-based method for simulating ink dispersion in absorbent paper for art creation purposes. We devise a novel fluid flow model based on the lattice Boltzmann equation suitable for simulating percolation in disordered media, like paper, in real time. Our model combines the simulations of spontaneous shape evolution and porous media flow under a unified framework. We also couple our physics simulation with simple implicit modeling and image-based methods to render high quality output. We demonstrate the effectiveness of our techniques in a digital paint system and achieve various realistic effects of ink dispersion, including complex flow patterns observed in real artwork, and other special effects.</div></span> <a id="expcoll19" href="JavaScript: expandcollapse('expcoll19',19)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073222&CFID=85074218&CFTOKEN=62570672">Line drawings from volume data</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81332491677&CFID=85074218&CFTOKEN=62570672">Michael Burns</a>, 
                        <a href="author_page.cfm?id=81100229938&CFID=85074218&CFTOKEN=62570672">Janek Klawe</a>, 
                        <a href="author_page.cfm?id=81100203803&CFID=85074218&CFTOKEN=62570672">Szymon Rusinkiewicz</a>, 
                        <a href="author_page.cfm?id=81100576882&CFID=85074218&CFTOKEN=62570672">Adam Finkelstein</a>, 
                        <a href="author_page.cfm?id=81100499844&CFID=85074218&CFTOKEN=62570672">Doug DeCarlo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 512 - 518</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073222" title="DOI">10.1145/1186822.1073222</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073222&ftid=321875&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow20" style="display:inline;"><br /><div style="display:inline">Renderings of volumetric data have become an important data analysis tool for applications ranging from medicine to scientific simulation. We propose a volumetric drawing system that directly extracts sparse linear features, such as silhouettes and suggestive ...</div></span>
          <span id="toHide20" style="display:none;"><br /><div style="display:inline">Renderings of volumetric data have become an important data analysis tool for applications ranging from medicine to scientific simulation. We propose a volumetric drawing system that directly extracts sparse linear features, such as silhouettes and suggestive contours, using a temporally coherent seed-and-traverse framework. In contrast to previous methods based on isosurfaces or nonrefractive transparency, producing these drawings requires examining an asymptotically smaller subset of the data, leading to efficiency on large data sets. In addition, the resulting imagery is often more comprehensible than standard rendering styles, since it focuses attention on important features in the data. We test our algorithms on datasets up to 512<sup>3</sup>, demonstrating interactive extraction and rendering of line drawings in a variety of drawing styles.</div></span> <a id="expcoll20" href="JavaScript: expandcollapse('expcoll20',20)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073223&CFID=85074218&CFTOKEN=62570672">Motion magnification</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100534688&CFID=85074218&CFTOKEN=62570672">Ce Liu</a>, 
                        <a href="author_page.cfm?id=81100064930&CFID=85074218&CFTOKEN=62570672">Antonio Torralba</a>, 
                        <a href="author_page.cfm?id=81452610969&CFID=85074218&CFTOKEN=62570672">William T. Freeman</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074218&CFTOKEN=62570672">Fr&#233;do Durand</a>, 
                        <a href="author_page.cfm?id=81100466478&CFID=85074218&CFTOKEN=62570672">Edward H. Adelson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 519 - 526</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073223" title="DOI">10.1145/1186822.1073223</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073223&ftid=321876&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow21" style="display:inline;"><br /><div style="display:inline">We present motion magnification, a technique that acts like a microscope for visual motion. It can amplify subtle motions in a video sequence, allowing for visualization of deformations that would otherwise be invisible. To achieve motion magnification, ...</div></span>
          <span id="toHide21" style="display:none;"><br /><div style="display:inline">We present motion magnification, a technique that acts like a microscope for visual motion. It can amplify subtle motions in a video sequence, allowing for visualization of deformations that would otherwise be invisible. To achieve motion magnification, we need to accurately measure visual motions, and group the pixels to be modified. After an initial image registration step, we measure motion by a robust analysis of feature point trajectories, and segment pixels based on similarity of position, color, and motion. A novel measure of motion similarity groups even very small motions according to correlation over time, which often relates to physical cause. An outlier mask marks observations not explained by our layered motion model, and those pixels are simply reproduced on the output from the original registered observations.The motion of any selected layer may be magnified by a user-specified amount; texture synthesis fills-in unseen "holes" revealed by the amplified motions. The resulting motion-magnified images can reveal or emphasize small motions in the original sequence, as we demonstrate with deformations in load-bearing structures, subtle motions or balancing corrections of people, and "rigid" structures bending under hand pressure.</div></span> <a id="expcoll21" href="JavaScript: expandcollapse('expcoll21',21)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073224&CFID=85074218&CFTOKEN=62570672">Out-of-core tensor approximation of multi-dimensional matrices of visual data</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100220442&CFID=85074218&CFTOKEN=62570672">Hongcheng Wang</a>, 
                        <a href="author_page.cfm?id=81100657570&CFID=85074218&CFTOKEN=62570672">Qing Wu</a>, 
                        <a href="author_page.cfm?id=81100646833&CFID=85074218&CFTOKEN=62570672">Lin Shi</a>, 
                        <a href="author_page.cfm?id=81100472713&CFID=85074218&CFTOKEN=62570672">Yizhou Yu</a>, 
                        <a href="author_page.cfm?id=81100609880&CFID=85074218&CFTOKEN=62570672">Narendra Ahuja</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 527 - 535</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073224" title="DOI">10.1145/1186822.1073224</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073224&ftid=321877&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow22" style="display:inline;"><br /><div style="display:inline">Tensor approximation is necessary to obtain compact multilinear models for multi-dimensional visual datasets. Traditionally, each multi-dimensional data item is represented as a vector. Such a scheme flattens the data and partially destroys the internal ...</div></span>
          <span id="toHide22" style="display:none;"><br /><div style="display:inline">Tensor approximation is necessary to obtain compact multilinear models for multi-dimensional visual datasets. Traditionally, each multi-dimensional data item is represented as a vector. Such a scheme flattens the data and partially destroys the internal structures established throughout the multiple dimensions. In this paper, we retain the original dimensionality of the data items to more effectively exploit existing spatial redundancy and allow more efficient computation. Since the size of visual datasets can easily exceed the memory capacity of a single machine, we also present an out-of-core algorithm for higher-order tensor approximation. The basic idea is to partition a tensor into smaller blocks and perform tensor-related operations blockwise. We have successfully applied our techniques to three graphics-related data-driven models, including 6D bidirectional texture functions, 7D dynamic BTFs and 4D volume simulation sequences. Experimental results indicate that our techniques can not only process out-of-core data, but also achieve higher compression ratios and quality than previous methods.</div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Meshes I</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Alla Sheffer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073226&CFID=85074218&CFTOKEN=62570672">Efficiently combining positions and normals for precise 3D geometry</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100057362&CFID=85074218&CFTOKEN=62570672">Diego Nehab</a>, 
                        <a href="author_page.cfm?id=81100203803&CFID=85074218&CFTOKEN=62570672">Szymon Rusinkiewicz</a>, 
                        <a href="author_page.cfm?id=81100603625&CFID=85074218&CFTOKEN=62570672">James Davis</a>, 
                        <a href="author_page.cfm?id=81100019585&CFID=85074218&CFTOKEN=62570672">Ravi Ramamoorthi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 536 - 543</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073226" title="DOI">10.1145/1186822.1073226</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073226&ftid=321878&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow24" style="display:inline;"><br /><div style="display:inline">Range scanning, manual 3D editing, and other modeling approaches can provide information about the geometry of surfaces in the form of either 3D positions (e.g., triangle meshes or range images) or orientations (normal maps or bump maps). We present ...</div></span>
          <span id="toHide24" style="display:none;"><br /><div style="display:inline">Range scanning, manual 3D editing, and other modeling approaches can provide information about the geometry of surfaces in the form of either 3D positions (e.g., triangle meshes or range images) or orientations (normal maps or bump maps). We present an algorithm that combines these two kinds of estimates to produce a new surface that approximates both. Our formulation is linear, allowing it to operate efficiently on complex meshes commonly used in graphics. It also treats high-and low-frequency components separately, allowing it to optimally combine outputs from data sources such as stereo triangulation and photometric stereo, which have different error-vs.-frequency characteristics. We demonstrate the ability of our technique to both recover high-frequency details and avoid low-frequency bias, producing surfaces that are more widely applicable than position or orientation data alone.</div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073227&CFID=85074218&CFTOKEN=62570672">Robust moving least-squares fitting with sharp features</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100447759&CFID=85074218&CFTOKEN=62570672">Shachar Fleishman</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074218&CFTOKEN=62570672">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81100093842&CFID=85074218&CFTOKEN=62570672">Cl&#225;udio T. Silva</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 544 - 552</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073227" title="DOI">10.1145/1186822.1073227</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073227&ftid=322126&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow25" style="display:inline;"><br /><div style="display:inline">We introduce a robust moving least-squares technique for reconstructing a piecewise smooth surface from a potentially noisy point cloud. We use techniques from robust statistics to guide the creation of the neighborhoods used by the moving least squares ...</div></span>
          <span id="toHide25" style="display:none;"><br /><div style="display:inline">We introduce a robust moving least-squares technique for reconstructing a piecewise smooth surface from a potentially noisy point cloud. We use techniques from robust statistics to guide the creation of the neighborhoods used by the moving least squares (MLS) computation. This leads to a conceptually simple approach that provides a unified framework for not only dealing with noise, but also for enabling the modeling of surfaces with sharp features.Our technique is based on a new robust statistics method for outlier detection: the forward-search paradigm. Using this powerful technique, we locally classify regions of a point-set to multiple outlier-free smooth regions. This classification allows us to project points on a locally smooth region rather than a surface that is smooth everywhere, thus defining a piecewise smooth surface and increasing the numerical stability of the projection operator. Furthermore, by treating the points across the discontinuities as outliers, we are able to define sharp features. One of the nice features of our approach is that it automatically disregards outliers during the surface-fitting phase.</div></span> <a id="expcoll25" href="JavaScript: expandcollapse('expcoll25',25)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073228&CFID=85074218&CFTOKEN=62570672">Fast exact and approximate geodesics on meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100625021&CFID=85074218&CFTOKEN=62570672">Vitaly Surazhsky</a>, 
                        <a href="author_page.cfm?id=81100625017&CFID=85074218&CFTOKEN=62570672">Tatiana Surazhsky</a>, 
                        <a href="author_page.cfm?id=81100460119&CFID=85074218&CFTOKEN=62570672">Danil Kirsanov</a>, 
                        <a href="author_page.cfm?id=81100259454&CFID=85074218&CFTOKEN=62570672">Steven J. Gortler</a>, 
                        <a href="author_page.cfm?id=81100397561&CFID=85074218&CFTOKEN=62570672">Hugues Hoppe</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 553 - 560</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073228" title="DOI">10.1145/1186822.1073228</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073228&ftid=322127&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow26" style="display:inline;"><br /><div style="display:inline">The computation of geodesic paths and distances on triangle meshes is a common operation in many computer graphics applications. We present several practical algorithms for computing such geodesics from a source point to one or all other points efficiently. ...</div></span>
          <span id="toHide26" style="display:none;"><br /><div style="display:inline">The computation of geodesic paths and distances on triangle meshes is a common operation in many computer graphics applications. We present several practical algorithms for computing such geodesics from a source point to one or all other points efficiently. First, we describe an implementation of the exact "single source, all destination" algorithm presented by Mitchell, Mount, and Papadimitriou (MMP). We show that the algorithm runs much faster in practice than suggested by worst case analysis. Next, we extend the algorithm with a merging operation to obtain computationally efficient and accurate approximations with bounded error. Finally, to compute the shortest path between two given points, we use a lower-bound property of our approximate geodesic algorithm to efficiently prune the frontier of the MMP algorithm. thereby obtaining an exact solution even more quickly.</div></span> <a id="expcoll26" href="JavaScript: expandcollapse('expcoll26',26)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073229&CFID=85074218&CFTOKEN=62570672">Mean value coordinates for closed triangular meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100098726&CFID=85074218&CFTOKEN=62570672">Tao Ju</a>, 
                        <a href="author_page.cfm?id=81100603187&CFID=85074218&CFTOKEN=62570672">Scott Schaefer</a>, 
                        <a href="author_page.cfm?id=81100611449&CFID=85074218&CFTOKEN=62570672">Joe Warren</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 561 - 566</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073229" title="DOI">10.1145/1186822.1073229</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073229&ftid=322128&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow27" style="display:inline;"><br /><div style="display:inline">Constructing a function that interpolates a set of values defined at vertices of a mesh is a fundamental operation in computer graphics. Such an interpolant has many uses in applications such as shading, parameterization and deformation. For closed polygons, ...</div></span>
          <span id="toHide27" style="display:none;"><br /><div style="display:inline">Constructing a function that interpolates a set of values defined at vertices of a mesh is a fundamental operation in computer graphics. Such an interpolant has many uses in applications such as shading, parameterization and deformation. For closed polygons, mean value coordinates have been proven to be an excellent method for constructing such an interpolant. In this paper, we generalize mean value coordinates from closed 2D polygons to closed triangular meshes. Given such a mesh <i>P</i>, we show that these coordinates are continuous everywhere and smooth on the interior of <i>P</i>. The coordinates are linear on the triangles of <i>P</i> and can reproduce linear functions on the interior of <i>P</i>. To illustrate their usefulness, we conclude by considering several interesting applications including constructing volumetric textures and surface deformation.</div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Video & image matting</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Wojciech Matusik 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073231&CFID=85074218&CFTOKEN=62570672">Defocus video matting</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81327490282&CFID=85074218&CFTOKEN=62570672">Morgan McGuire</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=85074218&CFTOKEN=62570672">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100199891&CFID=85074218&CFTOKEN=62570672">Hanspeter Pfister</a>, 
                        <a href="author_page.cfm?id=81100166298&CFID=85074218&CFTOKEN=62570672">John F. Hughes</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074218&CFTOKEN=62570672">Fr&#233;do Durand</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 567 - 576</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073231" title="DOI">10.1145/1186822.1073231</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073231&ftid=322129&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow29" style="display:inline;"><br /><div style="display:inline">Video matting is the process of pulling a high-quality alpha matte and foreground from a video sequence. Current techniques require either a known background (e.g., a blue screen) or extensive user interaction (e.g., to specify known foreground and background ...</div></span>
          <span id="toHide29" style="display:none;"><br /><div style="display:inline">Video matting is the process of pulling a high-quality alpha matte and foreground from a video sequence. Current techniques require either a known background (e.g., a blue screen) or extensive user interaction (e.g., to specify known foreground and background elements). The matting problem is generally under-constrained, since not enough information has been collected at capture time. We propose a novel, fully autonomous method for pulling a matte using multiple synchronized video streams that share a point of view but differ in their plane of focus. The solution is obtained by directly minimizing the error in filter-based image formation equations, which are over-constrained by our rich data stream. Our system solves the fully dynamic video matting problem without user assistance: both the foreground and background may be high frequency and have dynamic content, the foreground may resemble the background, and the scene is lit by natural (as opposed to polarized or collimated) illumination.</div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073232&CFID=85074218&CFTOKEN=62570672">Automatic photo pop-up</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100204007&CFID=85074218&CFTOKEN=62570672">Derek Hoiem</a>, 
                        <a href="author_page.cfm?id=81100604913&CFID=85074218&CFTOKEN=62570672">Alexei A. Efros</a>, 
                        <a href="author_page.cfm?id=81100021352&CFID=85074218&CFTOKEN=62570672">Martial Hebert</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 577 - 584</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073232" title="DOI">10.1145/1186822.1073232</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073232&ftid=322130&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow30" style="display:inline;"><br /><div style="display:inline">This paper presents a fully automatic method for creating a 3D model from a single photograph. The model is made up of several texture-mapped planar billboards and has the complexity of a typical children's pop-up book illustration. Our main insight ...</div></span>
          <span id="toHide30" style="display:none;"><br /><div style="display:inline">This paper presents a fully automatic method for creating a 3D model from a single photograph. The model is made up of several texture-mapped planar billboards and has the complexity of a typical children's pop-up book illustration. Our main insight is that instead of attempting to recover precise geometry, we statistically model <i>geometric classes</i> defined by their orientations in the scene. Our algorithm labels regions of the input image into coarse categories: "ground", "sky", and "vertical". These labels are then used to "cut and fold" the image into a pop-up model using a set of simple assumptions. Because of the inherent ambiguity of the problem and the statistical nature of the approach, the algorithm is not expected to work on every image. However. it performs surprisingly well for a wide range of scenes taken from a typical person's photo album.</div></span> <a id="expcoll30" href="JavaScript: expandcollapse('expcoll30',30)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073233&CFID=85074218&CFTOKEN=62570672">Interactive video cutout</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100233470&CFID=85074218&CFTOKEN=62570672">Jue Wang</a>, 
                        <a href="author_page.cfm?id=81100042831&CFID=85074218&CFTOKEN=62570672">Pravin Bhat</a>, 
                        <a href="author_page.cfm?id=81100138345&CFID=85074218&CFTOKEN=62570672">R. Alex Colburn</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=85074218&CFTOKEN=62570672">Maneesh Agrawala</a>, 
                        <a href="author_page.cfm?id=81406592138&CFID=85074218&CFTOKEN=62570672">Michael F. Cohen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 585 - 594</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073233" title="DOI">10.1145/1186822.1073233</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073233&ftid=322131&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow31" style="display:inline;"><br /><div style="display:inline">We present an interactive system for efficiently extracting foreground objects from a video. We extend previous min-cut based image segmentation techniques to the domain of video with four new contributions. We provide a novel painting-based user interface ...</div></span>
          <span id="toHide31" style="display:none;"><br /><div style="display:inline">We present an interactive system for efficiently extracting foreground objects from a video. We extend previous min-cut based image segmentation techniques to the domain of video with four new contributions. We provide a novel painting-based user interface that allows users to easily indicate the foreground object across space and time. We introduce a hierarchical mean-shift preprocess in order to minimize the number of nodes that min-cut must operate on. Within the min-cut we also define new local cost functions to augment the global costs defined in earlier work. Finally, we extend 2D alpha matting methods designed for images to work with 3D video volumes. We demonstrate that our matting approach preserves smoothness across both space and time. Our interactive video cutout system allows users to quickly extract foreground objects from video sequences for use in a variety of applications including compositing onto new backgrounds and NPR cartoon style rendering.</div></span> <a id="expcoll31" href="JavaScript: expandcollapse('expcoll31',31)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073234&CFID=85074218&CFTOKEN=62570672">Video object cut and paste</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81452600310&CFID=85074218&CFTOKEN=62570672">Yin Li</a>, 
                        <a href="author_page.cfm?id=81351592034&CFID=85074218&CFTOKEN=62570672">Jian Sun</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 595 - 600</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073234" title="DOI">10.1145/1186822.1073234</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073234&ftid=322132&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow32" style="display:inline;"><br /><div style="display:inline">In this paper, we present a system for cutting a moving object out from a video clip. The cutout object sequence can be pasted onto another video or a background image. To achieve this, we first apply a new 3D graph cut based segmentation approach on ...</div></span>
          <span id="toHide32" style="display:none;"><br /><div style="display:inline">In this paper, we present a system for cutting a moving object out from a video clip. The cutout object sequence can be pasted onto another video or a background image. To achieve this, we first apply a new 3D graph cut based segmentation approach on the spatial-temporal video volume. Our algorithm partitions watershed presegmentation regions into foreground and background while preserving temporal coherence. Then, the initial segmentation result is refined locally. Given two frames in the video sequence, we specify two respective windows of interest which are then tracked using a bi-directional feature tracking algorithm. For each frame in between these two given frames, the segmentation in each tracked window is refined using a 2D graph cut that utilizes a local color model. Moreover, we provide brush tools for the user to control the object boundary precisely wherever needed. Based on the accurate binary segmentation result, we apply coherent matting to extract the alpha mattes and foreground colors of the object.</div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Meshes II</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Hugues Hoppe 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073236&CFID=85074218&CFTOKEN=62570672">Surface compression with geometric bandelets</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100110267&CFID=85074218&CFTOKEN=62570672">Gabriel Peyr&#233;</a>, 
                        <a href="author_page.cfm?id=81100629546&CFID=85074218&CFTOKEN=62570672">St&#233;phane Mallat</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 601 - 608</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073236" title="DOI">10.1145/1186822.1073236</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073236&ftid=322133&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow34" style="display:inline;"><br /><div style="display:inline">This paper describes the construction of second generation bandelet bases and their application to 3D geometry compression. This new coding scheme is orthogonal and the corresponding basis functions are regular. In our method, surfaces are decomposed ...</div></span>
          <span id="toHide34" style="display:none;"><br /><div style="display:inline">This paper describes the construction of second generation bandelet bases and their application to 3D geometry compression. This new coding scheme is orthogonal and the corresponding basis functions are regular. In our method, surfaces are decomposed in a bandelet basis with a fast bandeletization algorithm that removes the geometric redundancy of orthogonal wavelet coefficients. The resulting transform coding scheme has an error decay that is asymptotically optimal for geometrically regular surfaces. We then use these bandelet bases to perform geometry image and normal map compression. Numerical tests show that for complex surfaces bandelets bring an improvement of 1.5dB to 2dB over state of the art compression schemes.</div></span> <a id="expcoll34" href="JavaScript: expandcollapse('expcoll34',34)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073237&CFID=85074218&CFTOKEN=62570672">Geometry-guided progressive lossless 3D mesh coding with octree (OT) decomposition</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81343502517&CFID=85074218&CFTOKEN=62570672">Jingliang Peng</a>, 
                        <a href="author_page.cfm?id=81384616778&CFID=85074218&CFTOKEN=62570672">C.-C. Jay Kuo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 609 - 616</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073237" title="DOI">10.1145/1186822.1073237</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073237&ftid=322134&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow35" style="display:inline;"><br /><div style="display:inline">A new progressive lossless 3D triangular mesh encoder is proposed in this work, which can encode any 3D triangular mesh with an arbitrary topological structure. Given a mesh, the quantized 3D vertices are first partitioned into an octree (OT) structure, ...</div></span>
          <span id="toHide35" style="display:none;"><br /><div style="display:inline">A new progressive lossless 3D triangular mesh encoder is proposed in this work, which can encode any 3D triangular mesh with an arbitrary topological structure. Given a mesh, the quantized 3D vertices are first partitioned into an octree (OT) structure, which is then traversed from the root and gradually to the leaves. During the traversal, each 3D cell in the tree front is subdivided into eight childcells. For each cell subdivision, both local geometry and connectivity changes are encoded, where the connectivity coding is guided by the geometry coding. Furthermore, prioritized cell subdivision is performed in the tree front to provide better rate-distortion (RD) performance. Experiments show that the proposed mesh coder outperforms the kd-tree algorithm in both geometry and connectivity coding efficiency. For the geometry coding part, the range of improvement is typically around 10%~20%, but may go up to 50%~60% for meshes with highly regular geometry data and/or tight clustering of vertices.</div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073238&CFID=85074218&CFTOKEN=62570672">Variational tetrahedral meshing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100223488&CFID=85074218&CFTOKEN=62570672">Pierre Alliez</a>, 
                        <a href="author_page.cfm?id=81100183127&CFID=85074218&CFTOKEN=62570672">David Cohen-Steiner</a>, 
                        <a href="author_page.cfm?id=81100130679&CFID=85074218&CFTOKEN=62570672">Mariette Yvinec</a>, 
                        <a href="author_page.cfm?id=81100041821&CFID=85074218&CFTOKEN=62570672">Mathieu Desbrun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 617 - 625</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073238" title="DOI">10.1145/1186822.1073238</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073238&ftid=322135&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow36" style="display:inline;"><br /><div style="display:inline">In this paper, a novel Delaunay-based variational approach to isotropic tetrahedral meshing is presented. To achieve both robustness and efficiency, we minimize a simple mesh-dependent energy through global updates of both vertex positions and ...</div></span>
          <span id="toHide36" style="display:none;"><br /><div style="display:inline">In this paper, a novel Delaunay-based variational approach to isotropic tetrahedral meshing is presented. To achieve both robustness and efficiency, we minimize a simple mesh-dependent energy through global updates of both vertex positions <i>and</i> connectivity. As this energy is known to be the &ang;<sup>1</sup> distance between an isotropic quadratic function and its linear interpolation on the mesh, our minimization procedure generates well-shaped tetrahedra. Mesh design is controlled through a gradation smoothness parameter and selection of the desired number of vertices. We provide the foundations of our approach by explaining both the underlying variational principle and its geometric interpretation. We demonstrate the quality of the resulting meshes through a series of examples.</div></span> <a id="expcoll36" href="JavaScript: expandcollapse('expcoll36',36)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073239&CFID=85074218&CFTOKEN=62570672">Shell maps</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100336096&CFID=85074218&CFTOKEN=62570672">Serban D. Porumbescu</a>, 
                        <a href="author_page.cfm?id=81100569476&CFID=85074218&CFTOKEN=62570672">Brian Budge</a>, 
                        <a href="author_page.cfm?id=81450593763&CFID=85074218&CFTOKEN=62570672">Louis Feng</a>, 
                        <a href="author_page.cfm?id=81100148606&CFID=85074218&CFTOKEN=62570672">Kenneth I. Joy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 626 - 633</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073239" title="DOI">10.1145/1186822.1073239</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073239&ftid=322136&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow37" style="display:inline;"><br /><div style="display:inline">A shell map is a bijective mapping between shell space and texture space that can be used to generate small-scale features on surfaces using a variety of modeling techniques. The method is based upon the generation of an offset surface and the construction ...</div></span>
          <span id="toHide37" style="display:none;"><br /><div style="display:inline">A shell map is a bijective mapping between shell space and texture space that can be used to generate small-scale features on surfaces using a variety of modeling techniques. The method is based upon the generation of an offset surface and the construction of a tetrahedral mesh that fills the space between the base surface and its offset. By identifying a corresponding tetrahedral mesh in texture space, the shell map can be implemented through a straightforward barycentric-coordinate map between corresponding tetrahedra. The generality of shell maps allows texture space to contain geometric objects, procedural volume textures, scalar fields, or other shell-mapped objects.</div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Perception</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Maneesh Agrawala 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073241&CFID=85074218&CFTOKEN=62570672">Color2Gray: salience-preserving color removal</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100057321&CFID=85074218&CFTOKEN=62570672">Amy A. Gooch</a>, 
                        <a href="author_page.cfm?id=81100587180&CFID=85074218&CFTOKEN=62570672">Sven C. Olsen</a>, 
                        <a href="author_page.cfm?id=81100216430&CFID=85074218&CFTOKEN=62570672">Jack Tumblin</a>, 
                        <a href="author_page.cfm?id=81100057328&CFID=85074218&CFTOKEN=62570672">Bruce Gooch</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 634 - 639</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073241" title="DOI">10.1145/1186822.1073241</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073241&ftid=322137&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow39" style="display:inline;"><br /><div style="display:inline">Visually important image features often disappear when color images are converted to grayscale. The algorithm introduced here reduces such losses by attempting to preserve the salient features of the color image. The Color2Gray algorithm is a ...</div></span>
          <span id="toHide39" style="display:none;"><br /><div style="display:inline">Visually important image features often disappear when color images are converted to grayscale. The algorithm introduced here reduces such losses by attempting to preserve the salient features of the color image. The <i>Color2Gray</i> algorithm is a 3-step process: 1) convert RGB inputs to a perceptually uniform CIE <i>L*a*b*</i> color space, 2) use chrominance and luminance differences to create grayscale target differences between nearby image pixels, and 3) solve an optimization problem designed to selectively modulate the grayscale representation as a function of the chroma variation of the source image. The <i>Color2Gray</i> results offer viewers salient information missing from previous grayscale image creation methods.</div></span> <a id="expcoll39" href="JavaScript: expandcollapse('expcoll39',39)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073242&CFID=85074218&CFTOKEN=62570672">Evaluation of tone mapping operators using a High Dynamic Range display</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100307825&CFID=85074218&CFTOKEN=62570672">Patrick Ledda</a>, 
                        <a href="author_page.cfm?id=81100086839&CFID=85074218&CFTOKEN=62570672">Alan Chalmers</a>, 
                        <a href="author_page.cfm?id=81100432760&CFID=85074218&CFTOKEN=62570672">Tom Troscianko</a>, 
                        <a href="author_page.cfm?id=81100573650&CFID=85074218&CFTOKEN=62570672">Helge Seetzen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 640 - 648</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073242" title="DOI">10.1145/1186822.1073242</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073242&ftid=322138&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow40" style="display:inline;"><br /><div style="display:inline">Tone mapping operators are designed to reproduce visibility and the overall impression of brightness, contrast and color of the real world onto limited dynamic range displays and printers. Although many tone mapping operators have been published in recent ...</div></span>
          <span id="toHide40" style="display:none;"><br /><div style="display:inline">Tone mapping operators are designed to reproduce visibility and the overall impression of brightness, contrast and color of the real world onto limited dynamic range displays and printers. Although many tone mapping operators have been published in recent years, no thorough psychophysical experiments have yet been undertaken to compare such operators against the real scenes they are purporting to depict. In this paper, we present the results of a series of psychophysical experiments to validate six frequently used tone mapping operators against linearly mapped High Dynamic Range (HDR) scenes displayed on a novel HDR device. Individual operators address the tone mapping issue using a variety of approaches and the goals of these techniques are often quite different from one another. Therefore, the purpose of this investigation was not simply to determine which is the "best" algorithm, but more generally to propose an experimental methodology to validate such operators and to determine the participants' impressions of the images produced compared to what is visible on a high contrast ratio display.</div></span> <a id="expcoll40" href="JavaScript: expandcollapse('expcoll40',40)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073243&CFID=85074218&CFTOKEN=62570672">A photon accurate model of the human eye</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100240083&CFID=85074218&CFTOKEN=62570672">Michael F. Deering</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 649 - 658</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073243" title="DOI">10.1145/1186822.1073243</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073243&ftid=322139&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow41" style="display:inline;"><br /><div style="display:inline">A photon accurate model of individual cones in the human eye perceiving images on digital display devices is presented. Playback of streams of pixel video data is modeled as individual photon emission events from within the physical substructure of each ...</div></span>
          <span id="toHide41" style="display:none;"><br /><div style="display:inline">A photon accurate model of individual cones in the human eye perceiving images on digital display devices is presented. Playback of streams of pixel video data is modeled as individual photon emission events from within the physical substructure of each display pixel. The thus generated electromagnetic wavefronts are refracted through a four surface model of the human cornea and lens, and diffracted at the pupil. The position, size, shape, and orientation of each of the five million photoreceptor cones in the retina are individually modeled by a new synthetic retina model. Photon absorption events map the collapsing wavefront to photon detection events in a particular cone, resulting in images of the photon counts in the retinal cone array. The custom rendering systems used to generate sequences of these images takes a number of optical and physical properties of the image formation into account, including wavelength dependent absorption in the tissues of the eye, and the motion blur caused by slight movement of the eye during a frame of viewing. The creation of this new model is part of a larger framework for understanding how changes to computer graphics rendering algorithms and changes in image display devices are related to artifacts visible to human viewers.</div></span> <a id="expcoll41" href="JavaScript: expandcollapse('expcoll41',41)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073244&CFID=85074218&CFTOKEN=62570672">Mesh saliency</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100399632&CFID=85074218&CFTOKEN=62570672">Chang Ha Lee</a>, 
                        <a href="author_page.cfm?id=81100561920&CFID=85074218&CFTOKEN=62570672">Amitabh Varshney</a>, 
                        <a href="author_page.cfm?id=81100069348&CFID=85074218&CFTOKEN=62570672">David W. Jacobs</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 659 - 666</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073244" title="DOI">10.1145/1186822.1073244</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073244&ftid=322140&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow42" style="display:inline;"><br /><div style="display:inline">Research over the last decade has built a solid mathematical foundation for representation and analysis of 3D meshes in graphics and geometric modeling. Much of this work however does not explicitly incorporate models of low-level human visual attention. ...</div></span>
          <span id="toHide42" style="display:none;"><br /><div style="display:inline">Research over the last decade has built a solid mathematical foundation for representation and analysis of 3D meshes in graphics and geometric modeling. Much of this work however does not explicitly incorporate models of low-level human visual attention. In this paper we introduce the idea of <i>mesh saliency</i> as a measure of regional importance for graphics meshes. Our notion of saliency is inspired by low-level human visual system cues. We define mesh saliency in a scale-dependent manner using a center-surround operator on Gaussian-weighted mean curvatures. We observe that such a definition of mesh saliency is able to capture what most would classify as visually interesting regions on a mesh. The human-perception-inspired importance measure computed by our mesh saliency operator results in more visually pleasing results in processing and viewing of 3D meshes. compared to using a purely geometric measure of shape. such as curvature. We discuss how mesh saliency can be incorporated in graphics applications such as mesh simplification and viewpoint selection and present examples that show visually appealing results from using mesh saliency.</div></span> <a id="expcoll42" href="JavaScript: expandcollapse('expcoll42',42)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Motion capture data: interaction and selection</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Nancy Pollard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073246&CFID=85074218&CFTOKEN=62570672">Action synopsis: pose selection and illustration</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100057632&CFID=85074218&CFTOKEN=62570672">Jackie Assa</a>, 
                        <a href="author_page.cfm?id=81100202594&CFID=85074218&CFTOKEN=62570672">Yaron Caspi</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074218&CFTOKEN=62570672">Daniel Cohen-Or</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 667 - 676</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073246" title="DOI">10.1145/1186822.1073246</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073246&ftid=322141&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow44" style="display:inline;"><br /><div style="display:inline">Illustrating motion in still imagery for the purpose of summary, abstraction and motion description is important for a diverse spectrum of fields, ranging from arts to sciences. In this paper, we introduce a method that produces an action synopsis for ...</div></span>
          <span id="toHide44" style="display:none;"><br /><div style="display:inline">Illustrating motion in still imagery for the purpose of summary, abstraction and motion description is important for a diverse spectrum of fields, ranging from arts to sciences. In this paper, we introduce a method that produces an action synopsis for presenting motion in still images. The method carefully selects key poses based on an analysis of a skeletal animation sequence, to facilitate expressing complex motions in a single image or a small number of concise views. Our approach is to embed the high-dimensional motion curve in a low-dimensional Euclidean space, where the main characteristics of the skeletal action are kept. The lower complexity of the embedded motion curve allows a simple iterative method which analyzes the curve and locates significant points, associated with the key poses of the original motion. We present methods for illustrating the selected poses in an image as a means to convey the action. We applied our methods to a variety of motions of human actions given either as 3D animation sequences or as video clips, and generated images that depict their synopsis.</div></span> <a id="expcoll44" href="JavaScript: expandcollapse('expcoll44',44)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073247&CFID=85074218&CFTOKEN=62570672">Efficient content-based retrieval of motion capture data</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81337491607&CFID=85074218&CFTOKEN=62570672">Meinard M&#252;ller</a>, 
                        <a href="author_page.cfm?id=81342509125&CFID=85074218&CFTOKEN=62570672">Tido R&#246;der</a>, 
                        <a href="author_page.cfm?id=81339494733&CFID=85074218&CFTOKEN=62570672">Michael Clausen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 677 - 685</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073247" title="DOI">10.1145/1186822.1073247</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073247&ftid=322142&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow45" style="display:inline;"><br /><div style="display:inline">The reuse of human motion capture data to create new, realistic motions by applying morphing and blending techniques has become an important issue in computer animation. This requires the identification and extraction of logically related motions scattered ...</div></span>
          <span id="toHide45" style="display:none;"><br /><div style="display:inline">The reuse of human motion capture data to create new, realistic motions by applying morphing and blending techniques has become an important issue in computer animation. This requires the identification and extraction of logically related motions scattered within some data set. Such content-based retrieval of motion capture data, which is the topic of this paper, constitutes a difficult and time-consuming problem due to significant spatio-temporal variations between logically related motions. In our approach, we introduce various kinds of qualitative features describing geometric relations between specified body points of a pose and show how these features induce a time segmentation of motion capture data streams. By incorporating spatio-temporal invariance into the geometric features and adaptive segments, we are able to adopt efficient indexing methods allowing for flexible and efficient content-based retrieval and browsing in huge motion capture databases. Furthermore, we obtain an efficient preprocessing method substantially accelerating the cost-intensive classical dynamic time warping techniques for the time alignment of logically similar motion data streams. We present experimental results on a test data set of more than one million frames, corresponding to 180 minutes of motion. The linearity of our indexing algorithms guarantees the scalability of our results to much larger data sets.</div></span> <a id="expcoll45" href="JavaScript: expandcollapse('expcoll45',45)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073248&CFID=85074218&CFTOKEN=62570672">Performance animation from low-dimensional control signals</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100205074&CFID=85074218&CFTOKEN=62570672">Jinxiang Chai</a>, 
                        <a href="author_page.cfm?id=81100049661&CFID=85074218&CFTOKEN=62570672">Jessica K. Hodgins</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 686 - 696</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073248" title="DOI">10.1145/1186822.1073248</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073248&ftid=322143&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow46" style="display:inline;"><br /><div style="display:inline">This paper introduces an approach to performance animation that employs video cameras and a small set of retro-reflective markers to create a low-cost, easy-to-use system that might someday be practical for home use. The low-dimensional control signals ...</div></span>
          <span id="toHide46" style="display:none;"><br /><div style="display:inline">This paper introduces an approach to performance animation that employs video cameras and a small set of retro-reflective markers to create a low-cost, easy-to-use system that might someday be practical for home use. The low-dimensional control signals from the user's performance are supplemented by a database of pre-recorded human motion. At run time, the system automatically learns a series of local models from a set of motion capture examples that are a close match to the marker locations captured by the cameras. These local models are then used to reconstruct the motion of the user as a full-body animation. We demonstrate the power of this approach with real-time control of six different behaviors using two video cameras and a small set of retro-reflective markers. We compare the resulting animation to animation from commercial motion capture equipment with a full set of markers.</div></span> <a id="expcoll46" href="JavaScript: expandcollapse('expcoll46',46)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073249&CFID=85074218&CFTOKEN=62570672">Dynamic response for motion capture animation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100319485&CFID=85074218&CFTOKEN=62570672">Victor Brian Zordan</a>, 
                        <a href="author_page.cfm?id=81100495930&CFID=85074218&CFTOKEN=62570672">Anna Majkowska</a>, 
                        <a href="author_page.cfm?id=81100341831&CFID=85074218&CFTOKEN=62570672">Bill Chiu</a>, 
                        <a href="author_page.cfm?id=81100455904&CFID=85074218&CFTOKEN=62570672">Matthew Fast</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 697 - 701</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073249" title="DOI">10.1145/1186822.1073249</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073249&ftid=322144&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow47" style="display:inline;"><br /><div style="display:inline">Human motion capture embeds rich detail and style which is difficult to generate with competing animation synthesis technologies. However, such recorded data requires principled means for creating responses in unpredicted situations, for example reactions ...</div></span>
          <span id="toHide47" style="display:none;"><br /><div style="display:inline">Human motion capture embeds rich detail and style which is difficult to generate with competing animation synthesis technologies. However, such recorded data requires principled means for creating responses in unpredicted situations, for example reactions immediately following impact. This paper introduces a novel technique for incorporating unexpected impacts into a motion capture-driven animation system through the combination of a physical simulation which responds to contact forces and a specialized search routine which determines the best plausible re-entry into motion library playback following the impact. Using an actuated dynamic model, our system generates a physics-based response while connecting motion capture segments. Our method allows characters to respond to unexpected changes in the environment based on the specific dynamic effects of a given contact while also taking advantage of the realistic movement made available through motion capture. We show the results of our system under various conditions and with varying responses using martial arts motion capture as a testbed.</div></span> <a id="expcoll47" href="JavaScript: expandcollapse('expcoll47',47)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Plants</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Greg Turk 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073251&CFID=85074218&CFTOKEN=62570672">Modeling and visualization of leaf venation patterns</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100174040&CFID=85074218&CFTOKEN=62570672">Adam Runions</a>, 
                        <a href="author_page.cfm?id=81100609377&CFID=85074218&CFTOKEN=62570672">Martin Fuhrer</a>, 
                        <a href="author_page.cfm?id=81100001180&CFID=85074218&CFTOKEN=62570672">Brendan Lane</a>, 
                        <a href="author_page.cfm?id=81100608535&CFID=85074218&CFTOKEN=62570672">Pavol Federl</a>, 
                        <a href="author_page.cfm?id=81100468929&CFID=85074218&CFTOKEN=62570672">Anne-Ga&#235;lle Rolland-Lagan</a>, 
                        <a href="author_page.cfm?id=81100465812&CFID=85074218&CFTOKEN=62570672">Przemyslaw Prusinkiewicz</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 702 - 711</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073251" title="DOI">10.1145/1186822.1073251</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073251&ftid=322145&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow49" style="display:inline;"><br /><div style="display:inline">We introduce a class of biologically-motivated algorithms for generating leaf venation patterns. These algorithms simulate the interplay between three processes: (1) development of veins towards hormone (auxin) sources embedded in the leaf blade; (2) ...</div></span>
          <span id="toHide49" style="display:none;"><br /><div style="display:inline">We introduce a class of biologically-motivated algorithms for generating leaf venation patterns. These algorithms simulate the interplay between three processes: (1) development of veins towards hormone (auxin) sources embedded in the leaf blade; (2) modification of the hormone source distribution by the proximity of veins; and (3) modification of both the vein pattern and source distribution by leaf growth. These processes are formulated in terms of iterative geometric operations on sets of points that represent vein nodes and auxin sources. In addition, a vein connection graph is maintained to determine vein widths. The effective implementation of the algorithms relies on the use of space subdivision (Voronoi diagrams) and time coherence between iteration steps. Depending on the specification details and parameters used, the algorithms can simulate many types of venation patterns, both open (tree-like) and closed (with loops). Applications of the presented algorithms include texture and detailed structure generation for image synthesis purposes, and modeling of morphogenetic processes in support of biological research.</div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073252&CFID=85074218&CFTOKEN=62570672">Real-time rendering of plant leaves</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81408602731&CFID=85074218&CFTOKEN=62570672">Lifeng Wang</a>, 
                        <a href="author_page.cfm?id=81100215783&CFID=85074218&CFTOKEN=62570672">Wenle Wang</a>, 
                        <a href="author_page.cfm?id=81100369597&CFID=85074218&CFTOKEN=62570672">Julie Dorsey</a>, 
                        <a href="author_page.cfm?id=81450593098&CFID=85074218&CFTOKEN=62570672">Xu Yang</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074218&CFTOKEN=62570672">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 712 - 719</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073252" title="DOI">10.1145/1186822.1073252</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073252&ftid=322146&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow50" style="display:inline;"><br /><div style="display:inline">This paper presents a framework for the real-time rendering of plant leaves with global illumination effects. Realistic rendering of leaves requires a sophisticated appearance model and accurate lighting computation. For leaf appearance we introduce ...</div></span>
          <span id="toHide50" style="display:none;"><br /><div style="display:inline">This paper presents a framework for the real-time rendering of plant leaves with global illumination effects. Realistic rendering of leaves requires a sophisticated appearance model and accurate lighting computation. For leaf appearance we introduce a parametric model that describes leaves in terms of spatially-variant BRDFs and BTDFs. These BRDFs and BTDFs, incorporating analysis of subsurface scattering inside leaf tissues and rough surface scattering on leaf surfaces, can be measured from real leaves. More importantly, this description is compact and can be loaded into graphics hardware for fast run-time shading calculations, which are essential for achieving high frame rates. For lighting computation, we present an algorithm that extends the Precomputed Radiance Transfer (PRT) approach to all-frequency lighting for leaves. In particular, we handle the combined illumination effects due to low-frequency environment light and high-frequency sunlight. This is done by decomposing the local incident radiance of sunlight into direct and indirect components. The direct component, which contains most of the high frequencies, is not pre-computed with spherical harmonics as in PRT; instead it is evaluated on-the-fly using pre-computed light-visibility convolution data. We demonstrate our framework by the rendering of a variety of leaves and assemblies thereof.</div></span> <a id="expcoll50" href="JavaScript: expandcollapse('expcoll50',50)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073253&CFID=85074218&CFTOKEN=62570672">Floral diagrams and inflorescences: interactive flower modeling using botanical structural constraints</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100057408&CFID=85074218&CFTOKEN=62570672">Takashi Ijiri</a>, 
                        <a href="author_page.cfm?id=81332519940&CFID=85074218&CFTOKEN=62570672">Shigeru Owada</a>, 
                        <a href="author_page.cfm?id=81100546396&CFID=85074218&CFTOKEN=62570672">Makoto Okabe</a>, 
                        <a href="author_page.cfm?id=81100444444&CFID=85074218&CFTOKEN=62570672">Takeo Igarashi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 720 - 726</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073253" title="DOI">10.1145/1186822.1073253</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073253&ftid=322147&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow51" style="display:inline;"><br /><div style="display:inline">We present a system for modeling flowers in three dimensions quickly and easily while preserving correct botanical structures. We use floral diagrams and inflorescences, which were developed by botanists to concisely describe structural ...</div></span>
          <span id="toHide51" style="display:none;"><br /><div style="display:inline">We present a system for modeling flowers in three dimensions quickly and easily while preserving correct botanical structures. We use <i>floral diagrams</i> and <i>inflorescences</i>, which were developed by botanists to concisely describe structural information of flowers. Floral diagrams represent the layout of floral components on a single flower, while inflorescences are arrangements of multiple flowers. Based on these notions, we created a simple user interface that is specially tailored to flower editing, while retaining a maximum variety of generable models. We also provide sketching interfaces to define the geometries of floral components. Separation of structural editing and editing of geometry makes the authoring process more flexible and efficient. We found that even novice users could easily design various flower models using our technique. Our system is an example of application-customized sketching, illustrating the potential power of a sketching interface that is carefully designed for a specific application.</div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073254&CFID=85074218&CFTOKEN=62570672">Measuring and modeling the appearance of finished wood</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100238316&CFID=85074218&CFTOKEN=62570672">Stephen R. Marschner</a>, 
                        <a href="author_page.cfm?id=81100345625&CFID=85074218&CFTOKEN=62570672">Stephen H. Westin</a>, 
                        <a href="author_page.cfm?id=81100118944&CFID=85074218&CFTOKEN=62570672">Adam Arbree</a>, 
                        <a href="author_page.cfm?id=81100243515&CFID=85074218&CFTOKEN=62570672">Jonathan T. Moon</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 727 - 734</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073254" title="DOI">10.1145/1186822.1073254</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073254&ftid=322148&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow52" style="display:inline;"><br /><div style="display:inline">Wood coated with transparent finish has a beautiful and distinctive appearance that is familiar to everyone. Woods with unusual grain patterns. such as tiger, burl, and birdseye figures, have a strikingly unusual directional reflectance that is prized ...</div></span>
          <span id="toHide52" style="display:none;"><br /><div style="display:inline">Wood coated with transparent finish has a beautiful and distinctive appearance that is familiar to everyone. Woods with unusual grain patterns. such as tiger, burl, and birdseye figures, have a strikingly unusual directional reflectance that is prized for decorative applications. With new, high resolution measurements of spatially varying BRDFs. we show that this distinctive appearance is due to light scattering that does not conform to the usual notion of anisotropic surface reflection. The behavior can be explained by scattering from the matrix of wood fibers below the surface, resulting in a subsurface highlight that occurs on a cone with an out-of-plane axis. We propose a new shading model component to handle reflection from subsurface fibers, which is combined with the standard diffuse and specular components to make a complete shading model. Rendered results from fits of our model to the measurement data demonstrate that this new model captures the distinctive appearance of wood.</div></span> <a id="expcoll52" href="JavaScript: expandcollapse('expcoll52',52)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Capturing reality I</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Szymon Rusinkiewicz 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073256&CFID=85074218&CFTOKEN=62570672">Fourier slice photography</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100471423&CFID=85074218&CFTOKEN=62570672">Ren Ng</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 735 - 744</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073256" title="DOI">10.1145/1186822.1073256</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073256&ftid=322149&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow54" style="display:inline;"><br /><div style="display:inline">This paper contributes to the theory of photograph formation from light fields. The main result is a theorem that, in the Fourier domain, a photograph formed by a full lens aperture is a 2D slice in the 4D light field. Photographs focused at different ...</div></span>
          <span id="toHide54" style="display:none;"><br /><div style="display:inline">This paper contributes to the theory of photograph formation from light fields. The main result is a theorem that, in the Fourier domain, a photograph formed by a full lens aperture is a 2D slice in the 4D light field. Photographs focused at different depths correspond to slices at different trajectories in the 4D space. The paper demonstrates the utility of this theorem in two different ways. First, the theorem is used to analyze the performance of digital refocusing, where one computes photographs focused at different depths from a single light field. The analysis shows in closed form that the sharpness of refocused photographs increases linearly with directional resolution. Second, the theorem yields a Fourier-domain algorithm for digital refocusing, where we extract the appropriate 2D slice of the light field's Fourier transform, and perform an inverse 2D Fourier transform. This method is faster than previous approaches.</div></span> <a id="expcoll54" href="JavaScript: expandcollapse('expcoll54',54)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073257&CFID=85074218&CFTOKEN=62570672">Dual photography</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100399113&CFID=85074218&CFTOKEN=62570672">Pradeep Sen</a>, 
                        <a href="author_page.cfm?id=81100108014&CFID=85074218&CFTOKEN=62570672">Billy Chen</a>, 
                        <a href="author_page.cfm?id=81100629896&CFID=85074218&CFTOKEN=62570672">Gaurav Garg</a>, 
                        <a href="author_page.cfm?id=81100238316&CFID=85074218&CFTOKEN=62570672">Stephen R. Marschner</a>, 
                        <a href="author_page.cfm?id=81100480527&CFID=85074218&CFTOKEN=62570672">Mark Horowitz</a>, 
                        <a href="author_page.cfm?id=81100593780&CFID=85074218&CFTOKEN=62570672">Marc Levoy</a>, 
                        <a href="author_page.cfm?id=81100504611&CFID=85074218&CFTOKEN=62570672">Hendrik P. A. Lensch</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 745 - 755</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073257" title="DOI">10.1145/1186822.1073257</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073257&ftid=322150&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow55" style="display:inline;"><br /><div style="display:inline">We present a novel photographic technique called dual photography, which exploits Helmholtz reciprocity to interchange the lights and cameras in a scene. With a video projector providing structured illumination, reciprocity permits us to generate pictures ...</div></span>
          <span id="toHide55" style="display:none;"><br /><div style="display:inline">We present a novel photographic technique called dual photography, which exploits Helmholtz reciprocity to interchange the lights and cameras in a scene. With a video projector providing structured illumination, reciprocity permits us to generate pictures from the viewpoint of the projector, even though no camera was present at that location. The technique is completely image-based, requiring no knowledge of scene geometry or surface properties, and by its nature automatically includes all transport paths, including shadows, inter-reflections and caustics. In its simplest form, the technique can be used to take photographs without a camera; we demonstrate this by capturing a photograph using a projector and a photo-resistor. If the photo-resistor is replaced by a camera, we can produce a 4D dataset that allows for relighting with 2D incident illumination. Using an array of cameras we can produce a 6D slice of the 8D reflectance field that allows for relighting with arbitrary light fields. Since an array of cameras can operate in parallel without interference, whereas an array of light sources cannot, dual photography is fundamentally a more efficient way to capture such a 6D dataset than a system based on multiple projectors and one camera. As an example, we show how dual photography can be used to capture and relight scenes.</div></span> <a id="expcoll55" href="JavaScript: expandcollapse('expcoll55',55)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073258&CFID=85074218&CFTOKEN=62570672">Performance relighting and reflectance transformation with time-multiplexed illumination</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100089374&CFID=85074218&CFTOKEN=62570672">Andreas Wenger</a>, 
                        <a href="author_page.cfm?id=81100521605&CFID=85074218&CFTOKEN=62570672">Andrew Gardner</a>, 
                        <a href="author_page.cfm?id=81100346087&CFID=85074218&CFTOKEN=62570672">Chris Tchou</a>, 
                        <a href="author_page.cfm?id=81100120690&CFID=85074218&CFTOKEN=62570672">Jonas Unger</a>, 
                        <a href="author_page.cfm?id=81100179328&CFID=85074218&CFTOKEN=62570672">Tim Hawkins</a>, 
                        <a href="author_page.cfm?id=81100086933&CFID=85074218&CFTOKEN=62570672">Paul Debevec</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 756 - 764</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073258" title="DOI">10.1145/1186822.1073258</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073258&ftid=322151&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow56" style="display:inline;"><br /><div style="display:inline">We present a technique for capturing an actor's live-action performance in such a way that the lighting and reflectance of the actor can be designed and modified in postproduction. Our approach is to illuminate the subject with a sequence of time-multiplexed ...</div></span>
          <span id="toHide56" style="display:none;"><br /><div style="display:inline">We present a technique for capturing an actor's live-action performance in such a way that the lighting and reflectance of the actor can be designed and modified in postproduction. Our approach is to illuminate the subject with a sequence of time-multiplexed basis lighting conditions, and to record these conditions with a high-speed video camera so that many conditions are recorded in the span of the desired output frame interval. We investigate several lighting bases for representing the sphere of incident illumination using a set of discrete LED light sources, and we estimate and compensate for subject motion using optical flow and image warping based on a set of tracking frames inserted into the lighting basis. To composite the illuminated performance into a new background, we include a time-multiplexed matte within the basis. We also show that the acquired data enables time-varying surface normals, albedo, and ambient occlusion to be estimated, which can be used to transform the actor's reflectance to produce both subtle and stylistic effects.</div></span> <a id="expcoll56" href="JavaScript: expandcollapse('expcoll56',56)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073259&CFID=85074218&CFTOKEN=62570672">High performance imaging using large camera arrays</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100522346&CFID=85074218&CFTOKEN=62570672">Bennett Wilburn</a>, 
                        <a href="author_page.cfm?id=81330493210&CFID=85074218&CFTOKEN=62570672">Neel Joshi</a>, 
                        <a href="author_page.cfm?id=81100588055&CFID=85074218&CFTOKEN=62570672">Vaibhav Vaish</a>, 
                        <a href="author_page.cfm?id=81100243243&CFID=85074218&CFTOKEN=62570672">Eino-Ville Talvala</a>, 
                        <a href="author_page.cfm?id=81309480879&CFID=85074218&CFTOKEN=62570672">Emilio Antunez</a>, 
                        <a href="author_page.cfm?id=81100581817&CFID=85074218&CFTOKEN=62570672">Adam Barth</a>, 
                        <a href="author_page.cfm?id=81406596762&CFID=85074218&CFTOKEN=62570672">Andrew Adams</a>, 
                        <a href="author_page.cfm?id=81100480527&CFID=85074218&CFTOKEN=62570672">Mark Horowitz</a>, 
                        <a href="author_page.cfm?id=81100593780&CFID=85074218&CFTOKEN=62570672">Marc Levoy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 765 - 776</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073259" title="DOI">10.1145/1186822.1073259</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073259&ftid=322152&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow57" style="display:inline;"><br /><div style="display:inline">The advent of inexpensive digital image sensors and the ability to create photographs that combine information from a number of sensed images are changing the way we think about photography. In this paper, we describe a unique array of 100 custom video ...</div></span>
          <span id="toHide57" style="display:none;"><br /><div style="display:inline">The advent of inexpensive digital image sensors and the ability to create photographs that combine information from a number of sensed images are changing the way we think about photography. In this paper, we describe a unique array of 100 custom video cameras that we have built, and we summarize our experiences using this array in a range of imaging applications. Our goal was to explore the capabilities of a system that would be inexpensive to produce in the future. With this in mind, we used simple cameras, lenses, and mountings, and we assumed that processing large numbers of images would eventually be easy and cheap. The applications we have explored include approximating a conventional single center of projection video camera with high performance along one or more axes, such as resolution, dynamic range, frame rate, and/or large aperture, and using multiple cameras to approximate a video camera with a large synthetic aperture. This permits us to capture a video light field, to which we can apply spatiotemporal view interpolation algorithms in order to digitally simulate time dilation and camera motion. It also permits us to create video sequences using custom non-uniform synthetic apertures.</div></span> <a id="expcoll57" href="JavaScript: expandcollapse('expcoll57',57)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Texture synthesis</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Heung-Yeung Shum 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073261&CFID=85074218&CFTOKEN=62570672">Parallel controllable texture synthesis</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100198784&CFID=85074218&CFTOKEN=62570672">Sylvain Lefebvre</a>, 
                        <a href="author_page.cfm?id=81100397561&CFID=85074218&CFTOKEN=62570672">Hugues Hoppe</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 777 - 786</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073261" title="DOI">10.1145/1186822.1073261</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073261&ftid=322153&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow59" style="display:inline;"><br /><div style="display:inline">We present a texture synthesis scheme based on neighborhood matching, with contributions in two areas: parallelism and control. Our scheme defines an infinite, deterministic, aperiodic texture, from which windows can be computed in real-time on a GPU. ...</div></span>
          <span id="toHide59" style="display:none;"><br /><div style="display:inline">We present a texture synthesis scheme based on neighborhood matching, with contributions in two areas: parallelism and control. Our scheme defines an infinite, deterministic, aperiodic texture, from which windows can be computed in real-time on a GPU. We attain high-quality synthesis using a new analysis structure called the Gaussian stack, together with a coordinate upsampling step and a subpass correction approach. Texture variation is achieved by multiresolution jittering of exemplar coordinates. Combined with the local support of parallel synthesis, the jitter enables intuitive user controls including multiscale randomness, spatial modulation over both exemplar and output, feature drag-and-drop, and periodicity constraints. We also introduce synthesis magnification, a fast method for amplifying coarse synthesis results to higher resolution.</div></span> <a id="expcoll59" href="JavaScript: expandcollapse('expcoll59',59)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073262&CFID=85074218&CFTOKEN=62570672">Texture design using a simplicial complex of morphable textures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100458116&CFID=85074218&CFTOKEN=62570672">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100289561&CFID=85074218&CFTOKEN=62570672">Matthias Zwicker</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074218&CFTOKEN=62570672">Fr&#233;do Durand</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 787 - 794</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073262" title="DOI">10.1145/1186822.1073262</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073262&ftid=322154&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow60" style="display:inline;"><br /><div style="display:inline">We present a system for designing novel textures in the space of textures induced by an input database. We capture the structure of the induced space by a simplicial complex where vertices of the simplices represent input textures. A user can generate ...</div></span>
          <span id="toHide60" style="display:none;"><br /><div style="display:inline">We present a system for designing novel textures in the space of textures induced by an input database. We capture the structure of the induced space by a simplicial complex where vertices of the simplices represent input textures. A user can generate new textures by interpolating within individual simplices. We propose a morphable interpolation for textures, which also defines a metric used to build the simplicial complex. To guarantee sharpness in interpolated textures, we enforce histograms of high-frequency content using a novel method for histogram interpolation. We allow users to continuously navigate in the simplicial complex and design new textures using a simple and efficient user interface. We demonstrate the usefulness of our system by integrating it with a 3D texture painting application, where the user interactively designs desired textures.</div></span> <a id="expcoll60" href="JavaScript: expandcollapse('expcoll60',60)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073263&CFID=85074218&CFTOKEN=62570672">Texture optimization for example-based synthesis</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100487847&CFID=85074218&CFTOKEN=62570672">Vivek Kwatra</a>, 
                        <a href="author_page.cfm?id=81100313702&CFID=85074218&CFTOKEN=62570672">Irfan Essa</a>, 
                        <a href="author_page.cfm?id=81100441050&CFID=85074218&CFTOKEN=62570672">Aaron Bobick</a>, 
                        <a href="author_page.cfm?id=81100487859&CFID=85074218&CFTOKEN=62570672">Nipun Kwatra</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 795 - 802</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073263" title="DOI">10.1145/1186822.1073263</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073263&ftid=322155&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow61" style="display:inline;"><br /><div style="display:inline">We present a novel technique for texture synthesis using optimization. We define a Markov Random Field (MRF)-based similarity metric for measuring the quality of synthesized texture with respect to a given input sample. This allows us to formulate the ...</div></span>
          <span id="toHide61" style="display:none;"><br /><div style="display:inline">We present a novel technique for texture synthesis using optimization. We define a Markov Random Field (MRF)-based similarity metric for measuring the quality of synthesized texture with respect to a given input sample. This allows us to formulate the synthesis problem as minimization of an energy function, which is optimized using an Expectation Maximization (EM)-like algorithm. In contrast to most example-based techniques that do region-growing, ours is a joint optimization approach that progressively refines the entire texture. Additionally, our approach is ideally suited to allow for controllable synthesis of textures. Specifically, we demonstrate controllability by animating image textures using flow fields. We allow for general two-dimensional flow fields that may dynamically change over time. Applications of this technique include dynamic texturing of fluid animations and texture-based flow visualization.</div></span> <a id="expcoll61" href="JavaScript: expandcollapse('expcoll61',61)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073264&CFID=85074218&CFTOKEN=62570672">Wavelet noise</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100111623&CFID=85074218&CFTOKEN=62570672">Robert L. Cook</a>, 
                        <a href="author_page.cfm?id=81100493833&CFID=85074218&CFTOKEN=62570672">Tony DeRose</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 803 - 811</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073264" title="DOI">10.1145/1186822.1073264</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073264&ftid=322156&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow62" style="display:inline;"><br /><div style="display:inline">Noise functions are an essential building block for writing procedural shaders in 3D computer graphics. The original noise function introduced by Ken Perlin is still the most popular because it is simple and fast, and many spectacular images have been ...</div></span>
          <span id="toHide62" style="display:none;"><br /><div style="display:inline">Noise functions are an essential building block for writing procedural shaders in 3D computer graphics. The original noise function introduced by Ken Perlin is still the most popular because it is simple and fast, and many spectacular images have been made with it. Nevertheless, it is prone to problems with aliasing and detail loss. In this paper we analyze these problems and show that they are particularly severe when 3D noise is used to texture a 2D surface. We use the theory of wavelets to create a new class of simple and fast noise functions that avoid these problems.</div></span> <a id="expcoll62" href="JavaScript: expandcollapse('expcoll62',62)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Capturing reality II</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Steve Marschner 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073266&CFID=85074218&CFTOKEN=62570672">Acquisition of time-varying participating media</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100179328&CFID=85074218&CFTOKEN=62570672">Tim Hawkins</a>, 
                        <a href="author_page.cfm?id=81100377186&CFID=85074218&CFTOKEN=62570672">Per Einarsson</a>, 
                        <a href="author_page.cfm?id=81100086933&CFID=85074218&CFTOKEN=62570672">Paul Debevec</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 812 - 815</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073266" title="DOI">10.1145/1186822.1073266</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073266&ftid=322157&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow64" style="display:inline;"><br /><div style="display:inline">We present a technique for capturing time-varying volumetric data of participating media. A laser sheet is swept repeatedly through the volume, and the scattered light is imaged using a high-speed camera. Each sweep of the laser provides a near-simultaneous ...</div></span>
          <span id="toHide64" style="display:none;"><br /><div style="display:inline">We present a technique for capturing time-varying volumetric data of participating media. A laser sheet is swept repeatedly through the volume, and the scattered light is imaged using a high-speed camera. Each sweep of the laser provides a near-simultaneous volume of density values. We demonstrate rendered animations under changing viewpoint and illumination, making use of measured values for the scattering phase function and albedo.</div></span> <a id="expcoll64" href="JavaScript: expandcollapse('expcoll64',64)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073267&CFID=85074218&CFTOKEN=62570672">Modeling hair from multiple views</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100474496&CFID=85074218&CFTOKEN=62570672">Yichen Wei</a>, 
                        <a href="author_page.cfm?id=81100064088&CFID=85074218&CFTOKEN=62570672">Eyal Ofek</a>, 
                        <a href="author_page.cfm?id=81100063997&CFID=85074218&CFTOKEN=62570672">Long Quan</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 816 - 820</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073267" title="DOI">10.1145/1186822.1073267</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073267&ftid=322158&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow65" style="display:inline;"><br /><div style="display:inline">In this paper, we propose a novel image-based approach to model hair geometry from images taken at multiple viewpoints. Unlike previous hair modeling techniques that require intensive user interactions or rely on special capturing setup under controlled ...</div></span>
          <span id="toHide65" style="display:none;"><br /><div style="display:inline">In this paper, we propose a novel image-based approach to model hair geometry from images taken at multiple viewpoints. Unlike previous hair modeling techniques that require intensive user interactions or rely on special capturing setup under controlled illumination conditions, we use a handheld camera to capture hair images under uncontrolled illumination conditions. Our multi-view approach is natural and flexible for capturing. It also provides inherent strong and accurate geometric constraints to recover hair models.In our approach, the hair fibers are synthesized from local image orientations. Each synthesized fiber segment is validated and optimally triangulated from all visible views. The hair volume and the visibility of synthesized fibers can also be reliably estimated from multiple views. Flexibility of acquisition, little user interaction, and high quality results of recovered complex hair models are the key advantages of our method.</div></span> <a id="expcoll65" href="JavaScript: expandcollapse('expcoll65',65)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073268&CFID=85074218&CFTOKEN=62570672">Panoramic video textures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100035467&CFID=85074218&CFTOKEN=62570672">Aseem Agarwala</a>, 
                        <a href="author_page.cfm?id=81100580585&CFID=85074218&CFTOKEN=62570672">Ke Colin Zheng</a>, 
                        <a href="author_page.cfm?id=81100249233&CFID=85074218&CFTOKEN=62570672">Chris Pal</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=85074218&CFTOKEN=62570672">Maneesh Agrawala</a>, 
                        <a href="author_page.cfm?id=81406592138&CFID=85074218&CFTOKEN=62570672">Michael Cohen</a>, 
                        <a href="author_page.cfm?id=81100587184&CFID=85074218&CFTOKEN=62570672">Brian Curless</a>, 
                        <a href="author_page.cfm?id=81100188207&CFID=85074218&CFTOKEN=62570672">David Salesin</a>, 
                        <a href="author_page.cfm?id=81100122769&CFID=85074218&CFTOKEN=62570672">Richard Szeliski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 821 - 827</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073268" title="DOI">10.1145/1186822.1073268</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073268&ftid=322159&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow66" style="display:inline;"><br /><div style="display:inline">This paper describes a mostly automatic method for taking the output of a single panning video camera and creating a panoramic video texture (PVT): a video that has been stitched into a single, wide field of view and that appears to play continuously ...</div></span>
          <span id="toHide66" style="display:none;"><br /><div style="display:inline">This paper describes a mostly automatic method for taking the output of a single panning video camera and creating a <i>panoramic video texture</i> (PVT): a video that has been stitched into a single, wide field of view and that appears to play continuously and indefinitely. The key problem in creating a PVT is that although only a portion of the scene has been imaged at any given time, the output must simultaneously portray motion throughout the scene. Like previous work in video textures, our method employs min-cut optimization to select fragments of video that can be stitched together both spatially and temporally. However, it differs from earlier work in that the optimization must take place over a much larger set of data. Thus, to create PVTs, we introduce a dynamic programming step, followed by a novel hierarchical min-cut optimization algorithm. We also use gradient-domain compositing to further smooth boundaries between video fragments. We demonstrate our results with an interactive viewer in which users can interactively pan and zoom on high-resolution PVTs.</div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073269&CFID=85074218&CFTOKEN=62570672">Removing photography artifacts using gradient projection and flash-exposure sampling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100634373&CFID=85074218&CFTOKEN=62570672">Amit Agrawal</a>, 
                        <a href="author_page.cfm?id=81100022847&CFID=85074218&CFTOKEN=62570672">Ramesh Raskar</a>, 
                        <a href="author_page.cfm?id=81100052215&CFID=85074218&CFTOKEN=62570672">Shree K. Nayar</a>, 
                        <a href="author_page.cfm?id=81100485034&CFID=85074218&CFTOKEN=62570672">Yuanzhen Li</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 828 - 835</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073269" title="DOI">10.1145/1186822.1073269</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073269&ftid=322160&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow67" style="display:inline;"><br /><div style="display:inline">Flash images are known to suffer from several problems: saturation of nearby objects, poor illumination of distant objects, reflections of objects strongly lit by the flash and strong highlights due to the reflection of flash itself by glossy surfaces. ...</div></span>
          <span id="toHide67" style="display:none;"><br /><div style="display:inline">Flash images are known to suffer from several problems: saturation of nearby objects, poor illumination of distant objects, reflections of objects strongly lit by the flash and strong highlights due to the reflection of flash itself by glossy surfaces. We propose to use a flash and no-flash (ambient) image pair to produce better flash images. We present a novel gradient projection scheme based on a gradient coherence model that allows removal of reflections and highlights from flash images. We also present a brightness-ratio based algorithm that allows us to compensate for the falloff in the flash image brightness due to depth. In several practical scenarios, the quality of flash/no-flash images may be limited in terms of dynamic range. In such cases, we advocate using several images taken under different flash intensities and exposures. We analyze the flash intensity-exposure space and propose a method for adaptively sampling this space so as to minimize the number of captured images for any given scene. We present several experimental results that demonstrate the ability of our algorithms to produce improved flash images.</div></span> <a id="expcoll67" href="JavaScript: expandcollapse('expcoll67',67)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Image processing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Chris Bregler 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073271&CFID=85074218&CFTOKEN=62570672">Compressing and companding high dynamic range images with subband architectures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100485034&CFID=85074218&CFTOKEN=62570672">Yuanzhen Li</a>, 
                        <a href="author_page.cfm?id=81100061412&CFID=85074218&CFTOKEN=62570672">Lavanya Sharan</a>, 
                        <a href="author_page.cfm?id=81100466478&CFID=85074218&CFTOKEN=62570672">Edward H. Adelson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 836 - 844</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073271" title="DOI">10.1145/1186822.1073271</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073271&ftid=322161&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow69" style="display:inline;"><br /><div style="display:inline">High dynamic range (HDR) imaging is an area of increasing importance, but most display devices still have limited dynamic range (LDR). Various techniques have been proposed for compressing the dynamic range while retaining important visual information. ...</div></span>
          <span id="toHide69" style="display:none;"><br /><div style="display:inline">High dynamic range (HDR) imaging is an area of increasing importance, but most display devices still have limited dynamic range (LDR). Various techniques have been proposed for compressing the dynamic range while retaining important visual information. Multi-scale image processing techniques, which are widely used for many image processing tasks, have a reputation of causing halo artifacts when used for range compression. However, we demonstrate that they can work when properly implemented. We use a symmetrical analysis-synthesis filter bank, and apply local gain control to the subbands. We also show that the technique can be adapted for the related problem of "companding", in which an HDR image is converted to an LDR image, and later expanded back to high dynamic range.</div></span> <a id="expcoll69" href="JavaScript: expandcollapse('expcoll69',69)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073272&CFID=85074218&CFTOKEN=62570672">Video enhancement using per-pixel virtual exposures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100291398&CFID=85074218&CFTOKEN=62570672">Eric P. Bennett</a>, 
                        <a href="author_page.cfm?id=81100137780&CFID=85074218&CFTOKEN=62570672">Leonard McMillan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 845 - 852</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073272" title="DOI">10.1145/1186822.1073272</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073272&ftid=322162&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow70" style="display:inline;"><br /><div style="display:inline">We enhance underexposed, low dynamic range videos by adaptively and independently varying the exposure at each photoreceptor in a post-process. This virtual exposure is a dynamic function of both the spatial neighborhood and temporal history at each ...</div></span>
          <span id="toHide70" style="display:none;"><br /><div style="display:inline">We enhance underexposed, low dynamic range videos by adaptively and independently varying the exposure at each photoreceptor in a post-process. This virtual exposure is a dynamic function of both the spatial neighborhood and temporal history at each pixel. Temporal integration enables us to expand the image's dynamic range while simultaneously reducing noise. Our non-linear exposure variation and denoising filters smoothly transition from temporal to spatial for moving scene elements. Our virtual exposure framework also supports temporally coherent per frame tone mapping. Our system outputs restored video sequences with significantly reduced noise, increased exposure time of dark pixels, intact motion, and improved details.</div></span> <a id="expcoll70" href="JavaScript: expandcollapse('expcoll70',70)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073273&CFID=85074218&CFTOKEN=62570672">Animating pictures with stochastic motion textures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350582710&CFID=85074218&CFTOKEN=62570672">Yung-Yu Chuang</a>, 
                        <a href="author_page.cfm?id=81100026255&CFID=85074218&CFTOKEN=62570672">Dan B Goldman</a>, 
                        <a href="author_page.cfm?id=81100580585&CFID=85074218&CFTOKEN=62570672">Ke Colin Zheng</a>, 
                        <a href="author_page.cfm?id=81100587184&CFID=85074218&CFTOKEN=62570672">Brian Curless</a>, 
                        <a href="author_page.cfm?id=81100188207&CFID=85074218&CFTOKEN=62570672">David H. Salesin</a>, 
                        <a href="author_page.cfm?id=81100122769&CFID=85074218&CFTOKEN=62570672">Richard Szeliski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 853 - 860</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073273" title="DOI">10.1145/1186822.1073273</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073273&ftid=322163&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow71" style="display:inline;"><br /><div style="display:inline">In this paper, we explore the problem of enhancing still pictures with subtly animated motions. We limit our domain to scenes containing passive elements that respond to natural forces in some fashion. We use a semi-automatic approach, in which a human ...</div></span>
          <span id="toHide71" style="display:none;"><br /><div style="display:inline">In this paper, we explore the problem of enhancing still pictures with subtly animated motions. We limit our domain to scenes containing passive elements that respond to natural forces in some fashion. We use a semi-automatic approach, in which a human user segments the scene into a series of layers to be individually animated. Then, a "stochastic motion texture" is automatically synthesized using a spectral method, i.e., the inverse Fourier transform of a filtered noise spectrum. The motion texture is a time-varying 2D displacement map, which is applied to each layer. The resulting warped layers are then recomposited to form the animated frames. The result is a looping video texture created from a single still image, which has the advantages of being more controllable and of generally higher image quality and resolution than a video texture created from a video source. We demonstrate the technique on a variety of photographs and paintings.</div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073274&CFID=85074218&CFTOKEN=62570672">Image completion with structure propagation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81351592034&CFID=85074218&CFTOKEN=62570672">Jian Sun</a>, 
                        <a href="author_page.cfm?id=81335499956&CFID=85074218&CFTOKEN=62570672">Lu Yuan</a>, 
                        <a href="author_page.cfm?id=81100499465&CFID=85074218&CFTOKEN=62570672">Jiaya Jia</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 861 - 868</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073274" title="DOI">10.1145/1186822.1073274</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073274&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow72" style="display:inline;"><br /><div style="display:inline">In this paper, we introduce a novel approach to image completion, which we call structure propagation. In our system, the user manually specifies important missing structure information by extending a few curves or line segments from the known to the ...</div></span>
          <span id="toHide72" style="display:none;"><br /><div style="display:inline">In this paper, we introduce a novel approach to image completion, which we call structure propagation. In our system, the user manually specifies important missing structure information by extending a few curves or line segments from the known to the unknown regions. Our approach synthesizes image patches along these user-specified curves in the unknown region using patches selected around the curves in the known region. Structure propagation is formulated as a global optimization problem by enforcing structure and consistency constraints. If only a single curve is specified, structure propagation is solved using Dynamic Programming. When multiple intersecting curves are specified, we adopt the Belief Propagation algorithm to find the optimal patches. After completing structure propagation, we fill in the remaining unknown regions using patch-based texture synthesis. We show that our approach works well on a number of examples that are challenging to state-of-the-art techniques.</div></span> <a id="expcoll72" href="JavaScript: expandcollapse('expcoll72',72)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Large models & large displays</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Marc Stamminger 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073276&CFID=85074218&CFTOKEN=62570672">GoLD: interactive display of huge colored and textured models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100484623&CFID=85074218&CFTOKEN=62570672">Louis Borgeat</a>, 
                        <a href="author_page.cfm?id=81100494822&CFID=85074218&CFTOKEN=62570672">Guy Godin</a>, 
                        <a href="author_page.cfm?id=81100466491&CFID=85074218&CFTOKEN=62570672">Fran&#231;ois Blais</a>, 
                        <a href="author_page.cfm?id=81100033105&CFID=85074218&CFTOKEN=62570672">Philippe Massicotte</a>, 
                        <a href="author_page.cfm?id=81100056590&CFID=85074218&CFTOKEN=62570672">Christian Lahanier</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 869 - 877</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073276" title="DOI">10.1145/1186822.1073276</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073276&ftid=322165&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow74" style="display:inline;"><br /><div style="display:inline">This paper presents a new technique for fast, view-dependent, real-time visualization of large multiresolution geometric models with color or texture information. This method uses geomorphing to smoothly interpolate between geometric patches composing ...</div></span>
          <span id="toHide74" style="display:none;"><br /><div style="display:inline">This paper presents a new technique for fast, view-dependent, real-time visualization of large multiresolution geometric models with color or texture information. This method uses geomorphing to smoothly interpolate between geometric patches composing a hierarchical level-of-detail structure, and to maintain seamless continuity between neighboring patches of the model. It combines the advantages of view-dependent rendering with numerous additional features: the high performance rendering associated with static preoptimized geometry, the capability to display at both low and high resolution with minimal artefacts, and a low CPU usage since all the geomorphing is done on the GPU. Furthermore, the hierarchical subdivision of the model into a tree structure can be accomplished according to any spatial or topological criteria. This property is particularly useful in dealing with models with high resolution textures derived from digital photographs. Results are presented for both highly tesselated models (372 million triangles), and for models which also contain large quantities of texture (200 million triangles + 20 GB of compressed texture). The method also incorporates asynchronous out-of-core model management. Performances obtained on commodity hardware are in the range of 50 million geomorphed triangles/second for a benchmark model such as Stanford's St. Matthew dataset.</div></span> <a id="expcoll74" href="JavaScript: expandcollapse('expcoll74',74)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073277&CFID=85074218&CFTOKEN=62570672">Far voxels: a multiresolution framework for interactive rendering of huge complex 3D models on commodity graphics platforms</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100044134&CFID=85074218&CFTOKEN=62570672">Enrico Gobbetti</a>, 
                        <a href="author_page.cfm?id=81100207265&CFID=85074218&CFTOKEN=62570672">Fabio Marton</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 878 - 885</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073277" title="DOI">10.1145/1186822.1073277</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073277&ftid=322166&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow75" style="display:inline;"><br /><div style="display:inline">We present an efficient approach for end-to-end out-of-core construction and interactive inspection of very large arbitrary surface models. The method tightly integrates visibility culling and out-of-core data management with a level-of-detail framework. ...</div></span>
          <span id="toHide75" style="display:none;"><br /><div style="display:inline">We present an efficient approach for end-to-end out-of-core construction and interactive inspection of very large arbitrary surface models. The method tightly integrates visibility culling and out-of-core data management with a level-of-detail framework. At preprocessing time, we generate a coarse volume hierarchy by binary space partitioning the input triangle soup. Leaf nodes partition the original data into chunks of a fixed maximum number of triangles, while inner nodes are discretized into a fixed number of cubical voxels. Each voxel contains a compact direction dependent approximation of the appearance of the associated volumetric subpart of the model when viewed from a distance. The approximation is constructed by a visibility aware algorithm that fits parametric shaders to samples obtained by casting rays against the full resolution dataset. At rendering time, the volumetric structure, maintained off-core, is refined and rendered in front-to-back order, exploiting vertex programs for GPU evaluation of view-dependent voxel representations, hardware occlusion queries for culling occluded subtrees, and asynchronous I/O for detecting and avoiding data access latencies. Since the granularity of the multiresolution structure is coarse, data management, traversal and occlusion culling cost is amortized over many graphics primitives. The efficiency and generality of the approach is demonstrated with the interactive rendering of extremely complex heterogeneous surface models on current commodity graphics platforms.</div></span> <a id="expcoll75" href="JavaScript: expandcollapse('expcoll75',75)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073278&CFID=85074218&CFTOKEN=62570672">Cache-oblivious mesh layouts</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100019061&CFID=85074218&CFTOKEN=62570672">Sung-Eui Yoon</a>, 
                        <a href="author_page.cfm?id=81100040340&CFID=85074218&CFTOKEN=62570672">Peter Lindstrom</a>, 
                        <a href="author_page.cfm?id=81408602369&CFID=85074218&CFTOKEN=62570672">Valerio Pascucci</a>, 
                        <a href="author_page.cfm?id=81100618474&CFID=85074218&CFTOKEN=62570672">Dinesh Manocha</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 886 - 893</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073278" title="DOI">10.1145/1186822.1073278</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073278&ftid=322167&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow76" style="display:inline;"><br /><div style="display:inline">We present a novel method for computing cache-oblivious layouts of large meshes that improve the performance of interactive visualization and geometric processing algorithms. Given that the mesh is accessed in a reasonably coherent manner, we assume ...</div></span>
          <span id="toHide76" style="display:none;"><br /><div style="display:inline">We present a novel method for computing cache-oblivious layouts of large meshes that improve the performance of interactive visualization and geometric processing algorithms. Given that the mesh is accessed in a reasonably coherent manner, we assume no particular data access patterns or cache parameters of the memory hierarchy involved in the computation. Furthermore, our formulation extends directly to computing layouts of multi-resolution and bounding volume hierarchies of large meshes.We develop a simple and practical cache-oblivious metric for estimating cache misses. Computing a coherent mesh layout is reduced to a combinatorial optimization problem. We designed and implemented an out-of-core multilevel minimization algorithm and tested its performance on unstructured meshes composed of tens to hundreds of millions of triangles. Our layouts can significantly reduce the number of cache misses. We have observed 2--20 times speedups in view-dependent rendering, collision detection, and isocontour extraction without any modification of the algorithms or runtime applications.</div></span> <a id="expcoll76" href="JavaScript: expandcollapse('expcoll76',76)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073279&CFID=85074218&CFTOKEN=62570672">The Varrier<sup>TM</sup> autostereoscopic virtual reality display</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100455127&CFID=85074218&CFTOKEN=62570672">Daniel J. Sandin</a>, 
                        <a href="author_page.cfm?id=81100629781&CFID=85074218&CFTOKEN=62570672">Todd Margolis</a>, 
                        <a href="author_page.cfm?id=81309480962&CFID=85074218&CFTOKEN=62570672">Jinghua Ge</a>, 
                        <a href="author_page.cfm?id=81100061434&CFID=85074218&CFTOKEN=62570672">Javier Girado</a>, 
                        <a href="author_page.cfm?id=81100489566&CFID=85074218&CFTOKEN=62570672">Tom Peterka</a>, 
                        <a href="author_page.cfm?id=81100432746&CFID=85074218&CFTOKEN=62570672">Thomas A. DeFanti</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 894 - 903</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073279" title="DOI">10.1145/1186822.1073279</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073279&ftid=322168&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow77" style="display:inline;"><br /><div style="display:inline">Virtual reality (VR) has long been hampered by the gear needed to make the experience possible; specifically, stereo glasses and tracking devices. Autostereoscopic display devices are gaining popularity by freeing the user from stereo glasses, however ...</div></span>
          <span id="toHide77" style="display:none;"><br /><div style="display:inline">Virtual reality (VR) has long been hampered by the gear needed to make the experience possible; specifically, stereo glasses and tracking devices. Autostereoscopic display devices are gaining popularity by freeing the user from stereo glasses, however few qualify as VR displays. The Electronic Visualization Laboratory (EVL) at the University of Illinois at Chicago (UIC) has designed and produced a large scale, high resolution head-tracked barrier-strip autostereoscopic display system that produces a VR immersive experience without requiring the user to wear any encumbrances. The resulting system, called Varrier, is a passive parallax barrier 35-panel tiled display that produces a wide field of view, head-tracked VR experience. This paper presents background material related to parallax barrier autostereoscopy, provides system configuration and construction details, examines Varrier interleaving algorithms used to produce the stereo images, introduces calibration and testing, and discusses the camera-based tracking subsystem.</div></span> <a id="expcoll77" href="JavaScript: expandcollapse('expcoll77',77)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Fluid simulation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          John Anderson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073281&CFID=85074218&CFTOKEN=62570672">Animating gases with hybrid meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100064338&CFID=85074218&CFTOKEN=62570672">Bryan E. Feldman</a>, 
                        <a href="author_page.cfm?id=81100311781&CFID=85074218&CFTOKEN=62570672">James F. O'Brien</a>, 
                        <a href="author_page.cfm?id=81100573144&CFID=85074218&CFTOKEN=62570672">Bryan M. Klingner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 904 - 909</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073281" title="DOI">10.1145/1186822.1073281</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073281&ftid=322169&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow79" style="display:inline;"><br /><div style="display:inline">This paper presents a method for animating gases on unstructured tetrahedral meshes to efficiently model the interaction of fluids with irregularly shaped obstacles. Because our discretization scheme parallels that of the standard staggered grid mesh. ...</div></span>
          <span id="toHide79" style="display:none;"><br /><div style="display:inline">This paper presents a method for animating gases on unstructured tetrahedral meshes to efficiently model the interaction of fluids with irregularly shaped obstacles. Because our discretization scheme parallels that of the standard staggered grid mesh. we are able to combine tetrahedral cells with regular hexahedral cells in a single mesh. This hybrid mesh offers both accuracy near obstacles and efficiency in open regions.</div></span> <a id="expcoll79" href="JavaScript: expandcollapse('expcoll79',79)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073282&CFID=85074218&CFTOKEN=62570672">A vortex particle method for smoke, water and explosions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100351513&CFID=85074218&CFTOKEN=62570672">Andrew Selle</a>, 
                        <a href="author_page.cfm?id=81100172208&CFID=85074218&CFTOKEN=62570672">Nick Rasmussen</a>, 
                        <a href="author_page.cfm?id=81100612327&CFID=85074218&CFTOKEN=62570672">Ronald Fedkiw</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 910 - 914</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073282" title="DOI">10.1145/1186822.1073282</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073282&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow80" style="display:inline;"><br /><div style="display:inline">Vorticity confinement reintroduces the small scale detail lost when using efficient semi-Lagrangian schemes for simulating smoke and fire. However, it only amplifies the existing vorticity, and thus can be insufficient for highly turbulent effects such ...</div></span>
          <span id="toHide80" style="display:none;"><br /><div style="display:inline">Vorticity confinement reintroduces the small scale detail lost when using efficient semi-Lagrangian schemes for simulating smoke and fire. However, it only amplifies the existing vorticity, and thus can be insufficient for highly turbulent effects such as explosions or rough water. We introduce a new hybrid technique that makes synergistic use of Lagrangian vortex particle methods and Eulerian grid based methods to overcome the weaknesses of both. Our approach uses vorticity confinement itself to couple these two methods together. We demonstrate that this approach can generate highly turbulent effects unachievable by standard grid based methods, and show applications to smoke, water and explosion simulations.</div></span> <a id="expcoll80" href="JavaScript: expandcollapse('expcoll80',80)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073283&CFID=85074218&CFTOKEN=62570672">Discontinuous fluids</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81329489309&CFID=85074218&CFTOKEN=62570672">Jeong-Mo Hong</a>, 
                        <a href="author_page.cfm?id=81100656332&CFID=85074218&CFTOKEN=62570672">Chang-Hun Kim</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 915 - 920</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073283" title="DOI">10.1145/1186822.1073283</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073283&ftid=322170&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow81" style="display:inline;"><br /><div style="display:inline">At interfaces between different fluids, properties such as density, viscosity, and molecular cohesion are discontinuous. To animate small-scale details of incompressible viscous multi-phase fluids realistically, we focus on the discontinuities in the ...</div></span>
          <span id="toHide81" style="display:none;"><br /><div style="display:inline">At interfaces between different fluids, properties such as density, viscosity, and molecular cohesion are discontinuous. To animate small-scale details of incompressible viscous multi-phase fluids realistically, we focus on the discontinuities in the state variables that express these properties. Surface tension of both free and bubble surfaces is modeled using the jump condition in the pressure field; and discontinuities in the velocity gradient field. driven by viscosity differences, are also considered. To obtain derivatives of the pressure and velocity fields with sub-grid accuracy, they are extrapolated across interfaces using continuous variables based on physical properties. The numerical methods that we present are easy to implement and do not impact the performance of existing solvers. Small-scale fluid motions, such as capillary instability, breakup of liquid sheets, and bubbly water can all be successfully animated.</div></span> <a id="expcoll81" href="JavaScript: expandcollapse('expcoll81',81)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073284&CFID=85074218&CFTOKEN=62570672">Water drops on surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100220529&CFID=85074218&CFTOKEN=62570672">Huamin Wang</a>, 
                        <a href="author_page.cfm?id=81100273084&CFID=85074218&CFTOKEN=62570672">Peter J. Mucha</a>, 
                        <a href="author_page.cfm?id=81100457973&CFID=85074218&CFTOKEN=62570672">Greg Turk</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 921 - 929</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073284" title="DOI">10.1145/1186822.1073284</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073284&ftid=322171&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow82" style="display:inline;"><br /><div style="display:inline">We present a physically-based method to enforce contact angles at the intersection of fluid free surfaces and solid objects, allowing us to simulate a variety of small-scale fluid phenomena including water drops on surfaces. The heart of this technique ...</div></span>
          <span id="toHide82" style="display:none;"><br /><div style="display:inline">We present a physically-based method to enforce contact angles at the intersection of fluid free surfaces and solid objects, allowing us to simulate a variety of small-scale fluid phenomena including water drops on surfaces. The heart of this technique is a <i>virtual surface</i> method, which modifies the level set distance field representing the fluid surface in order to maintain an appropriate contact angle. The surface tension that is calculated on the contact line between the solid surface and liquid surface can then capture all interfacial tensions, including liquid-solid, liquid-air and solid-air tensions. We use a simple dynamic contact angle model to select contact angles according to the solid material property, water history, and the fluid front's motion. Our algorithm robustly and accurately treats various drop shape deformations, and handles both flat and curved solid surfaces. Our results show that our algorithm is capable of realistically simulating several small-scale liquid phenomena such as beading and flattened drops, stretched and separating drops, suspended drops on curved surfaces, and capillary action.</div></span> <a id="expcoll82" href="JavaScript: expandcollapse('expcoll82',82)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Reprise of UIST and I3D: UIST (user interface software and technology)</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Steven Feiner 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073286&CFID=85074218&CFTOKEN=62570672">CrossY: a crossing-based drawing application</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100268174&CFID=85074218&CFTOKEN=62570672">Georg Apitz</a>, 
                        <a href="author_page.cfm?id=81100301845&CFID=85074218&CFTOKEN=62570672">Fran&#231;ois Guimbreti&#232;re</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 930 - 930</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073286" title="DOI">10.1145/1186822.1073286</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073286&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow84" style="display:inline;"><br /><div style="display:inline">We introduce CrossY, a simple drawing application developed as a benchmark to demonstrate the feasibility of goal-crossing as the basis for a graphical user interface. While crossing was previously identified as a potential substitute for the classic ...</div></span>
          <span id="toHide84" style="display:none;"><br /><div style="display:inline">We introduce CrossY, a simple drawing application developed as a benchmark to demonstrate the feasibility of goal-crossing as the basis for a graphical user interface. While crossing was previously identified as a potential substitute for the classic point-and-click interaction, this work is the first to report on the practical aspects of implementing an interface solely based on goal-crossing.</div></span> <a id="expcoll84" href="JavaScript: expandcollapse('expcoll84',84)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073287&CFID=85074218&CFTOKEN=62570672">Multi-finger gestural interaction with 3D volumetric displays</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100477897&CFID=85074218&CFTOKEN=62570672">Tovi Grossman</a>, 
                        <a href="author_page.cfm?id=81100606762&CFID=85074218&CFTOKEN=62570672">Daniel Wigdor</a>, 
                        <a href="author_page.cfm?id=81100503904&CFID=85074218&CFTOKEN=62570672">Ravin Balakrishnan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 931 - 931</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073287" title="DOI">10.1145/1186822.1073287</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073287&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow85" style="display:inline;"><br /><div style="display:inline">Volumetric displays provide interesting opportunities and challenges for 3D interaction and visualization, particularly when used in a highly interactive manner. We explore this area through the design and implementation of techniques for interactive ...</div></span>
          <span id="toHide85" style="display:none;"><br /><div style="display:inline">Volumetric displays provide interesting opportunities and challenges for 3D interaction and visualization, particularly when used in a highly interactive manner. We explore this area through the design and implementation of techniques for interactive direct manipulation of objects with a 3D volumetric display. Motion tracking of the user's fingers provides for direct gestural interaction with the virtual objects, through manipulations on and around the display's hemispheric enclosure. Our techniques leverage the unique features of volumetric displays, including a 360&deg; viewing volume that enables manipulation from any viewpoint around the display, as well as natural and accurate perception of true depth information in the displayed 3D scene. We demonstrate our techniques within a prototype 3D geometric model building application.</div></span> <a id="expcoll85" href="JavaScript: expandcollapse('expcoll85',85)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073288&CFID=85074218&CFTOKEN=62570672">DART: a toolkit for rapid design exploration of augmented reality experiences</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100099162&CFID=85074218&CFTOKEN=62570672">Blair MacIntyre</a>, 
                        <a href="author_page.cfm?id=81100532510&CFID=85074218&CFTOKEN=62570672">Maribeth Gandy</a>, 
                        <a href="author_page.cfm?id=81100380835&CFID=85074218&CFTOKEN=62570672">Steven Dow</a>, 
                        <a href="author_page.cfm?id=81332490551&CFID=85074218&CFTOKEN=62570672">Jay David Bolter</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 932 - 932</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073288" title="DOI">10.1145/1186822.1073288</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073288&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow86" style="display:inline;"><br /><div style="display:inline">In this paper [MacIntyre et al 2004]. we describe The Designer's Augmented Reality Toolkit (DART). DART is built on top of Macromedia Director, a widely used multimedia development environment. We summarize the most significant problems faced by designers ...</div></span>
          <span id="toHide86" style="display:none;"><br /><div style="display:inline">In this paper [MacIntyre et al 2004]. we describe The Designer's Augmented Reality Toolkit (DART). DART is built on top of Macromedia Director, a widely used multimedia development environment. We summarize the most significant problems faced by designers working with AR in the real world, and discuss how DART addresses them. Most of DART is implemented in an interpreted scripting language, and can be modified by designers to suit their needs. Our work focuses on supporting early design activities, especially a rapid transition from storyboards to working experience, so that the experiential part of a design can be tested early and often. DART allows designers to specify complex relationships between the physical and virtual worlds, and supports 3D animatic actors (informal, sketch-based content) in addition to more polished content. Designers can capture and replay synchronized video and sensor data, allowing them to work off-site and to test specific parts of their experience more effectively.</div></span> <a id="expcoll86" href="JavaScript: expandcollapse('expcoll86',86)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>I3D (symposium on interactive 3D graphics)</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          David Luebke 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073290&CFID=85074218&CFTOKEN=62570672">Geopostors: a real-time geometry/impostor crowd rendering system</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100273715&CFID=85074218&CFTOKEN=62570672">Simon Dobbyn</a>, 
                        <a href="author_page.cfm?id=81100096815&CFID=85074218&CFTOKEN=62570672">John Hamill</a>, 
                        <a href="author_page.cfm?id=81100396570&CFID=85074218&CFTOKEN=62570672">Keith O'Conor</a>, 
                        <a href="author_page.cfm?id=81100465557&CFID=85074218&CFTOKEN=62570672">Carol O'Sullivan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 933 - 933</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073290" title="DOI">10.1145/1186822.1073290</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073290&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow88" style="display:inline;"><br /><div style="display:inline">The simulation of large crowds of humans is important in many fields of computer graphics, including real-time applications such as games, as they can breathe life into otherwise static scenes and enhance believability. Although many new games are released ...</div></span>
          <span id="toHide88" style="display:none;"><br /><div style="display:inline">The simulation of large crowds of humans is important in many fields of computer graphics, including real-time applications such as games, as they can breathe life into otherwise static scenes and enhance believability. Although many new games are released each year, it is very unusual to find large-scale crowds populating the environments depicted. Such applications need to deal with having limited resources available at each frame. With many hundreds or thousands of potential virtual humans in a crowd, traditional techniques rapidly become overwhelmed and are not able to sustain an interactive frame-rate. Therefore, simpler approaches to the rendering, animation and behaviour control of the crowds are needed. Additionally, these new approaches must provide for variety, as environments inhabited by carbon-copy clones can be disconcerting and unrealistic.</div></span> <a id="expcoll88" href="JavaScript: expandcollapse('expcoll88',88)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073291&CFID=85074218&CFTOKEN=62570672">Sketching mesh deformations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100046389&CFID=85074218&CFTOKEN=62570672">Youngihn Kho</a>, 
                        <a href="author_page.cfm?id=81100516743&CFID=85074218&CFTOKEN=62570672">Michael Garland</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 934 - 934</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073291" title="DOI">10.1145/1186822.1073291</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073291&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow89" style="display:inline;"><br /><div style="display:inline">Techniques for interactive deformation of unstructured polygon meshes are of fundamental importance to a host of applications. Most traditional approaches to this problem have emphasized precise control over the deformation being made. However, they ...</div></span>
          <span id="toHide89" style="display:none;"><br /><div style="display:inline">Techniques for interactive deformation of unstructured polygon meshes are of fundamental importance to a host of applications. Most traditional approaches to this problem have emphasized precise control over the deformation being made. However, they are often cumbersome and unintuitive for non-expert users.In this paper, we present an interactive system for deforming unstructured polygon meshes that is very easy to use. The user interacts with the system by sketching curves in the image plane. A single stroke can define a free-form skeleton and the region of the model to be deformed. By sketching the desired deformation of this reference curve, the user can implicitly and intuitively control the deformation of an entire region of the surface. At the same time, the reference curve also provides a basis for controlling additional parameters, such as twist and scaling. We demonstrate that our system can be used to interactively edit a variety of unstructured mesh models with very little effort. Furthermore, we can also use our formulation of the deformation to achieve a natural interpolation between character poses, thus producing simple key framed animations.</div></span> <a id="expcoll89" href="JavaScript: expandcollapse('expcoll89',89)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073292&CFID=85074218&CFTOKEN=62570672">Real-time relief mapping on arbitrary polygonal surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100311116&CFID=85074218&CFTOKEN=62570672">F&#225;bio Policarpo</a>, 
                        <a href="author_page.cfm?id=81100516478&CFID=85074218&CFTOKEN=62570672">Manuel M. Oliveira</a>, 
                        <a href="author_page.cfm?id=81100002382&CFID=85074218&CFTOKEN=62570672">Jo&#227;o L. D. Comba</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 935 - 935</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073292" title="DOI">10.1145/1186822.1073292</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073292&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow90" style="display:inline;"><br /><div style="display:inline">We present a technique for mapping relief textures onto arbitrary polygonal models in real time, producing correct self-occlusions, interpenetrations, shadows and per-pixel lighting. The technique uses a pixel-driven formulation based on an efficient ...</div></span>
          <span id="toHide90" style="display:none;"><br /><div style="display:inline">We present a technique for mapping relief textures onto arbitrary polygonal models in real time, producing correct self-occlusions, interpenetrations, shadows and per-pixel lighting. The technique uses a pixel-driven formulation based on an efficient ray-height-field intersection implemented on the GPU. It has very low memory requirements, supports extreme close-up views of the surfaces and can be applicable to surfaces undergoing deformation.</div></span> <a id="expcoll90" href="JavaScript: expandcollapse('expcoll90',90)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Dynamics of solids</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jovan Popovic 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073294&CFID=85074218&CFTOKEN=62570672">Adaptive dynamics of articulated bodies</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100239543&CFID=85074218&CFTOKEN=62570672">Stephane Redon</a>, 
                        <a href="author_page.cfm?id=81332500016&CFID=85074218&CFTOKEN=62570672">Nico Galoppo</a>, 
                        <a href="author_page.cfm?id=81452602436&CFID=85074218&CFTOKEN=62570672">Ming C. Lin</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 936 - 945</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073294" title="DOI">10.1145/1186822.1073294</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073294&ftid=322178&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow92" style="display:inline;"><br /><div style="display:inline">Forward dynamics is central to physically-based simulation and control of articulated bodies. We present an adaptive algorithm for computing forward dynamics of articulated bodies: using novel motion error metrics, our algorithm can automatically simplify ...</div></span>
          <span id="toHide92" style="display:none;"><br /><div style="display:inline">Forward dynamics is central to physically-based simulation and control of articulated bodies. We present an adaptive algorithm for computing forward dynamics of articulated bodies: using novel motion error metrics, our algorithm can automatically simplify the dynamics of a multi-body system, based on the desired number of degrees of freedom and the location of external forces and active joint forces. We demonstrate this method in plausible animation of articulated bodies, including a large-scale simulation of 200 animated humanoids and multi-body dynamics systems with many degrees of freedom. The graceful simplification allows us to achieve up to two orders of magnitude performance improvement in several complex benchmarks.</div></span> <a id="expcoll92" href="JavaScript: expandcollapse('expcoll92',92)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073295&CFID=85074218&CFTOKEN=62570672">Fast frictional dynamics for rigid bodies</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100224608&CFID=85074218&CFTOKEN=62570672">Danny M. Kaufman</a>, 
                        <a href="author_page.cfm?id=81100295179&CFID=85074218&CFTOKEN=62570672">Timothy Edmunds</a>, 
                        <a href="author_page.cfm?id=81100642559&CFID=85074218&CFTOKEN=62570672">Dinesh K. Pai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 946 - 956</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073295" title="DOI">10.1145/1186822.1073295</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073295&ftid=322179&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow93" style="display:inline;"><br /><div style="display:inline">We describe an efficient algorithm for the simulation of large sets of non-convex rigid bodies. The algorithm finds a simultaneous solution for a multi-body system that is linear in the total number of contacts detected in each iteration. We employ a ...</div></span>
          <span id="toHide93" style="display:none;"><br /><div style="display:inline">We describe an efficient algorithm for the simulation of large sets of non-convex rigid bodies. The algorithm finds a simultaneous solution for a multi-body system that is linear in the total number of contacts detected in each iteration. We employ a novel contact model that uses mass, location, and velocity information from all contacts, at the moment of maximum compression, to constrain rigid body velocities. We also develop a new friction model in the configuration space of rigid bodies. These models are used to compute the feasible velocity and the frictional response of each body. Implementation is simple and leads to a fast rigid body simulator that computes steps on the order of seconds for simulations involving over one thousand non-convex objects in high contact configurations.</div></span> <a id="expcoll93" href="JavaScript: expandcollapse('expcoll93',93)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073296&CFID=85074218&CFTOKEN=62570672">Meshless animation of fracturing solids</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100582775&CFID=85074218&CFTOKEN=62570672">Mark Pauly</a>, 
                        <a href="author_page.cfm?id=81100346735&CFID=85074218&CFTOKEN=62570672">Richard Keiser</a>, 
                        <a href="author_page.cfm?id=81100312919&CFID=85074218&CFTOKEN=62570672">Bart Adams</a>, 
                        <a href="author_page.cfm?id=81100172909&CFID=85074218&CFTOKEN=62570672">Philip Dutr&#233;</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=85074218&CFTOKEN=62570672">Markus Gross</a>, 
                        <a href="author_page.cfm?id=81452606669&CFID=85074218&CFTOKEN=62570672">Leonidas J. Guibas</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 957 - 964</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073296" title="DOI">10.1145/1186822.1073296</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073296&ftid=322180&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow94" style="display:inline;"><br /><div style="display:inline">We present a new meshless animation framework for elastic and plastic materials that fracture. Central to our method is a highly dynamic surface and volume sampling method that supports arbitrary crack initiation, propagation, and termination, while ...</div></span>
          <span id="toHide94" style="display:none;"><br /><div style="display:inline">We present a new meshless animation framework for elastic and plastic materials that fracture. Central to our method is a highly dynamic surface and volume sampling method that supports arbitrary crack initiation, propagation, and termination, while avoiding many of the stability problems of traditional mesh-based techniques. We explicitly model advancing crack fronts and associated fracture surfaces embedded in the simulation volume. When cutting through the material, crack fronts directly affect the coupling between simulation nodes, requiring a dynamic adaptation of the nodal shape functions. We show how local visibility tests and dynamic caching lead to an efficient implementation of these effects based on point collocation. Complex fracture patterns of interacting and branching cracks are handled using a small set of topological operations for splitting, merging, and terminating crack fronts. This allows continuous propagation of cracks with highly detailed fracture surfaces, independent of the spatial resolution of the simulation nodes, and provides effective mechanisms for controlling fracture paths. We demonstrate our method for a wide range of materials, from stiff elastic to highly plastic objects that exhibit brittle and/or ductile fracture.</div></span> <a id="expcoll94" href="JavaScript: expandcollapse('expcoll94',94)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Deformable models</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Mathieu Desbrun 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073298&CFID=85074218&CFTOKEN=62570672">Animating sand as a fluid</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100415765&CFID=85074218&CFTOKEN=62570672">Yongning Zhu</a>, 
                        <a href="author_page.cfm?id=81100248660&CFID=85074218&CFTOKEN=62570672">Robert Bridson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 965 - 972</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073298" title="DOI">10.1145/1186822.1073298</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073298&ftid=322181&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow96" style="display:inline;"><br /><div style="display:inline">We present a physics-based simulation method for animating sand. To allow for efficiently scaling up to large volumes of sand, we abstract away the individual grains and think of the sand as a continuum. In particular we show that an existing water simulator ...</div></span>
          <span id="toHide96" style="display:none;"><br /><div style="display:inline">We present a physics-based simulation method for animating sand. To allow for efficiently scaling up to large volumes of sand, we abstract away the individual grains and think of the sand as a continuum. In particular we show that an existing water simulator can be turned into a sand simulator with only a few small additions to account for inter-grain and boundary friction.We also propose an alternative method for simulating fluids. Our core representation is a cloud of particles, which allows for accurate and flexible surface tracking and advection, but we use an auxiliary grid to efficiently enforce boundary conditions and incompressibility. We further address the issue of reconstructing a surface from particle data to render each frame.</div></span> <a id="expcoll96" href="JavaScript: expandcollapse('expcoll96',96)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073299&CFID=85074218&CFTOKEN=62570672">Coupling water and smoke to thin deformable and rigid shells</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100087539&CFID=85074218&CFTOKEN=62570672">Eran Guendelman</a>, 
                        <a href="author_page.cfm?id=81100351513&CFID=85074218&CFTOKEN=62570672">Andrew Selle</a>, 
                        <a href="author_page.cfm?id=81100603350&CFID=85074218&CFTOKEN=62570672">Frank Losasso</a>, 
                        <a href="author_page.cfm?id=81100612327&CFID=85074218&CFTOKEN=62570672">Ronald Fedkiw</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 973 - 981</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073299" title="DOI">10.1145/1186822.1073299</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073299&ftid=322182&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow97" style="display:inline;"><br /><div style="display:inline">We present a novel method for solid/fluid coupling that can treat infinitesimally thin solids modeled by a lower dimensional triangulated surface. Since classical solid/fluid coupling algorithms rasterize the solid body onto the fluid grid, an entirely ...</div></span>
          <span id="toHide97" style="display:none;"><br /><div style="display:inline">We present a novel method for solid/fluid coupling that can treat infinitesimally thin solids modeled by a lower dimensional triangulated surface. Since classical solid/fluid coupling algorithms rasterize the solid body onto the fluid grid, an entirely new approach is required to treat thin objects that do not contain an interior region. Robust ray casting is used to augment a number of interpolation, finite difference and rendering techniques so that fluid does not leak through the triangulated surface. Moreover, we propose a technique for properly enforcing incompressibility so that fluid does not incorrectly compress (and appear to lose mass) near the triangulated surface. This allows for the robust interaction of cloth and shells with thin sheets of water. The proposed method works for both rigid body shells and for deformable manifolds such as cloth, and we present a two way coupling technique that allows the fluid's pressure to affect the solid. Examples illustrate that our method performs well, especially in the difficult case of water and cloth where it produces visually rich interactions between the particle level set method for treating the water/air interface and our newly proposed method for treating the solid/fluid interface. We have implemented the method on both uniform and adaptive octree grids.</div></span> <a id="expcoll97" href="JavaScript: expandcollapse('expcoll97',97)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073300&CFID=85074218&CFTOKEN=62570672">Real-Time subspace integration for St. Venant-Kirchhoff deformable models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100158368&CFID=85074218&CFTOKEN=62570672">Jernej Barbi&#269;</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=85074218&CFTOKEN=62570672">Doug L. James</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 982 - 990</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073300" title="DOI">10.1145/1186822.1073300</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073300&ftid=322183&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow98" style="display:inline;"><br /><div style="display:inline">In this paper, we present an approach for fast subspace integration of reduced-coordinate nonlinear deformable models that is suitable for interactive applications in computer graphics and haptics. Our approach exploits dimensional model reduction to ...</div></span>
          <span id="toHide98" style="display:none;"><br /><div style="display:inline">In this paper, we present an approach for fast subspace integration of reduced-coordinate nonlinear deformable models that is suitable for interactive applications in computer graphics and haptics. Our approach exploits dimensional model reduction to build reduced-coordinate deformable models for objects with complex geometry. We exploit the fact that model reduction on large deformation models with <i>linear</i> materials (as commonly used in graphics) result in internal force models that are simply cubic polynomials in reduced coordinates. Coefficients of these polynomials can be precomputed, for efficient runtime evaluation. This allows simulation of nonlinear dynamics using fast implicit Newmark subspace integrators, with subspace integration costs independent of geometric complexity. We present two useful approaches for generating low-dimensional subspace bases: modal derivatives and an interactive sketching technique. Mass-scaled principal component analysis (mass-PCA) is suggested for dimensionality reduction. Finally, several examples are given from computer animation to illustrate high performance, including force-feedback haptic rendering of a complicated object undergoing large deformations.</div></span> <a id="expcoll98" href="JavaScript: expandcollapse('expcoll98',98)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073301&CFID=85074218&CFTOKEN=62570672">Interactive collision detection between deformable models using chromatic decomposition</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100383019&CFID=85074218&CFTOKEN=62570672">Naga K. Govindaraju</a>, 
                        <a href="author_page.cfm?id=81100305521&CFID=85074218&CFTOKEN=62570672">David Knott</a>, 
                        <a href="author_page.cfm?id=81100110153&CFID=85074218&CFTOKEN=62570672">Nitin Jain</a>, 
                        <a href="author_page.cfm?id=81100060342&CFID=85074218&CFTOKEN=62570672">Ilknur Kabul</a>, 
                        <a href="author_page.cfm?id=81100289069&CFID=85074218&CFTOKEN=62570672">Rasmus Tamstorf</a>, 
                        <a href="author_page.cfm?id=81319492027&CFID=85074218&CFTOKEN=62570672">Russell Gayle</a>, 
                        <a href="author_page.cfm?id=81452602436&CFID=85074218&CFTOKEN=62570672">Ming C. Lin</a>, 
                        <a href="author_page.cfm?id=81100618474&CFID=85074218&CFTOKEN=62570672">Dinesh Manocha</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 991 - 999</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073301" title="DOI">10.1145/1186822.1073301</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073301&ftid=322184&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow99" style="display:inline;"><br /><div style="display:inline">We present a novel algorithm for accurately detecting all contacts, including self-collisions, between deformable models. We precompute a chromatic decomposition of a mesh into non-adjacent primitives using graph coloring algorithms. The chromatic decomposition ...</div></span>
          <span id="toHide99" style="display:none;"><br /><div style="display:inline">We present a novel algorithm for accurately detecting all contacts, including self-collisions, between deformable models. We precompute a chromatic decomposition of a mesh into non-adjacent primitives using graph coloring algorithms. The chromatic decomposition enables us to check for collisions between non-adjacent primitives using a linear-time culling algorithm. As a result, we achieve higher culling efficiency and significantly reduce the number of false positives. We use our algorithm to check for collisions among complex deformable models consisting of tens of thousands of triangles for cloth modeling and medical simulation. Our algorithm accurately computes all contacts at interactive rates. We observed up to an order of magnitude speedup over prior methods.</div></span> <a id="expcoll99" href="JavaScript: expandcollapse('expcoll99',99)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Geometry on GPUs</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Henry Fuchs 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073303&CFID=85074218&CFTOKEN=62570672">Resolution independent curve rendering using programmable graphics hardware</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100073180&CFID=85074218&CFTOKEN=62570672">Charles Loop</a>, 
                        <a href="author_page.cfm?id=81100294395&CFID=85074218&CFTOKEN=62570672">Jim Blinn</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1000 - 1009</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073303" title="DOI">10.1145/1186822.1073303</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073303&ftid=322185&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow101" style="display:inline;"><br /><div style="display:inline">We present a method for resolution independent rendering of paths and bounded regions, defined by quadratic and cubic spline curves, that leverages the parallelism of programmable graphics hardware to achieve high performance. A simple implicit equation ...</div></span>
          <span id="toHide101" style="display:none;"><br /><div style="display:inline">We present a method for resolution independent rendering of paths and bounded regions, defined by quadratic and cubic spline curves, that leverages the parallelism of programmable graphics hardware to achieve high performance. A simple implicit equation for a parametric curve is found in a space that can be thought of as an analog to texture space. The image of a curve's B&eacute;zier control points are found in this space and assigned to the control points as texture coordinates. When the triangle(s) corresponding to the B&eacute;zier curve control hull are rendered, a pixel shader program evaluates the implicit equation for a pixel's interpolated texture coordinates to determine an inside/outside test for the curve. We extend our technique to handle anti-aliasing of boundaries. We also construct a vector image from mosaics of triangulated B&eacute;zier control points and show how to deform such images to create resolution independent texture on three dimensional objects.</div></span> <a id="expcoll101" href="JavaScript: expandcollapse('expcoll101',101)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073304&CFID=85074218&CFTOKEN=62570672">A realtime GPU subdivision kernel</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100569335&CFID=85074218&CFTOKEN=62570672">Le-Jeng Shiue</a>, 
                        <a href="author_page.cfm?id=81100554748&CFID=85074218&CFTOKEN=62570672">Ian Jones</a>, 
                        <a href="author_page.cfm?id=81100524297&CFID=85074218&CFTOKEN=62570672">J&#246;rg Peters</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1010 - 1015</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073304" title="DOI">10.1145/1186822.1073304</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073304&ftid=322186&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow102" style="display:inline;"><br /><div style="display:inline">By organizing the control mesh of subdivision in texture memory so that irregularities occur strictly inside independently refinable fragment meshes, all major features of subdivision algorithms can be realized in the framework of highly parallel stream ...</div></span>
          <span id="toHide102" style="display:none;"><br /><div style="display:inline">By organizing the control mesh of subdivision in texture memory so that irregularities occur strictly inside independently refinable fragment meshes, all major features of subdivision algorithms can be realized in the framework of highly parallel stream processing. Our implementation of Catmull-Clark subdivision as a GPU kernel in programmable graphics hardware can model features like semi-smooth creases and global boundaries; and a simplified version achieves near-realtime depth-five re-evaluation of moderate-sized subdivision meshes. The approach is easily adapted to other refinement patterns, such as Loop, Doo-Sabin or &radic;3 and it allows for postprocessing with additional shaders.</div></span> <a id="expcoll102" href="JavaScript: expandcollapse('expcoll102',102)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073305&CFID=85074218&CFTOKEN=62570672">GPU-based trimming and tessellation of NURBS and T-Spline surfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81339503213&CFID=85074218&CFTOKEN=62570672">Michael Guthe</a>, 
                        <a href="author_page.cfm?id=81320487638&CFID=85074218&CFTOKEN=62570672">A&#225;kos Bal&#225;zs</a>, 
                        <a href="author_page.cfm?id=81408597984&CFID=85074218&CFTOKEN=62570672">Reinhard Klein</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1016 - 1023</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073305" title="DOI">10.1145/1186822.1073305</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073305&ftid=322187&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow103" style="display:inline;"><br /><div style="display:inline">As there is no hardware support neither for rendering trimmed NURBS -- the standard surface representation in CAD -- nor for T-Spline surfaces the usability of existing rendering APIs like OpenGL, where a run-time tessellation is performed on the CPU, ...</div></span>
          <span id="toHide103" style="display:none;"><br /><div style="display:inline">As there is no hardware support neither for rendering trimmed NURBS -- the standard surface representation in CAD -- nor for T-Spline surfaces the usability of existing rendering APIs like OpenGL, where a run-time tessellation is performed on the CPU, is limited to simple scenes. Due to the irregular mesh data structures required for trimming no algorithms exists that exploit the GPU for tessellation. Therefore, recent approaches perform a pretessellation and use level-of-detail techniques. In contrast to a simple API these methods require tedious preparation of the models before rendering and hinder interactive editing. Furthermore, due to the tremendous amount of triangle data smooth zoom-ins from long shot to close-up are not possible, In this paper we show how the trimming region can be defined by a <i>trim-texture</i> that is dynamically adapted to the required resolution and allows for an efficient trimming of surfaces on the GPU. Combining this new method with GPU-based tessellation of cubic rational surfaces allows a new rendering algorithm for arbitrary trimmed NURBS and T-Spline surfaces with prescribed error in screen space on the GPU. The performance exceeds current CPU-based techniques by a factor of up to 1000 and makes real-time visualization of real-world trimmed NURBS and T-Spline models possible on consumer-level graphics cards.</div></span> <a id="expcoll103" href="JavaScript: expandcollapse('expcoll103',103)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073306&CFID=85074218&CFTOKEN=62570672">Blister: GPU-based rendering of Boolean combinations of free-form triangulated shapes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100297352&CFID=85074218&CFTOKEN=62570672">John Hable</a>, 
                        <a href="author_page.cfm?id=81100166952&CFID=85074218&CFTOKEN=62570672">Jarek Rossignac</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1024 - 1031</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073306" title="DOI">10.1145/1186822.1073306</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073306&ftid=322188&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow104" style="display:inline;"><br /><div style="display:inline">By combining depth peeling with a linear formulation of a Boolean expression called Blist, the Blister algorithm renders an arbitrary CSG model of n primitives in at most k steps, where k is the number of depth-layers in the arrangement of the primitives. ...</div></span>
          <span id="toHide104" style="display:none;"><br /><div style="display:inline">By combining depth peeling with a linear formulation of a Boolean expression called Blist, the Blister algorithm renders an arbitrary CSG model of n primitives in at most k steps, where k is the number of depth-layers in the arrangement of the primitives. Each step starts by rendering each primitive to produce candidate surfels on the next depth-layer. Then, it renders the primitives again, one at a time, to classify the candidate surfels against the primitive and to evaluate the Boolean expression directly on the GPU. Since Blist does not expand the CSG expression into a disjunctive (sum-of-products) form, Blister has O(kn) time complexity. We explain the Blist formulation while providing algorithms for CSG-to-Blist conversion and Blist-based parallel surfel classification. We report real-time performance for nontrivial CSG models. On hardware with an 8-bit stencil buffer, we can render all possible CSG expressions with 3909 primitives.</div></span> <a id="expcoll104" href="JavaScript: expandcollapse('expcoll104',104)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Transparency & translucency</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          George Drettakis 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073308&CFID=85074218&CFTOKEN=62570672">Light diffusion in multi-layered translucent materials</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100639133&CFID=85074218&CFTOKEN=62570672">Craig Donner</a>, 
                        <a href="author_page.cfm?id=81100640205&CFID=85074218&CFTOKEN=62570672">Henrik Wann Jensen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1032 - 1039</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073308" title="DOI">10.1145/1186822.1073308</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073308&ftid=322189&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow106" style="display:inline;"><br /><div style="display:inline">This paper introduces a shading model for light diffusion in multi-layered translucent materials. Previous work on diffusion in translucent materials has assumed smooth semi-infinite homogeneous materials and solved for the scattering of light using ...</div></span>
          <span id="toHide106" style="display:none;"><br /><div style="display:inline">This paper introduces a shading model for light diffusion in multi-layered translucent materials. Previous work on diffusion in translucent materials has assumed smooth semi-infinite homogeneous materials and solved for the scattering of light using a dipole diffusion approximation. This approximation breaks down in the case of thin translucent slabs and multi-layered materials. We present a new efficient technique based on multiple dipoles to account for diffusion in thin slabs. We enhance this multipole theory to account for mismatching indices of refraction at the top and bottom of of translucent slabs, and to model the effects of rough surfaces. To model multiple layers, we extend this single slab theory by convolving the diffusion profiles of the individual slabs. We account for multiple scattering between slabs by using a variant of Kubelka-Munk theory in frequency space. Our results demonstrate diffusion of light in thin slabs and multi-layered materials such as paint, paper, and human skin.</div></span> <a id="expcoll106" href="JavaScript: expandcollapse('expcoll106',106)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073309&CFID=85074218&CFTOKEN=62570672">A practical analytic single scattering model for real time rendering</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100446940&CFID=85074218&CFTOKEN=62570672">Bo Sun</a>, 
                        <a href="author_page.cfm?id=81100019585&CFID=85074218&CFTOKEN=62570672">Ravi Ramamoorthi</a>, 
                        <a href="author_page.cfm?id=81100599730&CFID=85074218&CFTOKEN=62570672">Srinivasa G. Narasimhan</a>, 
                        <a href="author_page.cfm?id=81100052215&CFID=85074218&CFTOKEN=62570672">Shree K. Nayar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1040 - 1049</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073309" title="DOI">10.1145/1186822.1073309</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073309&ftid=322190&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow107" style="display:inline;"><br /><div style="display:inline">We consider real-time rendering of scenes in participating media, capturing the effects of light scattering in fog, mist and haze. While a number of sophisticated approaches based on Monte Carlo and finite element simulation have been developed, those ...</div></span>
          <span id="toHide107" style="display:none;"><br /><div style="display:inline">We consider real-time rendering of scenes in participating media, capturing the effects of light scattering in fog, mist and haze. While a number of sophisticated approaches based on Monte Carlo and finite element simulation have been developed, those methods do not work at interactive rates. The most common real-time methods are essentially simple variants of the OpenGL fog model. While easy to use and specify, that model excludes many important qualitative effects like glows around light sources, the impact of volumetric scattering on the appearance of surfaces such as the diffusing of glossy highlights, and the appearance under complex lighting such as environment maps. In this paper, we present an alternative physically based approach that captures these effects while maintaining real time performance and the ease-of-use of the OpenGL fog model. Our method is based on an explicit analytic integration of the single scattering light transport equations for an isotropic point light source in a homogeneous participating medium. We can implement the model in modern programmable graphics hardware using a few small numerical lookup tables stored as texture maps. Our model can also be easily adapted to generate the appearances of materials with arbitrary BRDFs, environment map lighting, and precomputed radiance transfer methods, in the presence of participating media. Hence, our techniques can be widely used in real-time rendering.</div></span> <a id="expcoll107" href="JavaScript: expandcollapse('expcoll107',107)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073310&CFID=85074218&CFTOKEN=62570672">An approximate image-space approach for interactive refraction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100265704&CFID=85074218&CFTOKEN=62570672">Chris Wyman</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1050 - 1053</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073310" title="DOI">10.1145/1186822.1073310</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073310&ftid=322191&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow108" style="display:inline;"><br /><div style="display:inline">Many interactive applications strive for realistic renderings, but framerate constraints usually limit realism to effects that run efficiently in graphics hardware. One effect largely ignored in such applications is refraction. We introduce a simple, ...</div></span>
          <span id="toHide108" style="display:none;"><br /><div style="display:inline">Many interactive applications strive for realistic renderings, but framerate constraints usually limit realism to effects that run efficiently in graphics hardware. One effect largely ignored in such applications is refraction. We introduce a simple, image-space approach to refractions that easily runs on modern graphics cards. Our method requires two passes on a GPU, and allows refraction of a distant environment through two interfaces, compared to current interactive techniques that are restricted to a single interface. Like all image-based algorithms, aliasing can occur in certain circumstances, but the plausible refractions generated with our approach should suffice for many applications.</div></span> <a id="expcoll108" href="JavaScript: expandcollapse('expcoll108',108)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073311&CFID=85074218&CFTOKEN=62570672">Modeling and rendering of quasi-homogeneous materials</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100393166&CFID=85074218&CFTOKEN=62570672">Xin Tong</a>, 
                        <a href="author_page.cfm?id=81100233349&CFID=85074218&CFTOKEN=62570672">Jiaping Wang</a>, 
                        <a href="author_page.cfm?id=81100221388&CFID=85074218&CFTOKEN=62570672">Stephen Lin</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074218&CFTOKEN=62570672">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1054 - 1061</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073311" title="DOI">10.1145/1186822.1073311</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073311&ftid=322192&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow109" style="display:inline;"><br /><div style="display:inline">Many translucent materials consist of evenly-distributed heterogeneous elements which produce a complex appearance under different lighting and viewing directions. For these quasi-homogeneous materials, existing techniques do not address how to ...</div></span>
          <span id="toHide109" style="display:none;"><br /><div style="display:inline">Many translucent materials consist of evenly-distributed heterogeneous elements which produce a complex appearance under different lighting and viewing directions. For these <i>quasi-homogeneous</i> materials, existing techniques do not address how to acquire their material representations from physical samples in a way that allows arbitrary geometry models to be rendered with these materials. We propose a model for such materials that can be readily acquired from physical samples. This material model can be applied to geometric models of arbitrary shapes, and the resulting objects can be efficiently rendered without expensive subsurface light transport simulation. In developing a material model with these attributes, we capitalize on a key observation about the subsurface scattering characteristics of quasi-homogeneous materials at different scales. Locally, the non-uniformity of these materials leads to inhomogeneous subsurface scattering. For subsurface scattering on a global scale, we show that a lengthy photon path through an even distribution of heterogeneous elements statistically resembles scattering in a homogeneous medium. This observation allows us to represent and measure the global light transport within quasi-homogeneous materials as well as the transfer of light into and out of a material volume through surface mesostructures. We demonstrate our technique with results for several challenging materials that exhibit sophisticated appearance features such as transmission of back illumination through surface mesostructures.</div></span> <a id="expcoll109" href="JavaScript: expandcollapse('expcoll109',109)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Styles of human motion</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jehee Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073313&CFID=85074218&CFTOKEN=62570672">Geostatistical motion interpolation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81336491652&CFID=85074218&CFTOKEN=62570672">Tomohiko Mukai</a>, 
                        <a href="author_page.cfm?id=81100252511&CFID=85074218&CFTOKEN=62570672">Shigeru Kuriyama</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1062 - 1070</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073313" title="DOI">10.1145/1186822.1073313</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073313&ftid=322193&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow111" style="display:inline;"><br /><div style="display:inline">A common motion interpolation technique for realistic human animation is to blend similar motion samples with weighting functions whose parameters are embedded in an abstract space. Existing methods, however, are insensitive to statistical properties, ...</div></span>
          <span id="toHide111" style="display:none;"><br /><div style="display:inline">A common motion interpolation technique for realistic human animation is to blend similar motion samples with weighting functions whose parameters are embedded in an abstract space. Existing methods, however, are insensitive to statistical properties, such as correlations between motions. In addition, they lack the capability to quantitatively evaluate the reliability of synthesized motions. This paper proposes a method that treats motion interpolations as statistical predictions of missing data in an arbitrarily definable parametric space. A practical technique of geostatistics, called universal kriging, is then introduced for statistically estimating the correlations between the dissimilarity of motions and the distance in the parametric space. Our method statistically optimizes interpolation kernels for given parameters at each frame, using a pose distance metric to efficiently analyze the correlation. Motions are accurately predicted for the spatial constraints represented in the parametric space, and they therefore have few undesirable artifacts, if any. This property alleviates the problem of spatial inconsistencies, such as foot-sliding, that are associated with many existing methods. Moreover, numerical estimates for the reliability of predictions enable motions to be adaptively sampled. Since the interpolation kernels are computed with a linear system in real-time, motions can be interactively edited using various spatial controls.</div></span> <a id="expcoll111" href="JavaScript: expandcollapse('expcoll111',111)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073314&CFID=85074218&CFTOKEN=62570672">Learning physics-based motion style with nonlinear inverse optimization</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81452598193&CFID=85074218&CFTOKEN=62570672">C. Karen Liu</a>, 
                        <a href="author_page.cfm?id=81100015154&CFID=85074218&CFTOKEN=62570672">Aaron Hertzmann</a>, 
                        <a href="author_page.cfm?id=81100620346&CFID=85074218&CFTOKEN=62570672">Zoran Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1071 - 1081</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073314" title="DOI">10.1145/1186822.1073314</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1073314&type=pdf&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow112" style="display:inline;"><br /><div style="display:inline">This paper presents a novel physics-based representation of realistic character motion. The dynamical model incorporates several factors of locomotion derived from the biomechanical literature, including relative preferences for using some muscles more ...</div></span>
          <span id="toHide112" style="display:none;"><br /><div style="display:inline">This paper presents a novel physics-based representation of realistic character motion. The dynamical model incorporates several factors of locomotion derived from the biomechanical literature, including relative preferences for using some muscles more than others. elastic mechanisms at joints due to the mechanical properties of tendons, ligaments, and muscles, and variable stiffness at joints depending on the task. When used in a spacetime optimization framework, the parameters of this model define a wide range of styles of natural human movement.Due to the complexity of biological motion, these style parameters are too difficult to design by hand. To address this, we introduce Nonlinear Inverse Optimization, a novel algorithm for estimating optimization parameters from motion capture data. Our method can extract the physical parameters from a single short motion sequence. Once captured, this representation of style is extremely flexible: motions can be generated in the same style but performing different tasks, and styles may be edited to change the physical properties of the body.</div></span> <a id="expcoll112" href="JavaScript: expandcollapse('expcoll112',112)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073315&CFID=85074218&CFTOKEN=62570672">Style translation for human motion</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100320698&CFID=85074218&CFTOKEN=62570672">Eugene Hsu</a>, 
                        <a href="author_page.cfm?id=81100567347&CFID=85074218&CFTOKEN=62570672">Kari Pulli</a>, 
                        <a href="author_page.cfm?id=81100620337&CFID=85074218&CFTOKEN=62570672">Jovan Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1082 - 1089</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073315" title="DOI">10.1145/1186822.1073315</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073315&ftid=322195&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow113" style="display:inline;"><br /><div style="display:inline">Style translation is the process of transforming an input motion into a new style while preserving its original content. This problem is motivated by the needs of interactive applications, which require rapid processing of captured performances. Our ...</div></span>
          <span id="toHide113" style="display:none;"><br /><div style="display:inline">Style translation is the process of transforming an input motion into a new style while preserving its original content. This problem is motivated by the needs of interactive applications, which require rapid processing of captured performances. Our solution learns to translate by analyzing differences between performances of the same content in input and output styles. It relies on a novel correspondence algorithm to align motions, and a linear time-invariant model to represent stylistic differences. Once the model is estimated with system identification, our system is capable of translating streaming input with simple linear operations at each frame.</div></span> <a id="expcoll113" href="JavaScript: expandcollapse('expcoll113',113)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073316&CFID=85074218&CFTOKEN=62570672">A data-driven approach to quantifying natural human motion</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100597813&CFID=85074218&CFTOKEN=62570672">Liu Ren</a>, 
                        <a href="author_page.cfm?id=81100139536&CFID=85074218&CFTOKEN=62570672">Alton Patrick</a>, 
                        <a href="author_page.cfm?id=81100604913&CFID=85074218&CFTOKEN=62570672">Alexei A. Efros</a>, 
                        <a href="author_page.cfm?id=81100049661&CFID=85074218&CFTOKEN=62570672">Jessica K. Hodgins</a>, 
                        <a href="author_page.cfm?id=81341495589&CFID=85074218&CFTOKEN=62570672">James M. Rehg</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1090 - 1097</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073316" title="DOI">10.1145/1186822.1073316</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073316&ftid=322196&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow114" style="display:inline;"><br /><div style="display:inline">In this paper, we investigate whether it is possible to develop a measure that quantifies the naturalness of human motion (as defined by a large database). Such a measure might prove useful in verifying that a motion editing operation had not destroyed ...</div></span>
          <span id="toHide114" style="display:none;"><br /><div style="display:inline">In this paper, we investigate whether it is possible to develop a measure that quantifies the naturalness of human motion (as defined by a large database). Such a measure might prove useful in verifying that a motion editing operation had not destroyed the naturalness of a motion capture clip or that a synthetic motion transition was within the space of those seen in natural human motion. We explore the performance of mixture of Gaussians (MoG), hidden Markov models (HMM), and switching linear dynamic systems (SLDS) on this problem. We use each of these statistical models alone and as part of an ensemble of smaller statistical models. We also implement a Naive Bayes (NB) model for a baseline comparison. We test these techniques on motion capture data held out from a database, keyframed motions, edited motions, motions with noise added, and synthetic motion transitions. We present the results as receiver operating characteristic (ROC) curves and compare the results to the judgments made by subjects in a user study.</div></span> <a id="expcoll114" href="JavaScript: expandcollapse('expcoll114',114)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Appearance & illumination</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Julie Dorsey 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073318&CFID=85074218&CFTOKEN=62570672">Lightcuts: a scalable approach to illumination</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100010986&CFID=85074218&CFTOKEN=62570672">Bruce Walter</a>, 
                        <a href="author_page.cfm?id=81100383548&CFID=85074218&CFTOKEN=62570672">Sebastian Fernandez</a>, 
                        <a href="author_page.cfm?id=81100118944&CFID=85074218&CFTOKEN=62570672">Adam Arbree</a>, 
                        <a href="author_page.cfm?id=81100081277&CFID=85074218&CFTOKEN=62570672">Kavita Bala</a>, 
                        <a href="author_page.cfm?id=81100454985&CFID=85074218&CFTOKEN=62570672">Michael Donikian</a>, 
                        <a href="author_page.cfm?id=81100196982&CFID=85074218&CFTOKEN=62570672">Donald P. Greenberg</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1098 - 1107</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073318" title="DOI">10.1145/1186822.1073318</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073318&ftid=322197&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow116" style="display:inline;"><br /><div style="display:inline">Lightcuts is a scalable framework for computing realistic illumination. It handles arbitrary geometry, non-diffuse materials, and illumination from a wide variety of sources including point lights, area lights, HDR environment maps, sun/sky models, and ...</div></span>
          <span id="toHide116" style="display:none;"><br /><div style="display:inline">Lightcuts is a scalable framework for computing realistic illumination. It handles arbitrary geometry, non-diffuse materials, and illumination from a wide variety of sources including point lights, area lights, HDR environment maps, sun/sky models, and indirect illumination. At its core is a new algorithm for accurately approximating illumination from many point lights with a strongly <i>sublinear</i> cost. We show how a group of lights can be cheaply approximated while bounding the maximum approximation error. A binary light tree and perceptual metric are then used to adaptively partition the lights into groups to control the error vs. cost tradeoff.We also introduce reconstruction cuts that exploit spatial coherence to accelerate the generation of anti-aliased images with complex illumination. Results are demonstrated for five complex scenes and show that lightcuts can accurately approximate hundreds of thousands of point lights using only a few hundred shadow rays. Reconstruction cuts can reduce the number of shadow rays to tens.</div></span> <a id="expcoll116" href="JavaScript: expandcollapse('expcoll116',116)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073319&CFID=85074218&CFTOKEN=62570672">Fast and detailed approximate global illumination by irradiance decomposition</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100558890&CFID=85074218&CFTOKEN=62570672">Okan Arikan</a>, 
                        <a href="author_page.cfm?id=81100502370&CFID=85074218&CFTOKEN=62570672">David A. Forsyth</a>, 
                        <a href="author_page.cfm?id=81100311781&CFID=85074218&CFTOKEN=62570672">James F. O'Brien</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1108 - 1114</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073319" title="DOI">10.1145/1186822.1073319</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073319&ftid=322198&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow117" style="display:inline;"><br /><div style="display:inline">In this paper we present an approximate method for accelerated computation of the final gathering step in a global illumination algorithm. Our method operates by decomposing the radiance field close to surfaces into separate far- and near-field components ...</div></span>
          <span id="toHide117" style="display:none;"><br /><div style="display:inline">In this paper we present an approximate method for accelerated computation of the final gathering step in a global illumination algorithm. Our method operates by decomposing the radiance field close to surfaces into separate far- and near-field components that can be approximated individually. By computing surface shading using these approximations, instead of directly querying the global illumination solution, we have been able to obtain rendering time speed ups on the order of 10x compared to previous acceleration methods. Our approximation schemes rely mainly on the assumptions that radiance due to distant objects will exhibit low spatial and angular variation, and that the visibility between a surface and nearby surfaces can be reasonably predicted by simple location and orientation-based heuristics. Motivated by these assumptions, our far-field scheme uses scattered-data interpolation with spherical harmonics to represent spatial and angular variation, and our near-field scheme employs an aggressively simple visibility heuristic. For our test scenes, the errors introduced when our assumptions fail do not result in visually objectionable artifacts or easily noticeable deviation from a ground-truth solution. We also discuss how our near-field approximation can be used with standard local illumination algorithms to produce significantly improved images at only negligible additional cost.</div></span> <a id="expcoll117" href="JavaScript: expandcollapse('expcoll117',117)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073320&CFID=85074218&CFTOKEN=62570672">A frequency analysis of light transport</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100055904&CFID=85074218&CFTOKEN=62570672">Fr&#233;do Durand</a>, 
                        <a href="author_page.cfm?id=81100061765&CFID=85074218&CFTOKEN=62570672">Nicolas Holzschuch</a>, 
                        <a href="author_page.cfm?id=81100200748&CFID=85074218&CFTOKEN=62570672">Cyril Soler</a>, 
                        <a href="author_page.cfm?id=81408592916&CFID=85074218&CFTOKEN=62570672">Eric Chan</a>, 
                        <a href="author_page.cfm?id=81100402503&CFID=85074218&CFTOKEN=62570672">Fran&#231;ois X. Sillion</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1115 - 1126</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073320" title="DOI">10.1145/1186822.1073320</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073320&ftid=322199&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow118" style="display:inline;"><br /><div style="display:inline">We present a signal-processing framework for light transport. We study the frequency content of radiance and how it is altered by phenomena such as shading, occlusion, and transport. This extends previous work that considered either spatial or angular ...</div></span>
          <span id="toHide118" style="display:none;"><br /><div style="display:inline">We present a signal-processing framework for light transport. We study the frequency content of radiance and how it is altered by phenomena such as shading, occlusion, and transport. This extends previous work that considered either spatial or angular dimensions, and it offers a comprehensive treatment of both space and angle.We show that occlusion, a multiplication in the primal, amounts in the Fourier domain to a convolution by the spectrum of the blocker. Propagation corresponds to a shear in the space-angle frequency domain, while reflection on curved objects performs a different shear along the angular frequency axis. As shown by previous work, reflection is a convolution in the primal and therefore a multiplication in the Fourier domain. Our work shows how the spatial components of lighting are affected by this angular convolution.Our framework predicts the characteristics of interactions such as caustics and the disappearance of the shadows of small features. Predictions on the frequency content can then be used to control sampling rates for rendering. Other potential applications include precomputed radiance transfer and inverse rendering.</div></span> <a id="expcoll118" href="JavaScript: expandcollapse('expcoll118',118)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073321&CFID=85074218&CFTOKEN=62570672">Visual simulation of weathering by &gamma;-ton tracing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81408597193&CFID=85074218&CFTOKEN=62570672">Yanyun Chen</a>, 
                        <a href="author_page.cfm?id=81100496545&CFID=85074218&CFTOKEN=62570672">Lin Xia</a>, 
                        <a href="author_page.cfm?id=81343509200&CFID=85074218&CFTOKEN=62570672">Tien-Tsin Wong</a>, 
                        <a href="author_page.cfm?id=81100393166&CFID=85074218&CFTOKEN=62570672">Xin Tong</a>, 
                        <a href="author_page.cfm?id=81100451028&CFID=85074218&CFTOKEN=62570672">Hujun Bao</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074218&CFTOKEN=62570672">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1127 - 1133</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073321" title="DOI">10.1145/1186822.1073321</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073321&ftid=322200&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow119" style="display:inline;"><br /><div style="display:inline">Weathering modeling introduces blemishes such as dirt, rust, cracks and scratches to virtual scenery. In this paper we present a visual stimulation technique that works well for a wide variety of weathering phenomena. Our technique, called &gamma;-ton ...</div></span>
          <span id="toHide119" style="display:none;"><br /><div style="display:inline">Weathering modeling introduces blemishes such as dirt, rust, cracks and scratches to virtual scenery. In this paper we present a visual stimulation technique that works well for a wide variety of weathering phenomena. Our technique, called &gamma;-ton tracing, is based on a type of aging-inducing particles called &gamma;-tons. Modeling a weathering effect with &gamma;-ton tracing involves tracing a large number of &gamma;-tons through the scene in a way similar to photon tracing and then generating the weathering effect using the recorded &gamma;-ton transport information. With this technique, we can produce weathering effects that are customized to the scene geometry and tailored to the weathering sources. Several effects that are challenging for existing techniques can be readily captured by &gamma;-ton tracing. These include global transport effects. or "stainbleeding". &gamma;-ton tracing also enables visual simulations of complex multi-weathering effects. Lastly &gamma;-ton tracing can generate weathering effects that not only involve texture changes but also large-scale geometry changes. We demonstrate our technique with a variety of examples.</div></span> <a id="expcoll119" href="JavaScript: expandcollapse('expcoll119',119)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Shape & texture</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          David Ebert 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073323&CFID=85074218&CFTOKEN=62570672">As-rigid-as-possible shape manipulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100444444&CFID=85074218&CFTOKEN=62570672">Takeo Igarashi</a>, 
                        <a href="author_page.cfm?id=81100624219&CFID=85074218&CFTOKEN=62570672">Tomer Moscovich</a>, 
                        <a href="author_page.cfm?id=81100166298&CFID=85074218&CFTOKEN=62570672">John F. Hughes</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1134 - 1141</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073323" title="DOI">10.1145/1186822.1073323</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073323&ftid=322201&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow121" style="display:inline;"><br /><div style="display:inline">We present an interactive system that lets a user move and deform a two-dimensional shape without manually establishing a skeleton or freeform deformation (FFD) domain beforehand. The shape is represented by a triangle mesh and the user moves several ...</div></span>
          <span id="toHide121" style="display:none;"><br /><div style="display:inline">We present an interactive system that lets a user move and deform a two-dimensional shape without manually establishing a skeleton or freeform deformation (FFD) domain beforehand. The shape is represented by a triangle mesh and the user moves several vertices of the mesh as constrained handles. The system then computes the positions of the remaining free vertices by minimizing the distortion of each triangle. While physically based simulation or iterative refinement can also be used for this purpose, they tend to be slow. We present a two-step closed-form algorithm that achieves real-time interaction. The first step finds an appropriate rotation for each triangle and the second step adjusts its scale. The key idea is to use quadratic error metrics so that each minimization problem becomes a system of linear equations. After solving the simultaneous equations at the beginning of interaction, we can quickly find the positions of free vertices during interactive manipulation. Our approach successfully conveys a sense of rigidity of the shape, which is difficult in space-warp approaches. With a multiple-point input device, even beginners can easily move, rotate, and deform shapes at will.</div></span> <a id="expcoll121" href="JavaScript: expandcollapse('expcoll121',121)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073324&CFID=85074218&CFTOKEN=62570672">A sketch-based interface for detail-preserving mesh editing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100299565&CFID=85074218&CFTOKEN=62570672">Andrew Nealen</a>, 
                        <a href="author_page.cfm?id=81100036540&CFID=85074218&CFTOKEN=62570672">Olga Sorkine</a>, 
                        <a href="author_page.cfm?id=81100235480&CFID=85074218&CFTOKEN=62570672">Marc Alexa</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074218&CFTOKEN=62570672">Daniel Cohen-Or</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1142 - 1147</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073324" title="DOI">10.1145/1186822.1073324</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073324&ftid=322202&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow122" style="display:inline;"><br /><div style="display:inline">In this paper we present a method for the intuitive editing of surface meshes by means of view-dependent sketching. In most existing shape deformation work, editing is carried out by selecting and moving a handle, usually a set of vertices. Our ...</div></span>
          <span id="toHide122" style="display:none;"><br /><div style="display:inline">In this paper we present a method for the intuitive editing of surface meshes by means of view-dependent sketching. In most existing shape deformation work, editing is carried out by selecting and moving a <i>handle</i>, usually a set of vertices. Our system lets the user easily determine the handle, either by silhouette selection and cropping, or by sketching directly onto the surface. Subsequently, an edit is carried out by sketching a new, view-dependent handle position or by indirectly influencing differential properties along the sketch. Combined, these editing and handle metaphors greatly simplify otherwise complex shape modeling tasks.</div></span> <a id="expcoll122" href="JavaScript: expandcollapse('expcoll122',122)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073325&CFID=85074218&CFTOKEN=62570672">TextureMontage</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335500198&CFID=85074218&CFTOKEN=62570672">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81451596353&CFID=85074218&CFTOKEN=62570672">Xi Wang</a>, 
                        <a href="author_page.cfm?id=81100393143&CFID=85074218&CFTOKEN=62570672">Yiying Tong</a>, 
                        <a href="author_page.cfm?id=81100041821&CFID=85074218&CFTOKEN=62570672">Mathieu Desbrun</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074218&CFTOKEN=62570672">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1148 - 1155</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073325" title="DOI">10.1145/1186822.1073325</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073325&ftid=322203&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow123" style="display:inline;"><br /><div style="display:inline">We propose a technique, called TextureMontage, to seamlessly map a patchwork of texture images onto an arbitrary 3D model. A texture atlas can be created through the specification of a set of correspondences between the model and any number of ...</div></span>
          <span id="toHide123" style="display:none;"><br /><div style="display:inline">We propose a technique, called <i>TextureMontage</i>, to seamlessly map a patchwork of texture images onto an arbitrary 3D model. A texture atlas can be created through the specification of a set of correspondences between the model and any number of texture images. First, our technique automatically partitions the mesh and the images, driven solely by the choice of feature correspondences. Most charts will then be parameterized over their corresponding image planes through the minimization of a distortion metric based on both geometric distortion and texture mismatch across patch boundaries and images. Lastly, a surface texture inpainting technique is used to fill in the remaining charts of the surface with no corresponding texture patches. The resulting texture mapping satisfies the (sparse or dense) user-specified constraints while minimizing the distortion of the texture images and ensuring a smooth transition across the boundaries of different mesh patches. Seamless Texturing of Arbitrary Surfaces From Multiple Images</div></span> <a id="expcoll123" href="JavaScript: expandcollapse('expcoll123',123)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Ray tracing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Nelson Max 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073327&CFID=85074218&CFTOKEN=62570672">Soft shadow volumes for ray tracing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100622664&CFID=85074218&CFTOKEN=62570672">Samuli Laine</a>, 
                        <a href="author_page.cfm?id=81100649025&CFID=85074218&CFTOKEN=62570672">Timo Aila</a>, 
                        <a href="author_page.cfm?id=81100618307&CFID=85074218&CFTOKEN=62570672">Ulf Assarsson</a>, 
                        <a href="author_page.cfm?id=81339512060&CFID=85074218&CFTOKEN=62570672">Jaakko Lehtinen</a>, 
                        <a href="author_page.cfm?id=81100093806&CFID=85074218&CFTOKEN=62570672">Tomas Akenine-M&#246;ller</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1156 - 1165</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073327" title="DOI">10.1145/1186822.1073327</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073327&ftid=322204&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow125" style="display:inline;"><br /><div style="display:inline">We present a new, fast algorithm for rendering physically-based soft shadows in ray tracing-based renderers. Our method replaces the hundreds of shadow rays commonly used in stochastic ray tracers with a single shadow ray and a local reconstruction of ...</div></span>
          <span id="toHide125" style="display:none;"><br /><div style="display:inline">We present a new, fast algorithm for rendering physically-based soft shadows in ray tracing-based renderers. Our method replaces the hundreds of shadow rays commonly used in stochastic ray tracers with a single shadow ray and a local reconstruction of the visibility function. Compared to tracing the shadow rays. our algorithm produces exactly the same image while executing one to two orders of magnitude faster in the test scenes used. Our first contribution is a two-stage method for quickly determining the silhouette edges that overlap an area light source, as seen from the point to be shaded. Secondly, we show that these partial silhouettes of occluders, along with a single shadow ray, are sufficient for reconstructing the visibility function between the point and the light source.</div></span> <a id="expcoll125" href="JavaScript: expandcollapse('expcoll125',125)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073328&CFID=85074218&CFTOKEN=62570672">Wavelet importance sampling: efficiently evaluating products of complex functions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100620674&CFID=85074218&CFTOKEN=62570672">Petrik Clarberg</a>, 
                        <a href="author_page.cfm?id=81100389194&CFID=85074218&CFTOKEN=62570672">Wojciech Jarosz</a>, 
                        <a href="author_page.cfm?id=81100093806&CFID=85074218&CFTOKEN=62570672">Tomas Akenine-M&#246;ller</a>, 
                        <a href="author_page.cfm?id=81100640205&CFID=85074218&CFTOKEN=62570672">Henrik Wann Jensen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1166 - 1175</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073328" title="DOI">10.1145/1186822.1073328</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073328&ftid=322205&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow126" style="display:inline;"><br /><div style="display:inline">We present a new technique for importance sampling products of complex functions using wavelets. First, we generalize previous work on wavelet products to higher dimensional spaces and show how this product can be sampled on-the-fly without the need ...</div></span>
          <span id="toHide126" style="display:none;"><br /><div style="display:inline">We present a new technique for importance sampling products of complex functions using wavelets. First, we generalize previous work on wavelet products to higher dimensional spaces and show how this product can be sampled on-the-fly without the need of evaluating the full product. This makes it possible to sample products of high-dimensional functions even if the product of the two functions in itself is too memory consuming. Then, we present a novel hierarchical sample warping algorithm that generates high-quality point distributions, which match the wavelet representation exactly. One application of the new sampling technique is rendering of objects with measured BRDFs illuminated by complex distant lighting --- our results demonstrate how the new sampling technique is more than an order of magnitude more efficient than the best previous techniques.</div></span> <a id="expcoll126" href="JavaScript: expandcollapse('expcoll126',126)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073329&CFID=85074218&CFTOKEN=62570672">Multi-level ray tracing algorithm</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314494641&CFID=85074218&CFTOKEN=62570672">Alexander Reshetov</a>, 
                        <a href="author_page.cfm?id=81100563794&CFID=85074218&CFTOKEN=62570672">Alexei Soupikov</a>, 
                        <a href="author_page.cfm?id=81100444477&CFID=85074218&CFTOKEN=62570672">Jim Hurley</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1176 - 1185</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073329" title="DOI">10.1145/1186822.1073329</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073329&ftid=322206&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow127" style="display:inline;"><br /><div style="display:inline">We propose new approaches to ray tracing that greatly reduce the required number of operations while strictly preserving the geometrical correctness of the solution. A hierarchical "beam" structure serves as a proxy for a collection of rays. It is tested ...</div></span>
          <span id="toHide127" style="display:none;"><br /><div style="display:inline">We propose new approaches to ray tracing that greatly reduce the required number of operations while strictly preserving the geometrical correctness of the solution. A hierarchical "beam" structure serves as a proxy for a collection of rays. It is tested against a kd-tree representing the overall scene in order to discard from consideration the sub-set of the kd-tree (and hence the scene) that is guaranteed not to intersect with any possible ray inside the beam. This allows for all the rays inside the beam to start traversing the tree from some node deep inside thus eliminating unnecessary operations. The original beam can be further sub-divided, and we can either continue looking for new optimal entry points for the sub-beams, or we can decompose the beam into individual rays. This is a hierarchical process that can be adapted to the geometrical complexity of a particular view direction allowing for efficient geometric anti-aliasing. By amortizing the cost of partially traversing the tree for all the rays in a beam, up to an order of magnitude performance improvement can be achieved enabling interactivity for complex scenes on ordinary desktop machines.</div></span> <a id="expcoll127" href="JavaScript: expandcollapse('expcoll127',127)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073330&CFID=85074218&CFTOKEN=62570672">Energy redistribution path tracing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100021691&CFID=85074218&CFTOKEN=62570672">David Cline</a>, 
                        <a href="author_page.cfm?id=81100516544&CFID=85074218&CFTOKEN=62570672">Justin Talbot</a>, 
                        <a href="author_page.cfm?id=81100563633&CFID=85074218&CFTOKEN=62570672">Parris Egbert</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1186 - 1195</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073330" title="DOI">10.1145/1186822.1073330</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073330&ftid=322207&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow128" style="display:inline;"><br /><div style="display:inline">We present Energy Redistribution (ER) sampling as an unbiased method to solve correlated integral problems. ER sampling is a hybrid algorithm that uses Metropolis sampling-like mutation strategies in a standard Monte Carlo integration setting, rather ...</div></span>
          <span id="toHide128" style="display:none;"><br /><div style="display:inline">We present Energy Redistribution (ER) sampling as an unbiased method to solve correlated integral problems. ER sampling is a hybrid algorithm that uses Metropolis sampling-like mutation strategies in a standard Monte Carlo integration setting, rather than resorting to an intermediate probability distribution step. In the context of global illumination, we present Energy Redistribution Path Tracing (ERPT). Beginning with an inital set of light samples taken from a path tracer, ERPT uses path mutations to redistribute the energy of the samples over the image plane to reduce variance. The result is a global illumination algorithm that is conceptually simpler than Metropolis Light Transport (MLT) while retaining its most powerful feature, path mutation. We compare images generated with the new technique to standard path tracing and MLT.</div></span> <a id="expcoll128" href="JavaScript: expandcollapse('expcoll128',128)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Precomputed light transport</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Wolfgang Heidrich 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073332&CFID=85074218&CFTOKEN=62570672">Precomputed shadow fields for dynamic scenes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335500198&CFID=85074218&CFTOKEN=62570672">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81418592942&CFID=85074218&CFTOKEN=62570672">Yaohua Hu</a>, 
                        <a href="author_page.cfm?id=81100221388&CFID=85074218&CFTOKEN=62570672">Stephen Lin</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074218&CFTOKEN=62570672">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074218&CFTOKEN=62570672">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1196 - 1201</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073332" title="DOI">10.1145/1186822.1073332</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073332&ftid=322208&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow130" style="display:inline;"><br /><div style="display:inline">We present a soft shadow technique for dynamic scenes with moving objects under the combined illumination of moving local light sources and dynamic environment maps. The main idea of our technique is to precompute for each scene entity a shadow field ...</div></span>
          <span id="toHide130" style="display:none;"><br /><div style="display:inline">We present a soft shadow technique for dynamic scenes with moving objects under the combined illumination of moving local light sources and dynamic environment maps. The main idea of our technique is to precompute for each scene entity a <i>shadow field</i> that describes the shadowing effects of the entity at points around it. The shadow field for a light source, called a <i>source radiance field</i> (SRF), records radiance from an illuminant as cube maps at sampled points in its surrounding space. For an occluder, an <i>object occlusion field</i> (OOF) conversely represents in a similar manner the occlusion of radiance by an object. A fundamental difference between shadow fields and previous shadow computation concepts is that shadow fields can be precomputed independent of scene configuration. This is critical for dynamic scenes because, at any given instant, the shadow information at any receiver point can be rapidly computed as a simple combination of SRFs and OOFs according to the current scene configuration. Applications that particularly benefit from this technique include large dynamic scenes in which many instances of an entity can share a single shadow field. Our technique enables low-frequency shadowing effects in dynamic scenes in real-time and all-frequency shadows at interactive rates.</div></span> <a id="expcoll130" href="JavaScript: expandcollapse('expcoll130',130)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073333&CFID=85074218&CFTOKEN=62570672">All-frequency interactive relighting of translucent objects with single and multiple scattering</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81408591714&CFID=85074218&CFTOKEN=62570672">Rui Wang</a>, 
                        <a href="author_page.cfm?id=81100264889&CFID=85074218&CFTOKEN=62570672">John Tran</a>, 
                        <a href="author_page.cfm?id=81100131290&CFID=85074218&CFTOKEN=62570672">David Luebke</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1202 - 1207</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073333" title="DOI">10.1145/1186822.1073333</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073333&ftid=322209&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow131" style="display:inline;"><br /><div style="display:inline">We present a technique, based on precomputed light transport, for interactive rendering of translucent objects under all-frequency environment maps. We consider the complete BSSRDF model proposed by Jensen et al. [2001]. which includes both single and ...</div></span>
          <span id="toHide131" style="display:none;"><br /><div style="display:inline">We present a technique, based on precomputed light transport, for interactive rendering of translucent objects under all-frequency environment maps. We consider the complete BSSRDF model proposed by Jensen et al. [2001]. which includes both single and diffuse multiple scattering components. The challenge is how to efficiently precompute all-frequency light transport functions due to subsurface scattering. We apply the two-pass hierarchical technique by Jensen et al. [2002] in the space of non-linearly approximated transport vectors, which allows us to efficiently evaluate transport vectors due to diffuse multiple scattering. We then include an approximated single scattering term in the precomputation, which previous interactive systems have ignored. For an isotropic phase function, this approximation produces a diffuse transport vector per vertex, and is combined with the multiple scattering component. For a general phase function, we introduce a technique from BRDF rendering to factor the phase function using a separable decomposition to allow for view-dependent rendering. We show that our rendering results qualitatively match the appearance of translucent objects, achieving a high level of realism at interactive rates.</div></span> <a id="expcoll131" href="JavaScript: expandcollapse('expcoll131',131)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073334&CFID=85074218&CFTOKEN=62570672">Precomputed local radiance transfer for real-time lighting design</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100045239&CFID=85074218&CFTOKEN=62570672">Anders Wang Kristensen</a>, 
                        <a href="author_page.cfm?id=81100093806&CFID=85074218&CFTOKEN=62570672">Tomas Akenine-M&#246;ller</a>, 
                        <a href="author_page.cfm?id=81100640205&CFID=85074218&CFTOKEN=62570672">Henrik Wann Jensen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1208 - 1215</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073334" title="DOI">10.1145/1186822.1073334</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073334&ftid=322210&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow132" style="display:inline;"><br /><div style="display:inline">This paper introduces a new method for real-time relighting of scenes illuminated by local light sources. We extend previous work on precomputed radiance transfer for distant lighting to local lighting by introducing the concept of unstructured light ...</div></span>
          <span id="toHide132" style="display:none;"><br /><div style="display:inline">This paper introduces a new method for real-time relighting of scenes illuminated by local light sources. We extend previous work on precomputed radiance transfer for distant lighting to local lighting by introducing the concept of unstructured light clouds. The unstructured light cloud enables a compact representation of local lights in the model and real-time rendering of complex models with full global illumination due to local light sources. We use simplification of lights, and clustered PCA to obtain a compressed representation. When storing only the indirect component of the illumination, we are able to get high quality with only 8-16 lighting coefficients per vertex. Our results demonstrate real-time rendering of scenes with moving lights, dynamic cameras, glossy materials and global illumination.</div></span> <a id="expcoll132" href="JavaScript: expandcollapse('expcoll132',132)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1073335&CFID=85074218&CFTOKEN=62570672">Local, deformable precomputed radiance transfer</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100524617&CFID=85074218&CFTOKEN=62570672">Peter-Pike Sloan</a>, 
                        <a href="author_page.cfm?id=81100094823&CFID=85074218&CFTOKEN=62570672">Ben Luna</a>, 
                        <a href="author_page.cfm?id=81100167784&CFID=85074218&CFTOKEN=62570672">John Snyder</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1216 - 1224</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1186822.1073335" title="DOI">10.1145/1186822.1073335</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1073335&ftid=322211&dwn=1&CFID=85074218&CFTOKEN=62570672" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow133" style="display:inline;"><br /><div style="display:inline">Precomputed radiance transfer (PRT) captures realistic lighting effects from distant, low-frequency environmental lighting but has been limited to static models or precomputed sequences. We focus on PRT for local effects such as bumps, wrinkles, or other ...</div></span>
          <span id="toHide133" style="display:none;"><br /><div style="display:inline">Precomputed radiance transfer (PRT) captures realistic lighting effects from distant, low-frequency environmental lighting but has been limited to static models or precomputed sequences. We focus on PRT for local effects such as bumps, wrinkles, or other detailed features, but extend it to arbitrarily deformable models. Our approach applies zonal harmonics (ZH) which approximate spherical functions as sums of circularly symmetric Legendre polynomials around different axes. By spatially varying both the axes and coefficients of these basis functions, we can fit to spatially varying transfer signals. Compared to the spherical harmonic (SH) basis, the ZH basis yields a more compact approximation. More important, it can be trivially rotated whereas SH rotation is expensive and unsuited for dense per-vertex or per-pixel evaluation. This property allows, for the first time, PRT to be mapped onto deforming models which re-orient the local coordinate frame. We generate ZH transfer models by fitting to PRT signals simulated on meshes or simple parametric models for thin membranes and wrinkles. We show how shading with ZH transfer can be significantly accelerated by specializing to a given lighting environment. Finally, we demonstrate real-time rendering results with soft shadows, inter-reflections, and subsurface scatter on deforming models.</div></span> <a id="expcoll133" href="JavaScript: expandcollapse('expcoll133',133)">expand</a>
          </div>
		  </td>
          </tr>          
          
</table>


</div> 
</div>


 <p class="small-text" align="center">Powered by <a id="theguide" name="theguide" href="javascript:ColdFusion.Window.show('theguide')"><img src="img/poweredbyacm.jpg" width="336" height="11" alt="The ACM Guide to Computing Literature" border="0" /></a></p>



 <br />
<div class="footerbody" align="center" >
	

	The ACM Digital Library is published by the Association for Computing Machinery. Copyright &copy; 2012 ACM, Inc.<br />
	<a href="http://www.acm.org/publications/policies/usage">Terms of Usage</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/privacy-policy">Privacy Policy</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/code-of-ethics">Code of Ethics</a>&nbsp;&nbsp;	  
	<a href="http://www.acm.org/about/contact-us">Contact Us</a>

<br /><br />
Useful downloads: 
<a href="http://www.adobe.com/products/acrobat/readstep2.html"><img src="http://dl.acm.org/images/pdf_logo.gif" width="16" height="16" alt="" border="0" /> Adobe Acrobat</a>
&nbsp;&nbsp;
<a href="http://www.apple.com/quicktime/download/" target="_blank"><img src="http://dl.acm.org/images/qtlogo.gif" width="16" height="16" alt="" border="0" /> QuickTime</a>
&nbsp;&nbsp;
<a href="http://www.microsoft.com/windows/windowsmedia/download/default.asp" target="_blank"><img src="http://dl.acm.org/images/wmv.gif" width="16" height="15" alt="" border="0" /> Windows Media Player</a>
&nbsp;&nbsp;
<a href="http://www.real.com/" target="_blank"><img src="http://dl.acm.org/images/realplayer.gif" width="20" height="18" alt="" border="0" /> Real Player</a>

</div> 



<div  id="cf_window1338239898043" class="yuiextdlg">
	
	<div  id="theguide_title" class="x-dlg-hd">
		The ACM Guide to Computing Literature
	 </div>
	<div  id="theguide_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338239898046" class="yuiextdlg">
	
	<div  id="thetags_title" class="x-dlg-hd">
		All Tags
	 </div>
	<div  id="thetags_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338239898049" class="yuiextdlg">
	
	<div  id="theformats_title" class="x-dlg-hd">
		Export Formats
	 </div>
	<div  id="theformats_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338239898051" class="yuiextdlg">
	
	<div  id="theexplaination_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theexplaination_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338239898053" class="yuiextdlg">
	
	<div  id="theservices_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theservices_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338239898055" class="yuiextdlg">
	
	<div  id="savetobinder_title" class="x-dlg-hd">
		Save to Binder
	 </div>
	<div  id="savetobinder_body" class="x-dlg-bd">
		
		
	 </div>
 </div> 

</body>
</html>