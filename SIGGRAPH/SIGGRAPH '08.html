


<!doctype html>


<head><script type="text/javascript">_cf_loadingtexthtml="<img alt=' ' src='/CFIDE/scripts/ajax/resources/cf/images/loading.gif'/>";
_cf_contextpath="";
_cf_ajaxscriptsrc="/CFIDE/scripts/ajax";
_cf_jsonprefix='//';
_cf_clientid='B819D8B691D050B71175341C59BA7233';</script><script type="text/javascript" src="/CFIDE/scripts/ajax/messages/cfmessage.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfajax.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfform.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/masks.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfformhistory.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfrichtexteditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/FCKeditor/fckeditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/yahoo-dom-event/yahoo-dom-event.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/animation/animation-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/adapter/yui/ext-yui-adapter.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/ext-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/resizable.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dragdrop/dragdrop.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/util.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/build/state/State-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/widget-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dialog/dialogs.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfwindow.js"></script>
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/ext/css/ext-all.css" />
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/cf/cf.css" />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="css/dl.css" />



<title>ACM SIGGRAPH 2008 papers</title>
<style type="text/css"><!--
    body {margin-left: 0em; margin-top: 0}
    a:link {text-decoration: underline; 	Color: #1d4d0f;}
    a:visited  { color: #990033; text-decoration: underline;}
    a:hover {color: red; text-decoration: none}
    a.dLink1:link {color:#336699}
    a.dLink1:visited {color:#666666}
	a.isblack:link {text-decoration: underline; 	Color: #000000;}
    a.isblack:visited  { color: #000000; text-decoration: underline;}
    a.isblack:hover {color: #000000; text-decoration: none}
    h1 {font-size: 140%; margin-bottom: 0}
	ul {margin-top: .25em; list-style-type: disc}
	ol {margin-top: .25em;}
	li {padding-bottom: .25em}
    h2 {color: white; background-color: #069; 
        font-size: 100%; padding-left: 1em;
		margin: 0}
	h3 {color: black; background-color: yellow; 
    	font-size: 100%;
		margin: 0}
	 h4 {color: black; background-color: #99c5e8; 
        font-size: 100%;
		margin: 0}
    hr {color: #39176d;}
    form {margin-top: 10}
    form.xrs {margin-top: 0}
	
	a {text-decoration: none; }
	
	input {font-size: 1em;}
	.chevron {color: #ff0000;}
	.light-blue {color:#336699;}
	.black {color:#000000;}
	
	/* ### standard text styles, smallest to largest ### */
	
	.footer-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .75em; line-height: 1.33em;
		text-indent: -.75 em; margin-left: 2em; margin-right: .75em;}
		
	.footer-copy-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em; line-height: 1.3em;
		margin-left: .75em; margin-right: .75em;}
		
	.small-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; padding-bottom : 2px;
	  	padding-top : 2px;}

	.smallerer-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .65em;}
	.smaller-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em;}		
	.small-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em;}
	.small-textb {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; font-weight: bold;}
	.medium-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em;}
	.mediumb-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em; font-weight: bold;}
	.large-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1.3em;}		
	.instr-text {font-family: Arial, Helvetica, sans-serif;
		color:#666666; font-size: .83em;}
		
	.list-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .83em; line-height: 1.3em;}
	.list-link-btext {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; line-height: 1.3em;}
	
	.searchbox-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;}
	.footer-header-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;
		margin-left: .75em; margin-right: .75em;}
	.medium-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold; line-height: 1em;
		text-indent: -1.25em; margin-left: 2em; margin-right: .75em;}
	
	.text16 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 16px;}
		
	.text14 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 14px;}
	
	.text12 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 12px;}
		
	.text10 {font-family: Arial, Helvetica, sans-serif;
	    color:#000000; font-size: 12px;}
		
	.text9 {font-family: Arial, Helvetica, sans-serif;
	   color:#000000; font-size: 12px;}
	
	.error-text {color:red;}
	
	.small-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: .75em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}

	.medium-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1.3em; line-height: 1.5em;
		margin-left: .75em; margin-right: .75em;}
	
	.medium-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1.5em;
		margin-left: .75em; margin-right: .75em;}

		#side {
			width: 10px;
			float: left;
			margin-left: -1px;
			padding: 2px;
			}
							
		#content {
			padding: 2px;
			margin-left: 25px;
			
		        
		        }
	 .fulltext_lnk {border:0px;
	 				 margin-right: 2px;
					 vertical-align:baseline;
	 				}
	 
	  .leftcoltab { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:530px;  /* for IE5/WIN */
		  width:520px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	  .rightcoltab {
    float: right;
    margin: 0;
    padding: 5px;
    position: relative;
    right: 50px;
    top: 25px;
    width: 350px;
    z-index: 99;
}
	  .centercoltab {
		  position:absolute;
		  padding:0 0px;
		  }
	  .alt {
		background: #ece9d8;
		margin: 0;
		padding: 1px;
		}
		.leftcolc { 
	position:relative;
	top:5px;
	left:5px;
	float:left;
	width:420px;  /* for IE5/WIN */
	width:400px; /* actual value */
	margin:0 0 0px 0;
	padding:5px;
	z-index:100;
	}
.rightcolc {
	position:relative;
	top:0px;
	right:0px;
	float:right;
	margin:0 0px;
	padding:0px;
	width:500px;
	z-index:99;
	}
.centercolc {
	position:absolute;
	padding:0 0px;
	}
	
	.leftcoltabv { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:460px;  /* for IE5/WIN */
		  width:350px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	.rightcoltabv {
		position:relative;
		top:5px;
		right:0px;
		float:right;
		margin:0 0px 0 0;
		padding:15px;
		width:480px;
		z-index:99;
		}
	
  --></style>
 


<script type="text/javascript" src="cfformprotect/js/cffp.js"></script>


<script type="text/javascript">
 function expandcollapse(anchor,whichone) {
	 var inner = document.getElementById(anchor);
	 var theshow = "toShow" + whichone;
 	 var thehide = "toHide" + whichone;
	 var span = document.getElementById(theshow);
     span.style.display = (span.style.display=='inline')?'none':'inline';
     var span = document.getElementById(thehide);
     span.style.display = (span.style.display=='none')?'inline':'none';
     inner.innerHTML = (inner.innerHTML=='collapse')?'expand':'collapse';
    }

  function setDiv() {
	var m = document.getElementById('divmain');
	var mh = m.offsetHeight;
	var t = document.getElementById('divtools');
	var th = t.offsetHeight;
	var tg = document.getElementById('divtags');
	var tgh = tg.offsetHeight;
	var calcheight = mh - th;
	if (tgh > calcheight  ){
	  var x = (th + tgh) - mh;
	  if ( (th + tgh) - mh < 65) {
	  }
	  else {
		 document.getElementById('divtags').innerHTML = ""; 
		 var tg = document.getElementById('divtags');
		 var tgh = tg.offsetHeight;
		 tg.style.height = tgh  + 'px';
	  }
	}
	else {
		tg.style.height = calcheight + 'px';
		document.getElementById('divtags').innerHTML = "";
	}

//  do I need to check after I resize to be sure I didn't go too big?
//	var tg2 = document.getElementById('divtags');
//	var tgh2 = tg.offsetHeight;	
//	if (tgh2 > mh + 65) {
//	  var y = mh + 65;
//	  alert('expanded too much ' + tgh2 + ' should be at most ' + y);
//	  tg.style.height = y + 'px';
//	  document.getElementById('divtags').innerHTML = "";
//	}

  }
</script>

<script type="text/javascript">
 /* <!-- Begin
	if(document.layers || document.all) {
	a = 1;
	setInterval("Jump()", 10);
	}
	function Jump() {
	a = a + 1;
	//self.moveBy((Math.random() * a * 2 - a), (Math.random() * a * 2) - a);
	}
//  End --> */
</script>



<meta name="citation_publisher" content="ACM"> <meta name="citation_title" content="ACM SIGGRAPH 2008 papers"> <meta name="citation_date" content="08/11/2008"> <meta name="citation_isbn" content="978-1-4503-0112-1"> <meta name="citation_abstract_html_url" content="http://dl.acm.org/citation.cfm?id=1399504"> 



<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFAJAXPROXY');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFFORM');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFDIV');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFTEXTAREA');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFWINDOW');
</script>

<script type="text/javascript">
	var _cf_window_init_1338240376028=function()
	{
		_cf_bind_init_1338240376029=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'theguide_body','bindExpr':['whatisguide.cfm']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240376029);var _cf_window=ColdFusion.Window.create('theguide','The ACM Guide to Computing Literature','whatisguide.cfm',{ modal:false, closable:true, divid:'cf_window1338240376027', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240376028);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240376031=function()
	{
		_cf_bind_init_1338240376032=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'thetags_body','bindExpr':['showthetags.cfm?id=1399504']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240376032);var _cf_window=ColdFusion.Window.create('thetags','All Tags','showthetags.cfm?id=1399504',{ modal:false, closable:true, divid:'cf_window1338240376030', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240376031);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240376034=function()
	{
		var _cf_window=ColdFusion.Window.create('theformats','Export Formats','',{ modal:false, closable:true, divid:'cf_window1338240376033', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:250, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240376034);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240376036=function()
	{
		var _cf_window=ColdFusion.Window.create('theexplaination','','',{ modal:false, closable:true, divid:'cf_window1338240376035', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240376036);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240376038=function()
	{
		var _cf_window=ColdFusion.Window.create('theservices','','',{ modal:false, closable:true, divid:'cf_window1338240376037', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240376038);
</script>

<script type="text/javascript">
	var _cf_window_init_1338240376040=function()
	{
		_cf_bind_init_1338240376041=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'savetobinder_body','bindExpr':['savetobinder.cfm?id=1399504']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338240376041);var _cf_window=ColdFusion.Window.create('savetobinder','Save to Binder','savetobinder.cfm?id=1399504',{ modal:false, closable:true, divid:'cf_window1338240376039', draggable:true, resizable:true, fixedcenter:true, width:600, height:600, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false, _cf_refreshOnShow:true});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338240376040);
</script>
</head>

<body style="text-align:center" onLoad="window.focus();">

<script type="text/javascript">
						addthis_pub             = 'acm'; 
						//addthis_logo            = 'http://www.addthis.com/images/yourlogo.png';
						addthis_logo            = 'http://dl.acm.org/images/ACM_transparent.png';
						addthis_logo_background = 'c2d5fc';
						addthis_logo_color      = '000000';
						addthis_brand           = 'Citation Page';
						addthis_options         = 'favorites, email, slashdot, citeulike, digg, delicious, twitter, myspace, facebook, google, more';
						</script>
                        
<script src='AC_RunActiveContent.js' type="text/javascript"></script>




<div style="width:940px; margin-left: auto; margin-right: auto; text-align:left">
<a id="CIT"></a>



<table style="table-layout:fixed; margin-top: 5px; margin-bottom: 10px; border:0px; width:100%; border-collapse:collapse;">
	
    <tr style="vertical-align:top">
		
		<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; width:300px" class="small-link-text"  ><img src="http://dl.acm.org/images/ACMDL_Logo.jpg" alt="ACM DL" style="border:0px" usemap="#port" />
		</td>
        
        <td style="padding-left: 5px; padding-right:10px; padding-bottom:0px;" class="small-link-text">
        	<table style="width:100%; border-collapse:collapse; padding:0px">
			<tr><td style="text-align:center">
				
                            <div style="margin:0px auto;color:#356b20;font-size:10pt;line-height:10%;"> </div>
                    
					</td>		
			</tr>
			</table> 
        </td>
		<td style="padding-top: 0px; padding-left: 0px; padding-bottom:0px; text-align:right;" class="small-link-text">
			 <p style="margin-top:0px; margin-bottom:10px;">
					
                            <a href="https://dl.acm.org/signin.cfm?cfid=85074889&amp;cftoken=32802275" class="small-link-text" title="Sign in to personalize your Digital Library experience">SIGN IN</a>
                            &nbsp;&nbsp;<a href="https://dl.acm.org/signin.cfm?cfid=85074889&amp;cftoken=32802275"  class="small-link-text" title="Sign up to personalize your Digital Library experience">SIGN UP</a>
						
			 </p>
            
			<table style="padding: 5px; border-collapse:collapse; float:right">
				
				
                            
                            <tr>
                            <td class="small-link-text" style="text-align:right">
                            <form name="qiksearch" action="results.cfm?h=1&amp;cfid=85074889&amp;cftoken=32802275" method="post">
                           
                           
                            
                                     
                                    <span style="margin-left:0px"><label><input type="text" name="query" size="34" value=" " /></label>&nbsp;
                                    <input style="vertical-align:top;" type="image" alt="Search" name="Go" src="http://dl.acm.org/images/search_small.jpg" />
                                    
                                    </span>
							  </form>
                                </td>
                            </tr>
                          
				  
			</table>

			
			
		</td>

	</tr>
    
    
    <tr><td colspan="3" class="small-link-text" style="padding-bottom:5px; padding-top:0px; text-align:center">
		<div style="margin:0px auto;color:#356b20;line-height:10%;"> </div>
         
         </td>
    </tr>
    </table>
	
<map name="port" id="port" > 
  <area shape="rect" coords="1,1,60,50" href="http://www.acm.org/" alt="ACM Home Page" />
  <area shape="rect" coords="65,1,275,68" href="http://dl.acm.org/dl.cfm?CFID=85074889&CFTOKEN=32802275" alt="ACM Digital Library Home Page" />
</map>

<table style="table-layout:fixed; padding-bottom:10px; width:100%; padding:0px;">
	<tr style="vertical-align:top">
		<td style="padding-right:10px; text-align:left" class="small-link-text">
        	<div id="divmain" style="border:1px solid #356b20;">
				 
				<div class="large-text" style="text-align:left; margin-left:2px;margin-bottom:5px;">
					
                    	<h1 class="mediumb-text" style="margin-top:0px; margin-bottom:0px;"><strong>ACM SIGGRAPH 2008 papers</strong></h1>
                        
                </div>
                
                  

<table class="medium-text" style="border-collapse:collapse; padding:0px;">

<col style="width:540px" />

<tr style="vertical-align:top">
  <td>
    <table style="border-collapse:collapse; padding:2px;" class="medium-text">
      <col style="width:80px;" />
      <col style="width:auto" />
      <tr style="vertical-align:top">
        
      </tr>
    </table>

	
        <table style="margin-top: 10px" border="0" class="medium-text" cellpadding="2" cellspacing="0">
            <tr><td><table border="0" class="medium-text" cellpadding="1" cellspacing="0">

<tr valign="top">
    <td rowspan="20" nowrap="nowrap" align="center" style="padding-top:0px;">Publication of:<br />
     
                    	
					<a href="http://www.siggraph.org/s2008" title="Conference Website" target="_blank"><img style="margin-top:5px; border-width:1px; border-color:black" src="http://portalparts.acm.org/conference_logos/s2008.jpg" height="55"  width="79" alt="Cover Image" /></a><br />
					
                    
    </td>
</tr>
<tr><td>&nbsp;</td></tr>
 
	<tr valign="top">
    	<td nowrap="nowrap" style="padding-bottom:0px">&middot;&nbsp;Conference</td>
	</tr>
    <tr valign="top">
	    <td style="padding-left:10px;">
		   <a href="http://www.siggraph.org/s2008" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '08</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    
    <tr valign="top">
	    <td style="padding-left:10px; padding-bottom:10px"> Los Angeles, CA, USA &mdash; August 11 - 15, 2008
                    
                  <br />
                    
                  <a href="http://www.acm.org/publications" class="small-link-text" title="ACM">ACM</a> <span class="small-link-text">New York, NY</span><span class="small-link-text">, USA</span> <span class="small-link-text">  &copy;2008</span> 
                  <br />           
                  
      </td>
	</tr>
	 

</table></td></tr>
        </table>
    

  </td>

  <td rowspan="20" nowrap="nowrap">
	<table border="0" class="medium-text" cellpadding="0" cellspacing="0">
		<tr>
        	<td align="center" style="padding-bottom: 5px;">
			  
               
              </td>
              <td valign="top" align="left" nowrap="nowrap">
	             <img src="images/acm_mini.jpg" title="Published by ACM" alt="Published by ACM" /> 2008 Proceeding<br />
                 
        	 </td>
        </tr>
        
        <tr>
        	<td colspan="2" valign="baseline" style="padding-bottom:5px;">
            <img src="img/stats.jpg" alt="Bibliometrics Data" />&nbsp;
            <a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a>
            </td>
         </tr>
         <tr>
            <td  class="small-text" colspan="2" valign="top" style="padding-left:30px;">
				
	                    	&middot;&nbsp;Downloads (6 Weeks): 1,829<br />
    	                    &middot;&nbsp;Downloads (12 Months): 17,290<br />
                          
                        &middot;&nbsp;Citation Count: 1,423 
			</td>
         </tr>

	</table>
  </td>
</tr>
</table>

<br clear="all" />

                  
                 <br clear="all" />
			</div>
			
		</td>
		<td style="padding-left: 5px; vertical-align:top; text-align:left; width:170px" class="small-link-text">
	
            <div id="divtools" style="background-color:#ece9d8; text-align:left; padding-top:5px; padding-bottom:5px; ">
              <div class="medium-text" style="margin-left:3px; margin-top:10px;"><h1 class="mediumb-text" style="margin-top:-15px;"><strong>Tools and Resources</strong></h1></div>


<ul title="Tools and Resources" style="list-style: none; list-style-position:inside;
margin-left: 0px;
padding-left: 0em;
text-indent: 5px;
margin-bottom: 0px;">


<li style="list-style-image:url(img/toc_small.gif);margin-top:10px;"><span style="margin-left:6px;">
   <span class="small-link-text">TOC Service:</span>
   	  
	  <img src="http://dl.acm.org/images/blanks.gif" border="0" alt="Spacer Image reserves space for checkmark when TOC Service is updated" name="saved" />
      <ul style="margin-left: 0; padding-left: 0; display:inline;">
      	
        <li style="list-style:none; display:inline"><br /><img src="img/email_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Email</a></li>
        <li style="list-style:none; display:inline"><img src="img/rss_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');"  class="small-link-text">RSS</a></li>
		        
      </ul>
    </span>
</li>

        <li style="list-style-image:url(img/binder.gif);margin-top:10px;"><span style="margin-left:6px;">
        <a href="citation.cfm?id=1399504&preflayout=flat#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Save to Binder</a>
         </span></li>
    




<li style="list-style-image:url(img/binder_green.gif);margin-top:10px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Export Formats:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1399504&expformat=bibtex','theformats');" class="small-link-text">BibTeX</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1399504&expformat=endnotes','theformats');" class="small-link-text">EndNote</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1399504&expformat=acmref','theformats');" class="small-link-text">ACM&nbsp;Ref</a></li>
      </ul>
    </span>
</li>



 
   <li style="list-style-image:url(img/calbullet.jpg);margin-top:15px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Upcoming Conference:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px; margin-left:25px;"><a href="http://www.siggraph.org" title="Special Interest Group on Computer Graphics and Interactive Techniques Conference" class="small-link-text">SIGGRAPH '12</a></li>
      </ul>
    </span>
	</li>
    


</ul>           

  <!-- ADDTHIS BUTTON BEGIN -->
  
  <!-- ADDTHIS BUTTON END -->

<p class="small-link-text" style="padding-top: 0px; margin-left:6px; margin-bottom:0px">Share:</p>
  <!-- AddThis Button BEGIN -->



<!-- AddThis Button BEGIN -->
<div style="margin-left:5px;" class="addthis_toolbox addthis_default_style">
<a class="addthis_button_email"></a>
<a class="addthis_button_facebook"></a>
<a class="addthis_button_google"></a>
<a class="addthis_button_twitter"></a>
<a class="addthis_button_slashdot"></a>
<a class="addthis_button_reddit"></a>


<span class="addthis_separator">|</span>
<a href="http://www.addthis.com/bookmark.php?v=250&amp;username=acm" class="addthis_button_expanded" title="more"></a>
</div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=acm"></script>
<!-- AddThis Button END -->

  
 

  
  
            </div>
            
		</td>
	</tr>
    
</table>



</div>


<div class="layout" style="width:940px; margin-left: auto; margin-right: auto; text-align:left">




<div id="fback" style="text-align:left; padding-top:10px; padding-bottom:20px">
<span class="small-text" style="padding-right:10px; margin-bottom:0px;">
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design" style=" vertical-align:middle"><img src="img/feedbackg.gif" width="20" height="19" alt="feedback" border="0" /></a>
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design"><strong>Feedback</strong></a>

<span style="padding:10px;">|</span>




<span>Switch to <a href="citation.cfm?id=1399504&amp;preflayout=tabs">tabbed view</a> <noscript> (javascript required)</noscript></span>


</span>

 
<div class="small-text" style="margin-top:10px; margin-bottom:5px;"> 
<br />

    <a href="#abstract"  title="Abstract" style="padding:5px"><span>Abstract</span></a> |
    
    <a href="#authors"  title="Authors" style="padding:5px"><span style='color:#999999'>Authors</span></a> |
    <a href="#references"  title="References" style="padding:5px"><span style='color:#999999'>References</span></a> |
    <a href="#citedby"  title="Cited By" style="padding:5px"><span style='color:#999999'>Cited By</span></a> |
    <a href="#indexterms"  title="Index Terms" style="padding:5px"><span style='color:#999999'>Index Terms</span></a> |
    <a href="#source"  title="Publication" style="padding:5px"><span>Publication</span></a> |
    <a href="#revs"  title="Reviews" style="padding:5px"><span style='color:#999999'>Reviews</span></a> |               
	<a href="#comments"  title="Comments" style="padding:5px"><span>Comments</span></a>
	
     |               
	<a href="#prox"  title="Table of Contents" style="padding:5px"><span>Table of Contents</span></a>
    
</div>
    
<div style="right: 0pt; border-top:1px solid #356b20; font-size:1px; margin-bottom:20px;"/>



</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="abstract" class="small-text">ABSTRACT</A></h1>
       	
			<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

			

		
			
           
			
				
				<p>
					<div style="display:inline"><p>I have often been asked for suggestions on how to manage one's time at SIGGRAPH, given that there are always so many things going on at once. My answer is always the same. I prefer to immerse myself in as many technical papers sessions as possible so that I can hear about all of the wonderful new research directly from the authors. Of course you can read papers before or after the conference, but I almost always find that the best introduction to the ideas is the author's own words and images from their talks. Part of what makes the SIGGRAPH conference so special is the care that the authors put into their presentations, making the talks a joy to attend. This year the papers program is filled with exciting papers that span the entire range of topics in graphics. I hope that you will take the opportunity to attend many of the talks so that you can enjoy these new research contributions more fully.</p> <p>There were 518 papers submitted to the ACM SIGGRAPH 2008 Technical Papers Program, and 90 of these papers were accepted to the conference. These paper counts have more meaning when compared to previous conferences, and I refer you to the table and graph at the end of this preface to see the submission and acceptance rates for earlier SIGGRAPH conferences. What you will find is that the number of submissions this year took a big jump from previous years, but that the acceptance rate is in line with previous years.</p> <p>The biggest change to the technical papers program this year is the introduction of TOG presentations to SIGGRAPH. Every author of a paper appearing this year in the ACM Transactions on Graphics (TOG) has the opportunity to give a full presentation of their work in a SIGGRAPH technical papers session. As I write this, the October 2008 issue of TOG has yet to be compiled, so we do not know the exact number of TOG presentations that will be at the conference. Our best guess is that roughly 30 such TOG presentations will be given, spread over seven or eight different papers sessions. This important change to the conference was the result of long deliberations by a working group that was led by Rob Cook, and that also included Adam Finkelstein, John Hart, Jessica Hodgins, Holly Rushmeier and myself.</p> <p>In addition to TOG presentations at SIGGRAPH, there is another way that TOG and SIGGRAPH are tied together. For several years now, in addition to the choices of "accept" or "reject", there has been a third option in the review process for papers submitted to SIGGRAPH. If the reviewers think that the content of a paper is SIGGRAPH quality, but that the paper needs more revisions than time permits in the conference review cycle, such a paper can be designated as "reject and refer to TOG." Then, if the authors wish, their paper can be brought into the TOG review process, carrying with it the SIGGRAPH reviews and the ongoing input from the SIGGRAPH papers committee members that made the referral. This year, 24 papers were referred to TOG in this manner.</p> <p>One of the most important responsibilities of the SIGGRAPH papers chair is to seek out ways in which the papers review process can be improved. The SIGGRAPH review process is considered by many to be a model of fairness and care. I have talked to papers chairs from other computer science conferences that have deliberately borrowed ideas from the SIGGRAPH review process to improve their own conference. One of the most frequent comments that I hear from first-time papers committee members is how much better they feel about the review process once they have seen what the face-to-face papers committee meeting is like. As good as the review process is, however, there is always room for improvements. A concern that is sometimes voiced is that papers committee members have too much control over the decision-making process for papers, in contrast to the tertiary reviewers who do not attend the PC meeting. To help address this issue, all tertiary reviewers this year were able to post to the public bulletin-board during the rebuttal phase of reviews. In addition, I asked all of the reviewers (including tertiaries) to try to reach a reviewer consensus for each paper prior to the papers committee meeting, via discussions on the private bulletin-boards. I view this as the logical progression that has been taking place over the last several years of including tertiary reviewers more in the decision process.</p></div>
				</p>
   				
           	</div>
			
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="authors" class="small-text"><SPAN class="heading">AUTHORS</SPAN></A></h1>
		
             <div class="small-text" style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;">
                  Author information is not available
              </div>            

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="references" class="small-text"><SPAN class="heading">REFERENCES</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	References are not available

</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="citedby" class="small-text"><SPAN class="heading">CITED BY</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	Citings are not available
		
 </div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="indexterms" class="small-text"><SPAN class="heading">INDEX TERMS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

Index Terms are not available


</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="source" class="small-text"><SPAN class="heading">PUBLICATION</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">



<table border="0" class="medium-text" cellpadding="0" cellspacing="5">



    <tr valign="top">
    	<td>Title</td> 
	    <td>
		   <a href="http://www.siggraph.org/s2008" title="Conference Website"  target="_self" class="link-text">SIGGRAPH '08</a> Special Interest Group on Computer Graphics and Interactive Techniques Conference 
        </td>
	</tr>
    <tr><td></td><td>Los Angeles, CA, USA &mdash; August 11 - 15, 2008</td></tr> <tr><td>Pages</td><td>887</td></tr> 
                 <tr>
                 
                     <td>Sponsor</td>
                    
                  <td>
                  <a href="sig.cfm?id=SP932&CFID=85074889&CFTOKEN=32802275"> SIGGRAPH</a> ACM Special Interest Group on Computer Graphics and Interactive Techniques
                  </td>
                  </tr>
              
                  <tr><td>Publisher</td><td><a href="http://www.acm.org/publications">ACM</a> New York, NY, USA</td>
				  </tr>
             <tr><td>ISBN</td><td> 978-1-4503-0112-1</td></tr> <tr><td>Order Number</td><td>428083</td></tr> 
			<tr valign="top">
        	<td>Conference</td>
            <td valign="top" align="left"  style="padding-bottom: 25px;">
	            <strong style="padding-right:10px">GRAPH</strong><a href="event.cfm?id=RE214&CFID=85074889&CFTOKEN=32802275" title="International Conference on Computer Graphics and Interactive Techniques">International Conference on Computer Graphics and Interactive Techniques</a>
                
                       
                        <a href="event.cfm?id=RE214&CFID=85074889&CFTOKEN=32802275" title="International Conference on Computer Graphics and Interactive Techniques"><img border="0" src="http://portalparts.acm.org/event_logos/382/382.jpg" title="GRAPH logo" height="100"  width="100" ALT="GRAPH logo" style="vertical-align:top"></a>
						 

        	 </td>
            </tr>
		    <tr><td colspan="2">Paper Acceptance Rate 90 of 518 submissions, 17%</td></tr> <tr valign="top"><td style="pading-top:20px;" colspan="2">Overall Acceptance Rate 2,079 of 8,858 submissions, 23%</td></tr>
                       <tr valign="top">
                        <td colspan="2" style="padding-left:25px;">
                        	<table>
                            	<tr><td>
                                        <!-- WebCharts3D v5.1(2077) -->
<IMG SRC="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=Images/5240418480583957.JPG" id="Images_5240418480583957_JPG" name="Images_5240418480583957_JPG" usemap="#Images_5240418480583957_JPG_map" border="0"/>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAB' id='GP1338240396625AAAB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>120</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAC' id='GP1338240396625AAAC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '78</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>64</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAD' id='GP1338240396625AAAD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>110</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAE' id='GP1338240396625AAAE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '79</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAF' id='GP1338240396625AAAF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAG' id='GP1338240396625AAAG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '80</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAH' id='GP1338240396625AAAH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>132</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAI' id='GP1338240396625AAAI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '81</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAJ' id='GP1338240396625AAAJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>118</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAK' id='GP1338240396625AAAK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '84</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>41</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAL' id='GP1338240396625AAAL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>175</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAM' id='GP1338240396625AAAM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '85</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>35</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAN' id='GP1338240396625AAAN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAO' id='GP1338240396625AAAO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '87</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>33</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAP' id='GP1338240396625AAAP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>161</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAQ' id='GP1338240396625AAAQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '88</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>34</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAR' id='GP1338240396625AAAR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>190</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAS' id='GP1338240396625AAAS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '89</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>38</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAT' id='GP1338240396625AAAT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>210</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAU' id='GP1338240396625AAAU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '90</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>43</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAV' id='GP1338240396625AAAV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>213</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAW' id='GP1338240396625AAAW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '92</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAX' id='GP1338240396625AAAX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>225</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAY' id='GP1338240396625AAAY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '93</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>46</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AAAZ' id='GP1338240396625AAAZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>242</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABA' id='GP1338240396625AABA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '94</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>57</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABB' id='GP1338240396625AABB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABC' id='GP1338240396625AABC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '95</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>56</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABD' id='GP1338240396625AABD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>247</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABE' id='GP1338240396625AABE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '96</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABF' id='GP1338240396625AABF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>265</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABG' id='GP1338240396625AABG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '97</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>48</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABH' id='GP1338240396625AABH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>303</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABI' id='GP1338240396625AABI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '98</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>45</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABJ' id='GP1338240396625AABJ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>320</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABK' id='GP1338240396625AABK'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '99</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>52</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABL' id='GP1338240396625AABL'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>304</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABM' id='GP1338240396625AABM'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '00</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>59</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABN' id='GP1338240396625AABN'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>300</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABO' id='GP1338240396625AABO'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '01</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>65</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABP' id='GP1338240396625AABP'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABQ' id='GP1338240396625AABQ'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '02</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>257</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABR' id='GP1338240396625AABR'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>424</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABS' id='GP1338240396625AABS'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '03</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>81</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABT' id='GP1338240396625AABT'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>478</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABU' id='GP1338240396625AABU'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '04</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>83</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABV' id='GP1338240396625AABV'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>461</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABW' id='GP1338240396625AABW'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '05</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>98</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABX' id='GP1338240396625AABX'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>474</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABY' id='GP1338240396625AABY'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '06</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>86</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AABZ' id='GP1338240396625AABZ'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>455</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACA' id='GP1338240396625AACA'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '07</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>108</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACB' id='GP1338240396625AACB'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>518</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACC' id='GP1338240396625AACC'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '08</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>90</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACD' id='GP1338240396625AACD'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>439</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACE' id='GP1338240396625AACE'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '09</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>78</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACF' id='GP1338240396625AACF'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>390</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACG' id='GP1338240396625AACG'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '10</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>103</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACH' id='GP1338240396625AACH'><tr><td width='8'>&nbsp;</td><td width='82'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>432</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338240396625AACI' id='GP1338240396625AACI'><tr><td width='8'>&nbsp;</td><td width='82'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>SIGGRAPH '11</td></tr><tr><td width='8'>&nbsp;</td><td width='82'>82</td></tr></table>
<MAP name='Images_5240418480583957_JPG_map'>
<AREA shape='rect' coords='0,0,1,1'/>
<AREA shape="rect" coords="287,179,290,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACI",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACI",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACI",event)'/>
<AREA shape="rect" coords="284,92,287,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACH",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACH",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACH",event)'/>
<AREA shape="rect" coords="278,174,281,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACG",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACG",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACG",event)'/>
<AREA shape="rect" coords="275,103,278,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACF",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACF",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACF",event)'/>
<AREA shape="rect" coords="270,180,273,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACE",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACE",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACE",event)'/>
<AREA shape="rect" coords="267,90,270,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACD",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACD",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACD",event)'/>
<AREA shape="rect" coords="261,177,264,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACC",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACC",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACC",event)'/>
<AREA shape="rect" coords="258,71,261,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACB",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACB",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACB",event)'/>
<AREA shape="rect" coords="253,173,256,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACA",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AACA",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AACA",event)'/>
<AREA shape="rect" coords="250,87,253,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABZ",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABZ",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABZ",event)'/>
<AREA shape="rect" coords="244,178,247,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABY",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABY",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABY",event)'/>
<AREA shape="rect" coords="241,82,244,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABX",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABX",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABX",event)'/>
<AREA shape="rect" coords="235,175,238,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABW",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABW",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABW",event)'/>
<AREA shape="rect" coords="232,85,235,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABV",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABV",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABV",event)'/>
<AREA shape="rect" coords="227,179,230,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABU",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABU",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABU",event)'/>
<AREA shape="rect" coords="224,81,227,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABT",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABT",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABT",event)'/>
<AREA shape="rect" coords="218,179,221,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABS",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABS",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABS",event)'/>
<AREA shape="rect" coords="215,94,218,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABR",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABR",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABR",event)'/>
<AREA shape="rect" coords="210,136,213,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABQ",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABQ",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABQ",event)'/>
<AREA shape="rect" coords="207,136,210,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABP",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABP",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABP",event)'/>
<AREA shape="rect" coords="201,183,204,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABO",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABO",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABO",event)'/>
<AREA shape="rect" coords="198,125,201,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABN",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABN",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABN",event)'/>
<AREA shape="rect" coords="192,185,195,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABM",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABM",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABM",event)'/>
<AREA shape="rect" coords="189,124,192,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABL",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABL",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABL",event)'/>
<AREA shape="rect" coords="184,187,187,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABK",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABK",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABK",event)'/>
<AREA shape="rect" coords="181,120,184,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABJ",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABJ",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABJ",event)'/>
<AREA shape="rect" coords="175,188,178,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABI",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABI",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABI",event)'/>
<AREA shape="rect" coords="172,124,175,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABH",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABH",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABH",event)'/>
<AREA shape="rect" coords="167,188,170,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABG",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABG",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABG",event)'/>
<AREA shape="rect" coords="164,134,167,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABF",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABF",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABF",event)'/>
<AREA shape="rect" coords="158,187,161,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABE",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABE",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABE",event)'/>
<AREA shape="rect" coords="155,138,158,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABD",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABD",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABD",event)'/>
<AREA shape="rect" coords="149,186,152,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABC",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABC",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABC",event)'/>
<AREA shape="rect" coords="146,136,149,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABB",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABB",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABB",event)'/>
<AREA shape="rect" coords="141,185,144,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABA",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AABA",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AABA",event)'/>
<AREA shape="rect" coords="138,139,141,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAZ",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAZ",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAZ",event)'/>
<AREA shape="rect" coords="132,188,135,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAY",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAY",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAY",event)'/>
<AREA shape="rect" coords="129,144,132,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAX",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAX",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAX",event)'/>
<AREA shape="rect" coords="124,188,127,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAW",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAW",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAW",event)'/>
<AREA shape="rect" coords="121,147,124,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAV",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAV",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAV",event)'/>
<AREA shape="rect" coords="115,189,118,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAU",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAU",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAU",event)'/>
<AREA shape="rect" coords="112,147,115,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAT",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAT",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAT",event)'/>
<AREA shape="rect" coords="106,190,109,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAS",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAS",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAS",event)'/>
<AREA shape="rect" coords="103,152,106,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAR",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAR",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAR",event)'/>
<AREA shape="rect" coords="98,191,101,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAQ",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAQ",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAQ",event)'/>
<AREA shape="rect" coords="95,160,98,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAP",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAP",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAP",event)'/>
<AREA shape="rect" coords="89,191,92,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAO",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAO",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAO",event)'/>
<AREA shape="rect" coords="86,165,89,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAN",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAN",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAN",event)'/>
<AREA shape="rect" coords="81,191,84,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAM",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAM",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAM",event)'/>
<AREA shape="rect" coords="78,156,81,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAL",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAL",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAL",event)'/>
<AREA shape="rect" coords="72,189,75,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAK",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAK",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAK",event)'/>
<AREA shape="rect" coords="69,170,72,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAJ",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAJ",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAJ",event)'/>
<AREA shape="rect" coords="63,190,66,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAI",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAI",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAI",event)'/>
<AREA shape="rect" coords="60,167,63,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAH",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAH",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAH",event)'/>
<AREA shape="rect" coords="55,187,58,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAG",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAG",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAG",event)'/>
<AREA shape="rect" coords="52,165,55,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAF",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAF",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAF",event)'/>
<AREA shape="rect" coords="46,189,49,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAE",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAE",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAE",event)'/>
<AREA shape="rect" coords="43,172,46,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAD",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAD",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAD",event)'/>
<AREA shape="rect" coords="38,184,41,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAC",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAC",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAC",event)'/>
<AREA shape="rect" coords="35,170,38,199" onMouseover='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAB",event,true)' onMouseout='xx_set_visible("Images_5240418480583957_JPG","GP1338240396625AAAB",event,false)' onMousemove='xx_move_tag("Images_5240418480583957_JPG","GP1338240396625AAAB",event)'/>
<AREA shape="rect" coords="160,13,227,27"/>
<AREA shape="rect" coords="89,13,160,27"/>
</MAP>

<script language="javascript" src="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=script.js"></script>

                                      </td>
                                      <td style="padding-left:20px;">
                                             <table style="border-width: 1px; border-style: solid; width:100%;  border-spacing: 6px;" class="text12">
                                                <tr bgcolor="#ffffff">
                                                  <th style="width:50%">Year</th>
                                                  <th  align="right" style="width:15%">Submitted</th>
                                                  <th  align="right" style="width:15%">Accepted</th>
                                                  <th  align="center">Rate</th>
                                                </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '78</td>
                                                            <td align="right">120</td>
                                                            <td align="right">64</td>
                                                            <td align="center">53%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '79</td>
                                                            <td align="right">110</td>
                                                            <td align="right">43</td>
                                                            <td align="center">39%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '80</td>
                                                            <td align="right">140</td>
                                                            <td align="right">52</td>
                                                            <td align="center">37%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '81</td>
                                                            <td align="right">132</td>
                                                            <td align="right">38</td>
                                                            <td align="center">29%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '84</td>
                                                            <td align="right">118</td>
                                                            <td align="right">41</td>
                                                            <td align="center">35%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '85</td>
                                                            <td align="right">175</td>
                                                            <td align="right">35</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '87</td>
                                                            <td align="right">140</td>
                                                            <td align="right">33</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '88</td>
                                                            <td align="right">161</td>
                                                            <td align="right">34</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '89</td>
                                                            <td align="right">190</td>
                                                            <td align="right">38</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '90</td>
                                                            <td align="right">210</td>
                                                            <td align="right">43</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '92</td>
                                                            <td align="right">213</td>
                                                            <td align="right">45</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '93</td>
                                                            <td align="right">225</td>
                                                            <td align="right">46</td>
                                                            <td align="center">20%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '94</td>
                                                            <td align="right">242</td>
                                                            <td align="right">57</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '95</td>
                                                            <td align="right">257</td>
                                                            <td align="right">56</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '96</td>
                                                            <td align="right">247</td>
                                                            <td align="right">52</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '97</td>
                                                            <td align="right">265</td>
                                                            <td align="right">48</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '98</td>
                                                            <td align="right">303</td>
                                                            <td align="right">45</td>
                                                            <td align="center">15%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '99</td>
                                                            <td align="right">320</td>
                                                            <td align="right">52</td>
                                                            <td align="center">16%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '00</td>
                                                            <td align="right">304</td>
                                                            <td align="right">59</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '01</td>
                                                            <td align="right">300</td>
                                                            <td align="right">65</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">358</td>
                                                            <td align="right">67</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '02</td>
                                                            <td align="right">257</td>
                                                            <td align="right">257</td>
                                                            <td align="center">100%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '03</td>
                                                            <td align="right">424</td>
                                                            <td align="right">81</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '04</td>
                                                            <td align="right">478</td>
                                                            <td align="right">83</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '05</td>
                                                            <td align="right">461</td>
                                                            <td align="right">98</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '06</td>
                                                            <td align="right">474</td>
                                                            <td align="right">86</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '07</td>
                                                            <td align="right">455</td>
                                                            <td align="right">108</td>
                                                            <td align="center">24%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '08</td>
                                                            <td align="right">518</td>
                                                            <td align="right">90</td>
                                                            <td align="center">17%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '09</td>
                                                            <td align="right">439</td>
                                                            <td align="right">78</td>
                                                            <td align="center">18%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>SIGGRAPH '10</td>
                                                            <td align="right">390</td>
                                                            <td align="right">103</td>
                                                            <td align="center">26%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>SIGGRAPH '11</td>
                                                            <td align="right">432</td>
                                                            <td align="right">82</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                 <tr bgcolor="#ffffff">
                                                    <td><strong>Overall</strong></td>
                                                    <td align="right">8,858</td>
                                                    <td align="right">2,079</td>
                                                    <td align="center">23%</td>
                                                  </tr>
                                                </table>
                                       </td>
                                     </tr>
                               </table>
                        </td>
                    </tr>
                     
                     
            
</table>


</table>




</div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="revs" class="small-text"><SPAN class="heading">REVIEWS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	<br />Reviews are not available for this item
        
        <div align="left" style="margin-top:30px">
					<a title="Computing Reviews" href="ocr_review_main.cfm?CFID=85074889&CFTOKEN=32802275">
                 <img src="http://dl.acm.org/images/ocrs-s.jpg" alt="Computing Reviews logo" border="0" style="vertical-align:middle"></a>
        
        
       		<ul style="list-style:disc; display:inline-block">
	            <li>Access <a href="ocr_review_main.cfm?CFID=85074889&CFTOKEN=32802275" target="_blank">critical reviews</a> of computing literature.</li>
            	<li><a href="http://www.computingreviews.com/Reviewer/"  target="_blank">Become a reviewer</a> for Computing Reviews</li>
            </ul>
        </div>
        
</div>



<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="comments" class="small-text"><SPAN class="heading">COMMENTS</SPAN></A></h1>
         
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<div>
<div>
	
	<p style="margin-left:5px;">
    <strong>Be the first to comment</strong>
    	
          	To Post a comment please <a href="signin.cfm?CFID=85074889&CFTOKEN=32802275">sign in or create</a> a free Web account</a>
        
    
    
	 </p>
	   	
 
</div>


</div>

	
		<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="prox" class="small-text">Table of Contents</A></h1>
        
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" >

<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">ACM SIGGRAPH 2008 papers</h5>


<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>

<div style="clear:both">
    
        <div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><a href="citation.cfm?id=1401132&picked=prox&CFID=85074889&CFTOKEN=32802275" title="previous: SIGGRAPH '08"><img hspace="5" align="absmiddle" border="0" src="img/prev.gif" width="19" height="11" alt="previous" />previous proceeding</a> <span style="padding-left:5px;padding-right:5px;">|</span><a href="citation.cfm?id=1401032&picked=prox&CFID=85074889&CFTOKEN=32802275" title="Next: SIGGRAPH '08">next proceeding <img align="absmiddle" hspace="5" border="0" src="img/next.gif" width="19" height="11" alt="next" /></a></div>
        
</div>


 
<table class="text12" border="0">

  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Image collections and video</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Aseem Agarwala 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360613&CFID=85074889&CFTOKEN=32802275">Factoring repeated content within and among images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100220529&CFID=85074889&CFTOKEN=32802275">Huamin Wang</a>, 
                        <a href="author_page.cfm?id=81100425952&CFID=85074889&CFTOKEN=32802275">Yonatan Wexler</a>, 
                        <a href="author_page.cfm?id=81100064088&CFID=85074889&CFTOKEN=32802275">Eyal Ofek</a>, 
                        <a href="author_page.cfm?id=81100397561&CFID=85074889&CFTOKEN=32802275">Hugues Hoppe</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 14</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360613" title="DOI">10.1145/1399504.1360613</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360613&ftid=534140&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360613&ftid=979777&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow2" style="display:inline;"><br /><div style="display:inline">We reduce transmission bandwidth and memory space for images by factoring their repeated content. A transform map and a condensed epitome are created such that all image blocks can be reconstructed from transformed epitome patches. The transforms may ...</div></span>
          <span id="toHide2" style="display:none;"><br /><div style="display:inline"><p>We reduce transmission bandwidth and memory space for images by factoring their repeated content. A transform map and a condensed epitome are created such that all image blocks can be reconstructed from transformed epitome patches. The transforms may include affine deformation and color scaling to account for perspective and tonal variations across the image. The factored representation allows efficient random-access through a simple indirection, and can therefore be used for real-time texture mapping without expansion in memory. Our scheme is orthogonal to traditional image compression, in the sense that the epitome is amenable to further compression such as DXT. Moreover it allows a new mode of progressivity, whereby generic features appear before unique detail. Factoring is also effective across a collection of images, particularly in the context of image-based rendering. Eliminating redundant content lets us include textures that are several times as large in the same memory space.</p></div></span> <a id="expcoll2" href="JavaScript: expandcollapse('expcoll2',2)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360614&CFID=85074889&CFTOKEN=32802275">Finding paths through the world's photos</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100156470&CFID=85074889&CFTOKEN=32802275">Noah Snavely</a>, 
                        <a href="author_page.cfm?id=81100629901&CFID=85074889&CFTOKEN=32802275">Rahul Garg</a>, 
                        <a href="author_page.cfm?id=81407593498&CFID=85074889&CFTOKEN=32802275">Steven M. Seitz</a>, 
                        <a href="author_page.cfm?id=81100122769&CFID=85074889&CFTOKEN=32802275">Richard Szeliski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 15</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360614" title="DOI">10.1145/1399504.1360614</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360614&ftid=534141&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360614&ftid=634568&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360614&ftid=977948&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow3" style="display:inline;"><br /><div style="display:inline">When a scene is photographed many times by different people, the viewpoints often cluster along certain paths. These paths are largely specific to the scene being photographed, and follow interesting regions and viewpoints. We seek to discover a range ...</div></span>
          <span id="toHide3" style="display:none;"><br /><div style="display:inline"><p>When a scene is photographed many times by different people, the viewpoints often cluster along certain paths. These paths are largely specific to the scene being photographed, and follow interesting regions and viewpoints. We seek to discover a range of such paths and turn them into controls for image-based rendering. Our approach takes as input a large set of community or personal photos, reconstructs camera viewpoints, and automatically computes orbits, panoramas, canonical views, and optimal paths between views. The scene can then be interactively browsed in 3D using these controls or with six degree-of-freedom free-viewpoint control. As the user browses the scene, nearby views are continuously selected and transformed, using control-adaptive reprojection techniques.</p></div></span> <a id="expcoll3" href="JavaScript: expandcollapse('expcoll3',3)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360615&CFID=85074889&CFTOKEN=32802275">Improved seam carving for video retargeting</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365595167&CFID=85074889&CFTOKEN=32802275">Michael Rubinstein</a>, 
                        <a href="author_page.cfm?id=81100081895&CFID=85074889&CFTOKEN=32802275">Ariel Shamir</a>, 
                        <a href="author_page.cfm?id=81100356625&CFID=85074889&CFTOKEN=32802275">Shai Avidan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 16</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360615" title="DOI">10.1145/1399504.1360615</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360615&ftid=534142&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360615&ftid=979778&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow4" style="display:inline;"><br /><div style="display:inline">Video, like images, should support content aware resizing. We present video retargeting using an improved seam carving operator. Instead of removing 1D seams from 2D images we remove 2D seam manifolds from 3D space-time volumes. To achieve this we replace ...</div></span>
          <span id="toHide4" style="display:none;"><br /><div style="display:inline"><p>Video, like images, should support content aware resizing. We present video retargeting using an improved seam carving operator. Instead of removing 1D seams from 2D images we remove 2D seam manifolds from 3D space-time volumes. To achieve this we replace the dynamic programming method of seam carving with graph cuts that are suitable for 3D volumes. In the new formulation, a seam is given by a minimal cut in the graph and we show how to construct a graph such that the resulting cut is a valid seam. That is, the cut is monotonic and connected. In addition, we present a novel energy criterion that improves the visual quality of the retargeted images and videos. The original seam carving operator is focused on removing seams with the least amount of energy, ignoring energy that is introduced into the images and video by applying the operator. To counter this, the new criterion is looking forward in time - removing seams that introduce the least amount of energy into the retargeted result. We show how to encode the improved criterion into graph cuts (for images and video) as well as dynamic programming (for images). We apply our technique to images and videos and present results of various applications.</p></div></span> <a id="expcoll4" href="JavaScript: expandcollapse('expcoll4',4)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360616&CFID=85074889&CFTOKEN=32802275">Unwrap mosaics: a new representation for video editing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100464230&CFID=85074889&CFTOKEN=32802275">Alex Rav-Acha</a>, 
                        <a href="author_page.cfm?id=81339510339&CFID=85074889&CFTOKEN=32802275">Pushmeet Kohli</a>, 
                        <a href="author_page.cfm?id=81100467323&CFID=85074889&CFTOKEN=32802275">Carsten Rother</a>, 
                        <a href="author_page.cfm?id=81100376259&CFID=85074889&CFTOKEN=32802275">Andrew Fitzgibbon</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 17</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360616" title="DOI">10.1145/1399504.1360616</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360616&ftid=534143&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360616&ftid=977949&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow5" style="display:inline;"><br /><div style="display:inline">We introduce a new representation for video which facilitates a number of common editing tasks. The representation has some of the power of a full reconstruction of 3D surface models from video, but is designed to be easy to recover from a priori ...</div></span>
          <span id="toHide5" style="display:none;"><br /><div style="display:inline"><p>We introduce a new representation for video which facilitates a number of common editing tasks. The representation has some of the power of a full reconstruction of 3D surface models from video, but is designed to be easy to recover from <i>a priori</i> unseen and uncalibrated footage. By modelling the image-formation process as a 2D-to-2D transformation from an object's texture map to the image, modulated by an object-space occlusion mask, we can recover a representation which we term the "unwrap mosaic". Many editing operations can be performed on the unwrap mosaic, and then re-composited into the original sequence, for example resizing objects, repainting textures, copying/cutting/pasting objects, and attaching effects layers to deforming objects.</p></div></span> <a id="expcoll5" href="JavaScript: expandcollapse('expcoll5',5)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Parallelism</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Marc Olano 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360617&CFID=85074889&CFTOKEN=32802275">Larrabee: a many-core x86 architecture for visual computing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100625268&CFID=85074889&CFTOKEN=32802275">Larry Seiler</a>, 
                        <a href="author_page.cfm?id=81100308747&CFID=85074889&CFTOKEN=32802275">Doug Carmean</a>, 
                        <a href="author_page.cfm?id=81100251438&CFID=85074889&CFTOKEN=32802275">Eric Sprangle</a>, 
                        <a href="author_page.cfm?id=81100501844&CFID=85074889&CFTOKEN=32802275">Tom Forsyth</a>, 
                        <a href="author_page.cfm?id=81100515360&CFID=85074889&CFTOKEN=32802275">Michael Abrash</a>, 
                        <a href="author_page.cfm?id=81332496734&CFID=85074889&CFTOKEN=32802275">Pradeep Dubey</a>, 
                        <a href="author_page.cfm?id=81414617032&CFID=85074889&CFTOKEN=32802275">Stephen Junkins</a>, 
                        <a href="author_page.cfm?id=81100639760&CFID=85074889&CFTOKEN=32802275">Adam Lake</a>, 
                        <a href="author_page.cfm?id=81100529660&CFID=85074889&CFTOKEN=32802275">Jeremy Sugerman</a>, 
                        <a href="author_page.cfm?id=81365596562&CFID=85074889&CFTOKEN=32802275">Robert Cavin</a>, 
                        <a href="author_page.cfm?id=81100258369&CFID=85074889&CFTOKEN=32802275">Roger Espasa</a>, 
                        <a href="author_page.cfm?id=81100393360&CFID=85074889&CFTOKEN=32802275">Ed Grochowski</a>, 
                        <a href="author_page.cfm?id=81332507475&CFID=85074889&CFTOKEN=32802275">Toni Juan</a>, 
                        <a href="author_page.cfm?id=81100482576&CFID=85074889&CFTOKEN=32802275">Pat Hanrahan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 18</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360617" title="DOI">10.1145/1399504.1360617</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360617&ftid=534144&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360617&ftid=979779&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow7" style="display:inline;"><br /><div style="display:inline">This paper presents a many-core visual computing architecture code named Larrabee, a new software rendering pipeline, a manycore programming model, and performance analysis for several applications. Larrabee uses multiple in-order x86 CPU cores that ...</div></span>
          <span id="toHide7" style="display:none;"><br /><div style="display:inline"><p>This paper presents a many-core visual computing architecture code named Larrabee, a new software rendering pipeline, a manycore programming model, and performance analysis for several applications. Larrabee uses multiple in-order x86 CPU cores that are augmented by a wide vector processor unit, as well as some fixed function logic blocks. This provides dramatically higher performance per watt and per unit of area than out-of-order CPUs on highly parallel workloads. It also greatly increases the flexibility and programmability of the architecture as compared to standard GPUs. A coherent on-die 2<sup>nd</sup> level cache allows efficient inter-processor communication and high-bandwidth local data access by CPU cores. Task scheduling is performed entirely with software in Larrabee, rather than in fixed function logic. The customizable software graphics rendering pipeline for this architecture uses binning in order to reduce required memory bandwidth, minimize lock contention, and increase opportunities for parallelism relative to standard GPUs. The Larrabee native programming model supports a variety of highly parallel applications that use irregular data structures. Performance analysis on those applications demonstrates Larrabee's potential for a broad range of parallel computation.</p></div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360618&CFID=85074889&CFTOKEN=32802275">BSGP: bulk-synchronous GPU programming</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365597044&CFID=85074889&CFTOKEN=32802275">Qiming Hou</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=85074889&CFTOKEN=32802275">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074889&CFTOKEN=32802275">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 19</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360618" title="DOI">10.1145/1399504.1360618</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360618&ftid=534145&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360618&ftid=979780&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow8" style="display:inline;"><br /><div style="display:inline">We present BSGP, a new programming language for general purpose computation on the GPU. A BSGP program looks much the same as a sequential C program. Programmers only need to supply a bare minimum of extra information to describe parallel processing ...</div></span>
          <span id="toHide8" style="display:none;"><br /><div style="display:inline"><p>We present BSGP, a new programming language for general purpose computation on the GPU. A BSGP program looks much the same as a sequential C program. Programmers only need to supply a bare minimum of extra information to describe parallel processing on GPUs. As a result, BSGP programs are easy to read, write, and maintain. Moreover, the ease of programming does not come at the cost of performance. A well-designed BSGP compiler converts BSGP programs to kernels and combines them using optimally allocated temporary streams. In our benchmark, BSGP programs achieve similar or better performance than well-optimized CUDA programs, while the source code complexity and programming time are significantly reduced. To test BSGP's code efficiency and ease of programming, we implemented a variety of GPU applications, including a highly sophisticated X3D parser that would be extremely difficult to develop with existing GPU programming languages.</p></div></span> <a id="expcoll8" href="JavaScript: expandcollapse('expcoll8',8)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360619&CFID=85074889&CFTOKEN=32802275">Parallel Poisson disk sampling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81452594229&CFID=85074889&CFTOKEN=32802275">Li-Yi Wei</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 20</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360619" title="DOI">10.1145/1399504.1360619</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360619&ftid=534146&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360619&ftid=977950&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow9" style="display:inline;"><br /><div style="display:inline">Sampling is important for a variety of graphics applications include rendering, imaging, and geometry processing. However, producing sample sets with desired efficiency and blue noise statistics has been a major challenge, as existing methods are either ...</div></span>
          <span id="toHide9" style="display:none;"><br /><div style="display:inline"><p>Sampling is important for a variety of graphics applications include rendering, imaging, and geometry processing. However, producing sample sets with desired efficiency and blue noise statistics has been a major challenge, as existing methods are either sequential with limited speed, or are parallel but only through pre-computed datasets and thus fall short in producing samples with blue noise statistics. We present a Poisson disk sampling algorithm that runs in parallel and produces all samples on the fly with desired blue noise properties. Our main idea is to subdivide the sample domain into grid cells and we draw samples concurrently from multiple cells that are sufficiently far apart so that their samples cannot conflict one another. We present a parallel implementation of our algorithm running on a GPU with constant cost per sample and constant number of computation passes for a target number of samples. Our algorithm also works in arbitrary dimension, and allows adaptive sampling from a user-specified importance field. Furthermore, our algorithm is simple and easy to implement, and runs faster than existing techniques.</p></div></span> <a id="expcoll9" href="JavaScript: expandcollapse('expcoll9',9)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360620&CFID=85074889&CFTOKEN=32802275">Streaming multigrid for gradient-domain operations on large images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100017967&CFID=85074889&CFTOKEN=32802275">Michael Kazhdan</a>, 
                        <a href="author_page.cfm?id=81100397561&CFID=85074889&CFTOKEN=32802275">Hugues Hoppe</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 21</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360620" title="DOI">10.1145/1399504.1360620</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360620&ftid=534147&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360620&ftid=977951&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow10" style="display:inline;"><br /><div style="display:inline">We introduce a new tool to solve the large linear systems arising from gradient-domain image processing. Specifically, we develop a streaming multigrid solver, which needs just two sequential passes over out-of-core data. This fast solution is enabled ...</div></span>
          <span id="toHide10" style="display:none;"><br /><div style="display:inline"><p>We introduce a new tool to solve the large linear systems arising from gradient-domain image processing. Specifically, we develop a streaming multigrid solver, which needs just two sequential passes over out-of-core data. This fast solution is enabled by a combination of three techniques: (1) use of second-order finite elements (rather than traditional finite differences) to reach sufficient accuracy in a single V-cycle, (2) temporally blocked relaxation, and (3) multi-level streaming to pipeline the restriction and prolongation phases into single streaming passes. A key contribution is the extension of the B-spline finite-element method to be compatible with the forward-difference gradient representation commonly used with images. Our streaming solver is also efficient for in-memory images, due to its fast convergence and excellent cache behavior. Remarkably, it can outperform spatially adaptive solvers that exploit application-specific knowledge. We demonstrate seamless stitching and tone-mapping of gigapixel images in about an hour on a notebook PC.</p></div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Noisy collisions</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Miguel Otaduy 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360621&CFID=85074889&CFTOKEN=32802275">Spline joints for multibody dynamics</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100410859&CFID=85074889&CFTOKEN=32802275">Sung-Hee Lee</a>, 
                        <a href="author_page.cfm?id=81100294834&CFID=85074889&CFTOKEN=32802275">Demetri Terzopoulos</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 22</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360621" title="DOI">10.1145/1399504.1360621</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360621&ftid=534148&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360621&ftid=979781&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow12" style="display:inline;"><br /><div style="display:inline">Spline joints are a novel class of joints that can model general scleronomic constraints for multibody dynamics based on the minimal-coordinates formulation. The main idea is to introduce spline curves and surfaces in the modeling of joints: We ...</div></span>
          <span id="toHide12" style="display:none;"><br /><div style="display:inline"><p><i>Spline joints</i> are a novel class of joints that can model general scleronomic constraints for multibody dynamics based on the minimal-coordinates formulation. The main idea is to introduce spline curves and surfaces in the modeling of joints: We model 1-DOF joints using splines on SE(3), and construct multi-DOF joints as the product of exponentials of splines in Euclidean space. We present efficient recursive algorithms to compute the derivatives of the spline joint, as well as geometric algorithms to determine optimal parameters in order to achieve the desired joint motion. Our spline joints can be used to create interesting new simulated mechanisms for computer animation and they can more accurately model complex biomechanical joints such as the knee and shoulder.</p></div></span> <a id="expcoll12" href="JavaScript: expandcollapse('expcoll12',12)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360622&CFID=85074889&CFTOKEN=32802275">Robust treatment of simultaneous collisions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81410595560&CFID=85074889&CFTOKEN=32802275">David Harmon</a>, 
                        <a href="author_page.cfm?id=81365594364&CFID=85074889&CFTOKEN=32802275">Etienne Vouga</a>, 
                        <a href="author_page.cfm?id=81100289069&CFID=85074889&CFTOKEN=32802275">Rasmus Tamstorf</a>, 
                        <a href="author_page.cfm?id=81320489894&CFID=85074889&CFTOKEN=32802275">Eitan Grinspun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 23</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360622" title="DOI">10.1145/1399504.1360622</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360622&ftid=534149&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360622&ftid=979782&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow13" style="display:inline;"><br /><div style="display:inline">Robust treatment of complex collisions is a challenging problem in cloth simulation. Some state of the art methods resolve collisions iteratively, invoking a fail-safe when a bound on iteration count is exceeded. The best-known fail-safe rigidifies the ...</div></span>
          <span id="toHide13" style="display:none;"><br /><div style="display:inline"><p>Robust treatment of complex collisions is a challenging problem in cloth simulation. Some state of the art methods resolve collisions iteratively, invoking a fail-safe when a bound on iteration count is exceeded. The best-known fail-safe rigidifies the contact region, causing simulation artifacts. We present a fail-safe that cancels impact but not sliding motion, considerably reducing artificial dissipation. We equip the proposed fail-safe with an approximation of Coulomb friction, allowing finer control of sliding dissipation.</p></div></span> <a id="expcoll13" href="JavaScript: expandcollapse('expcoll13',13)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360623&CFID=85074889&CFTOKEN=32802275">Fast modal sounds with scalable frequency-domain synthesis</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365594092&CFID=85074889&CFTOKEN=32802275">Nicolas Bonneel</a>, 
                        <a href="author_page.cfm?id=81100408270&CFID=85074889&CFTOKEN=32802275">George Drettakis</a>, 
                        <a href="author_page.cfm?id=81100520793&CFID=85074889&CFTOKEN=32802275">Nicolas Tsingos</a>, 
                        <a href="author_page.cfm?id=81365596304&CFID=85074889&CFTOKEN=32802275">Isabelle Viaud-Delmon</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=85074889&CFTOKEN=32802275">Doug James</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 24</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360623" title="DOI">10.1145/1399504.1360623</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360623&ftid=534150&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360623&ftid=979783&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow14" style="display:inline;"><br /><div style="display:inline">Audio rendering of impact sounds, such as those caused by falling objects or explosion debris, adds realism to interactive 3D audiovisual applications, and can be convincingly achieved using modal sound synthesis. Unfortunately, mode-based computations ...</div></span>
          <span id="toHide14" style="display:none;"><br /><div style="display:inline"><p>Audio rendering of impact sounds, such as those caused by falling objects or explosion debris, adds realism to interactive 3D audiovisual applications, and can be convincingly achieved using modal sound synthesis. Unfortunately, mode-based computations can become prohibitively expensive when many objects, each with many modes, are impacted simultaneously. We introduce a fast sound synthesis approach, based on short-time Fourier Tranforms, that exploits the inherent sparsity of modal sounds in the frequency domain. For our test scenes, this "fast mode summation" can give speedups of 5--8 times compared to a time-domain solution, with slight degradation in quality. We discuss different reconstruction windows, affecting the quality of impact sound "attacks". Our Fourier-domain processing method allows us to introduce a scalable, real-time, audio processing pipeline for both recorded and modal sounds, with auditory masking and sound source clustering. To avoid abrupt computation peaks, such as during the simultaneous impacts of an explosion, we use crossmodal perception results on audiovisual synchrony to effect temporal scheduling. We also conducted a pilot perceptual user evaluation of our method. Our implementation results show that we can treat complex audiovisual scenes in real time with high quality.</p></div></span> <a id="expcoll14" href="JavaScript: expandcollapse('expcoll14',14)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360624&CFID=85074889&CFTOKEN=32802275">Backward steps in rigid body simulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100231532&CFID=85074889&CFTOKEN=32802275">Christopher D. Twigg</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=85074889&CFTOKEN=32802275">Doug L. James</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 25</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360624" title="DOI">10.1145/1399504.1360624</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360624&ftid=534151&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360624&ftid=977952&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow15" style="display:inline;"><br /><div style="display:inline">Physically based simulation of rigid body dynamics is commonly done by time-stepping systems forward in time. In this paper, we propose methods to allow time-stepping rigid body systems back-ward in time. Unfortunately, reverse-time integration ...</div></span>
          <span id="toHide15" style="display:none;"><br /><div style="display:inline"><p>Physically based simulation of rigid body dynamics is commonly done by time-stepping systems <i>forward</i> in time. In this paper, we propose methods to allow time-stepping rigid body systems <i>back-ward</i> in time. Unfortunately, reverse-time integration of rigid bodies involving frictional contact is mathematically ill-posed, and can lack unique solutions. We instead propose time-reversed rigid body integrators that can sample <i>possible</i> solutions when unique ones do not exist. We also discuss challenges related to dissipation-related energy gain, sensitivity to initial conditions, stacking, constraints and articulation, rolling, sliding, skidding, bouncing, high angular velocities, rapid velocity growth from micro-collisions, and other problems encountered when going against the usual flow of time.</p></div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Characters</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Karen Liu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360625&CFID=85074889&CFTOKEN=32802275">Clone attack! Perception of crowd variety</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81328489544&CFID=85074889&CFTOKEN=32802275">Rachel McDonnell</a>, 
                        <a href="author_page.cfm?id=81365593071&CFID=85074889&CFTOKEN=32802275">Mich&#233;al Larkin</a>, 
                        <a href="author_page.cfm?id=81100273715&CFID=85074889&CFTOKEN=32802275">Simon Dobbyn</a>, 
                        <a href="author_page.cfm?id=81100445174&CFID=85074889&CFTOKEN=32802275">Steven Collins</a>, 
                        <a href="author_page.cfm?id=81100465557&CFID=85074889&CFTOKEN=32802275">Carol O'Sullivan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 26</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360625" title="DOI">10.1145/1399504.1360625</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360625&ftid=534152&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360625&ftid=634569&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360625&ftid=979784&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow17" style="display:inline;"><br /><div style="display:inline">When simulating large crowds, it is inevitable that the models and motions of many virtual characters will be cloned. However, the perceptual impact of this trade-off has never been studied. In this paper, we consider the ways in which an impression ...</div></span>
          <span id="toHide17" style="display:none;"><br /><div style="display:inline"><p>When simulating large crowds, it is inevitable that the models and motions of many virtual characters will be cloned. However, the perceptual impact of this trade-off has never been studied. In this paper, we consider the ways in which an impression of variety can be created and the perceptual consequences of certain design choices. In a series of experiments designed to test people's perception of variety in crowds, we found that clones of appearance are far easier to detect than motion clones. Furthermore, we established that cloned models can be masked by color variation, random orientation, and motion. Conversely, the perception of cloned motions remains unaffected by the model on which they are displayed. Other factors that influence the ability to detect clones were examined, such as proximity, model type and characteristic motion. Our results provide novel insights and useful thresholds that will assist in creating more realistic, heterogeneous crowds.</p></div></span> <a id="expcoll17" href="JavaScript: expandcollapse('expcoll17',17)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360626&CFID=85074889&CFTOKEN=32802275">Real-time motion retargeting to highly varied user-created morphologies</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335491736&CFID=85074889&CFTOKEN=32802275">Chris Hecker</a>, 
                        <a href="author_page.cfm?id=81365598731&CFID=85074889&CFTOKEN=32802275">Bernd Raabe</a>, 
                        <a href="author_page.cfm?id=81365597694&CFID=85074889&CFTOKEN=32802275">Ryan W. Enslow</a>, 
                        <a href="author_page.cfm?id=81365597089&CFID=85074889&CFTOKEN=32802275">John DeWeese</a>, 
                        <a href="author_page.cfm?id=81365596316&CFID=85074889&CFTOKEN=32802275">Jordan Maynard</a>, 
                        <a href="author_page.cfm?id=81365598484&CFID=85074889&CFTOKEN=32802275">Kees van Prooijen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 27</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360626" title="DOI">10.1145/1399504.1360626</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360626&ftid=534153&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360626&ftid=634570&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360626&ftid=977953&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow18" style="display:inline;"><br /><div style="display:inline">Character animation in video games---whether manually keyframed or motion captured---has traditionally relied on codifying skeletons early in a game's development, and creating animations rigidly tied to these fixed skeleton morphologies. This paper ...</div></span>
          <span id="toHide18" style="display:none;"><br /><div style="display:inline"><p>Character animation in video games---whether manually keyframed or motion captured---has traditionally relied on codifying skeletons early in a game's development, and creating animations rigidly tied to these fixed skeleton morphologies. This paper introduces a novel system for animating characters whose morphologies are unknown at the time the animation is created. Our authoring tool allows animators to describe motion using familiar posing and key-framing methods. The system records the data in a morphology-independent form, preserving both the animation's structural relationships and its stylistic information. At runtime, the generalized data are applied to specific characters to yield pose goals that are supplied to a robust and efficient inverse kinematics solver. This system allows us to animate characters with highly varying skeleton morphologies that did not exist when the animation was authored, and, indeed, may be radically different than anything the original animator envisioned.</p></div></span> <a id="expcoll18" href="JavaScript: expandcollapse('expcoll18',18)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360627&CFID=85074889&CFTOKEN=32802275">Animating oscillatory motion with overlap: wiggly splines</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100215003&CFID=85074889&CFTOKEN=32802275">Michael Kass</a>, 
                        <a href="author_page.cfm?id=81365591492&CFID=85074889&CFTOKEN=32802275">John Anderson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 28</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360627" title="DOI">10.1145/1399504.1360627</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360627&ftid=534154&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360627&ftid=979785&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow19" style="display:inline;"><br /><div style="display:inline">Oscillatory motion is ubiquitous in computer graphics, yet existing animation techniques are ill-suited to its authoring. We introduce a new type of spline for this purpose, known as a "Wiggly Spline." The spline generalizes traditional piecewise cubics ...</div></span>
          <span id="toHide19" style="display:none;"><br /><div style="display:inline"><p>Oscillatory motion is ubiquitous in computer graphics, yet existing animation techniques are ill-suited to its authoring. We introduce a new type of spline for this purpose, known as a "Wiggly Spline." The spline generalizes traditional piecewise cubics when its resonance and damping are set to zero, but creates oscillatory animation when its resonance and damping are changed. The spline provides a combination of direct manipulation and physical realism. To create overlapped and propagating motion, we generate phase shifts of the Wiggly Spline, and use these to control appropriate degrees of freedom in a model. The phase shifts can be created directly by procedural techniques or through a paint-like interface. A further option is to derive the phase shifts statistically by analyzing a time-series of a simulation. In this case, the Wiggly Spline makes it possible to canonicalize a simulation, generalize it by providing frequency and damping controls and control it through direct manipulation.</p></div></span> <a id="expcoll19" href="JavaScript: expandcollapse('expcoll19',19)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360628&CFID=85074889&CFTOKEN=32802275">Example-based dynamic skinning in real time</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100646636&CFID=85074889&CFTOKEN=32802275">Xiaohan Shi</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=85074889&CFTOKEN=32802275">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81100393143&CFID=85074889&CFTOKEN=32802275">Yiying Tong</a>, 
                        <a href="author_page.cfm?id=81100041821&CFID=85074889&CFTOKEN=32802275">Mathieu Desbrun</a>, 
                        <a href="author_page.cfm?id=81100451028&CFID=85074889&CFTOKEN=32802275">Hujun Bao</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074889&CFTOKEN=32802275">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 29</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360628" title="DOI">10.1145/1399504.1360628</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360628&ftid=534155&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360628&ftid=977954&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow20" style="display:inline;"><br /><div style="display:inline">In this paper we present an approach to enrich skeleton-driven animations with physically-based secondary deformation in real time. To achieve this goal, we propose a novel, surface-based deformable model that can interactively emulate the dynamics of ...</div></span>
          <span id="toHide20" style="display:none;"><br /><div style="display:inline"><p>In this paper we present an approach to enrich skeleton-driven animations with physically-based secondary deformation in real time. To achieve this goal, we propose a novel, surface-based deformable model that can interactively emulate the dynamics of both low-and high-frequency volumetric effects. Given a surface mesh and a few sample sequences of its physical behavior, a set of motion parameters of the material are learned during an off-line preprocessing step. The deformable model is then applicable to any given skeleton-driven animation of the surface mesh. Additionally, our dynamic skinning technique can be entirely implemented on GPUs and executed with great efficiency. Thus, with minimal changes to the conventional graphics pipeline, our approach can drastically enhance the visual experience of skeleton-driven animations by adding secondary deformation in real time.</p></div></span> <a id="expcoll20" href="JavaScript: expandcollapse('expcoll20',20)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Hair and realistic rendering</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Bruce Walter 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360629&CFID=85074889&CFTOKEN=32802275">Hair photobooth: geometric and photometric acquisition of real hairstyles</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100495713&CFID=85074889&CFTOKEN=32802275">Sylvain Paris</a>, 
                        <a href="author_page.cfm?id=81365593074&CFID=85074889&CFTOKEN=32802275">Will Chang</a>, 
                        <a href="author_page.cfm?id=81365597646&CFID=85074889&CFTOKEN=32802275">Oleg I. Kozhushnyan</a>, 
                        <a href="author_page.cfm?id=81100389194&CFID=85074889&CFTOKEN=32802275">Wojciech Jarosz</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=85074889&CFTOKEN=32802275">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100289561&CFID=85074889&CFTOKEN=32802275">Matthias Zwicker</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074889&CFTOKEN=32802275">Fr&#233;do Durand</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 30</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360629" title="DOI">10.1145/1399504.1360629</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360629&ftid=534156&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360629&ftid=634571&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360629&ftid=979786&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow22" style="display:inline;"><br /><div style="display:inline">We accurately capture the shape and appearance of a person's hairstyle. We use triangulation and a sweep with planes of light for the geometry. Multiple projectors and cameras address the challenges raised by the reflectance and intricate geometry of ...</div></span>
          <span id="toHide22" style="display:none;"><br /><div style="display:inline"><p>We accurately capture the shape and appearance of a person's hairstyle. We use triangulation and a sweep with planes of light for the geometry. Multiple projectors and cameras address the challenges raised by the reflectance and intricate geometry of hair. We introduce the use of structure tensors to infer the hidden geometry between the hair surface and the scalp. Our triangulation approach affords substantial accuracy improvement and we are able to measure elaborate hair geometry including complex curls and concavities. To reproduce the hair appearance, we capture a six-dimensional reflectance field. We introduce a new reflectance interpolation technique that leverages an analytical reflectance model to alleviate cross-fading artifacts caused by linear methods. Our results closely match the real hairstyles and can be used for animation.</p></div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360630&CFID=85074889&CFTOKEN=32802275">Efficient multiple scattering in hair using spherical harmonics</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100243515&CFID=85074889&CFTOKEN=32802275">Jonathan T. Moon</a>, 
                        <a href="author_page.cfm?id=81100010986&CFID=85074889&CFTOKEN=32802275">Bruce Walter</a>, 
                        <a href="author_page.cfm?id=81100238316&CFID=85074889&CFTOKEN=32802275">Steve Marschner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 31</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360630" title="DOI">10.1145/1399504.1360630</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360630&ftid=534157&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360630&ftid=979787&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow23" style="display:inline;"><br /><div style="display:inline">Previous research has shown that a global multiple scattering simulation is needed to achieve physically realistic renderings of hair, particularly light-colored hair with low absorption. However, previous methods have either sacrificed accuracy or have ...</div></span>
          <span id="toHide23" style="display:none;"><br /><div style="display:inline"><p>Previous research has shown that a global multiple scattering simulation is needed to achieve physically realistic renderings of hair, particularly light-colored hair with low absorption. However, previous methods have either sacrificed accuracy or have been too computationally expensive for practical use. In this paper we describe a physically based, volumetric rendering method that computes multiple scattering solutions, including directional effects, much faster than previous accurate methods. Our two-pass method first traces light paths through a volumetric representation of the hair, contributing power to a 3D grid of spherical harmonic coefficients that store the directional distribution of scattered radiance everywhere in the hair volume. Then, in a ray tracing pass, multiple scattering is computed by integrating the stored radiance against the scattering functions of visible fibers using an efficient matrix multiplication. Single scattering is computed using conventional direct illumination methods. In our comparisons the new method produces quality similar to that of the best previous methods, but computes multiple scattering more than 10 times faster.</p></div></span> <a id="expcoll23" href="JavaScript: expandcollapse('expcoll23',23)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360631&CFID=85074889&CFTOKEN=32802275">Dual scattering approximation for fast multiple scattering in hair</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100187977&CFID=85074889&CFTOKEN=32802275">Arno Zinke</a>, 
                        <a href="author_page.cfm?id=81319505055&CFID=85074889&CFTOKEN=32802275">Cem Yuksel</a>, 
                        <a href="author_page.cfm?id=81100649702&CFID=85074889&CFTOKEN=32802275">Andreas Weber</a>, 
                        <a href="author_page.cfm?id=81100431503&CFID=85074889&CFTOKEN=32802275">John Keyser</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 32</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360631" title="DOI">10.1145/1399504.1360631</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360631&ftid=534158&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360631&ftid=977955&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow24" style="display:inline;"><br /><div style="display:inline">When rendering light colored hair, multiple fiber scattering is essential for the right perception of the overall hair color. In this context, we present a novel technique to efficiently approximate multiple fiber scattering for a full head of human ...</div></span>
          <span id="toHide24" style="display:none;"><br /><div style="display:inline"><p>When rendering light colored hair, multiple fiber scattering is essential for the right perception of the overall hair color. In this context, we present a novel technique to efficiently approximate multiple fiber scattering for a full head of human hair or a similar fiber based geometry. In contrast to previous ad-hoc approaches, our method relies on the physically accurate concept of the Bidirectional Scattering Distribution Functions and gives physically plausible results with no need for parameter tweaking. We show that complex scattering effects can be approximated very well by using aggressive simplifications based on this theoretical model. When compared to unbiased Monte-Carlo path tracing, our approximations preserve photo-realism in most settings but with rendering times at least two-orders of magnitude lower. Time and space complexity are much lower compared to photon mapping-based techniques and we can even achieve realistic results in real-time on a standard PC with consumer graphics hardware.</p></div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360632&CFID=85074889&CFTOKEN=32802275">Multidimensional adaptive sampling and reconstruction for ray tracing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81320490282&CFID=85074889&CFTOKEN=32802275">Toshiya Hachisuka</a>, 
                        <a href="author_page.cfm?id=81100389194&CFID=85074889&CFTOKEN=32802275">Wojciech Jarosz</a>, 
                        <a href="author_page.cfm?id=81365598214&CFID=85074889&CFTOKEN=32802275">Richard Peter Weistroffer</a>, 
                        <a href="author_page.cfm?id=81365594215&CFID=85074889&CFTOKEN=32802275">Kevin Dale</a>, 
                        <a href="author_page.cfm?id=81365593097&CFID=85074889&CFTOKEN=32802275">Greg Humphreys</a>, 
                        <a href="author_page.cfm?id=81100289561&CFID=85074889&CFTOKEN=32802275">Matthias Zwicker</a>, 
                        <a href="author_page.cfm?id=81100640205&CFID=85074889&CFTOKEN=32802275">Henrik Wann Jensen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 33</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360632" title="DOI">10.1145/1399504.1360632</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360632&ftid=534159&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360632&ftid=979788&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow25" style="display:inline;"><br /><div style="display:inline">We present a new adaptive sampling strategy for ray tracing. Our technique is specifically designed to handle multidimensional sample domains, and it is well suited for efficiently generating images with effects such as soft shadows, motion blur, and ...</div></span>
          <span id="toHide25" style="display:none;"><br /><div style="display:inline"><p>We present a new adaptive sampling strategy for ray tracing. Our technique is specifically designed to handle multidimensional sample domains, and it is well suited for efficiently generating images with effects such as soft shadows, motion blur, and depth of field. These effects are problematic for existing image based adaptive sampling techniques as they operate on pixels, which are possibly noisy results of a Monte Carlo ray tracing process. Our sampling technique operates on samples in the multidimensional space given by the rendering equation and as a consequence the value of each sample is noise-free. Our algorithm consists of two passes. In the first pass we adaptively generate samples in the multidimensional space, focusing on regions where the local contrast between samples is high. In the second pass we reconstruct the image by integrating the multidimensional function along all but the image dimensions. We perform a high quality anisotropic reconstruction by determining the extent of each sample in the multidimensional space using a structure tensor. We demonstrate our method on scenes with a 3 to 5 dimensional space, including soft shadows, motion blur, and depth of field. The results show that our method uses fewer samples than Mittchell's adaptive sampling technique while producing images with less noise.</p></div></span> <a id="expcoll25" href="JavaScript: expandcollapse('expcoll25',25)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Real time rendering (mostly)</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Sumanta Pattanaik 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360633&CFID=85074889&CFTOKEN=32802275">Real-time, all-frequency shadows in dynamic scenes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100586472&CFID=85074889&CFTOKEN=32802275">Thomas Annen</a>, 
                        <a href="author_page.cfm?id=81440592319&CFID=85074889&CFTOKEN=32802275">Zhao Dong</a>, 
                        <a href="author_page.cfm?id=81335494509&CFID=85074889&CFTOKEN=32802275">Tom Mertens</a>, 
                        <a href="author_page.cfm?id=81100093388&CFID=85074889&CFTOKEN=32802275">Philippe Bekaert</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=85074889&CFTOKEN=32802275">Hans-Peter Seidel</a>, 
                        <a href="author_page.cfm?id=81100016395&CFID=85074889&CFTOKEN=32802275">Jan Kautz</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 34</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360633" title="DOI">10.1145/1399504.1360633</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360633&ftid=534160&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360633&ftid=977956&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow27" style="display:inline;"><br /><div style="display:inline">Shadow computation in dynamic scenes under complex illumination is a challenging problem. Methods based on precomputation provide accurate, real-time solutions, but are hard to extend to dynamic scenes. Specialized approaches for soft shadows can deal ...</div></span>
          <span id="toHide27" style="display:none;"><br /><div style="display:inline"><p>Shadow computation in dynamic scenes under complex illumination is a challenging problem. Methods based on precomputation provide accurate, real-time solutions, but are hard to extend to dynamic scenes. Specialized approaches for soft shadows can deal with dynamic objects but are not fast enough to handle more than one light source. In this paper, we present a technique for rendering dynamic objects under arbitrary environment illumination, which does not require any precomputation. The key ingredient is a fast, approximate technique for computing soft shadows, which achieves several hundred frames per second for a single light source. This allows for approximating environment illumination with a sparse collection of area light sources and yields real-time frame rates.</p></div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360634&CFID=85074889&CFTOKEN=32802275">Interactive relighting of dynamic refractive objects</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81330498607&CFID=85074889&CFTOKEN=32802275">Xin Sun</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=85074889&CFTOKEN=32802275">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81100083423&CFID=85074889&CFTOKEN=32802275">Eric Stollnitz</a>, 
                        <a href="author_page.cfm?id=81100647127&CFID=85074889&CFTOKEN=32802275">Jiaoying Shi</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074889&CFTOKEN=32802275">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 35</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360634" title="DOI">10.1145/1399504.1360634</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360634&ftid=534161&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360634&ftid=979155&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow28" style="display:inline;"><br /><div style="display:inline">We present a new technique for interactive relighting of dynamic refractive objects with complex material properties. We describe our technique in terms of a rendering pipeline in which each stage runs entirely on the GPU. The rendering pipeline converts ...</div></span>
          <span id="toHide28" style="display:none;"><br /><div style="display:inline"><p>We present a new technique for interactive relighting of dynamic refractive objects with complex material properties. We describe our technique in terms of a rendering pipeline in which each stage runs entirely on the GPU. The rendering pipeline converts surfaces to volumetric data, traces the curved paths of photons as they refract through the volume, and renders arbitrary views of the resulting radiance distribution. Our rendering pipeline is fast enough to permit interactive updates to lighting, materials, geometry, and viewing parameters without any precomputation. Applications of our technique include the visualization of caustics, absorption, and scattering while running physical simulations or while manipulating surfaces in real time.</p></div></span> <a id="expcoll28" href="JavaScript: expandcollapse('expcoll28',28)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360635&CFID=85074889&CFTOKEN=32802275">Real-time smoke rendering using compensated ray marching</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335500198&CFID=85074889&CFTOKEN=32802275">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81314494646&CFID=85074889&CFTOKEN=32802275">Zhong Ren</a>, 
                        <a href="author_page.cfm?id=81100221388&CFID=85074889&CFTOKEN=32802275">Stephen Lin</a>, 
                        <a href="author_page.cfm?id=81100451028&CFID=85074889&CFTOKEN=32802275">Hujun Bao</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074889&CFTOKEN=32802275">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074889&CFTOKEN=32802275">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 36</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360635" title="DOI">10.1145/1399504.1360635</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360635&ftid=534162&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360635&ftid=977725&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow29" style="display:inline;"><br /><div style="display:inline">We present a real-time algorithm called compensated ray marching for rendering of smoke under dynamic low-frequency environment lighting. Our approach is based on a decomposition of the input smoke animation, represented as a sequence of volumetric ...</div></span>
          <span id="toHide29" style="display:none;"><br /><div style="display:inline"><p>We present a real-time algorithm called <i>compensated ray marching</i> for rendering of smoke under dynamic low-frequency environment lighting. Our approach is based on a decomposition of the input smoke animation, represented as a sequence of volumetric density fields, into a set of radial basis functions (RBFs) and a sequence of residual fields. To expedite rendering, the source radiance distribution within the smoke is computed from only the low-frequency RBF approximation of the density fields, since the high-frequency residuals have little impact on global illumination under low-frequency environment lighting. Furthermore, in computing source radiances the contributions from single and multiple scattering are evaluated at only the RBF centers and then approximated at other points in the volume using an RBF-based interpolation. A slice-based integration of these source radiances along each view ray is then performed to render the final image. The high-frequency residual fields, which are a critical component in the local appearance of smoke, are compensated back into the radiance integral during this ray march to generate images of high detail.</p> <p>The runtime algorithm, which includes both light transfer simulation and ray marching, can be easily implemented on the GPU, and thus allows for real-time manipulation of viewpoint and lighting, as well as interactive editing of smoke attributes such as extinction cross section, scattering albedo, and phase function. Only moderate preprocessing time and storage is needed. This approach provides the first method for real-time smoke rendering that includes single and multiple scattering while generating results comparable in quality to offline algorithms like ray tracing.</p></div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360636&CFID=85074889&CFTOKEN=32802275">A meshless hierarchical representation for light transport</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81339512060&CFID=85074889&CFTOKEN=32802275">Jaakko Lehtinen</a>, 
                        <a href="author_page.cfm?id=81100289561&CFID=85074889&CFTOKEN=32802275">Matthias Zwicker</a>, 
                        <a href="author_page.cfm?id=81320495606&CFID=85074889&CFTOKEN=32802275">Emmanuel Turquin</a>, 
                        <a href="author_page.cfm?id=81365592304&CFID=85074889&CFTOKEN=32802275">Janne Kontkanen</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074889&CFTOKEN=32802275">Fr&#233;do Durand</a>, 
                        <a href="author_page.cfm?id=81100402503&CFID=85074889&CFTOKEN=32802275">Fran&#231;ois X. Sillion</a>, 
                        <a href="author_page.cfm?id=81100649025&CFID=85074889&CFTOKEN=32802275">Timo Aila</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 37</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360636" title="DOI">10.1145/1399504.1360636</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360636&ftid=534163&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360636&ftid=979156&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow30" style="display:inline;"><br /><div style="display:inline">We introduce a meshless hierarchical representation for solving light transport problems. Precomputed radiance transfer (PRT) and finite elements require a discrete representation of illumination over the scene. Non-hierarchical approaches such as per-vertex ...</div></span>
          <span id="toHide30" style="display:none;"><br /><div style="display:inline"><p>We introduce a meshless hierarchical representation for solving light transport problems. Precomputed radiance transfer (PRT) and finite elements require a discrete representation of illumination over the scene. Non-hierarchical approaches such as per-vertex values are simple to implement, but lead to long precomputation. Hierarchical bases like wavelets lead to dramatic acceleration, but in their basic form they work well only on flat or smooth surfaces. We introduce a hierarchical function basis induced by scattered data approximation. It is decoupled from the geometric representation, allowing the hierarchical representation of illumination on complex objects. We present simple data structures and algorithms for constructing and evaluating the basis functions. Due to its hierarchical nature, our representation adapts to the complexity of the illumination, and can be queried at different scales. We demonstrate the power of the new basis in a novel precomputed direct-to-indirect light transport algorithm that greatly increases the complexity of scenes that can be handled by PRT approaches.</p></div></span> <a id="expcoll30" href="JavaScript: expandcollapse('expcoll30',30)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Faces & reflectance</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jason Lawrence 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360637&CFID=85074889&CFTOKEN=32802275">Data-driven enhancement of facial attractiveness</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100255576&CFID=85074889&CFTOKEN=32802275">Tommer Leyvand</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074889&CFTOKEN=32802275">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81319490834&CFID=85074889&CFTOKEN=32802275">Gideon Dror</a>, 
                        <a href="author_page.cfm?id=81311486606&CFID=85074889&CFTOKEN=32802275">Dani Lischinski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 38</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360637" title="DOI">10.1145/1399504.1360637</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360637&ftid=534164&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360637&ftid=634572&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360637&ftid=979157&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow32" style="display:inline;"><br /><div style="display:inline">When human raters are presented with a collection of shapes and asked to rank them according to their aesthetic appeal, the results often indicate that there is a statistical consensus among the raters. Yet it might be difficult to define a succinct ...</div></span>
          <span id="toHide32" style="display:none;"><br /><div style="display:inline"><p>When human raters are presented with a collection of shapes and asked to rank them according to their aesthetic appeal, the results often indicate that there is a statistical consensus among the raters. Yet it might be difficult to define a succinct set of rules that capture the aesthetic preferences of the raters. In this work, we explore a data-driven approach to aesthetic enhancement of such shapes. Specifically, we focus on the challenging problem of enhancing the aesthetic appeal (or the <i>attractiveness</i>) of human faces in frontal photographs (portraits), while maintaining close similarity with the original.</p> <p>The key component in our approach is an automatic facial attractiveness engine trained on datasets of faces with accompanying facial attractiveness ratings collected from groups of human raters. Given a new face, we extract a set of distances between a variety of facial feature locations, which define a point in a high-dimensional "face space". We then search the face space for a nearby point with a higher predicted attractiveness rating. Once such a point is found, the corresponding facial distances are embedded in the plane and serve as a target to define a 2D warp field which maps the original facial features to their adjusted locations. The effectiveness of our technique was experimentally validated by independent rating experiments, which indicate that it is indeed capable of increasing the facial attractiveness of most portraits that we have experimented with.</p></div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360638&CFID=85074889&CFTOKEN=32802275">Face swapping: automatically replacing faces in photographs</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100629850&CFID=85074889&CFTOKEN=32802275">Dmitri Bitouk</a>, 
                        <a href="author_page.cfm?id=81387606684&CFID=85074889&CFTOKEN=32802275">Neeraj Kumar</a>, 
                        <a href="author_page.cfm?id=81365594998&CFID=85074889&CFTOKEN=32802275">Samreen Dhillon</a>, 
                        <a href="author_page.cfm?id=81100101008&CFID=85074889&CFTOKEN=32802275">Peter Belhumeur</a>, 
                        <a href="author_page.cfm?id=81100052215&CFID=85074889&CFTOKEN=32802275">Shree K. Nayar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 39</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360638" title="DOI">10.1145/1399504.1360638</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360638&ftid=534165&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow33" style="display:inline;"><br /><div style="display:inline">In this paper, we present a complete system for automatic face replacement in images. Our system uses a large library of face images created automatically by downloading images from the internet, extracting faces using face detection software, and aligning ...</div></span>
          <span id="toHide33" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present a complete system for automatic face replacement in images. Our system uses a large library of face images created automatically by downloading images from the internet, extracting faces using face detection software, and aligning each extracted face to a common coordinate system. This library is constructed off-line, once, and can be efficiently accessed during face replacement. Our replacement algorithm has three main stages. First, given an input image, we detect all faces that are present, align them to the coordinate system used by our face library, and select candidate face images from our face library that are similar to the input face in appearance and pose. Second, we adjust the pose, lighting, and color of the candidate face images to match the appearance of those in the input image, and seamlessly blend in the results. Third, we rank the blended candidate replacements by computing a match distance over the overlap region. Our approach requires no 3D model, is fully automatic, and generates highly plausible results across a wide range of skin tones, lighting conditions, and viewpoints. We show how our approach can be used for a variety of applications including face de-identification and the creation of appealing group photographs from a set of images. We conclude with a user study that validates the high quality of our replacement results, and a discussion on the current limitations of our system.</p></div></span> <a id="expcoll33" href="JavaScript: expandcollapse('expcoll33',33)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360639&CFID=85074889&CFTOKEN=32802275">AppProp: all-pairs appearance-space edit propagation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81315487614&CFID=85074889&CFTOKEN=32802275">Xiaobo An</a>, 
                        <a href="author_page.cfm?id=81100112064&CFID=85074889&CFTOKEN=32802275">Fabio Pellacini</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 40</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360639" title="DOI">10.1145/1399504.1360639</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360639&ftid=534166&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360639&ftid=977726&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow34" style="display:inline;"><br /><div style="display:inline">We present an intuitive and efficient method for editing the appearance of complex spatially-varying datasets, such as images and measured materials. In our framework, users specify rough adjustments that are refined interactively by enforcing the policy ...</div></span>
          <span id="toHide34" style="display:none;"><br /><div style="display:inline"><p>We present an intuitive and efficient method for editing the appearance of complex spatially-varying datasets, such as images and measured materials. In our framework, users specify rough adjustments that are refined interactively by enforcing the policy that similar edits are applied to spatially-close regions of similar appearance. Rather than proposing a specific user interface, our method allows artists to quickly and imprecisely specify the initial edits with any method or workflow they feel most comfortable with. An energy optimization formulation is used to propagate the initial rough adjustments to the final refined ones by enforcing the editing policy over all pairs of points in the dataset. We show that this formulation is equivalent to solving a large linear system defined by a dense matrix. We derive an approximate algorithm to compute such a solution interactively by taking advantage of the inherent structure of the matrix. We demonstrate our approach by editing images, HDR radiance maps, and measured materials. Finally, we show that our framework generalizes prior methods while providing significant improvements in generality, robustness and efficiency.</p></div></span> <a id="expcoll34" href="JavaScript: expandcollapse('expcoll34',34)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360640&CFID=85074889&CFTOKEN=32802275">Modeling anisotropic surface reflectance with example-based microfacet synthesis</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100233349&CFID=85074889&CFTOKEN=32802275">Jiaping Wang</a>, 
                        <a href="author_page.cfm?id=81365591212&CFID=85074889&CFTOKEN=32802275">Shuang Zhao</a>, 
                        <a href="author_page.cfm?id=81314492380&CFID=85074889&CFTOKEN=32802275">Xin Tong</a>, 
                        <a href="author_page.cfm?id=81100167784&CFID=85074889&CFTOKEN=32802275">John Snyder</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074889&CFTOKEN=32802275">Baining Guo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 41</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360640" title="DOI">10.1145/1399504.1360640</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360640&ftid=534167&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360640&ftid=977727&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow35" style="display:inline;"><br /><div style="display:inline">We present a new technique for the visual modeling of spatiallyvarying anisotropic reflectance using data captured from a single view. Reflectance is represented using a microfacet-based BRDF which tabulates the facets' normal distribution (NDF) as a ...</div></span>
          <span id="toHide35" style="display:none;"><br /><div style="display:inline"><p>We present a new technique for the visual modeling of spatiallyvarying anisotropic reflectance using data captured from a single view. Reflectance is represented using a microfacet-based BRDF which tabulates the facets' normal distribution (NDF) as a function of surface location. Data from a single view provides a 2D slice of the 4D BRDF at each surface point from which we fit a partial NDF. The fitted NDF is partial because the single view direction coupled with the set of light directions covers only a portion of the "half-angle" hemisphere. We complete the NDF at each point by applying a novel variant of texture synthesis using similar, overlapping partial NDFs from other points. Our similarity measure allows azimuthal rotation of partial NDFs, under the assumption that reflectance is spatially redundant but the local frame may be arbitrarily oriented. Our system includes a simple acquisition device that collects images over a 2D set of light directions by scanning a linear array of LEDs over a flat sample. Results demonstrate that our approach preserves spatial and directional BRDF details and generates a visually compelling match to measured materials.</p></div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Shape analysis</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Eitan Grinspun 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360641&CFID=85074889&CFTOKEN=32802275">Upright orientation of man-made objects</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81331492402&CFID=85074889&CFTOKEN=32802275">Hongbo Fu</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074889&CFTOKEN=32802275">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81319490834&CFID=85074889&CFTOKEN=32802275">Gideon Dror</a>, 
                        <a href="author_page.cfm?id=81100389496&CFID=85074889&CFTOKEN=32802275">Alla Sheffer</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 42</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360641" title="DOI">10.1145/1399504.1360641</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360641&ftid=534168&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360641&ftid=634573&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360641&ftid=979158&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow37" style="display:inline;"><br /><div style="display:inline">Humans usually associate an upright orientation with objects, placing them in a way that they are most commonly seen in our surroundings. While it is an open challenge to recover the functionality of a shape from its geometry alone, this paper shows ...</div></span>
          <span id="toHide37" style="display:none;"><br /><div style="display:inline"><p>Humans usually associate an upright orientation with objects, placing them in a way that they are most commonly seen in our surroundings. While it is an open challenge to recover the functionality of a shape from its geometry alone, this paper shows that it is often possible to infer its upright orientation by analyzing its geometry. Our key idea is to reduce the two-dimensional (spherical) orientation space to a small set of orientation candidates using functionality-related geometric properties of the object, and then determine the best orientation using an assessment function of several functional geometric attributes defined with respect to each candidate. Specifically we focus on obtaining the upright orientation for man-made objects that typically stand on some flat surface (ground, floor, table, etc.), which include the vast majority of objects in our everyday surroundings. For these types of models orientation candidates can be defined according to static equilibrium. For each candidate, we introduce a set of discriminative attributes linking shape to function. We learn an assessment function of these attributes from a training set using a combination of Random Forest classifier and Support Vector Machine classifier. Experiments demonstrate that our method generalizes well and achieves about 90% prediction accuracy for both a 10-fold cross-validation over the training set and a validation with an independent test set.</p></div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360642&CFID=85074889&CFTOKEN=32802275">Discovering structural regularity in 3D geometry</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100582775&CFID=85074889&CFTOKEN=32802275">Mark Pauly</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=85074889&CFTOKEN=32802275">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81100493818&CFID=85074889&CFTOKEN=32802275">Johannes Wallner</a>, 
                        <a href="author_page.cfm?id=81100537406&CFID=85074889&CFTOKEN=32802275">Helmut Pottmann</a>, 
                        <a href="author_page.cfm?id=81452606669&CFID=85074889&CFTOKEN=32802275">Leonidas J. Guibas</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 43</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360642" title="DOI">10.1145/1399504.1360642</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360642&ftid=534169&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360642&ftid=979159&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow38" style="display:inline;"><br /><div style="display:inline">We introduce a computational framework for discovering regular or repeated geometric structures in 3D shapes. We describe and classify possible regular structures and present an effective algorithm for detecting such repeated geometric patterns in point- ...</div></span>
          <span id="toHide38" style="display:none;"><br /><div style="display:inline"><p>We introduce a computational framework for discovering regular or repeated geometric structures in 3D shapes. We describe and classify possible regular structures and present an effective algorithm for detecting such repeated geometric patterns in point- or meshbased models. Our method assumes no prior knowledge of the geometry or spatial location of the individual elements that define the pattern. Structure discovery is made possible by a careful analysis of pairwise similarity transformations that reveals prominent lattice structures in a suitable model of transformation space. We introduce an optimization method for detecting such uniform grids specifically designed to deal with outliers and missing elements. This yields a robust algorithm that successfully discovers complex regular structures amidst clutter, noise, and missing geometry. The accuracy of the extracted generating transformations is further improved using a novel simultaneous registration method in the spatial domain. We demonstrate the effectiveness of our algorithm on a variety of examples and show applications to compression, model repair, and geometry synthesis.</p></div></span> <a id="expcoll38" href="JavaScript: expandcollapse('expcoll38',38)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360643&CFID=85074889&CFTOKEN=32802275">Skeleton extraction by mesh contraction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81451593010&CFID=85074889&CFTOKEN=32802275">Oscar Kin-Chung Au</a>, 
                        <a href="author_page.cfm?id=81100311561&CFID=85074889&CFTOKEN=32802275">Chiew-Lan Tai</a>, 
                        <a href="author_page.cfm?id=81100141344&CFID=85074889&CFTOKEN=32802275">Hung-Kuo Chu</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074889&CFTOKEN=32802275">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81409592133&CFID=85074889&CFTOKEN=32802275">Tong-Yee Lee</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 44</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360643" title="DOI">10.1145/1399504.1360643</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360643&ftid=534170&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360643&ftid=979160&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow39" style="display:inline;"><br /><div style="display:inline">Extraction of curve-skeletons is a fundamental problem with many applications in computer graphics and visualization. In this paper, we present a simple and robust skeleton extraction method based on mesh contraction. The method works directly on the ...</div></span>
          <span id="toHide39" style="display:none;"><br /><div style="display:inline"><p>Extraction of curve-skeletons is a fundamental problem with many applications in computer graphics and visualization. In this paper, we present a simple and robust skeleton extraction method based on mesh contraction. The method works directly on the mesh domain, without pre-sampling the mesh model into a volumetric representation. The method first contracts the mesh geometry into zero-volume skeletal shape by applying implicit Laplacian smoothing with global positional constraints. The contraction does not alter the mesh connectivity and retains the key features of the original mesh. The contracted mesh is then converted into a 1D curve-skeleton through a connectivity surgery process to remove all the collapsed faces while preserving the shape of the contracted mesh and the original topology. The centeredness of the skeleton is refined by exploiting the induced skeleton-mesh mapping. In addition to producing a curve skeleton, the method generates other valuable information about the object's geometry, in particular, the skeleton-vertex correspondence and the local thickness, which are useful for various applications. We demonstrate its effectiveness in mesh segmentation and skinning animation.</p></div></span> <a id="expcoll39" href="JavaScript: expandcollapse('expcoll39',39)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360644&CFID=85074889&CFTOKEN=32802275">Computing geometry-aware handle and tunnel loops in 3D models</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100327484&CFID=85074889&CFTOKEN=32802275">Tamal K. Dey</a>, 
                        <a href="author_page.cfm?id=81361597246&CFID=85074889&CFTOKEN=32802275">Kuiyu Li</a>, 
                        <a href="author_page.cfm?id=81335498087&CFID=85074889&CFTOKEN=32802275">Jian Sun</a>, 
                        <a href="author_page.cfm?id=81100183127&CFID=85074889&CFTOKEN=32802275">David Cohen-Steiner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 45</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360644" title="DOI">10.1145/1399504.1360644</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360644&ftid=534171&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360644&ftid=977728&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow40" style="display:inline;"><br /><div style="display:inline">Many applications such as topology repair, model editing, surface parameterization, and feature recognition benefit from computing loops on surfaces that wrap around their 'handles' and 'tunnels'. Computing such loops while optimizing their geometric ...</div></span>
          <span id="toHide40" style="display:none;"><br /><div style="display:inline"><p>Many applications such as topology repair, model editing, surface parameterization, and feature recognition benefit from computing loops on surfaces that wrap around their 'handles' and 'tunnels'. Computing such loops while optimizing their geometric lengths is difficult. On the other hand, computing such loops without considering geometry is easy but may not be very useful. In this paper we strike a balance by computing topologically correct loops that are also geometrically relevant. Our algorithm is a novel application of the concepts from topological persistence introduced recently in computational topology. The usability of the computed loops is demonstrated with some examples in feature identification and topology simplification.</p></div></span> <a id="expcoll40" href="JavaScript: expandcollapse('expcoll40',40)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Jiggly fluids</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Adam Bargteil 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360645&CFID=85074889&CFTOKEN=32802275">Two-way coupling of fluids to rigid and deformable solids and shells</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365596100&CFID=85074889&CFTOKEN=32802275">Avi Robinson-Mosher</a>, 
                        <a href="author_page.cfm?id=81314494823&CFID=85074889&CFTOKEN=32802275">Tamar Shinar</a>, 
                        <a href="author_page.cfm?id=81365595779&CFID=85074889&CFTOKEN=32802275">Jon Gretarsson</a>, 
                        <a href="author_page.cfm?id=81365596620&CFID=85074889&CFTOKEN=32802275">Jonathan Su</a>, 
                        <a href="author_page.cfm?id=81100612327&CFID=85074889&CFTOKEN=32802275">Ronald Fedkiw</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 46</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360645" title="DOI">10.1145/1399504.1360645</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360645&ftid=534172&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360645&ftid=979161&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow42" style="display:inline;"><br /><div style="display:inline">We propose a novel solid/fluid coupling method that treats the coupled system in a fully implicit manner making it stable for arbitrary time steps, large density ratios, etc. In contrast to previous work in computer graphics, we derive our method using ...</div></span>
          <span id="toHide42" style="display:none;"><br /><div style="display:inline"><p>We propose a novel solid/fluid coupling method that treats the coupled system in a fully implicit manner making it stable for arbitrary time steps, large density ratios, etc. In contrast to previous work in computer graphics, we derive our method using a simple back-of-the-envelope approach which lumps the solid and fluid momenta together, and which we show exactly conserves the momentum of the coupled system. Notably, our method uses the standard Cartesian fluid discretization and does not require (moving) conforming tetrahedral meshes or ALE frameworks. Furthermore, we use a standard Lagrangian framework for the solid, thus supporting arbitrary solid constitutive models, both implicit and explicit time integration, etc. The method is quite general, working for smoke, water, and multiphase fluids as well as both rigid and deformable solids, and both volumes and thin shells. Rigid shells and cloth are handled automatically without special treatment, and we support fully one-sided discretizations without leaking. Our equations are fully symmetric, allowing for the use of fast solvers, which is a natural result of properly conserving momentum. Finally, for simple explicit time integration of rigid bodies, we show that our equations reduce to form similar to previous work via a single block Gaussian elimination operation, but that this approach scales poorly, i.e. as though four spatial dimensions rather than three.</p></div></span> <a id="expcoll42" href="JavaScript: expandcollapse('expcoll42',42)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360646&CFID=85074889&CFTOKEN=32802275">Fast viscoelastic behavior with thin features</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81323497785&CFID=85074889&CFTOKEN=32802275">Chris Wojtan</a>, 
                        <a href="author_page.cfm?id=81100457973&CFID=85074889&CFTOKEN=32802275">Greg Turk</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 47</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360646" title="DOI">10.1145/1399504.1360646</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360646&ftid=534173&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360646&ftid=977729&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow43" style="display:inline;"><br /><div style="display:inline">We introduce a method for efficiently animating a wide range of deformable materials. We combine a high resolution surface mesh with a tetrahedral finite element simulator that makes use of frequent re-meshing. This combination allows for fast and detailed ...</div></span>
          <span id="toHide43" style="display:none;"><br /><div style="display:inline"><p>We introduce a method for efficiently animating a wide range of deformable materials. We combine a high resolution surface mesh with a tetrahedral finite element simulator that makes use of frequent re-meshing. This combination allows for fast and detailed simulations of complex elastic and plastic behavior. We significantly expand the range of physical parameters that can be simulated with a single technique, and the results are free from common artifacts such as volume-loss, smoothing, popping, and the absence of thin features like strands and sheets. Our decision to couple a high resolution surface with low-resolution physics leads to efficient simulation and detailed surface features, and our approach to creating the tetrahedral mesh leads to an order-of-magnitude speedup over previous techniques in the time spent re-meshing. We compute masses, collisions, and surface tension forces on the scale of the fine mesh, which helps avoid visual artifacts due to the differing mesh resolutions. The result is a method that can simulate a large array of different material behaviors with high resolution features in a short amount of time.</p></div></span> <a id="expcoll43" href="JavaScript: expandcollapse('expcoll43',43)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360647&CFID=85074889&CFTOKEN=32802275">Bubbles alive</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81329489309&CFID=85074889&CFTOKEN=32802275">Jeong-Mo Hong</a>, 
                        <a href="author_page.cfm?id=81421600204&CFID=85074889&CFTOKEN=32802275">Ho-Young Lee</a>, 
                        <a href="author_page.cfm?id=81365595291&CFID=85074889&CFTOKEN=32802275">Jong-Chul Yoon</a>, 
                        <a href="author_page.cfm?id=81100656332&CFID=85074889&CFTOKEN=32802275">Chang-Hun Kim</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 48</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360647" title="DOI">10.1145/1399504.1360647</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360647&ftid=534174&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360647&ftid=979162&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow44" style="display:inline;"><br /><div style="display:inline">We propose a hybrid method for simulating multiphase fluids such as bubbly water. The appearance of subgrid visual details is improved by incorporating a new bubble model based on smoothed particle hydrodynamics (SPH) into an Eulerian grid-based simulation ...</div></span>
          <span id="toHide44" style="display:none;"><br /><div style="display:inline"><p>We propose a hybrid method for simulating multiphase fluids such as bubbly water. The appearance of subgrid visual details is improved by incorporating a new bubble model based on smoothed particle hydrodynamics (SPH) into an Eulerian grid-based simulation that handles background flows of large bodies of water and air. To overcome the difficulty in simulating small bubbles in the context of the multiphase flows on a coarse grid, we heuristically model the interphase properties of water and air by means of the interactions between bubble particles. As a result, we can animate lively motion of bubbly water with small scale details efficiently.</p></div></span> <a id="expcoll44" href="JavaScript: expandcollapse('expcoll44',44)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360648&CFID=85074889&CFTOKEN=32802275">Porous flow in particle-based fluid simulations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365595584&CFID=85074889&CFTOKEN=32802275">Toon Lenaerts</a>, 
                        <a href="author_page.cfm?id=81100312919&CFID=85074889&CFTOKEN=32802275">Bart Adams</a>, 
                        <a href="author_page.cfm?id=81100172909&CFID=85074889&CFTOKEN=32802275">Philip Dutr&#233;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 49</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360648" title="DOI">10.1145/1399504.1360648</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360648&ftid=534175&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360648&ftid=977730&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow45" style="display:inline;"><br /><div style="display:inline">This paper presents the simulation of a fluid flowing through a porous deformable material. We introduce the physical principles governing porous flow, expressed by the Law of Darcy, into the Smoothed Particle Hydrodynamics (SPH) framework for simulating ...</div></span>
          <span id="toHide45" style="display:none;"><br /><div style="display:inline"><p>This paper presents the simulation of a fluid flowing through a porous deformable material. We introduce the physical principles governing porous flow, expressed by the Law of Darcy, into the Smoothed Particle Hydrodynamics (SPH) framework for simulating fluids and deformable objects. Contrary to previous SPH approaches, we simulate porous flow at a macroscopic scale, making abstraction of individual pores or cavities inside the material. Thus, the number of computational elements is kept low, while at the same time realistic simulations can be achieved. Our algorithm models the changing behavior of the wet material as well as the full two-way coupling between the fluid and the porous material. This enables various new effects, such as the simulation of sponge-like elastic bodies and water-absorbing sticky cloth.</p></div></span> <a id="expcoll45" href="JavaScript: expandcollapse('expcoll45',45)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360649&CFID=85074889&CFTOKEN=32802275">Wavelet turbulence for fluid simulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365596226&CFID=85074889&CFTOKEN=32802275">Theodore Kim</a>, 
                        <a href="author_page.cfm?id=81335498663&CFID=85074889&CFTOKEN=32802275">Nils Th&#252;rey</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=85074889&CFTOKEN=32802275">Doug James</a>, 
                        <a href="author_page.cfm?id=81100260276&CFID=85074889&CFTOKEN=32802275">Markus Gross</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 50</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360649" title="DOI">10.1145/1399504.1360649</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360649&ftid=534176&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360649&ftid=979163&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow46" style="display:inline;"><br /><div style="display:inline">We present a novel wavelet method for the simulation of fluids at high spatial resolution. The algorithm enables large- and small-scale detail to be edited separately, allowing high-resolution detail to be added as a post-processing step. Instead of ...</div></span>
          <span id="toHide46" style="display:none;"><br /><div style="display:inline"><p>We present a novel wavelet method for the simulation of fluids at high spatial resolution. The algorithm enables large- and small-scale detail to be edited separately, allowing high-resolution detail to be added as a post-processing step. Instead of solving the Navier-Stokes equations over a highly refined mesh, we use the wavelet decomposition of a low-resolution simulation to determine the location and energy characteristics of missing high-frequency components. We then synthesize these missing components using a novel incompressible turbulence function, and provide a method to maintain the temporal coherence of the resulting structures. There is no linear system to solve, so the method parallelizes trivially and requires only a few auxiliary arrays. The method guarantees that the new frequencies will not interfere with existing frequencies, allowing animators to set up a low resolution simulation quickly and later add details without changing the overall fluid motion.</p></div></span> <a id="expcoll46" href="JavaScript: expandcollapse('expcoll46',46)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Texture</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Yizhou Yu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360650&CFID=85074889&CFTOKEN=32802275">Multiscale texture synthesis</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335491392&CFID=85074889&CFTOKEN=32802275">Charles Han</a>, 
                        <a href="author_page.cfm?id=81331502452&CFID=85074889&CFTOKEN=32802275">Eric Risser</a>, 
                        <a href="author_page.cfm?id=81100019585&CFID=85074889&CFTOKEN=32802275">Ravi Ramamoorthi</a>, 
                        <a href="author_page.cfm?id=81320489894&CFID=85074889&CFTOKEN=32802275">Eitan Grinspun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 51</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360650" title="DOI">10.1145/1399504.1360650</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360650&ftid=534177&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360650&ftid=979164&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow48" style="display:inline;"><br /><div style="display:inline">Example-based texture synthesis algorithms have gained widespread popularity for their ability to take a single input image and create a perceptually similar non-periodic texture. However, previous methods rely on single input exemplars that can capture ...</div></span>
          <span id="toHide48" style="display:none;"><br /><div style="display:inline"><p>Example-based texture synthesis algorithms have gained widespread popularity for their ability to take a single input image and create a perceptually similar non-periodic texture. However, previous methods rely on single input exemplars that can capture only a limited band of spatial scales. For example, synthesizing a continent-like appearance at a variety of zoom levels would require an impractically high input resolution. In this paper, we develop a multiscale texture synthesis algorithm. We propose a novel example-based representation, which we call an exemplar graph, that simply requires a few low-resolution input exemplars at different scales. Moreover, by allowing loops in the graph, we can create infinite zooms and infinitely detailed textures that are impossible with current example-based methods. We also introduce a technique that ameliorates inconsistencies in the user's input, and show that the application of this method yields improved interscale coherence and higher visual quality. We demonstrate optimizations for both CPU and GPU implementations of our method, and use them to produce animations with zooming and panning at multiple scales, as well as static gigapixel-sized images with features spanning many spatial scales.</p></div></span> <a id="expcoll48" href="JavaScript: expandcollapse('expcoll48',48)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360651&CFID=85074889&CFTOKEN=32802275">Inverse texture synthesis</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81452594229&CFID=85074889&CFTOKEN=32802275">Li-Yi Wei</a>, 
                        <a href="author_page.cfm?id=81363593457&CFID=85074889&CFTOKEN=32802275">Jianwei Han</a>, 
                        <a href="author_page.cfm?id=81335500198&CFID=85074889&CFTOKEN=32802275">Kun Zhou</a>, 
                        <a href="author_page.cfm?id=81100451028&CFID=85074889&CFTOKEN=32802275">Hujun Bao</a>, 
                        <a href="author_page.cfm?id=81100085615&CFID=85074889&CFTOKEN=32802275">Baining Guo</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074889&CFTOKEN=32802275">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 52</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360651" title="DOI">10.1145/1399504.1360651</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360651&ftid=534178&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360651&ftid=977731&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow49" style="display:inline;"><br /><div style="display:inline">The quality and speed of most texture synthesis algorithms depend on a 2D input sample that is small and contains enough texture variations. However, little research exists on how to acquire such sample. For homogeneous patterns this can be achieved ...</div></span>
          <span id="toHide49" style="display:none;"><br /><div style="display:inline"><p>The quality and speed of most texture synthesis algorithms depend on a 2D input sample that is small and contains enough texture variations. However, little research exists on how to acquire such sample. For homogeneous patterns this can be achieved via manual cropping, but no adequate solution exists for inhomogeneous or <i>globally varying</i> textures, i.e. patterns that are local but not stationary, such as rusting over an iron statue with appearance conditioned on varying moisture levels.</p> <p>We present <i>inverse texture synthesis</i> to address this issue. Our inverse synthesis runs in the opposite direction with respect to traditional forward synthesis: given a large globally varying texture, our algorithm automatically produces a small texture compaction that best summarizes the original. This small compaction can be used to reconstruct the original texture or to re-synthesize new textures under user-supplied controls. More important, our technique allows real-time synthesis of globally varying textures on a GPU, where the texture memory is usually too small for large textures. We propose an optimization framework for inverse texture synthesis, ensuring that each input region is properly encoded in the output compaction. Our optimization process also automatically computes orientation fields for anisotropic textures containing both low- and high-frequency regions, a situation difficult to handle via existing techniques.</p></div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360652&CFID=85074889&CFTOKEN=32802275">Lapped solid textures: filling a model with anisotropic textures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335498203&CFID=85074889&CFTOKEN=32802275">Kenshi Takayama</a>, 
                        <a href="author_page.cfm?id=81100546396&CFID=85074889&CFTOKEN=32802275">Makoto Okabe</a>, 
                        <a href="author_page.cfm?id=81100057408&CFID=85074889&CFTOKEN=32802275">Takashi Ijiri</a>, 
                        <a href="author_page.cfm?id=81100444444&CFID=85074889&CFTOKEN=32802275">Takeo Igarashi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 53</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360652" title="DOI">10.1145/1399504.1360652</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360652&ftid=534179&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360652&ftid=979165&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow50" style="display:inline;"><br /><div style="display:inline">We present a method for representing solid objects with spatially-varying oriented textures by repeatedly pasting solid texture exemplars. The underlying concept is to extend the 2D texture patch-pasting approach of lapped textures to 3D solids using ...</div></span>
          <span id="toHide50" style="display:none;"><br /><div style="display:inline"><p>We present a method for representing solid objects with spatially-varying oriented textures by repeatedly pasting solid texture exemplars. The underlying concept is to extend the 2D texture patch-pasting approach of lapped textures to 3D solids using a tetrahedral mesh and 3D texture patches. The system places texture patches according to the user-defined volumetric tensor fields over the mesh to represent oriented textures. We have also extended the original technique to handle nonhomogeneous textures for creating solid models whose textural patterns change gradually along the depth fields. We identify several texture types considering the amount of anisotropy and spatial variation and provide a tailored user interface for each. With our simple framework, large-scale realistic solid models can be created easily with little memory and computational cost. We demonstrate the effectiveness of our approach with several examples including trees, fruits, and vegetables.</p></div></span> <a id="expcoll50" href="JavaScript: expandcollapse('expcoll50',50)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360653&CFID=85074889&CFTOKEN=32802275">Anisotropic noise</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365594692&CFID=85074889&CFTOKEN=32802275">Alexander Goldberg</a>, 
                        <a href="author_page.cfm?id=81100289561&CFID=85074889&CFTOKEN=32802275">Matthias Zwicker</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074889&CFTOKEN=32802275">Fr&#233;do Durand</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 54</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360653" title="DOI">10.1145/1399504.1360653</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360653&ftid=534180&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360653&ftid=977732&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow51" style="display:inline;"><br /><div style="display:inline">Programmable graphics hardware makes it possible to generate procedural noise textures on the fly for interactive rendering. However, filtering and antialiasing procedural noise involves a tradeoff between aliasing artifacts and loss of detail. In this ...</div></span>
          <span id="toHide51" style="display:none;"><br /><div style="display:inline"><p>Programmable graphics hardware makes it possible to generate procedural noise textures on the fly for interactive rendering. However, filtering and antialiasing procedural noise involves a tradeoff between aliasing artifacts and loss of detail. In this paper we present a technique, targeted at interactive applications, that provides high-quality anisotropic filtering for noise textures. We generate noise tiles directly in the frequency domain by partitioning the frequency domain into oriented subbands. We then compute weighted sums of the subband textures to accurately approximate noise with a desired spectrum. This allows us to achieve high-quality anisotropic filtering. Our approach is based solely on 2D textures, avoiding the memory overhead of techniques based on 3D noise tiles. We devise a technique to compensate for texture distortions to generate uniform noise on arbitrary meshes. We develop a GPU-based implementation of our technique that achieves similar rendering performance as state-of-the-art algorithms for procedural noise. In addition, it provides anisotropic filtering and achieves superior image quality.</p></div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Computational photography & display</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Wojciech Matusik 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360654&CFID=85074889&CFTOKEN=32802275">Programmable aperture photography: multiplexed light field acquisition</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440606777&CFID=85074889&CFTOKEN=32802275">Chia-Kai Liang</a>, 
                        <a href="author_page.cfm?id=81365598760&CFID=85074889&CFTOKEN=32802275">Tai-Hsu Lin</a>, 
                        <a href="author_page.cfm?id=81365592469&CFID=85074889&CFTOKEN=32802275">Bing-Yi Wong</a>, 
                        <a href="author_page.cfm?id=81365596512&CFID=85074889&CFTOKEN=32802275">Chi Liu</a>, 
                        <a href="author_page.cfm?id=81407593814&CFID=85074889&CFTOKEN=32802275">Homer H. Chen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 55</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360654" title="DOI">10.1145/1399504.1360654</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360654&ftid=534181&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360654&ftid=979166&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow53" style="display:inline;"><br /><div style="display:inline">In this paper, we present a system including a novel component called programmable aperture and two associated post-processing algorithms for high-quality light field acquisition. The shape of the programmable aperture can be adjusted and used to capture ...</div></span>
          <span id="toHide53" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present a system including a novel component called programmable aperture and two associated post-processing algorithms for high-quality light field acquisition. The shape of the programmable aperture can be adjusted and used to capture light field at full sensor resolution through multiple exposures without any additional optics and without moving the camera. High acquisition efficiency is achieved by employing an optimal multiplexing scheme, and quality data is obtained by using the two post-processing algorithms designed for self calibration of photometric distortion and for multi-view depth estimation. View-dependent depth maps thus generated help boost the angular resolution of light field. Various post-exposure photographic effects are given to demonstrate the effectiveness of the system and the quality of the captured light field.</p></div></span> <a id="expcoll53" href="JavaScript: expandcollapse('expcoll53',53)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360655&CFID=85074889&CFTOKEN=32802275">Glare aware photography: 4D ray sampling for reducing glare effects of camera lenses</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100022847&CFID=85074889&CFTOKEN=32802275">Ramesh Raskar</a>, 
                        <a href="author_page.cfm?id=81317490848&CFID=85074889&CFTOKEN=32802275">Amit Agrawal</a>, 
                        <a href="author_page.cfm?id=81365591679&CFID=85074889&CFTOKEN=32802275">Cyrus A. Wilson</a>, 
                        <a href="author_page.cfm?id=81300333501&CFID=85074889&CFTOKEN=32802275">Ashok Veeraraghavan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 56</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360655" title="DOI">10.1145/1399504.1360655</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360655&ftid=534182&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360655&ftid=979167&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow54" style="display:inline;"><br /><div style="display:inline">Glare arises due to multiple scattering of light inside the camera's body and lens optics and reduces image contrast. While previous approaches have analyzed glare in 2D image space, we show that glare is inherently a 4D ray-space phenomenon. By statistically ...</div></span>
          <span id="toHide54" style="display:none;"><br /><div style="display:inline"><p>Glare arises due to multiple scattering of light inside the camera's body and lens optics and reduces image contrast. While previous approaches have analyzed glare in 2D image space, we show that glare is inherently a 4D ray-space phenomenon. By statistically analyzing the ray-space inside a camera, we can classify and remove glare artifacts. In ray-space, glare behaves as high frequency noise and can be reduced by outlier rejection. While such analysis can be performed by capturing the light field inside the camera, it results in the loss of spatial resolution. Unlike light field cameras, we do not need to reversibly encode the spatial structure of the ray-space, leading to simpler designs. We explore masks for uniform and non-uniform ray sampling and show a practical solution to analyze the 4D statistics without significantly compromising image resolution. Although diffuse scattering of the lens introduces 4D low-frequency glare, we can produce useful solutions in a variety of common scenarios. Our approach handles photography looking into the sun and photos taken without a hood, removes the effect of lens smudges and reduces loss of contrast due to camera body reflections. We show various applications in contrast enhancement and glare manipulation.</p></div></span> <a id="expcoll54" href="JavaScript: expandcollapse('expcoll54',54)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360656&CFID=85074889&CFTOKEN=32802275">Light field transfer: global illumination between real and synthetic objects</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365598191&CFID=85074889&CFTOKEN=32802275">Oliver Cossairt</a>, 
                        <a href="author_page.cfm?id=81100052215&CFID=85074889&CFTOKEN=32802275">Shree Nayar</a>, 
                        <a href="author_page.cfm?id=81100019585&CFID=85074889&CFTOKEN=32802275">Ravi Ramamoorthi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 57</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360656" title="DOI">10.1145/1399504.1360656</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360656&ftid=534183&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360656&ftid=977733&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow55" style="display:inline;"><br /><div style="display:inline">We present a novel image-based method for compositing real and synthetic objects in the same scene with a high degree of visual realism. Ours is the first technique to allow global illumination and near-field lighting effects between both real and synthetic ...</div></span>
          <span id="toHide55" style="display:none;"><br /><div style="display:inline"><p>We present a novel image-based method for compositing real and synthetic objects in the same scene with a high degree of visual realism. Ours is the first technique to allow global illumination and near-field lighting effects between both real and synthetic objects at interactive rates, without needing a geometric and material model of the real scene. We achieve this by using a light field interface between real and synthetic components---thus, indirect illumination can be simulated using only two 4D light fields, one captured from and one projected onto the real scene. Multiple bounces of interreflections are obtained simply by iterating this approach. The interactivity of our technique enables its use with time-varying scenes, including dynamic objects. This is in sharp contrast to the alternative approach of using 6D or 8D light transport functions of real objects, which are very expensive in terms of acquisition and storage and hence not suitable for real-time applications. In our method, 4D radiance fields are simultaneously captured and projected by using a lens array, video camera, and digital projector. The method supports full global illumination with restricted object placement, and accommodates moderately specular materials. We implement a complete system and show several example scene compositions that demonstrate global illumination effects between dynamic real and synthetic objects. Our implementation requires a single point light source and dark background.</p></div></span> <a id="expcoll55" href="JavaScript: expandcollapse('expcoll55',55)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360657&CFID=85074889&CFTOKEN=32802275">Towards passive 6D reflectance field displays</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81332499566&CFID=85074889&CFTOKEN=32802275">Martin Fuchs</a>, 
                        <a href="author_page.cfm?id=81100022847&CFID=85074889&CFTOKEN=32802275">Ramesh Raskar</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=85074889&CFTOKEN=32802275">Hans-Peter Seidel</a>, 
                        <a href="author_page.cfm?id=81100504611&CFID=85074889&CFTOKEN=32802275">Hendrik P. A. Lensch</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 58</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360657" title="DOI">10.1145/1399504.1360657</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360657&ftid=534184&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360657&ftid=634574&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360657&ftid=979168&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow56" style="display:inline;"><br /><div style="display:inline">Traditional flat screen displays present 2D images. 3D and 4D displays have been proposed making use of lenslet arrays to shape a fixed outgoing light field for horizontal or bidirectional parallax. In this article, we present different designs of multi-dimensional ...</div></span>
          <span id="toHide56" style="display:none;"><br /><div style="display:inline"><p>Traditional flat screen displays present 2D images. 3D and 4D displays have been proposed making use of lenslet arrays to shape a fixed outgoing light field for horizontal or bidirectional parallax. In this article, we present different designs of multi-dimensional displays which passively react to the light of the environment behind. The prototypes physically implement a reflectance field and generate different light fields depending on the incident illumination, for example light falling through a window. We discretize the incident light field using an optical system, and modulate it with a 2D pattern, creating a flat display which is view <i>and</i> illumination-dependent. It is free from electronic components. For distant light and a fixed observer position, we demonstrate a passive optical configuration which directly renders a 4D reflectance field in the real-world illumination behind it. We further propose an optical setup that allows for projecting out different angular distributions depending on the incident light direction. Combining multiple of these devices we build a display that renders a 6D experience, where the incident 2D illumination influences the outgoing light field, both in the spatial and in the angular domain. Possible applications of this technology are time-dependent displays driven by sunlight, object virtualization and programmable light benders / ray blockers without moving parts.</p></div></span> <a id="expcoll56" href="JavaScript: expandcollapse('expcoll56',56)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Perception & hallucination</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Karol Myszkowski 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360658&CFID=85074889&CFTOKEN=32802275">A perceptually validated model for surface depth hallucination</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81408602556&CFID=85074889&CFTOKEN=32802275">Mashhuda Glencross</a>, 
                        <a href="author_page.cfm?id=81100633003&CFID=85074889&CFTOKEN=32802275">Gregory J. Ward</a>, 
                        <a href="author_page.cfm?id=81365597937&CFID=85074889&CFTOKEN=32802275">Francho Melendez</a>, 
                        <a href="author_page.cfm?id=81100091861&CFID=85074889&CFTOKEN=32802275">Caroline Jay</a>, 
                        <a href="author_page.cfm?id=81365593421&CFID=85074889&CFTOKEN=32802275">Jun Liu</a>, 
                        <a href="author_page.cfm?id=81100561115&CFID=85074889&CFTOKEN=32802275">Roger Hubbold</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 59</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360658" title="DOI">10.1145/1399504.1360658</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360658&ftid=534185&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360658&ftid=634575&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360658&ftid=979169&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow58" style="display:inline;"><br /><div style="display:inline">Capturing detailed surface geometry currently requires specialized equipment such as laser range scanners, which despite their high accuracy, leave gaps in the surfaces that must be reconciled with photographic capture for relighting applications. Using ...</div></span>
          <span id="toHide58" style="display:none;"><br /><div style="display:inline"><p>Capturing detailed surface geometry currently requires specialized equipment such as laser range scanners, which despite their high accuracy, leave gaps in the surfaces that must be reconciled with photographic capture for relighting applications. Using only a standard digital camera and a single view, we present a method for recovering models of predominantly diffuse textured surfaces that can be plausibly relit and viewed from any angle under any illumination. Our multiscale shape-from-shading technique uses diffuse-lit/flash-lit image pairs to produce an albedo map and textured height field. Using two lighting conditions enables us to subtract one from the other to estimate albedo. In the absence of a flash-lit image of a surface for which we already have a similar exemplar pair, we approximate both albedo and diffuse shading images using histogram matching. Our depth estimation is based on local visibility. Unlike other depth-from-shading approaches, all operations are performed on the diffuse shading image in image space, and we impose no constant albedo restrictions. An experimental validation shows our method works for a broad range of textured surfaces, and viewers are frequently unable to identify our results as synthetic in a randomized presentation. Furthermore, in side-by-side comparisons, subjects found a rendering of our depth map equally plausible to one generated from a laser range scan. We see this method as a significant advance in acquiring surface detail for texturing using a standard digital camera, with applications in architecture, archaeological reconstruction, games and special effects.</p></div></span> <a id="expcoll58" href="JavaScript: expandcollapse('expcoll58',58)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360659&CFID=85074889&CFTOKEN=32802275">Perception of complex aggregates</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81320493826&CFID=85074889&CFTOKEN=32802275">Ganesh Ramanarayanan</a>, 
                        <a href="author_page.cfm?id=81100081277&CFID=85074889&CFTOKEN=32802275">Kavita Bala</a>, 
                        <a href="author_page.cfm?id=81100459651&CFID=85074889&CFTOKEN=32802275">James A. Ferwerda</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 60</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360659" title="DOI">10.1145/1399504.1360659</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360659&ftid=534186&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360659&ftid=977734&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow59" style="display:inline;"><br /><div style="display:inline">Aggregates of individual objects, such as forests, crowds, and piles of fruit, are a common source of complexity in computer graphics scenes. When viewing an aggregate, observers attend less to individual objects and focus more on overall properties ...</div></span>
          <span id="toHide59" style="display:none;"><br /><div style="display:inline"><p>Aggregates of individual objects, such as forests, crowds, and piles of fruit, are a common source of complexity in computer graphics scenes. When viewing an aggregate, observers attend less to individual objects and focus more on overall properties such as numerosity, variety, and arrangement. Paradoxically, rendering and modeling costs increase with aggregate complexity, exactly when observers are attending less to individual objects.</p> <p>In this paper we take some first steps to characterize the limits of visual coding of aggregates to efficiently represent their appearance in scenes. We describe psychophysical experiments that explore the roles played by the geometric and material properties of individual objects in observers' abilities to discriminate different aggregate collections. Based on these experiments we derive metrics to predict when two aggregates have the same appearance, even when composed of different objects. In a follow-up experiment we confirm that these metrics can be used to predict the appearance of a range of realistic aggregates. Finally, as a proof-of-concept we show how these new aggregate perception metrics can be applied to simplify scenes by allowing substitution of geometrically simpler aggregates for more complex ones without changing appearance.</p></div></span> <a id="expcoll59" href="JavaScript: expandcollapse('expcoll59',59)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360660&CFID=85074889&CFTOKEN=32802275">A perception-based color space for illumination-invariant image processing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365595957&CFID=85074889&CFTOKEN=32802275">Hamilton Y. Chong</a>, 
                        <a href="author_page.cfm?id=81100259454&CFID=85074889&CFTOKEN=32802275">Steven J. Gortler</a>, 
                        <a href="author_page.cfm?id=81100015971&CFID=85074889&CFTOKEN=32802275">Todd Zickler</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 61</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360660" title="DOI">10.1145/1399504.1360660</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360660&ftid=534187&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360660&ftid=977735&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow60" style="display:inline;"><br /><div style="display:inline">Motivated by perceptual principles, we derive a new color space in which the associated metric approximates perceived distances and color displacements capture relationships that are robust to spectral changes in illumination. The resulting color space ...</div></span>
          <span id="toHide60" style="display:none;"><br /><div style="display:inline"><p>Motivated by perceptual principles, we derive a new color space in which the associated metric approximates perceived distances and color displacements capture relationships that are robust to spectral changes in illumination. The resulting color space can be used with existing image processing algorithms with little or no change to the methods.</p></div></span> <a id="expcoll60" href="JavaScript: expandcollapse('expcoll60',60)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360661&CFID=85074889&CFTOKEN=32802275">Self-animating images: illusory motion using repeated asymmetric patterns</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81309487399&CFID=85074889&CFTOKEN=32802275">Ming-Te Chi</a>, 
                        <a href="author_page.cfm?id=81409592133&CFID=85074889&CFTOKEN=32802275">Tong-Yee Lee</a>, 
                        <a href="author_page.cfm?id=81100337844&CFID=85074889&CFTOKEN=32802275">Yingge Qu</a>, 
                        <a href="author_page.cfm?id=81343509200&CFID=85074889&CFTOKEN=32802275">Tien-Tsin Wong</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 62</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360661" title="DOI">10.1145/1399504.1360661</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360661&ftid=534188&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360661&ftid=979170&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow61" style="display:inline;"><br /><div style="display:inline">Illusory motion in a still image is a fascinating research topic in the study of human motion perception. Physiologists and psychologists have attempted to understand this phenomenon by constructing simple, color repeated asymmetric patterns (RAP) and ...</div></span>
          <span id="toHide61" style="display:none;"><br /><div style="display:inline"><p>Illusory motion in a still image is a fascinating research topic in the study of human motion perception. Physiologists and psychologists have attempted to understand this phenomenon by constructing simple, color repeated asymmetric patterns (RAP) and have found several useful rules to enhance the strength of illusory motion. Based on their knowledge, we propose a computational method to generate self-animating images. First, we present an optimized RAP placement on streamlines to generate illusory motion for a given static vector field. Next, a general coloring scheme for RAP is proposed to render streamlines. Furthermore, to enhance the strength of illusion and respect the shape of the region, a smooth vector field with opposite directional flow is automatically generated given an input image. Examples generated by our method are shown as evidence of the illusory effect and the potential applications for entertainment and design purposes.</p></div></span> <a id="expcoll61" href="JavaScript: expandcollapse('expcoll61',61)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Hair, rods & cloth</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Mark Carlson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360662&CFID=85074889&CFTOKEN=32802275">Discrete elastic rods</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81320488452&CFID=85074889&CFTOKEN=32802275">Mikl&#243;s Bergou</a>, 
                        <a href="author_page.cfm?id=81320496298&CFID=85074889&CFTOKEN=32802275">Max Wardetzky</a>, 
                        <a href="author_page.cfm?id=81413593580&CFID=85074889&CFTOKEN=32802275">Stephen Robinson</a>, 
                        <a href="author_page.cfm?id=81314493420&CFID=85074889&CFTOKEN=32802275">Basile Audoly</a>, 
                        <a href="author_page.cfm?id=81320489894&CFID=85074889&CFTOKEN=32802275">Eitan Grinspun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 63</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360662" title="DOI">10.1145/1399504.1360662</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360662&ftid=534189&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360662&ftid=979171&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow63" style="display:inline;"><br /><div style="display:inline">We present a discrete treatment of adapted framed curves, parallel transport, and holonomy, thus establishing the language for a discrete geometric model of thin flexible rods with arbitrary cross section and undeformed configuration. Our approach differs ...</div></span>
          <span id="toHide63" style="display:none;"><br /><div style="display:inline"><p>We present a discrete treatment of adapted framed curves, parallel transport, and holonomy, thus establishing the language for a discrete geometric model of thin flexible rods with arbitrary cross section and undeformed configuration. Our approach differs from existing simulation techniques in the graphics and mechanics literature both in the kinematic description---we represent the material frame by its angular deviation from the natural Bishop frame---as well as in the dynamical treatment---we treat the centerline as dynamic and the material frame as quasistatic. Additionally, we describe a manifold projection method for coupling rods to rigid-bodies and simultaneously enforcing rod inextensibility. The use of quasistatics and constraints provides an efficient treatment for stiff twisting and stretching modes; at the same time, we retain the dynamic bending of the centerline and accurately reproduce the coupling between bending and twisting modes. We validate the discrete rod model via quantitative buckling, stability, and coupled-mode experiments, and via qualitative knot-tying comparisons.</p></div></span> <a id="expcoll63" href="JavaScript: expandcollapse('expcoll63',63)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360663&CFID=85074889&CFTOKEN=32802275">A mass spring model for hair simulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100351513&CFID=85074889&CFTOKEN=32802275">Andrew Selle</a>, 
                        <a href="author_page.cfm?id=81365597634&CFID=85074889&CFTOKEN=32802275">Michael Lentine</a>, 
                        <a href="author_page.cfm?id=81100612327&CFID=85074889&CFTOKEN=32802275">Ronald Fedkiw</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 64</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360663" title="DOI">10.1145/1399504.1360663</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360663&ftid=534190&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360663&ftid=977736&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow64" style="display:inline;"><br /><div style="display:inline">Our goal is to simulate the full hair geometry, consisting of approximately one hundred thousand hairs on a typical human head. This will require scalable methods that can simulate every hair as opposed to only a few guide hairs. Novel to this approach ...</div></span>
          <span id="toHide64" style="display:none;"><br /><div style="display:inline"><p>Our goal is to simulate the full hair geometry, consisting of approximately one hundred thousand hairs on a typical human head. This will require scalable methods that can simulate every hair as opposed to only a few guide hairs. Novel to this approach is that the individual hair/hair interactions can be modeled with physical parameters (friction, static attraction, etc.) at the scale of a single hair as opposed to clumped or continuum interactions. In this vein, we first propose a new altitude spring model for preventing collapse in the simulation of volumetric tetrahedra, and we show that it is also applicable both to bending in cloth and torsion in hair. We demonstrate that this new torsion model for hair behaves in a fashion similar to more sophisticated models with significantly reduced computational cost. For added efficiency, we introduce a semi-implicit discretization of standard springs that makes them truly linear in multiple spatial dimensions and thus unconditionally stable without requiring Newton-Raphson iteration. We also simulate complex hair/hair interactions including sticking and clumping behavior, collisions with objects (e.g. head and shoulders) and self-collisions. Notably, in line with our goal to simulate the full head of hair, we do not generate any new hairs at render time.</p></div></span> <a id="expcoll64" href="JavaScript: expandcollapse('expcoll64',64)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360664&CFID=85074889&CFTOKEN=32802275">Simulating knitted cloth at the yarn level</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81421597937&CFID=85074889&CFTOKEN=32802275">Jonathan M. Kaldor</a>, 
                        <a href="author_page.cfm?id=81100415142&CFID=85074889&CFTOKEN=32802275">Doug L. James</a>, 
                        <a href="author_page.cfm?id=81100238316&CFID=85074889&CFTOKEN=32802275">Steve Marschner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 65</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360664" title="DOI">10.1145/1399504.1360664</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360664&ftid=534191&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360664&ftid=979172&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow65" style="display:inline;"><br /><div style="display:inline">Knitted fabric is widely used in clothing because of its unique and stretchy behavior, which is fundamentally different from the behavior of woven cloth. The properties of knits come from the nonlinear, three-dimensional kinematics of long, inter-looping ...</div></span>
          <span id="toHide65" style="display:none;"><br /><div style="display:inline"><p>Knitted fabric is widely used in clothing because of its unique and stretchy behavior, which is fundamentally different from the behavior of woven cloth. The properties of knits come from the nonlinear, three-dimensional kinematics of long, inter-looping yarns, and despite significant advances in cloth animation we still do not know how to simulate knitted fabric faithfully. Existing cloth simulators mainly adopt elastic-sheet mechanical models inspired by woven materials, focusing less on the model itself than on important simulation challenges such as efficiency, stability, and robustness. We define a new computational model for knits in terms of the motion of yarns, rather than the motion of a sheet. Each yarn is modeled as an inextensible, yet otherwise flexible, B-spline tube. To simulate complex knitted garments, we propose an implicit-explicit integrator, with yarn inextensibility constraints imposed using efficient projections. Friction among yarns is approximated using rigid-body velocity filters, and key yarn-yarn interactions are mediated by stiff penalty forces. Our results show that this simple model predicts the key mechanical properties of different knits, as demonstrated by qualitative comparisons to observed deformations of actual samples in the laboratory, and that the simulator can scale up to substantial animations with complex dynamic motion.</p></div></span> <a id="expcoll65" href="JavaScript: expandcollapse('expcoll65',65)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360665&CFID=85074889&CFTOKEN=32802275">Animating developable surfaces using nonconforming elements</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365596523&CFID=85074889&CFTOKEN=32802275">Elliot English</a>, 
                        <a href="author_page.cfm?id=81100248660&CFID=85074889&CFTOKEN=32802275">Robert Bridson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 66</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360665" title="DOI">10.1145/1399504.1360665</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360665&ftid=534594&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360665&ftid=979173&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow66" style="display:inline;"><br /><div style="display:inline">We present a new discretization for the physics-based animation of developable surfaces. Constrained to not deform at all in-plane but free to bend out-of-plane, these are an excellent approximation for many materials, including most cloth, paper, and ...</div></span>
          <span id="toHide66" style="display:none;"><br /><div style="display:inline"><p>We present a new discretization for the physics-based animation of developable surfaces. Constrained to not deform at all in-plane but free to bend out-of-plane, these are an excellent approximation for many materials, including most cloth, paper, and stiffer materials. Unfortunately the conforming (geometrically continuous) discretizations used in graphics break down in this limit. Our nonconforming approach solves this problem, allowing us to simulate surfaces with zero in-plane deformation as a hard constraint. However, it produces discontinuous meshes, so we further couple this with a "ghost" conforming mesh for collision processing and rendering. We also propose a new second order accurate constrained mechanics time integration method that greatly reduces the numerical damping present in the usual first order methods used in graphics, for virtually no extra cost and sometimes significant speed-up.</p></div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Tone & color</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Ramesh Raskar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360666&CFID=85074889&CFTOKEN=32802275">Edge-preserving decompositions for multi-scale tone and detail manipulation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365591397&CFID=85074889&CFTOKEN=32802275">Zeev Farbman</a>, 
                        <a href="author_page.cfm?id=81100376142&CFID=85074889&CFTOKEN=32802275">Raanan Fattal</a>, 
                        <a href="author_page.cfm?id=81311486606&CFID=85074889&CFTOKEN=32802275">Dani Lischinski</a>, 
                        <a href="author_page.cfm?id=81100122769&CFID=85074889&CFTOKEN=32802275">Richard Szeliski</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 67</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360666" title="DOI">10.1145/1399504.1360666</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360666&ftid=534595&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360666&ftid=977737&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow68" style="display:inline;"><br /><div style="display:inline">Many recent computational photography techniques decompose an image into a piecewise smooth base layer, containing large scale variations in intensity, and a residual detail layer capturing the smaller scale details in the image. In many of these applications, ...</div></span>
          <span id="toHide68" style="display:none;"><br /><div style="display:inline"><p>Many recent computational photography techniques decompose an image into a piecewise smooth base layer, containing large scale variations in intensity, and a residual detail layer capturing the smaller scale details in the image. In many of these applications, it is important to control the spatial scale of the extracted details, and it is often desirable to manipulate details at multiple scales, while avoiding visual artifacts.</p> <p>In this paper we introduce a new way to construct edge-preserving multi-scale image decompositions. We show that current basedetail decomposition techniques, based on the bilateral filter, are limited in their ability to extract detail at arbitrary scales. Instead, we advocate the use of an alternative edge-preserving smoothing operator, based on the weighted least squares optimization framework, which is particularly well suited for progressive coarsening of images and for multi-scale detail extraction. After describing this operator, we show how to use it to construct edge-preserving multi-scale decompositions, and compare it to the bilateral filter, as well as to other schemes. Finally, we demonstrate the effectiveness of our edge-preserving decompositions in the context of LDR and HDR tone mapping, detail enhancement, and other applications.</p></div></span> <a id="expcoll68" href="JavaScript: expandcollapse('expcoll68',68)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360667&CFID=85074889&CFTOKEN=32802275">Display adaptive tone mapping</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100175469&CFID=85074889&CFTOKEN=32802275">Rafa&#322; Mantiuk</a>, 
                        <a href="author_page.cfm?id=81100489461&CFID=85074889&CFTOKEN=32802275">Scott Daly</a>, 
                        <a href="author_page.cfm?id=81365597495&CFID=85074889&CFTOKEN=32802275">Louis Kerofsky</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 68</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360667" title="DOI">10.1145/1399504.1360667</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360667&ftid=534596&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360667&ftid=979174&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow69" style="display:inline;"><br /><div style="display:inline">We propose a tone mapping operator that can minimize visible contrast distortions for a range of output devices, ranging from e-paper to HDR displays. The operator weights contrast distortions according to their visibility predicted by the model of the ...</div></span>
          <span id="toHide69" style="display:none;"><br /><div style="display:inline"><p>We propose a tone mapping operator that can minimize visible contrast distortions for a range of output devices, ranging from e-paper to HDR displays. The operator weights contrast distortions according to their visibility predicted by the model of the human visual system. The distortions are minimized given a display model that enforces constraints on the solution. We show that the problem can be solved very efficiently by employing higher order image statistics and quadratic programming. Our tone mapping technique can adjust image or video content for optimum contrast visibility taking into account ambient illumination and display characteristics. We discuss the differences between our method and previous approaches to the tone mapping problem.</p></div></span> <a id="expcoll69" href="JavaScript: expandcollapse('expcoll69',69)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360668&CFID=85074889&CFTOKEN=32802275">Dynamic range independent image quality assessment</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365597558&CFID=85074889&CFTOKEN=32802275">Tun&#231; Ozan Aydin</a>, 
                        <a href="author_page.cfm?id=81100175469&CFID=85074889&CFTOKEN=32802275">Rafa&#322; Mantiuk</a>, 
                        <a href="author_page.cfm?id=81332517742&CFID=85074889&CFTOKEN=32802275">Karol Myszkowski</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=85074889&CFTOKEN=32802275">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 69</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360668" title="DOI">10.1145/1399504.1360668</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360668&ftid=534597&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360668&ftid=977738&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow70" style="display:inline;"><br /><div style="display:inline">The diversity of display technologies and introduction of high dynamic range imagery introduces the necessity of comparing images of radically different dynamic ranges. Current quality assessment metrics are not suitable for this task, as they assume ...</div></span>
          <span id="toHide70" style="display:none;"><br /><div style="display:inline"><p>The diversity of display technologies and introduction of high dynamic range imagery introduces the necessity of comparing images of radically different dynamic ranges. Current quality assessment metrics are not suitable for this task, as they assume that both reference and test images have the same dynamic range. Image fidelity measures employed by a majority of current metrics, based on the difference of pixel intensity or contrast values between test and reference images, result in meaningless predictions if this assumption does not hold. We present a novel image quality metric capable of operating on an image pair where both images have arbitrary dynamic ranges. Our metric utilizes a model of the human visual system, and its central idea is a new definition of visible distortion based on the detection and classification of visible changes in the image structure. Our metric is carefully calibrated and its performance is validated through perceptual experiments. We demonstrate possible applications of our metric to the evaluation of direct and inverse tone mapping operators as well as the analysis of the image appearance on displays with various characteristics.</p></div></span> <a id="expcoll70" href="JavaScript: expandcollapse('expcoll70',70)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360669&CFID=85074889&CFTOKEN=32802275">Light mixture estimation for spatially varying white balance</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100320698&CFID=85074889&CFTOKEN=32802275">Eugene Hsu</a>, 
                        <a href="author_page.cfm?id=81335494509&CFID=85074889&CFTOKEN=32802275">Tom Mertens</a>, 
                        <a href="author_page.cfm?id=81100495713&CFID=85074889&CFTOKEN=32802275">Sylvain Paris</a>, 
                        <a href="author_page.cfm?id=81100356625&CFID=85074889&CFTOKEN=32802275">Shai Avidan</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074889&CFTOKEN=32802275">Fr&#233;do Durand</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 70</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360669" title="DOI">10.1145/1399504.1360669</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360669&ftid=534598&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360669&ftid=979175&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow71" style="display:inline;"><br /><div style="display:inline">White balance is a crucial step in the photographic pipeline. It ensures the proper rendition of images by eliminating color casts due to differing illuminants. Digital cameras and editing programs provide white balance tools that assume a single type ...</div></span>
          <span id="toHide71" style="display:none;"><br /><div style="display:inline"><p>White balance is a crucial step in the photographic pipeline. It ensures the proper rendition of images by eliminating color casts due to differing illuminants. Digital cameras and editing programs provide white balance tools that assume a single type of light per image, such as daylight. However, many photos are taken under mixed lighting. We propose a white balance technique for scenes with two light types that are specified by the user. This covers many typical situations involving indoor/outdoor or flash/ambient light mixtures. Since we work from a single image, the problem is highly underconstrained. Our method recovers a set of dominant material colors which allows us to estimate the local intensity mixture of the two light types. Using this mixture, we can neutralize the light colors and render visually pleasing images. Our method can also be used to achieve post-exposure relighting effects.</p></div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Deblurring & dehazing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Hendrik Lensch 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360670&CFID=85074889&CFTOKEN=32802275">Motion-invariant photography</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100404851&CFID=85074889&CFTOKEN=32802275">Anat Levin</a>, 
                        <a href="author_page.cfm?id=81100292416&CFID=85074889&CFTOKEN=32802275">Peter Sand</a>, 
                        <a href="author_page.cfm?id=81365594380&CFID=85074889&CFTOKEN=32802275">Taeg Sang Cho</a>, 
                        <a href="author_page.cfm?id=81100055904&CFID=85074889&CFTOKEN=32802275">Fr&#233;do Durand</a>, 
                        <a href="author_page.cfm?id=81452610969&CFID=85074889&CFTOKEN=32802275">William T. Freeman</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 71</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360670" title="DOI">10.1145/1399504.1360670</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360670&ftid=534599&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360670&ftid=634576&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360670&ftid=979176&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow73" style="display:inline;"><br /><div style="display:inline">Object motion during camera exposure often leads to noticeable blurring artifacts. Proper elimination of this blur is challenging because the blur kernel is unknown, varies over the image as a function of object velocity, and destroys high frequencies. ...</div></span>
          <span id="toHide73" style="display:none;"><br /><div style="display:inline"><p>Object motion during camera exposure often leads to noticeable blurring artifacts. Proper elimination of this blur is challenging because the blur kernel is unknown, varies over the image as a function of object velocity, and destroys high frequencies. In the case of motions along a 1D direction (e.g. horizontal) we show that these challenges can be addressed using a camera that moves during the exposure. Through the analysis of motion blur as space-time integration, we show that a parabolic integration (corresponding to constant sensor acceleration) leads to motion blur that is invariant to object velocity. Thus, a single deconvolution kernel can be used to remove blur and create sharp images of scenes with objects moving at different speeds, without requiring any segmentation and without knowledge of the object speeds. Apart from motion invariance, we prove that the derived parabolic motion preserves image frequency content nearly optimally. That is, while static objects are degraded relative to their image from a static camera, a reliable reconstruction of all moving objects within a given velocities range is made possible. We have built a prototype camera and present successful deblurring results over a wide variety of human motions.</p></div></span> <a id="expcoll73" href="JavaScript: expandcollapse('expcoll73',73)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360671&CFID=85074889&CFTOKEN=32802275">Single image dehazing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100376142&CFID=85074889&CFTOKEN=32802275">Raanan Fattal</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 72</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360671" title="DOI">10.1145/1399504.1360671</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360671&ftid=534600&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360671&ftid=977739&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow74" style="display:inline;"><br /><div style="display:inline">In this paper we present a new method for estimating the optical transmission in hazy scenes given a single input image. Based on this estimation, the scattered light is eliminated to increase scene visibility and recover haze-free scene contrasts. In ...</div></span>
          <span id="toHide74" style="display:none;"><br /><div style="display:inline"><p>In this paper we present a new method for estimating the optical transmission in hazy scenes given a single input image. Based on this estimation, the scattered light is eliminated to increase scene visibility and recover haze-free scene contrasts. In this new approach we formulate a refined image formation model that accounts for surface shading in addition to the transmission function. This allows us to resolve ambiguities in the data by searching for a solution in which the resulting shading and transmission functions are locally statistically uncorrelated. A similar principle is used to estimate the color of the haze. Results demonstrate the new method abilities to remove the haze layer as well as provide a reliable transmission estimate which can be used for additional applications such as image refocusing and novel view synthesis.</p></div></span> <a id="expcoll74" href="JavaScript: expandcollapse('expcoll74',74)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360672&CFID=85074889&CFTOKEN=32802275">High-quality motion deblurring from a single image</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81385594442&CFID=85074889&CFTOKEN=32802275">Qi Shan</a>, 
                        <a href="author_page.cfm?id=81100499465&CFID=85074889&CFTOKEN=32802275">Jiaya Jia</a>, 
                        <a href="author_page.cfm?id=81100035467&CFID=85074889&CFTOKEN=32802275">Aseem Agarwala</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 73</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360672" title="DOI">10.1145/1399504.1360672</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360672&ftid=534601&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360672&ftid=979177&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow75" style="display:inline;"><br /><div style="display:inline">We present a new algorithm for removing motion blur from a single image. Our method computes a deblurred image using a unified probabilistic model of both blur kernel estimation and unblurred image restoration. We present an analysis of the causes ...</div></span>
          <span id="toHide75" style="display:none;"><br /><div style="display:inline"><p>We present a new algorithm for removing motion blur from a single image. Our method computes a deblurred image using a unified probabilistic model of <i>both</i> blur kernel estimation and unblurred image restoration. We present an analysis of the causes of common artifacts found in current deblurring methods, and then introduce several novel terms within this probabilistic model that are inspired by our analysis. These terms include a model of the spatial randomness of noise in the blurred image, as well a new local smoothness prior that reduces ringing artifacts by constraining contrast in the unblurred image wherever the blurred image exhibits low contrast. Finally, we describe an effficient optimization scheme that alternates between blur kernel estimation and unblurred image restoration until convergence. As a result of these steps, we are able to produce high quality deblurred results in low computation time. We are even able to produce results of comparable quality to techniques that require additional input images beyond a single blurry photograph, and to methods that require additional hardware.</p></div></span> <a id="expcoll75" href="JavaScript: expandcollapse('expcoll75',75)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360673&CFID=85074889&CFTOKEN=32802275">Progressive inter-scale and intra-scale non-blind image deconvolution</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440594006&CFID=85074889&CFTOKEN=32802275">Lu Yuan</a>, 
                        <a href="author_page.cfm?id=81351592034&CFID=85074889&CFTOKEN=32802275">Jian Sun</a>, 
                        <a href="author_page.cfm?id=81100063997&CFID=85074889&CFTOKEN=32802275">Long Quan</a>, 
                        <a href="author_page.cfm?id=81365591566&CFID=85074889&CFTOKEN=32802275">Heung-Yeung Shum</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 74</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360673" title="DOI">10.1145/1399504.1360673</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360673&ftid=534602&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360673&ftid=977740&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow76" style="display:inline;"><br /><div style="display:inline">Ringing is the most disturbing artifact in the image deconvolution. In this paper, we present a progressive inter-scale and intra-scale non-blind image deconvolution approach that significantly reduces ringing. Our approach is built on a novel edge-preserving ...</div></span>
          <span id="toHide76" style="display:none;"><br /><div style="display:inline"><p>Ringing is the most disturbing artifact in the image deconvolution. In this paper, we present a progressive inter-scale and intra-scale non-blind image deconvolution approach that significantly reduces ringing. Our approach is built on a novel edge-preserving deconvolution algorithm called <i>bilateral Richardson-Lucy (BRL)</i> which uses a large spatial support to handle large blur. We progressively recover the image from a coarse scale to a fine scale (inter-scale), and progressively restore image details within every scale (intra-scale). To perform the inter-scale deconvolution, we propose a <i>joint bilateral Richardson-Lucy (JBRL)</i> algorithm so that the recovered image in one scale can guide the deconvolution in the next scale. In each scale, we propose an iterative residual deconvolution to progressively recover image details. The experimental results show that our progressive deconvolution can produce images with very little ringing for large blur kernels.</p></div></span> <a id="expcoll76" href="JavaScript: expandcollapse('expcoll76',76)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Folding & unfolding surfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Bruno Levy 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360674&CFID=85074889&CFTOKEN=32802275">Curved folding</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365594691&CFID=85074889&CFTOKEN=32802275">Martin Kilian</a>, 
                        <a href="author_page.cfm?id=81335490132&CFID=85074889&CFTOKEN=32802275">Simon Fl&#246;ry</a>, 
                        <a href="author_page.cfm?id=81365593478&CFID=85074889&CFTOKEN=32802275">Zhonggui Chen</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=85074889&CFTOKEN=32802275">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81100389496&CFID=85074889&CFTOKEN=32802275">Alla Sheffer</a>, 
                        <a href="author_page.cfm?id=81100537406&CFID=85074889&CFTOKEN=32802275">Helmut Pottmann</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 75</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360674" title="DOI">10.1145/1399504.1360674</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360674&ftid=534631&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360674&ftid=634577&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360674&ftid=979178&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow78" style="display:inline;"><br /><div style="display:inline">Fascinating and elegant shapes may be folded from a single planar sheet of material without stretching, tearing or cutting, if one incorporates curved folds into the design. We present an optimization-based computational framework for design and digital ...</div></span>
          <span id="toHide78" style="display:none;"><br /><div style="display:inline"><p>Fascinating and elegant shapes may be folded from a single planar sheet of material without stretching, tearing or cutting, if one incorporates curved folds into the design. We present an optimization-based computational framework for design and digital reconstruction of surfaces which can be produced by curved folding. Our work not only contributes to applications in architecture and industrial design, but it also provides a new way to study the complex and largely unexplored phenomena arising in curved folding.</p></div></span> <a id="expcoll78" href="JavaScript: expandcollapse('expcoll78',78)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360675&CFID=85074889&CFTOKEN=32802275">Freeform surfaces from single curved panels</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100537406&CFID=85074889&CFTOKEN=32802275">Helmut Pottmann</a>, 
                        <a href="author_page.cfm?id=81365598099&CFID=85074889&CFTOKEN=32802275">Alexander Schiftner</a>, 
                        <a href="author_page.cfm?id=81365596214&CFID=85074889&CFTOKEN=32802275">Pengbo Bo</a>, 
                        <a href="author_page.cfm?id=81365597685&CFID=85074889&CFTOKEN=32802275">Heinz Schmiedhofer</a>, 
                        <a href="author_page.cfm?id=81451595839&CFID=85074889&CFTOKEN=32802275">Wenping Wang</a>, 
                        <a href="author_page.cfm?id=81365598654&CFID=85074889&CFTOKEN=32802275">Niccolo Baldassini</a>, 
                        <a href="author_page.cfm?id=81100493818&CFID=85074889&CFTOKEN=32802275">Johannes Wallner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 76</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360675" title="DOI">10.1145/1399504.1360675</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360675&ftid=534603&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360675&ftid=979179&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow79" style="display:inline;"><br /><div style="display:inline">Motivated by applications in architecture and manufacturing, we discuss the problem of covering a freeform surface by single curved panels. This leads to the new concept of semi-discrete surface representation, which constitutes a link between smooth ...</div></span>
          <span id="toHide79" style="display:none;"><br /><div style="display:inline"><p>Motivated by applications in architecture and manufacturing, we discuss the problem of covering a freeform surface by single curved panels. This leads to the new concept of semi-discrete surface representation, which constitutes a link between smooth and discrete surfaces. The basic entity we are working with is the developable strip model. It is the semi-discrete equivalent of a quad mesh with planar faces, or a conjugate parametrization of a smooth surface. We present a B-spline based optimization framework for efficient computing with D-strip models. In particular we study conical and circular models, which semi-discretize the network of principal curvature lines, and which enjoy elegant geometric properties. Together with geodesic models and cylindrical models they offer a rich source of solutions for surface panelization problems.</p></div></span> <a id="expcoll79" href="JavaScript: expandcollapse('expcoll79',79)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360676&CFID=85074889&CFTOKEN=32802275">Conformal equivalence of triangle meshes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314491710&CFID=85074889&CFTOKEN=32802275">Boris Springborn</a>, 
                        <a href="author_page.cfm?id=81100117380&CFID=85074889&CFTOKEN=32802275">Peter Schr&#246;der</a>, 
                        <a href="author_page.cfm?id=81365591193&CFID=85074889&CFTOKEN=32802275">Ulrich Pinkall</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 77</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360676" title="DOI">10.1145/1399504.1360676</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360676&ftid=534604&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360676&ftid=977741&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow80" style="display:inline;"><br /><div style="display:inline">We present a new algorithm for conformal mesh parameterization. It is based on a precise notion of discrete conformal equivalence for triangle meshes which mimics the notion of conformal equivalence for smooth surfaces. The problem of finding ...</div></span>
          <span id="toHide80" style="display:none;"><br /><div style="display:inline"><p>We present a new algorithm for conformal mesh parameterization. It is based on a precise notion of <i>discrete conformal equivalence</i> for triangle meshes which mimics the notion of conformal equivalence for smooth surfaces. The problem of finding a flat mesh that is discretely conformally equivalent to a given mesh can be solved efficiently by minimizing a convex energy function, whose Hessian turns out to be the well known cot-Laplace operator. This method can also be used to map a surface mesh to a parameter domain which is flat except for isolated cone singularities, and we show how these can be placed automatically in order to reduce the distortion of the parameterization. We present the salient features of the theory and elaborate the algorithms with a number of examples.</p></div></span> <a id="expcoll80" href="JavaScript: expandcollapse('expcoll80',80)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360677&CFID=85074889&CFTOKEN=32802275">Green Coordinates</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100456149&CFID=85074889&CFTOKEN=32802275">Yaron Lipman</a>, 
                        <a href="author_page.cfm?id=81100404814&CFID=85074889&CFTOKEN=32802275">David Levin</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074889&CFTOKEN=32802275">Daniel Cohen-Or</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 78</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360677" title="DOI">10.1145/1399504.1360677</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360677&ftid=534605&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360677&ftid=979180&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow81" style="display:inline;"><br /><div style="display:inline">We introduce Green Coordinates for closed polyhedral cages. The coordinates are motivated by Green's third integral identity and respect both the vertices position and faces orientation of the cage. We show that Green Coordinates lead to space deformations ...</div></span>
          <span id="toHide81" style="display:none;"><br /><div style="display:inline"><p>We introduce Green Coordinates for closed polyhedral cages. The coordinates are motivated by Green's third integral identity and respect both the vertices position and faces orientation of the cage. We show that Green Coordinates lead to space deformations with a shape-preserving property. In particular, in 2D they induce conformal mappings, and extend naturally to quasi-conformal mappings in 3D. In both cases we derive closed-form expressions for the coordinates, yielding a simple and fast algorithm for cage-based space deformation. We compare the performance of Green Coordinates with those of Mean Value Coordinates and Harmonic Coordinates and show that the advantage of the shape-preserving property is not achieved at the expense of speed or simplicity. We also show that the new coordinates extend the mapping in a natural analytic manner to the exterior of the cage, allowing the employment of partial cages.</p></div></span> <a id="expcoll81" href="JavaScript: expandcollapse('expcoll81',81)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360678&CFID=85074889&CFTOKEN=32802275">Watertight trimmed NURBS</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100400673&CFID=85074889&CFTOKEN=32802275">Thomas W. Sederberg</a>, 
                        <a href="author_page.cfm?id=81365596411&CFID=85074889&CFTOKEN=32802275">G. Thomas Finnigan</a>, 
                        <a href="author_page.cfm?id=81351597620&CFID=85074889&CFTOKEN=32802275">Xin Li</a>, 
                        <a href="author_page.cfm?id=81408600174&CFID=85074889&CFTOKEN=32802275">Hongwei Lin</a>, 
                        <a href="author_page.cfm?id=81365598512&CFID=85074889&CFTOKEN=32802275">Heather Ipson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 79</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360678" title="DOI">10.1145/1399504.1360678</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360678&ftid=534606&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360678&ftid=977742&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow82" style="display:inline;"><br /><div style="display:inline">This paper addresses the long-standing problem of the unavoidable gaps that arise when expressing the intersection of two NURBS surfaces using conventional trimmed-NURBS representation. The solution converts each trimmed NURBS into an untrimmed T-Spline, ...</div></span>
          <span id="toHide82" style="display:none;"><br /><div style="display:inline"><p>This paper addresses the long-standing problem of the unavoidable gaps that arise when expressing the intersection of two NURBS surfaces using conventional trimmed-NURBS representation. The solution converts each trimmed NURBS into an untrimmed T-Spline, and then merges the untrimmed T-Splines into a single, watertight model. The solution enables watertight fillets of NURBS models, as well as arbitrary feature curves that do not have to follow iso-parameter curves. The resulting T-Spline representation can be exported without error as a collection of NURBS surfaces.</p></div></span> <a id="expcoll82" href="JavaScript: expandcollapse('expcoll82',82)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Humans</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Adrien Treuille 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360679&CFID=85074889&CFTOKEN=32802275">Group motion editing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100183995&CFID=85074889&CFTOKEN=32802275">Taesoo Kwon</a>, 
                        <a href="author_page.cfm?id=81409592814&CFID=85074889&CFTOKEN=32802275">Kang Hoon Lee</a>, 
                        <a href="author_page.cfm?id=81100429553&CFID=85074889&CFTOKEN=32802275">Jehee Lee</a>, 
                        <a href="author_page.cfm?id=81410594549&CFID=85074889&CFTOKEN=32802275">Shigeo Takahashi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 80</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360679" title="DOI">10.1145/1399504.1360679</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360679&ftid=534607&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360679&ftid=634578&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360679&ftid=979181&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow84" style="display:inline;"><br /><div style="display:inline">Animating a crowd of characters is an important problem in computer graphics. The latest techniques enable highly realistic group motions to be produced in feature animation films and video games. However, interactive methods have not emerged yet for ...</div></span>
          <span id="toHide84" style="display:none;"><br /><div style="display:inline"><p>Animating a crowd of characters is an important problem in computer graphics. The latest techniques enable highly realistic group motions to be produced in feature animation films and video games. However, interactive methods have not emerged yet for editing the existing group motion of multiple characters. We present an approach to editing group motion as a whole while maintaining its neighborhood formation and individual moving trajectories in the original animation as much as possible. The user can deform a group motion by pinning or dragging individuals. Multiple group motions can be stitched or merged to form a longer or larger group motion while avoiding collisions. These editing operations rely on a novel graph structure, in which vertices represent positions of individuals at specific frames and edges encode neighborhood formations and moving trajectories. We employ a shape-manipulation technique to minimize the distortion of relative arrangements among adjacent vertices while editing the graph structure. The usefulness and flexibility of our approach is demonstrated through examples in which the user creates and edits complex crowd animations interactively using a collection of group motion clips.</p></div></span> <a id="expcoll84" href="JavaScript: expandcollapse('expcoll84',84)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360680&CFID=85074889&CFTOKEN=32802275">Continuation methods for adapting simulated skills</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100408711&CFID=85074889&CFTOKEN=32802275">KangKang Yin</a>, 
                        <a href="author_page.cfm?id=81320488815&CFID=85074889&CFTOKEN=32802275">Stelian Coros</a>, 
                        <a href="author_page.cfm?id=81100525234&CFID=85074889&CFTOKEN=32802275">Philippe Beaudoin</a>, 
                        <a href="author_page.cfm?id=81319502903&CFID=85074889&CFTOKEN=32802275">Michiel van de Panne</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 81</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360680" title="DOI">10.1145/1399504.1360680</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360680&ftid=534608&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360680&ftid=634579&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360680&ftid=979182&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow85" style="display:inline;"><br /><div style="display:inline">Modeling the large space of possible human motions requires scalable techniques. Generalizing from example motions or example controllers is one way to provide the required scalability. We present techniques for generalizing a controller for physics-based ...</div></span>
          <span id="toHide85" style="display:none;"><br /><div style="display:inline"><p>Modeling the large space of possible human motions requires scalable techniques. Generalizing from example motions or example controllers is one way to provide the required scalability. We present techniques for generalizing a controller for physics-based walking to significantly different tasks, such as climbing a large step up, or pushing a heavy object. Continuation methods solve such problems using a progressive sequence of problems that trace a path from an existing solved problem to the final desired-but-unsolved problem. Each step in the continuation sequence makes progress towards the target problem while further adapting the solution. We describe and evaluate a number of choices in applying continuation methods to adapting walking gaits for tasks involving interaction with the environment. The methods have been successfully applied to automatically adapt a regular cyclic walk to climbing a 65<i>cm</i> step, stepping over a 55<i>cm</i> sill, pushing heavy furniture, walking up steep inclines, and walking on ice. The continuation path further provides parameterized solutions to these problems.</p></div></span> <a id="expcoll85" href="JavaScript: expandcollapse('expcoll85',85)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360681&CFID=85074889&CFTOKEN=32802275">Interactive simulation of stylized human locomotion</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335489454&CFID=85074889&CFTOKEN=32802275">Marco da Silva</a>, 
                        <a href="author_page.cfm?id=81323487451&CFID=85074889&CFTOKEN=32802275">Yeuhi Abe</a>, 
                        <a href="author_page.cfm?id=81100620337&CFID=85074889&CFTOKEN=32802275">Jovan Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 82</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360681" title="DOI">10.1145/1399504.1360681</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360681&ftid=534609&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360681&ftid=634580&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360681&ftid=977743&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow86" style="display:inline;"><br /><div style="display:inline">Animating natural human motion in dynamic environments is difficult because of complex geometric and physical interactions. Simulation provides an automatic solution to parts of this problem, but it needs control systems to produce lifelike motions. ...</div></span>
          <span id="toHide86" style="display:none;"><br /><div style="display:inline"><p>Animating natural human motion in dynamic environments is difficult because of complex geometric and physical interactions. Simulation provides an automatic solution to parts of this problem, but it needs control systems to produce lifelike motions. This paper describes the systematic computation of controllers that can reproduce a range of locomotion styles in interactive simulations. Given a reference motion that describes the desired style, a derived control system can reproduce that style in simulation and in new environments. Because it produces high-quality motions that are both geometrically and physically consistent with simulated surroundings, interactive animation systems could begin to use this approach along with more established kinematic methods.</p></div></span> <a id="expcoll86" href="JavaScript: expandcollapse('expcoll86',86)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360682&CFID=85074889&CFTOKEN=32802275">Musculotendon simulation for hand animation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335498230&CFID=85074889&CFTOKEN=32802275">Shinjiro Sueda</a>, 
                        <a href="author_page.cfm?id=81365594265&CFID=85074889&CFTOKEN=32802275">Andrew Kaufman</a>, 
                        <a href="author_page.cfm?id=81100642559&CFID=85074889&CFTOKEN=32802275">Dinesh K. Pai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 83</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360682" title="DOI">10.1145/1399504.1360682</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360682&ftid=534610&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360682&ftid=634581&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360682&ftid=979183&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow87" style="display:inline;"><br /><div style="display:inline">We describe an automatic technique for generating the motion of tendons and muscles under the skin of a traditionally animated character. This is achieved by integrating the traditional animation pipeline with a novel biomechanical simulator capable ...</div></span>
          <span id="toHide87" style="display:none;"><br /><div style="display:inline"><p>We describe an automatic technique for generating the motion of tendons and muscles under the skin of a traditionally animated character. This is achieved by integrating the traditional animation pipeline with a novel biomechanical simulator capable of dynamic simulation with complex routing constraints on muscles and tendons. We also describe an algorithm for computing the activation levels of muscles required to track the input animation. We demonstrate the results with several animations of the human hand.</p></div></span> <a id="expcoll87" href="JavaScript: expandcollapse('expcoll87',87)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Shape acquisition</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Srinivasa Narasimhan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360683&CFID=85074889&CFTOKEN=32802275">A system for high-volume acquisition and matching of fresco fragments: reassembling Theran wall paintings</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100013389&CFID=85074889&CFTOKEN=32802275">Benedict J. Brown</a>, 
                        <a href="author_page.cfm?id=81365591561&CFID=85074889&CFTOKEN=32802275">Corey Toler-Franklin</a>, 
                        <a href="author_page.cfm?id=81100057362&CFID=85074889&CFTOKEN=32802275">Diego Nehab</a>, 
                        <a href="author_page.cfm?id=81332491677&CFID=85074889&CFTOKEN=32802275">Michael Burns</a>, 
                        <a href="author_page.cfm?id=81100388507&CFID=85074889&CFTOKEN=32802275">David Dobkin</a>, 
                        <a href="author_page.cfm?id=81365598169&CFID=85074889&CFTOKEN=32802275">Andreas Vlachopoulos</a>, 
                        <a href="author_page.cfm?id=81365598196&CFID=85074889&CFTOKEN=32802275">Christos Doumas</a>, 
                        <a href="author_page.cfm?id=81100203803&CFID=85074889&CFTOKEN=32802275">Szymon Rusinkiewicz</a>, 
                        <a href="author_page.cfm?id=81100258924&CFID=85074889&CFTOKEN=32802275">Tim Weyrich</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 84</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360683" title="DOI">10.1145/1399504.1360683</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360683&ftid=534611&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360683&ftid=977744&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow89" style="display:inline;"><br /><div style="display:inline">Although mature technologies exist for acquiring images, geometry, and normals of small objects, they remain cumbersome and time-consuming for non-experts to employ on a large scale. In an archaeological setting, a practical acquisition system for routine ...</div></span>
          <span id="toHide89" style="display:none;"><br /><div style="display:inline"><p>Although mature technologies exist for acquiring images, geometry, and normals of small objects, they remain cumbersome and time-consuming for non-experts to employ on a large scale. In an archaeological setting, a practical acquisition system for routine use on <i>every</i> artifact and fragment would open new possibilities for archiving, analysis, and dissemination. We present an inexpensive system for acquiring all three types of information, and associated metadata, for small objects such as fragments of wall paintings. The acquisition system requires minimal supervision, so that a single, non-expert user can scan at least 10 fragments per hour. To achieve this performance, we introduce new algorithms to robustly and automatically align range scans, register 2-D scans to 3-D geometry, and compute normals from 2-D scans. As an illustrative application, we present a novel 3-D matching algorithm that efficiently searches for matching fragments using the scanned geometry.</p></div></span> <a id="expcoll89" href="JavaScript: expandcollapse('expcoll89',89)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360684&CFID=85074889&CFTOKEN=32802275">4-points congruent sets for robust pairwise surface registration</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100659706&CFID=85074889&CFTOKEN=32802275">Dror Aiger</a>, 
                        <a href="author_page.cfm?id=81335494949&CFID=85074889&CFTOKEN=32802275">Niloy J. Mitra</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074889&CFTOKEN=32802275">Daniel Cohen-Or</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 85</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360684" title="DOI">10.1145/1399504.1360684</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360684&ftid=534612&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360684&ftid=979184&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow90" style="display:inline;"><br /><div style="display:inline">We introduce 4PCS, a fast and robust alignment scheme for 3D point sets that uses wide bases, which are known to be resilient to noise and outliers. The algorithm allows registering raw noisy data, possibly contaminated with outliers, without pre-filtering ...</div></span>
          <span id="toHide90" style="display:none;"><br /><div style="display:inline"><p>We introduce 4PCS, a fast and robust alignment scheme for 3D point sets that uses wide bases, which are known to be resilient to noise and outliers. The algorithm allows registering raw noisy data, possibly contaminated with outliers, without pre-filtering or denoising the data. Further, the method significantly reduces the number of trials required to establish a reliable registration between the underlying surfaces in the presence of noise, without any assumptions about starting alignment. Our method is based on a novel technique to extract all coplanar 4-points sets from a 3D point set that are approximately congruent, under rigid transformation, to a given set of coplanar 4-points. This extraction procedure runs in roughly <i>O(n<sup>2</sup> + k)</i> time, where <i>n</i> is the number of candidate points and <i>k</i> is the number of reported 4-points sets. In practice, when noise level is low and there is sufficient overlap, using local descriptors the time complexity reduces to <i>O(n + k)</i>. We also propose an extension to handle similarity and affine transforms. Our technique achieves an order of magnitude asymptotic acceleration compared to common randomized alignment techniques. We demonstrate the robustness of our algorithm on several sets of multiple range scans with varying degree of noise, outliers, and extent of overlap.</p></div></span> <a id="expcoll90" href="JavaScript: expandcollapse('expcoll90',90)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360685&CFID=85074889&CFTOKEN=32802275">3D-modeling by ortho-image generation from image sequences</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81317501299&CFID=85074889&CFTOKEN=32802275">Thorsten Thorm&#228;hlen</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=85074889&CFTOKEN=32802275">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 86</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360685" title="DOI">10.1145/1399504.1360685</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360685&ftid=534613&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360685&ftid=634582&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360685&ftid=979185&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow91" style="display:inline;"><br /><div style="display:inline">A semi-automatic approach is presented that enables the generation of a high-quality 3D model of a static object from an image sequence that was taken by a moving, uncalibrated consumer camera. A bounding box is placed around the object, and orthographic ...</div></span>
          <span id="toHide91" style="display:none;"><br /><div style="display:inline"><p>A semi-automatic approach is presented that enables the generation of a high-quality 3D model of a static object from an image sequence that was taken by a moving, uncalibrated consumer camera. A bounding box is placed around the object, and orthographic projections onto the sides of the bounding box are automatically generated out of the image sequence. These ortho-images can be imported as background maps in the orthographic views (e.g., the top, side, and front view) of any modeling package. Modelers can now use these ortho-images to guide their modeling by tracing the shape of the object over the ortho-images. This greatly improves the accuracy and efficiency of the manual modeling process. An additional advantage over existing semi-automatic systems is that modelers can use the modeling package that they are trained in and can thereby increase their productivity by applying the advanced modeling features the package offers. The results presented show that accurate 3D models can even be generated for translucent or specular surfaces, and the approach is therefore still applicable in cases where today's fully automatic image-based approaches or laser scanners would fail.</p></div></span> <a id="expcoll91" href="JavaScript: expandcollapse('expcoll91',91)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360686&CFID=85074889&CFTOKEN=32802275">Fluorescent immersion range scanning</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365598554&CFID=85074889&CFTOKEN=32802275">Matthias B. Hullin</a>, 
                        <a href="author_page.cfm?id=81332499566&CFID=85074889&CFTOKEN=32802275">Martin Fuchs</a>, 
                        <a href="author_page.cfm?id=81331495034&CFID=85074889&CFTOKEN=32802275">Ivo Ihrke</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=85074889&CFTOKEN=32802275">Hans-Peter Seidel</a>, 
                        <a href="author_page.cfm?id=81100504611&CFID=85074889&CFTOKEN=32802275">Hendrik P. A. Lensch</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 87</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360686" title="DOI">10.1145/1399504.1360686</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360686&ftid=534614&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360686&ftid=977745&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow92" style="display:inline;"><br /><div style="display:inline">The quality of a 3D range scan should not depend on the surface properties of the object. Most active range scanning techniques, however, assume a diffuse reflector to allow for a robust detection of incident light patterns. In our approach we embed ...</div></span>
          <span id="toHide92" style="display:none;"><br /><div style="display:inline"><p>The quality of a 3D range scan should not depend on the surface properties of the object. Most active range scanning techniques, however, assume a diffuse reflector to allow for a robust detection of incident light patterns. In our approach we embed the object into a fluorescent liquid. By analyzing the light rays that become visible due to fluorescence rather than analyzing their reflections off the surface, we can detect the intersection points between the projected laser sheet and the object surface for a wide range of different materials. For transparent objects we can even directly depict a slice through the object in just one image by matching its refractive index to the one of the embedding liquid. This enables a direct sampling of the object geometry without the need for computational reconstruction. This way, a high-resolution 3D volume can be assembled simply by sweeping a laser plane through the object. We demonstrate the effectiveness of our light sheet range scanning approach on a set of objects manufactured from a variety of materials and material mixes, including dark, translucent and transparent objects.</p></div></span> <a id="expcoll92" href="JavaScript: expandcollapse('expcoll92',92)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>NPR & deformation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Olga Sorkine 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360687&CFID=85074889&CFTOKEN=32802275">Where do people draw lines?</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81351604051&CFID=85074889&CFTOKEN=32802275">Forrester Cole</a>, 
                        <a href="author_page.cfm?id=81314494022&CFID=85074889&CFTOKEN=32802275">Aleksey Golovinskiy</a>, 
                        <a href="author_page.cfm?id=81365597857&CFID=85074889&CFTOKEN=32802275">Alex Limpaecher</a>, 
                        <a href="author_page.cfm?id=81365595149&CFID=85074889&CFTOKEN=32802275">Heather Stoddart Barros</a>, 
                        <a href="author_page.cfm?id=81100576882&CFID=85074889&CFTOKEN=32802275">Adam Finkelstein</a>, 
                        <a href="author_page.cfm?id=81100182132&CFID=85074889&CFTOKEN=32802275">Thomas Funkhouser</a>, 
                        <a href="author_page.cfm?id=81100203803&CFID=85074889&CFTOKEN=32802275">Szymon Rusinkiewicz</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 88</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360687" title="DOI">10.1145/1399504.1360687</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360687&ftid=534615&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360687&ftid=977939&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow94" style="display:inline;"><br /><div style="display:inline">This paper presents the results of a study in which artists made line drawings intended to convey specific 3D shapes. The study was designed so that drawings could be registered with rendered images of 3D models, supporting an analysis of how well the ...</div></span>
          <span id="toHide94" style="display:none;"><br /><div style="display:inline"><p>This paper presents the results of a study in which artists made line drawings intended to convey specific 3D shapes. The study was designed so that drawings could be registered with rendered images of 3D models, supporting an analysis of how well the locations of the artists' lines correlate with other artists', with current computer graphics line definitions, and with the underlying differential properties of the 3D surface. Lines drawn by artists in this study largely overlapped one another (75% are within 1mm of another line), particularly along the occluding contours of the object. Most lines that do not overlap contours overlap large gradients of the image intensity, and correlate strongly with predictions made by recent line drawing algorithms in computer graphics. 14% were not well described by any of the local properties considered in this study. The result of our work is a publicly available data set of aligned drawings, an analysis of where lines appear in that data set based on local properties of 3D models, and algorithms to predict where artists will draw lines for new scenes.</p></div></span> <a id="expcoll94" href="JavaScript: expandcollapse('expcoll94',94)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360688&CFID=85074889&CFTOKEN=32802275">Structure-aware halftoning</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365591899&CFID=85074889&CFTOKEN=32802275">Wai-Man Pang</a>, 
                        <a href="author_page.cfm?id=81100337844&CFID=85074889&CFTOKEN=32802275">Yingge Qu</a>, 
                        <a href="author_page.cfm?id=81343509200&CFID=85074889&CFTOKEN=32802275">Tien-Tsin Wong</a>, 
                        <a href="author_page.cfm?id=81100264399&CFID=85074889&CFTOKEN=32802275">Daniel Cohen-Or</a>, 
                        <a href="author_page.cfm?id=81452597418&CFID=85074889&CFTOKEN=32802275">Pheng-Ann Heng</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 89</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360688" title="DOI">10.1145/1399504.1360688</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360688&ftid=534616&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360688&ftid=977940&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow95" style="display:inline;"><br /><div style="display:inline">This paper presents an optimization-based halftoning technique that preserves the structure and tone similarities between the original and the halftone images. By optimizing an objective function consisting of both the structure and the tone metrics, ...</div></span>
          <span id="toHide95" style="display:none;"><br /><div style="display:inline"><p>This paper presents an optimization-based halftoning technique that preserves the structure and tone similarities between the original and the halftone images. By optimizing an objective function consisting of both the structure and the tone metrics, the generated halftone images preserve visually sensitive texture details as well as the local tone. It possesses the blue-noise property and does not introduce annoying patterns. Unlike the existing edge-enhancement halftoning, the proposed method does not suffer from the deficiencies of edge detector. Our method is tested on various types of images. In multiple experiments and the user study, our method consistently obtains the best scores among all tested methods.</p></div></span> <a id="expcoll95" href="JavaScript: expandcollapse('expcoll95',95)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360689&CFID=85074889&CFTOKEN=32802275">3D unsharp masking for scene coherent enhancement</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81351607404&CFID=85074889&CFTOKEN=32802275">Tobias Ritschel</a>, 
                        <a href="author_page.cfm?id=81365592382&CFID=85074889&CFTOKEN=32802275">Kaleigh Smith</a>, 
                        <a href="author_page.cfm?id=81365598523&CFID=85074889&CFTOKEN=32802275">Matthias Ihrke</a>, 
                        <a href="author_page.cfm?id=81351597401&CFID=85074889&CFTOKEN=32802275">Thorsten Grosch</a>, 
                        <a href="author_page.cfm?id=81332517742&CFID=85074889&CFTOKEN=32802275">Karol Myszkowski</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=85074889&CFTOKEN=32802275">Hans-Peter Seidel</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 90</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360689" title="DOI">10.1145/1399504.1360689</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360689&ftid=534617&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360689&ftid=977941&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow96" style="display:inline;"><br /><div style="display:inline">We present a new approach for enhancing local scene contrast by unsharp masking over arbitrary surfaces under any form of illumination. Our adaptation of a well-known 2D technique to 3D interactive scenarios is designed to aid viewers in tasks like understanding ...</div></span>
          <span id="toHide96" style="display:none;"><br /><div style="display:inline"><p>We present a new approach for enhancing local scene contrast by unsharp masking over arbitrary surfaces under any form of illumination. Our adaptation of a well-known 2D technique to 3D interactive scenarios is designed to aid viewers in tasks like understanding complex or detailed geometric models, medical visualization and navigation in virtual environments. Our holistic approach enhances the depiction of various visual cues, including gradients from surface shading, surface reflectance, shadows, and highlights, to ease estimation of viewpoint, lighting conditions, shapes of objects and their world-space organization. Motivated by recent perceptual findings on 3D aspects of the Cornsweet illusion, we create scene coherent enhancements by treating cues in terms of their 3D context; doing so has a stronger effect than approaches that operate in a 2D image context and also achieves temporal coherence. We validate our unsharp masking in 3D with psychophysical experiments showing that the enhanced images are perceived to have better contrast and are preferred over unenhanced originals. Our operator runs at real-time rates on a GPU and the effect is easily controlled interactively within the rendering pipeline.</p></div></span> <a id="expcoll96" href="JavaScript: expandcollapse('expcoll96',96)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360690&CFID=85074889&CFTOKEN=32802275">Real-time data driven deformation using kernel canonical correlation analysis</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314493746&CFID=85074889&CFTOKEN=32802275">Wei-Wen Feng</a>, 
                        <a href="author_page.cfm?id=81365593919&CFID=85074889&CFTOKEN=32802275">Byung-Uck Kim</a>, 
                        <a href="author_page.cfm?id=81100472713&CFID=85074889&CFTOKEN=32802275">Yizhou Yu</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 91</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360690" title="DOI">10.1145/1399504.1360690</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360690&ftid=534618&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360690&ftid=977942&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow97" style="display:inline;"><br /><div style="display:inline">Achieving intuitive control of animated surface deformation while observing a specific style is an important but challenging task in computer graphics. Solutions to this task can find many applications in data-driven skin animation, computer puppetry, ...</div></span>
          <span id="toHide97" style="display:none;"><br /><div style="display:inline"><p>Achieving intuitive control of animated surface deformation while observing a specific style is an important but challenging task in computer graphics. Solutions to this task can find many applications in data-driven skin animation, computer puppetry, and computer games. In this paper, we present an intuitive and powerful animation interface to simultaneously control the deformation of a large number of local regions on a deformable surface with a minimal number of control points. Our method learns suitable deformation subspaces from training examples, and generate new deformations on the fly according to the movements of the control points. Our contributions include a novel deformation regression method based on kernel Canonical Correlation Analysis (CCA) and a Poisson-based translation solving technique for easy and fast deformation control based on examples. Our run-time algorithm can be implemented on GPUs and can achieve a few hundred frames per second even for large datasets with hundreds of training examples.</p></div></span> <a id="expcoll97" href="JavaScript: expandcollapse('expcoll97',97)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Painting & sketching</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Matthias Zwicker 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360691&CFID=85074889&CFTOKEN=32802275">Diffusion curves: a vector representation for smooth-shaded images</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335495800&CFID=85074889&CFTOKEN=32802275">Alexandrina Orzan</a>, 
                        <a href="author_page.cfm?id=81314487615&CFID=85074889&CFTOKEN=32802275">Adrien Bousseau</a>, 
                        <a href="author_page.cfm?id=81314495028&CFID=85074889&CFTOKEN=32802275">Holger Winnem&#246;ller</a>, 
                        <a href="author_page.cfm?id=81314487621&CFID=85074889&CFTOKEN=32802275">Pascal Barla</a>, 
                        <a href="author_page.cfm?id=81319502458&CFID=85074889&CFTOKEN=32802275">Jo&#235;lle Thollot</a>, 
                        <a href="author_page.cfm?id=81100188207&CFID=85074889&CFTOKEN=32802275">David Salesin</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 92</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360691" title="DOI">10.1145/1399504.1360691</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360691&ftid=534619&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360691&ftid=977943&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow99" style="display:inline;"><br /><div style="display:inline">We describe a new vector-based primitive for creating smooth-shaded images, called the diffusion curve. A diffusion curve partitions the space through which it is drawn, defining different colors on either side. These colors may vary smoothly ...</div></span>
          <span id="toHide99" style="display:none;"><br /><div style="display:inline"><p>We describe a new vector-based primitive for creating smooth-shaded images, called the <i>diffusion curve</i>. A diffusion curve partitions the space through which it is drawn, defining different colors on either side. These colors may vary smoothly along the curve. In addition, the sharpness of the color transition from one side of the curve to the other can be controlled. Given a set of diffusion curves, the final image is constructed by solving a Poisson equation whose constraints are specified by the set of gradients across all diffusion curves. Like all vector-based primitives, diffusion curves conveniently support a variety of operations, including geometry-based editing, keyframe animation, and ready stylization. Moreover, their representation is compact and inherently resolution-independent. We describe a GPU-based implementation for rendering images defined by a set of diffusion curves in realtime. We then demonstrate an interactive drawing system for allowing artists to create artworks using diffusion curves, either by drawing the curves in a freehand style, or by tracing existing imagery. The system is simple and intuitive: we show results created by artists after just a few minutes of instruction. Furthermore, we describe a completely automatic conversion process for taking an image and turning it into a set of diffusion curves that closely approximate the original image content.</p></div></span> <a id="expcoll99" href="JavaScript: expandcollapse('expcoll99',99)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360692&CFID=85074889&CFTOKEN=32802275">Real-time gradient-domain painting</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81331499170&CFID=85074889&CFTOKEN=32802275">James McCann</a>, 
                        <a href="author_page.cfm?id=81100495142&CFID=85074889&CFTOKEN=32802275">Nancy S. Pollard</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 93</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360692" title="DOI">10.1145/1399504.1360692</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360692&ftid=534620&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360692&ftid=977944&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow100" style="display:inline;"><br /><div style="display:inline">We present an image editing program which allows artists to paint in the gradient domain with real-time feedback on megapixel-sized images. Along with a pedestrian, though powerful, gradient-painting brush and gradient-clone tool, we introduce an edge ...</div></span>
          <span id="toHide100" style="display:none;"><br /><div style="display:inline"><p>We present an image editing program which allows artists to paint in the gradient domain with real-time feedback on megapixel-sized images. Along with a pedestrian, though powerful, gradient-painting brush and gradient-clone tool, we introduce an <i>edge brush</i> designed for edge selection and replay. These brushes, coupled with special blending modes, allow users to accomplish global lighting and contrast adjustments using only local image manipulations --- e.g. strengthening a given edge or removing a shadow boundary. Such operations would be tedious in a conventional intensity-based paint program and hard for users to get right in the gradient domain without real-time feedback. The core of our paint program is a simple-to-implement GPU multigrid method which allows integration of megapixel-sized full-color gradient fields at over 20 frames per second on modest hardware. By way of evaluation, we present example images produced with our program and characterize the iteration time and convergence rate of our integration method.</p></div></span> <a id="expcoll100" href="JavaScript: expandcollapse('expcoll100',100)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360693&CFID=85074889&CFTOKEN=32802275">Feedback control of cumuliform cloud formation based on computational fluid dynamics</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100329647&CFID=85074889&CFTOKEN=32802275">Yoshinori Dobashi</a>, 
                        <a href="author_page.cfm?id=81365594241&CFID=85074889&CFTOKEN=32802275">Katsutoshi Kusumoto</a>, 
                        <a href="author_page.cfm?id=81100539710&CFID=85074889&CFTOKEN=32802275">Tomoyuki Nishita</a>, 
                        <a href="author_page.cfm?id=81100602092&CFID=85074889&CFTOKEN=32802275">Tsuyoshi Yamamoto</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 94</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360693" title="DOI">10.1145/1399504.1360693</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360693&ftid=534621&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360693&ftid=979771&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow101" style="display:inline;"><br /><div style="display:inline">Clouds play an important role for creating realistic images of outdoor scenes. In order to generate realistic clouds, many methods have been developed for modeling and animating clouds. One of the most effective approaches for synthesizing realistic ...</div></span>
          <span id="toHide101" style="display:none;"><br /><div style="display:inline"><p>Clouds play an important role for creating realistic images of outdoor scenes. In order to generate realistic clouds, many methods have been developed for modeling and animating clouds. One of the most effective approaches for synthesizing realistic clouds is to simulate cloud formation processes based on the atmospheric fluid dynamics. Although this approach can create realistic clouds, the resulting shapes and motion depend on many simulation parameters and the initial status. Therefore, it is very difficult to adjust those parameters so that the clouds form the desired shapes. This paper addresses this problem and presents a method for controlling the simulation of cloud formation. In this paper, we focus on controlling cumuliform cloud formation. The user specifies the overall shape of the clouds. Then, our method automatically adjusts parameters during the simulation in order to generate clouds forming the specified shape. Our method can generate realistic clouds while their shapes closely match to the desired shape.</p></div></span> <a id="expcoll101" href="JavaScript: expandcollapse('expcoll101',101)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360694&CFID=85074889&CFTOKEN=32802275">Shading-based surface editing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81314488646&CFID=85074889&CFTOKEN=32802275">Yotam Gingold</a>, 
                        <a href="author_page.cfm?id=81100328351&CFID=85074889&CFTOKEN=32802275">Denis Zorin</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 95</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360694" title="DOI">10.1145/1399504.1360694</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360694&ftid=534622&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360694&ftid=979772&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow102" style="display:inline;"><br /><div style="display:inline">We present a system for free-form surface modeling that allows a user to modify a shape by changing its rendered, shaded image using stroke-based drawing tools. User input is translated into a set of tangent and positional constraints on the surface. ...</div></span>
          <span id="toHide102" style="display:none;"><br /><div style="display:inline"><p>We present a system for free-form surface modeling that allows a user to modify a shape by changing its rendered, shaded image using stroke-based drawing tools. User input is translated into a set of tangent and positional constraints on the surface. A new shape, whose rendered image closely approximates user input, is computed using an efficient and stable surface optimization procedure. We demonstrate how several types of free-form surface edits which may be difficult to cast in terms of standard deformation approaches can be easily performed using our system.</p></div></span> <a id="expcoll102" href="JavaScript: expandcollapse('expcoll102',102)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Performance capture</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jehee Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360695&CFID=85074889&CFTOKEN=32802275">Data-driven modeling of skin and muscle deformation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100161153&CFID=85074889&CFTOKEN=32802275">Sang Il Park</a>, 
                        <a href="author_page.cfm?id=81100049661&CFID=85074889&CFTOKEN=32802275">Jessica K. Hodgins</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 96</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360695" title="DOI">10.1145/1399504.1360695</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360695&ftid=534623&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360695&ftid=634583&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360695&ftid=977945&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow104" style="display:inline;"><br /><div style="display:inline">In this paper, we present a data-driven technique for synthesizing skin deformation from skeletal motion. We first create a database of dynamic skin deformations by recording the motion of the surface of the skin with a very large set of motion capture ...</div></span>
          <span id="toHide104" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present a data-driven technique for synthesizing skin deformation from skeletal motion. We first create a database of dynamic skin deformations by recording the motion of the surface of the skin with a very large set of motion capture markers. We then build a statistical model of the deformations by dividing them into two parts: static and dynamic. Static deformations are modeled as a function of pose. Dynamic deformations are caused by the actions of the muscles as they move the joints and the inertia of muscles and fat. We approximate these effects by fitting a set of dynamic equations to the pre-recorded data. We demonstrate the viability of this approach by generating skin deformations from the skeletal motion of an actor. We compare the generated animation both to synchronized video of the actor and to ground truth animation created directly from the large marker set.</p></div></span> <a id="expcoll104" href="JavaScript: expandcollapse('expcoll104',104)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360696&CFID=85074889&CFTOKEN=32802275">Articulated mesh animation from multi-view silhouettes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100451297&CFID=85074889&CFTOKEN=32802275">Daniel Vlasic</a>, 
                        <a href="author_page.cfm?id=81100129752&CFID=85074889&CFTOKEN=32802275">Ilya Baran</a>, 
                        <a href="author_page.cfm?id=81100458116&CFID=85074889&CFTOKEN=32802275">Wojciech Matusik</a>, 
                        <a href="author_page.cfm?id=81100620337&CFID=85074889&CFTOKEN=32802275">Jovan Popovi&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 97</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360696" title="DOI">10.1145/1399504.1360696</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360696&ftid=534624&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360696&ftid=634584&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360696&ftid=979773&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow105" style="display:inline;"><br /><div style="display:inline">Details in mesh animations are difficult to generate but they have great impact on visual quality. In this work, we demonstrate a practical software system for capturing such details from multi-view video recordings. Given a stream of synchronized video ...</div></span>
          <span id="toHide105" style="display:none;"><br /><div style="display:inline"><p>Details in mesh animations are difficult to generate but they have great impact on visual quality. In this work, we demonstrate a practical software system for capturing such details from multi-view video recordings. Given a stream of synchronized video images that record a human performance from multiple viewpoints and an articulated template of the performer, our system captures the motion of both the skeleton and the shape. The output mesh animation is enhanced with the details observed in the image silhouettes. For example, a performance in casual loose-fitting clothes will generate mesh animations with flowing garment motions. We accomplish this with a fast pose tracking method followed by nonrigid deformation of the template to fit the silhouettes. The entire process takes less than sixteen seconds per frame and requires no markers or texture cues. Captured meshes are in full correspondence making them readily usable for editing operations including texturing, deformation transfer, and deformation model learning.</p></div></span> <a id="expcoll105" href="JavaScript: expandcollapse('expcoll105',105)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360697&CFID=85074889&CFTOKEN=32802275">Performance capture from sparse multi-view video</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81309506780&CFID=85074889&CFTOKEN=32802275">Edilson de Aguiar</a>, 
                        <a href="author_page.cfm?id=81365595377&CFID=85074889&CFTOKEN=32802275">Carsten Stoll</a>, 
                        <a href="author_page.cfm?id=81331505042&CFID=85074889&CFTOKEN=32802275">Christian Theobalt</a>, 
                        <a href="author_page.cfm?id=81309488412&CFID=85074889&CFTOKEN=32802275">Naveed Ahmed</a>, 
                        <a href="author_page.cfm?id=81100315426&CFID=85074889&CFTOKEN=32802275">Hans-Peter Seidel</a>, 
                        <a href="author_page.cfm?id=81100590972&CFID=85074889&CFTOKEN=32802275">Sebastian Thrun</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 98</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360697" title="DOI">10.1145/1399504.1360697</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360697&ftid=534625&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360697&ftid=634585&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360697&ftid=979774&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow106" style="display:inline;"><br /><div style="display:inline">This paper proposes a new marker-less approach to capturing human performances from multi-view video. Our algorithm can jointly reconstruct spatio-temporally coherent geometry, motion and textural surface appearance of actors that perform complex and ...</div></span>
          <span id="toHide106" style="display:none;"><br /><div style="display:inline"><p>This paper proposes a new marker-less approach to capturing human performances from multi-view video. Our algorithm can jointly reconstruct spatio-temporally coherent geometry, motion and textural surface appearance of actors that perform complex and rapid moves. Furthermore, since our algorithm is purely meshbased and makes as few as possible prior assumptions about the type of subject being tracked, it can even capture performances of people wearing wide apparel, such as a dancer wearing a skirt. To serve this purpose our method efficiently and effectively combines the power of surface- and volume-based shape deformation techniques with a new mesh-based analysis-through-synthesis framework. This framework extracts motion constraints from video and makes the laser-scan of the tracked subject mimic the recorded performance. Also small-scale time-varying shape detail is recovered by applying model-guided multi-view stereo to refine the model surface. Our method delivers captured performance data at high level of detail, is highly versatile, and is applicable to many complex types of scenes that could not be handled by alternative marker-based or marker-free recording techniques.</p></div></span> <a id="expcoll106" href="JavaScript: expandcollapse('expcoll106',106)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360698&CFID=85074889&CFTOKEN=32802275">Markerless garment capture</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81319488885&CFID=85074889&CFTOKEN=32802275">Derek Bradley</a>, 
                        <a href="author_page.cfm?id=81331501922&CFID=85074889&CFTOKEN=32802275">Tiberiu Popa</a>, 
                        <a href="author_page.cfm?id=81100389496&CFID=85074889&CFTOKEN=32802275">Alla Sheffer</a>, 
                        <a href="author_page.cfm?id=81100644737&CFID=85074889&CFTOKEN=32802275">Wolfgang Heidrich</a>, 
                        <a href="author_page.cfm?id=81309487978&CFID=85074889&CFTOKEN=32802275">Tamy Boubekeur</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 99</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360698" title="DOI">10.1145/1399504.1360698</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360698&ftid=534626&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360698&ftid=979851&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow107" style="display:inline;"><br /><div style="display:inline">A lot of research has recently focused on the problem of capturing the geometry and motion of garments. Such work usually relies on special markers printed on the fabric to establish temporally coherent correspondences between points on the garment's ...</div></span>
          <span id="toHide107" style="display:none;"><br /><div style="display:inline"><p>A lot of research has recently focused on the problem of capturing the geometry and motion of garments. Such work usually relies on special markers printed on the fabric to establish temporally coherent correspondences between points on the garment's surface at different times. Unfortunately, this approach is tedious and prevents the capture of off-the-shelf clothing made from interesting fabrics.</p> <p>In this paper, we describe a marker-free approach to capturing garment motion that avoids these downsides. We establish temporally coherent parameterizations between incomplete geometries that we extract at each timestep with a multiview stereo algorithm. We then fill holes in the geometry using a template. This approach, for the first time, allows us to capture the geometry and motion of unpatterned, off-the-shelf garments made from a range of different fabrics.</p></div></span> <a id="expcoll107" href="JavaScript: expandcollapse('expcoll107',107)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Procedural modeling & design</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Claudio Silva 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360699&CFID=85074889&CFTOKEN=32802275">Automatic generation of tourist maps</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81440610414&CFID=85074889&CFTOKEN=32802275">Floraine Grabler</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=85074889&CFTOKEN=32802275">Maneesh Agrawala</a>, 
                        <a href="author_page.cfm?id=81100099182&CFID=85074889&CFTOKEN=32802275">Robert W. Sumner</a>, 
                        <a href="author_page.cfm?id=81100582775&CFID=85074889&CFTOKEN=32802275">Mark Pauly</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 100</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360699" title="DOI">10.1145/1399504.1360699</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360699&ftid=534627&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360699&ftid=634586&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360699&ftid=977946&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow109" style="display:inline;"><br /><div style="display:inline">Tourist maps are essential resources for visitors to an unfamiliar city because they visually highlight landmarks and other points of interest. Yet, hand-designed maps are static representations that cannot adapt to the needs and tastes of the individual ...</div></span>
          <span id="toHide109" style="display:none;"><br /><div style="display:inline"><p>Tourist maps are essential resources for visitors to an unfamiliar city because they visually highlight landmarks and other points of interest. Yet, hand-designed maps are static representations that cannot adapt to the needs and tastes of the individual tourist. In this paper we present an automated system for designing tourist maps that selects and highlights the information that is most important to tourists. Our system determines the salience of map elements using bottom-up vision-based image analysis and top-down web-based information extraction techniques. It then generates a map that emphasizes the most important elements, using a combination of multiperspective rendering to increase visibility of streets and landmarks, and cartographic generalization techniques such as simplification, deformation, and displacement to emphasize landmarks and de-emphasize less important buildings. We show a number of automatically generated tourist maps of San Francisco and compare them to existing automated and manual approaches.</p></div></span> <a id="expcoll109" href="JavaScript: expandcollapse('expcoll109',109)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360700&CFID=85074889&CFTOKEN=32802275">Automated generation of interactive 3D exploded view diagrams</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100480929&CFID=85074889&CFTOKEN=32802275">Wilmot Li</a>, 
                        <a href="author_page.cfm?id=81100346089&CFID=85074889&CFTOKEN=32802275">Maneesh Agrawala</a>, 
                        <a href="author_page.cfm?id=81100587184&CFID=85074889&CFTOKEN=32802275">Brian Curless</a>, 
                        <a href="author_page.cfm?id=81100188207&CFID=85074889&CFTOKEN=32802275">David Salesin</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 101</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360700" title="DOI">10.1145/1399504.1360700</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360700&ftid=534628&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360700&ftid=977947&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow110" style="display:inline;"><br /><div style="display:inline">We present a system for creating and viewing interactive exploded views of complex 3D models. In our approach, a 3D input model is organized into an explosion graph that encodes how parts explode with respect to each other. We present an automatic ...</div></span>
          <span id="toHide110" style="display:none;"><br /><div style="display:inline"><p>We present a system for creating and viewing interactive exploded views of complex 3D models. In our approach, a 3D input model is organized into an <i>explosion graph</i> that encodes how parts explode with respect to each other. We present an automatic method for computing explosion graphs that takes into account part hierarchies in the input models and handles common classes of interlocking parts. Our system also includes an interface that allows users to interactively explore our exploded views using both direct controls and higher-level interaction modes.</p></div></span> <a id="expcoll110" href="JavaScript: expandcollapse('expcoll110',110)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360701&CFID=85074889&CFTOKEN=32802275">Interactive visual editing of grammars for procedural architecture</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81365596021&CFID=85074889&CFTOKEN=32802275">Markus Lipp</a>, 
                        <a href="author_page.cfm?id=81100473306&CFID=85074889&CFTOKEN=32802275">Peter Wonka</a>, 
                        <a href="author_page.cfm?id=81100084933&CFID=85074889&CFTOKEN=32802275">Michael Wimmer</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 102</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360701" title="DOI">10.1145/1399504.1360701</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360701&ftid=534629&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360701&ftid=979775&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow111" style="display:inline;"><br /><div style="display:inline">We introduce a real-time interactive visual editing paradigm for shape grammars, allowing the creation of rulebases from scratch without text file editing. In previous work, shape-grammar based procedural techniques were successfully applied to the creation ...</div></span>
          <span id="toHide111" style="display:none;"><br /><div style="display:inline"><p>We introduce a real-time interactive visual editing paradigm for shape grammars, allowing the creation of rulebases from scratch without text file editing. In previous work, shape-grammar based procedural techniques were successfully applied to the creation of architectural models. However, those methods are text based, and may therefore be difficult to use for artists with little computer science background. Therefore the goal was to enable a visual work-flow combining the power of shape grammars with traditional modeling techniques. We extend previous shape grammar approaches by providing direct and persistent local control over the generated instances, avoiding the combinatorial explosion of grammar rules for modifications that should not affect all instances. The resulting visual editor is flexible: All elements of a complex state-of-the-art grammar can be created and modified visually.</p></div></span> <a id="expcoll111" href="JavaScript: expandcollapse('expcoll111',111)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1360702&CFID=85074889&CFTOKEN=32802275">Interactive procedural street modeling</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81331490280&CFID=85074889&CFTOKEN=32802275">Guoning Chen</a>, 
                        <a href="author_page.cfm?id=81335490127&CFID=85074889&CFTOKEN=32802275">Gregory Esch</a>, 
                        <a href="author_page.cfm?id=81100473306&CFID=85074889&CFTOKEN=32802275">Peter Wonka</a>, 
                        <a href="author_page.cfm?id=81332517324&CFID=85074889&CFTOKEN=32802275">Pascal M&#252;ller</a>, 
                        <a href="author_page.cfm?id=81100115231&CFID=85074889&CFTOKEN=32802275">Eugene Zhang</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Article No.: 103</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1399504.1360702" title="DOI">10.1145/1399504.1360702</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1360702&ftid=534630&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1360702&ftid=634587&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1360702&ftid=979776&dwn=1&CFID=85074889&CFTOKEN=32802275" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow112" style="display:inline;"><br /><div style="display:inline">This paper addresses the problem of interactively modeling large street networks. We introduce an intuitive and flexible modeling framework in which a user can create a street network from scratch or modify an existing street network. This is achieved ...</div></span>
          <span id="toHide112" style="display:none;"><br /><div style="display:inline"><p>This paper addresses the problem of interactively modeling large street networks. We introduce an intuitive and flexible modeling framework in which a user can create a street network from scratch or modify an existing street network. This is achieved through designing an underlying tensor field and editing the graph representing the street network. The framework is intuitive because it uses tensor fields to guide the generation of a street network. The framework is flexible because it allows the user to combine various global and local modeling operations such as brush strokes, smoothing, constraints, noise and rotation fields. Our results will show street networks and three-dimensional urban geometry of high visual quality.</p></div></span> <a id="expcoll112" href="JavaScript: expandcollapse('expcoll112',112)">expand</a>
          </div>
		  </td>
          </tr>          
          
</table>


</div> 
</div>


 <p class="small-text" align="center">Powered by <a id="theguide" name="theguide" href="javascript:ColdFusion.Window.show('theguide')"><img src="img/poweredbyacm.jpg" width="336" height="11" alt="The ACM Guide to Computing Literature" border="0" /></a></p>



 <br />
<div class="footerbody" align="center" >
	

	The ACM Digital Library is published by the Association for Computing Machinery. Copyright &copy; 2012 ACM, Inc.<br />
	<a href="http://www.acm.org/publications/policies/usage">Terms of Usage</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/privacy-policy">Privacy Policy</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/code-of-ethics">Code of Ethics</a>&nbsp;&nbsp;	  
	<a href="http://www.acm.org/about/contact-us">Contact Us</a>

<br /><br />
Useful downloads: 
<a href="http://www.adobe.com/products/acrobat/readstep2.html"><img src="http://dl.acm.org/images/pdf_logo.gif" width="16" height="16" alt="" border="0" /> Adobe Acrobat</a>
&nbsp;&nbsp;
<a href="http://www.apple.com/quicktime/download/" target="_blank"><img src="http://dl.acm.org/images/qtlogo.gif" width="16" height="16" alt="" border="0" /> QuickTime</a>
&nbsp;&nbsp;
<a href="http://www.microsoft.com/windows/windowsmedia/download/default.asp" target="_blank"><img src="http://dl.acm.org/images/wmv.gif" width="16" height="15" alt="" border="0" /> Windows Media Player</a>
&nbsp;&nbsp;
<a href="http://www.real.com/" target="_blank"><img src="http://dl.acm.org/images/realplayer.gif" width="20" height="18" alt="" border="0" /> Real Player</a>

</div> 



<div  id="cf_window1338240376027" class="yuiextdlg">
	
	<div  id="theguide_title" class="x-dlg-hd">
		The ACM Guide to Computing Literature
	 </div>
	<div  id="theguide_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240376030" class="yuiextdlg">
	
	<div  id="thetags_title" class="x-dlg-hd">
		All Tags
	 </div>
	<div  id="thetags_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240376033" class="yuiextdlg">
	
	<div  id="theformats_title" class="x-dlg-hd">
		Export Formats
	 </div>
	<div  id="theformats_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240376035" class="yuiextdlg">
	
	<div  id="theexplaination_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theexplaination_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240376037" class="yuiextdlg">
	
	<div  id="theservices_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theservices_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338240376039" class="yuiextdlg">
	
	<div  id="savetobinder_title" class="x-dlg-hd">
		Save to Binder
	 </div>
	<div  id="savetobinder_body" class="x-dlg-bd">
		
		
	 </div>
 </div> 

</body>
</html>