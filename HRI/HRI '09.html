


<!doctype html>


<head><script type="text/javascript">_cf_loadingtexthtml="<img alt=' ' src='/CFIDE/scripts/ajax/resources/cf/images/loading.gif'/>";
_cf_contextpath="";
_cf_ajaxscriptsrc="/CFIDE/scripts/ajax";
_cf_jsonprefix='//';
_cf_clientid='8E0307237B2AD47AD901BA98E0FCE29B';</script><script type="text/javascript" src="/CFIDE/scripts/ajax/messages/cfmessage.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfajax.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfform.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/masks.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfformhistory.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfrichtexteditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/FCKeditor/fckeditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/yahoo-dom-event/yahoo-dom-event.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/animation/animation-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/adapter/yui/ext-yui-adapter.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/ext-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/resizable.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dragdrop/dragdrop.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/util.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/build/state/State-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/widget-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dialog/dialogs.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfwindow.js"></script>
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/ext/css/ext-all.css" />
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/cf/cf.css" />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="css/dl.css" />



<title>Proceedings of the 4th ACM/IEEE international conference on Human robot interaction</title>
<style type="text/css"><!--
    body {margin-left: 0em; margin-top: 0}
    a:link {text-decoration: underline; 	Color: #1d4d0f;}
    a:visited  { color: #990033; text-decoration: underline;}
    a:hover {color: red; text-decoration: none}
    a.dLink1:link {color:#336699}
    a.dLink1:visited {color:#666666}
	a.isblack:link {text-decoration: underline; 	Color: #000000;}
    a.isblack:visited  { color: #000000; text-decoration: underline;}
    a.isblack:hover {color: #000000; text-decoration: none}
    h1 {font-size: 140%; margin-bottom: 0}
	ul {margin-top: .25em; list-style-type: disc}
	ol {margin-top: .25em;}
	li {padding-bottom: .25em}
    h2 {color: white; background-color: #069; 
        font-size: 100%; padding-left: 1em;
		margin: 0}
	h3 {color: black; background-color: yellow; 
    	font-size: 100%;
		margin: 0}
	 h4 {color: black; background-color: #99c5e8; 
        font-size: 100%;
		margin: 0}
    hr {color: #39176d;}
    form {margin-top: 10}
    form.xrs {margin-top: 0}
	
	a {text-decoration: none; }
	
	input {font-size: 1em;}
	.chevron {color: #ff0000;}
	.light-blue {color:#336699;}
	.black {color:#000000;}
	
	/* ### standard text styles, smallest to largest ### */
	
	.footer-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .75em; line-height: 1.33em;
		text-indent: -.75 em; margin-left: 2em; margin-right: .75em;}
		
	.footer-copy-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em; line-height: 1.3em;
		margin-left: .75em; margin-right: .75em;}
		
	.small-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; padding-bottom : 2px;
	  	padding-top : 2px;}

	.smallerer-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .65em;}
	.smaller-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em;}		
	.small-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em;}
	.small-textb {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; font-weight: bold;}
	.medium-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em;}
	.mediumb-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em; font-weight: bold;}
	.large-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1.3em;}		
	.instr-text {font-family: Arial, Helvetica, sans-serif;
		color:#666666; font-size: .83em;}
		
	.list-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .83em; line-height: 1.3em;}
	.list-link-btext {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; line-height: 1.3em;}
	
	.searchbox-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;}
	.footer-header-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;
		margin-left: .75em; margin-right: .75em;}
	.medium-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold; line-height: 1em;
		text-indent: -1.25em; margin-left: 2em; margin-right: .75em;}
	
	.text16 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 16px;}
		
	.text14 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 14px;}
	
	.text12 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 12px;}
		
	.text10 {font-family: Arial, Helvetica, sans-serif;
	    color:#000000; font-size: 12px;}
		
	.text9 {font-family: Arial, Helvetica, sans-serif;
	   color:#000000; font-size: 12px;}
	
	.error-text {color:red;}
	
	.small-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: .75em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}

	.medium-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1.3em; line-height: 1.5em;
		margin-left: .75em; margin-right: .75em;}
	
	.medium-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1.5em;
		margin-left: .75em; margin-right: .75em;}

		#side {
			width: 10px;
			float: left;
			margin-left: -1px;
			padding: 2px;
			}
							
		#content {
			padding: 2px;
			margin-left: 25px;
			
		        
		        }
	 .fulltext_lnk {border:0px;
	 				 margin-right: 2px;
					 vertical-align:baseline;
	 				}
	 
	  .leftcoltab { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:530px;  /* for IE5/WIN */
		  width:520px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	  .rightcoltab {
    float: right;
    margin: 0;
    padding: 5px;
    position: relative;
    right: 50px;
    top: 25px;
    width: 350px;
    z-index: 99;
}
	  .centercoltab {
		  position:absolute;
		  padding:0 0px;
		  }
	  .alt {
		background: #ece9d8;
		margin: 0;
		padding: 1px;
		}
		.leftcolc { 
	position:relative;
	top:5px;
	left:5px;
	float:left;
	width:420px;  /* for IE5/WIN */
	width:400px; /* actual value */
	margin:0 0 0px 0;
	padding:5px;
	z-index:100;
	}
.rightcolc {
	position:relative;
	top:0px;
	right:0px;
	float:right;
	margin:0 0px;
	padding:0px;
	width:500px;
	z-index:99;
	}
.centercolc {
	position:absolute;
	padding:0 0px;
	}
	
	.leftcoltabv { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:460px;  /* for IE5/WIN */
		  width:350px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	.rightcoltabv {
		position:relative;
		top:5px;
		right:0px;
		float:right;
		margin:0 0px 0 0;
		padding:15px;
		width:480px;
		z-index:99;
		}
	
  --></style>
 


<script type="text/javascript" src="cfformprotect/js/cffp.js"></script>


<script type="text/javascript">
 function expandcollapse(anchor,whichone) {
	 var inner = document.getElementById(anchor);
	 var theshow = "toShow" + whichone;
 	 var thehide = "toHide" + whichone;
	 var span = document.getElementById(theshow);
     span.style.display = (span.style.display=='inline')?'none':'inline';
     var span = document.getElementById(thehide);
     span.style.display = (span.style.display=='none')?'inline':'none';
     inner.innerHTML = (inner.innerHTML=='collapse')?'expand':'collapse';
    }

  function setDiv() {
	var m = document.getElementById('divmain');
	var mh = m.offsetHeight;
	var t = document.getElementById('divtools');
	var th = t.offsetHeight;
	var tg = document.getElementById('divtags');
	var tgh = tg.offsetHeight;
	var calcheight = mh - th;
	if (tgh > calcheight  ){
	  var x = (th + tgh) - mh;
	  if ( (th + tgh) - mh < 65) {
	  }
	  else {
		 document.getElementById('divtags').innerHTML = ""; 
		 var tg = document.getElementById('divtags');
		 var tgh = tg.offsetHeight;
		 tg.style.height = tgh  + 'px';
	  }
	}
	else {
		tg.style.height = calcheight + 'px';
		document.getElementById('divtags').innerHTML = "";
	}

//  do I need to check after I resize to be sure I didn't go too big?
//	var tg2 = document.getElementById('divtags');
//	var tgh2 = tg.offsetHeight;	
//	if (tgh2 > mh + 65) {
//	  var y = mh + 65;
//	  alert('expanded too much ' + tgh2 + ' should be at most ' + y);
//	  tg.style.height = y + 'px';
//	  document.getElementById('divtags').innerHTML = "";
//	}

  }
</script>

<script type="text/javascript">
 /* <!-- Begin
	if(document.layers || document.all) {
	a = 1;
	setInterval("Jump()", 10);
	}
	function Jump() {
	a = a + 1;
	//self.moveBy((Math.random() * a * 2 - a), (Math.random() * a * 2) - a);
	}
//  End --> */
</script>



<meta name="citation_publisher" content="ACM"> <meta name="citation_authors" content="General Chair-Scheutz, Matthias; General Chair-Michaud, Fran&#231;ois; Program Chair-Hinds, Pamela; Program Chair-Scassellati, Brian"> <meta name="citation_title" content="Proceedings of the 4th ACM/IEEE international conference on Human robot interaction"> <meta name="citation_date" content="03/09/2009"> <meta name="citation_isbn" content="978-1-60558-404-1"> <meta name="citation_abstract_html_url" content="http://dl.acm.org/citation.cfm?id=1514095"> 



<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFAJAXPROXY');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFFORM');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFDIV');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFTEXTAREA');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFWINDOW');
</script>

<script type="text/javascript">
	var _cf_window_init_1338242209237=function()
	{
		_cf_bind_init_1338242209238=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'theguide_body','bindExpr':['whatisguide.cfm']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338242209238);var _cf_window=ColdFusion.Window.create('theguide','The ACM Guide to Computing Literature','whatisguide.cfm',{ modal:false, closable:true, divid:'cf_window1338242209236', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338242209237);
</script>

<script type="text/javascript">
	var _cf_window_init_1338242209240=function()
	{
		_cf_bind_init_1338242209241=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'thetags_body','bindExpr':['showthetags.cfm?id=1514095']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338242209241);var _cf_window=ColdFusion.Window.create('thetags','All Tags','showthetags.cfm?id=1514095',{ modal:false, closable:true, divid:'cf_window1338242209239', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338242209240);
</script>

<script type="text/javascript">
	var _cf_window_init_1338242209243=function()
	{
		var _cf_window=ColdFusion.Window.create('theformats','Export Formats','',{ modal:false, closable:true, divid:'cf_window1338242209242', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:250, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338242209243);
</script>

<script type="text/javascript">
	var _cf_window_init_1338242209245=function()
	{
		var _cf_window=ColdFusion.Window.create('theexplaination','','',{ modal:false, closable:true, divid:'cf_window1338242209244', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338242209245);
</script>

<script type="text/javascript">
	var _cf_window_init_1338242209247=function()
	{
		var _cf_window=ColdFusion.Window.create('theservices','','',{ modal:false, closable:true, divid:'cf_window1338242209246', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338242209247);
</script>

<script type="text/javascript">
	var _cf_window_init_1338242209249=function()
	{
		_cf_bind_init_1338242209250=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'savetobinder_body','bindExpr':['savetobinder.cfm?id=1514095']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338242209250);var _cf_window=ColdFusion.Window.create('savetobinder','Save to Binder','savetobinder.cfm?id=1514095',{ modal:false, closable:true, divid:'cf_window1338242209248', draggable:true, resizable:true, fixedcenter:true, width:600, height:600, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false, _cf_refreshOnShow:true});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338242209249);
</script>
</head>

<body style="text-align:center" onLoad="window.focus();">

<script type="text/javascript">
						addthis_pub             = 'acm'; 
						//addthis_logo            = 'http://www.addthis.com/images/yourlogo.png';
						addthis_logo            = 'http://dl.acm.org/images/ACM_transparent.png';
						addthis_logo_background = 'c2d5fc';
						addthis_logo_color      = '000000';
						addthis_brand           = 'Citation Page';
						addthis_options         = 'favorites, email, slashdot, citeulike, digg, delicious, twitter, myspace, facebook, google, more';
						</script>
                        
<script src='AC_RunActiveContent.js' type="text/javascript"></script>




<div style="width:940px; margin-left: auto; margin-right: auto; text-align:left">
<a id="CIT"></a>



<table style="table-layout:fixed; margin-top: 5px; margin-bottom: 10px; border:0px; width:100%; border-collapse:collapse;">
	
    <tr style="vertical-align:top">
		
		<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; width:300px" class="small-link-text"  ><img src="http://dl.acm.org/images/ACMDL_Logo.jpg" alt="ACM DL" style="border:0px" usemap="#port" />
		</td>
        
        <td style="padding-left: 5px; padding-right:10px; padding-bottom:0px;" class="small-link-text">
        	<table style="width:100%; border-collapse:collapse; padding:0px">
			<tr><td style="text-align:center">
				
                            <div style="margin:0px auto;color:#356b20;font-size:10pt;line-height:10%;"> </div>
                    
					</td>		
			</tr>
			</table> 
        </td>
		<td style="padding-top: 0px; padding-left: 0px; padding-bottom:0px; text-align:right;" class="small-link-text">
			 <p style="margin-top:0px; margin-bottom:10px;">
					
                            <a href="https://dl.acm.org/signin.cfm?cfid=105752665&amp;cftoken=60368223" class="small-link-text" title="Sign in to personalize your Digital Library experience">SIGN IN</a>
                            &nbsp;&nbsp;<a href="https://dl.acm.org/signin.cfm?cfid=105752665&amp;cftoken=60368223"  class="small-link-text" title="Sign up to personalize your Digital Library experience">SIGN UP</a>
						
			 </p>
            
			<table style="padding: 5px; border-collapse:collapse; float:right">
				
				
                            
                            <tr>
                            <td class="small-link-text" style="text-align:right">
                            <form name="qiksearch" action="results.cfm?h=1&amp;cfid=105752665&amp;cftoken=60368223" method="post">
                           
                           
                            
                                     
                                    <span style="margin-left:0px"><label><input type="text" name="query" size="34" value=" " /></label>&nbsp;
                                    <input style="vertical-align:top;" type="image" alt="Search" name="Go" src="http://dl.acm.org/images/search_small.jpg" />
                                    
                                    </span>
							  </form>
                                </td>
                            </tr>
                          
				  
			</table>

			
			
		</td>

	</tr>
    
    
    <tr><td colspan="3" class="small-link-text" style="padding-bottom:5px; padding-top:0px; text-align:center">
		<div style="margin:0px auto;color:#356b20;line-height:10%;"> </div>
         
         </td>
    </tr>
    </table>
	
<map name="port" id="port" > 
  <area shape="rect" coords="1,1,60,50" href="http://www.acm.org/" alt="ACM Home Page" />
  <area shape="rect" coords="65,1,275,68" href="http://dl.acm.org/dl.cfm?CFID=105752665&CFTOKEN=60368223" alt="ACM Digital Library Home Page" />
</map>

<table style="table-layout:fixed; padding-bottom:10px; width:100%; padding:0px;">
	<tr style="vertical-align:top">
		<td style="padding-right:10px; text-align:left" class="small-link-text">
        	<div id="divmain" style="border:1px solid #356b20;">
				 
				<div class="large-text" style="text-align:left; margin-left:2px;margin-bottom:5px;">
					
                    	<h1 class="mediumb-text" style="margin-top:0px; margin-bottom:0px;"><strong>Proceedings of the 4th ACM/IEEE international conference on Human robot interaction</strong></h1>
                        
                </div>
                
                  

<table class="medium-text" style="border-collapse:collapse; padding:0px;">

<col style="width:540px" />

<tr style="vertical-align:top">
  <td>
    <table style="border-collapse:collapse; padding:2px;" class="medium-text">
      <col style="width:80px;" />
      <col style="width:auto" />
      <tr style="vertical-align:top">
        
      </tr>
    </table>

	
        <table style="margin-top: 10px; border-collapse:collapse; padding:2px;" class="medium-text">
            <col style="width:80px" />
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             General Chairs:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100029514&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105752665&amp;cftoken=60368223" title="Author Profile Page" target="_self">Matthias Scheutz</a>
                
            </td>
            <td valign="bottom">
                
                        <small>Indiana University, USA</small>
                    	
            </td>
            </tr>
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100593688&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105752665&amp;cftoken=60368223" title="Author Profile Page" target="_self">Fran&#231;ois Michaud</a>
                
            </td>
            <td valign="bottom">
                
                        <a href="inst_page.cfm?id=1031511&CFID=105752665&CFTOKEN=60368223" title="Institutional Profile Page"><small>Universit&#233; de Sherbrooke, Canada</small></a>
                      	
            </td>
            </tr>
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             Program Chairs:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100572021&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105752665&amp;cftoken=60368223" title="Author Profile Page" target="_self">Pamela Hinds</a>
                
            </td>
            <td valign="bottom">
                
                        <a href="inst_page.cfm?id=1030795&CFID=105752665&CFTOKEN=60368223" title="Institutional Profile Page"><small>Stanford University, USA</small></a>
                      	
            </td>
            </tr>
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81326492306&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105752665&amp;cftoken=60368223" title="Author Profile Page" target="_self">Brian Scassellati</a>
                
            </td>
            <td valign="bottom">
                
                        <a href="inst_page.cfm?id=1031959&CFID=105752665&CFTOKEN=60368223" title="Institutional Profile Page"><small>Yale University, USA</small></a>
                      	
            </td>
            </tr>
            
        </table>
    

  </td>

  <td rowspan="20" nowrap="nowrap">
	<table border="0" class="medium-text" cellpadding="0" cellspacing="0">
		<tr>
        	<td align="center" style="padding-bottom: 5px;">
			  
               <img src="http://portalparts.acm.org/1520000/1514095/thumb/cover_thumb.jpg" title="Proceedings of the 4th ACM/IEEE international conference on Human robot interaction" height="100"  width="77" ALT="Proceedings of the 4th ACM/IEEE international conference on Human robot interaction" /> 
              </td>
              <td valign="top" align="left" nowrap="nowrap">
	             <img src="images/acm_mini.jpg" title="Published by ACM" alt="Published by ACM" /> 2009 Proceeding<br />
                 
        	 </td>
        </tr>
        
        <tr>
        	<td colspan="2" valign="baseline" style="padding-bottom:5px;">
            <img src="img/stats.jpg" alt="Bibliometrics Data" />&nbsp;
            <a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a>
            </td>
         </tr>
         <tr>
            <td  class="small-text" colspan="2" valign="top" style="padding-left:30px;">
				
	                    	&middot;&nbsp;Downloads (6 Weeks): 387<br />
    	                    &middot;&nbsp;Downloads (12 Months): 3,395<br />
                          
                        &middot;&nbsp;Citation Count: 160 
			</td>
         </tr>

	</table>
  </td>
</tr>
</table>

<br clear="all" />

<table border="0" class="medium-text" cellpadding="2" cellspacing="0">

<tr valign="top">
    <td colspan="3"><table border="0" class="medium-text" cellpadding="1" cellspacing="0">

<tr valign="top">
    <td nowrap="nowrap" style="padding-top:10px;">Publication of:</td>
</tr>

	<tr valign="top">
    	<td nowrap="nowrap" style="padding-bottom:0px">&middot;&nbsp;Conference</td>
	</tr>
    <tr valign="top">
	    <td style="padding-left:10px;">
		   <a href="http://hri2009.org/" title="Conference Website"  target="_self" class="link-text">HRI'09</a> International Conference on Human Robot Interaction 
        </td>
	</tr>
    
    <tr valign="top">
	    <td style="padding-left:10px; padding-bottom:10px"> La Jolla, CA, USA &mdash; March 09 - 13, 2009
                    
                  <br />
                    
                  <a href="http://www.acm.org/publications" class="small-link-text" title="ACM">ACM</a> <span class="small-link-text">New York, NY</span><span class="small-link-text">, USA</span> <span class="small-link-text">  &copy;2009</span> 
                  <br />           
                  
      </td>
	</tr>
	 

</table></td>
</tr>

</table>

                  
                 <br clear="all" />
			</div>
			
		</td>
		<td style="padding-left: 5px; vertical-align:top; text-align:left; width:170px" class="small-link-text">
	
            <div id="divtools" style="background-color:#ece9d8; text-align:left; padding-top:5px; padding-bottom:5px; ">
              <div class="medium-text" style="margin-left:3px; margin-top:10px;"><h1 class="mediumb-text" style="margin-top:-15px;"><strong>Tools and Resources</strong></h1></div>


<ul title="Tools and Resources" style="list-style: none; list-style-position:inside;
margin-left: 0px;
padding-left: 0em;
text-indent: 5px;
margin-bottom: 0px;">


<li style="list-style-image:url(img/toc_small.gif);margin-top:10px;"><span style="margin-left:6px;">
   <span class="small-link-text">TOC Service:</span>
   	  
	  <img src="http://dl.acm.org/images/blanks.gif" border="0" alt="Spacer Image reserves space for checkmark when TOC Service is updated" name="saved" />
      <ul style="margin-left: 0; padding-left: 0; display:inline;">
      	
        <li style="list-style:none; display:inline"><br /><img src="img/email_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Email</a></li>
        <li style="list-style:none; display:inline"><img src="img/rss_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');"  class="small-link-text">RSS</a></li>
		        
      </ul>
    </span>
</li>

        <li style="list-style-image:url(img/binder.gif);margin-top:10px;"><span style="margin-left:6px;">
        <a href="citation.cfm?id=1514095&preflayout=flat#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Save to Binder</a>
         </span></li>
    




<li style="list-style-image:url(img/binder_green.gif);margin-top:10px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Export Formats:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1514095&expformat=bibtex','theformats');" class="small-link-text">BibTeX</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1514095&expformat=endnotes','theformats');" class="small-link-text">EndNote</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1514095&expformat=acmref','theformats');" class="small-link-text">ACM&nbsp;Ref</a></li>
      </ul>
    </span>
</li>



 
   <li style="list-style-image:url(img/calbullet.jpg);margin-top:15px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Upcoming Conference:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px; margin-left:25px;"><a href="http://humanrobotinteraction.org/2013/" title="ACM/IEEE International Conference on Human-Robot Interaction" class="small-link-text">HRI'13</a></li>
      </ul>
    </span>
	</li>
    


</ul>           

  <!-- ADDTHIS BUTTON BEGIN -->
  
  <!-- ADDTHIS BUTTON END -->

<p class="small-link-text" style="padding-top: 0px; margin-left:6px; margin-bottom:0px">Share:</p>
  <!-- AddThis Button BEGIN -->



<!-- AddThis Button BEGIN -->
<div style="margin-left:5px;" class="addthis_toolbox addthis_default_style">
<a class="addthis_button_email"></a>
<a class="addthis_button_facebook"></a>
<a class="addthis_button_google"></a>
<a class="addthis_button_twitter"></a>
<a class="addthis_button_slashdot"></a>
<a class="addthis_button_reddit"></a>


<span class="addthis_separator">|</span>
<a href="http://www.addthis.com/bookmark.php?v=250&amp;username=acm" class="addthis_button_expanded" title="more"></a>
</div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=acm"></script>
<!-- AddThis Button END -->

  
 

  
  
            </div>
            
		</td>
	</tr>
    
</table>



</div>


<div class="layout" style="width:940px; margin-left: auto; margin-right: auto; text-align:left">




<div id="fback" style="text-align:left; padding-top:10px; padding-bottom:20px">
<span class="small-text" style="padding-right:10px; margin-bottom:0px;">
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design" style=" vertical-align:middle"><img src="img/feedbackg.gif" width="20" height="19" alt="feedback" border="0" /></a>
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design"><strong>Feedback</strong></a>

<span style="padding:10px;">|</span>




<span>Switch to <a href="citation.cfm?id=1514095&amp;preflayout=tabs">tabbed view</a> <noscript> (javascript required)</noscript></span>


</span>

 
<div class="small-text" style="margin-top:10px; margin-bottom:5px;"> 
<br />

    <a href="#abstract"  title="Abstract" style="padding:5px"><span>Abstract</span></a> |
    
    <a href="#formats"  title="Source Materials" style="padding:5px"><span>Source Materials</span></a> |
    
    <a href="#authors"  title="Authors" style="padding:5px"><span>Authors</span></a> |
    <a href="#references"  title="References" style="padding:5px"><span style='color:#999999'>References</span></a> |
    <a href="#citedby"  title="Cited By" style="padding:5px"><span style='color:#999999'>Cited By</span></a> |
    <a href="#indexterms"  title="Index Terms" style="padding:5px"><span style='color:#999999'>Index Terms</span></a> |
    <a href="#source"  title="Publication" style="padding:5px"><span>Publication</span></a> |
    <a href="#revs"  title="Reviews" style="padding:5px"><span style='color:#999999'>Reviews</span></a> |               
	<a href="#comments"  title="Comments" style="padding:5px"><span>Comments</span></a>
	
     |               
	<a href="#prox"  title="Table of Contents" style="padding:5px"><span>Table of Contents</span></a>
    
</div>
    
<div style="right: 0pt; border-top:1px solid #356b20; font-size:1px; margin-bottom:20px;"/>



</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="abstract" class="small-text">ABSTRACT</A></h1>
       	
			<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

			

		
			
           
			
				
				<p>
					<div style="display:inline"><p>It is our great pleasure to welcome you to the <i>4th ACM/IEEE International Conference on Human-Robot Interaction (HRI 2009)</i>. HRI is a single-track, highly selective annual conference that showcases the very best research and thinking in human-robot interaction. HRI is inherently interdisciplinary and multidisciplinary, reflecting work from researchers in social psychology, cognitive science, HCI, human factors, artificial intelligence, robotics, organizational behavior, anthropology, and many more.</p> <p>The theme of HRI 2009, "Interacting Naturally With Robots" reflects the importance of robots meeting the complex demands of the environments and contexts in which they operate. In particular, natural human-like communications are becoming critical for robots operating in everyday settings such as the home, office, schools, shopping malls, and other public and private spaces. This year's conference places special emphasis on robots interacting naturally with people.</p> <p>The call for papers attracted 120 full paper and 62 late-breaking abstract submissions from Asia, Europe, the Middle East, Canada, and the United States. The program committee led by the program co-chairs conducted a very rigorous review process for full papers this year, accepting 23 full papers for oral presentation and publication in the proceedings in the ACM Digital Library. Furthermore, 59 late-breaking abstracts were screened for relevance to the HRI conference, and are presented as posters, exposing a broader perspective of solutions and challenges in HRI. They will be made available in the ACM Digital Library as non-archival abstracts. Finally, a total of 13 videos (out of 19 submissions) were accepted based on importance, novelty and entertainment value and will be shown in a special video session. The accepted presentations cover a variety of topics, including human-robot communication, robot perception and prediction, interface design, and methods for studying human-robot interaction.</p></div>
				</p>
   				
           	</div>
			
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="formats" class="small-text"><SPAN class="heading">SOURCE MATERIALS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


  <div class="abstract">
        <SPAN><strong>FRONT MATTER</strong></span>
  </div>
  <div style="margin-left:10px; line-height:180%;">
      
          <A NAME="FullText" HREF="http://portalparts.acm.org/1520000/1514095/fm/frontmatter.pdf?ip=188.194.239.219&CFID=105752665&CFTOKEN=60368223" title="PDF" target="_blank">
          <img src="http://dl.acm.org/imagetypes/pdf_logo.gif" alt="PDF" border="0" align="middle" style="margin-right: 2px">PDF</A>
          &nbsp;(cd label, copyright, welcome, contents, organization, reviewers, sponsors) 
  </div>          
  
  <div style="margin-top: 10px;"  class="abstract">
        <SPAN><strong>BACK MATTER</strong></span>
  </div>
  <div style="margin-left:10px; line-height:180%;">
      
          <A NAME="FullText" HREF="http://portalparts.acm.org/1520000/1514095/bm/backmatter.pdf?ip=188.194.239.219&CFID=105752665&CFTOKEN=60368223" title="PDF" target="_blank">
          <img src="http://dl.acm.org/imagetypes/pdf_logo.gif" alt="PDF" border="0" align="middle" style="margin-right: 2px">PDF</A>
          &nbsp;(author index) 
  </div>          
  
<div style="margin-top: 10px; height: auto; padding: 5px; ">
		
		
        


	</div>

<br clear="all" />
</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="authors" class="small-text"><SPAN class="heading">AUTHORS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<dl title="Authors" style="margin-top:0px">




<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 General Chairs 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Matthias Scheutz" href="author_page.cfm?id=81100029514&CFID=105752665&CFTOKEN=60368223">Matthias Scheutz</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1999-2012</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">40</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">114</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">17</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">156</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">894</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Matthias Scheutz" href="author_page.cfm?id=81100029514&amp;dsp=coll&amp;trk=1&amp;CFID=105752665&CFTOKEN=60368223" target="_self">View colleagues</a> of Matthias Scheutz
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Fran&#231;ois Michaud" href="author_page.cfm?id=81100593688&CFID=105752665&CFTOKEN=60368223">Fran&#231;ois Michaud</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1996-2012</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">32</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">58</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">11</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">38</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">226</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Fran&#231;ois Michaud" href="author_page.cfm?id=81100593688&amp;dsp=coll&amp;trk=1&amp;CFID=105752665&CFTOKEN=60368223" target="_self">View colleagues</a> of Fran&#231;ois Michaud
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              



<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 Program Chairs 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Pamela Hinds" href="author_page.cfm?id=81100572021&CFID=105752665&CFTOKEN=60368223">Pamela Hinds</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">2000-2012</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">18</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">157</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">12</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">148</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">673</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Pamela Hinds" href="author_page.cfm?id=81100572021&amp;dsp=coll&amp;trk=1&amp;CFID=105752665&CFTOKEN=60368223" target="_self">View colleagues</a> of Pamela Hinds
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Brian Scassellati" href="author_page.cfm?id=81326492306&CFID=105752665&CFTOKEN=60368223">Brian Scassellati</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1998-2010</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">26</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">243</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">7</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">40</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">336</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Brian Scassellati" href="author_page.cfm?id=81326492306&amp;dsp=coll&amp;trk=1&amp;CFID=105752665&CFTOKEN=60368223" target="_self">View colleagues</a> of Brian Scassellati
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              

</dl>
</div>

		  
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="references" class="small-text"><SPAN class="heading">REFERENCES</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	References are not available

</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="citedby" class="small-text"><SPAN class="heading">CITED BY</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	Citings are not available
		
 </div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="indexterms" class="small-text"><SPAN class="heading">INDEX TERMS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

Index Terms are not available


</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="source" class="small-text"><SPAN class="heading">PUBLICATION</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">



<table border="0" class="medium-text" cellpadding="0" cellspacing="5">



    <tr valign="top">
    	<td>Title</td> 
	    <td>
		   <a href="http://hri2009.org/" title="Conference Website"  target="_self" class="link-text">HRI'09</a> International Conference on Human Robot Interaction 
        </td>
	</tr>
    <tr><td></td><td>La Jolla, CA, USA &mdash; March 09 - 13, 2009</td></tr> <tr><td>Pages</td><td>332</td></tr> 
                 <tr>
                 
                     <td>Sponsors</td>
                    
                  <td>
                  <a href="sig.cfm?id=SP918&CFID=105752665&CFTOKEN=60368223"> SIGART</a> ACM Special Interest Group on Artificial Intelligence
                  </td>
                  </tr>
              
                 <tr>
                 
                      <td></td>
                  
                  <td>
                  <a href="sig.cfm?id=SP923&CFID=105752665&CFTOKEN=60368223"> SIGCHI</a> ACM Special Interest Group on Computer-Human Interaction
                  </td>
                  </tr>
              
                 <tr>
                 
                      <td></td>
                  
                  <td>
                  <a href="http://www.acm.org/"> ACM</a> Association for Computing Machinery
                  </td>
                  </tr>
              
                  <tr><td>Publisher</td><td><a href="http://www.acm.org/publications">ACM</a> New York, NY, USA</td>
				  </tr>
             <tr><td>ISBN</td><td> 978-1-60558-404-1</td></tr> <tr><td>Order Number</td><td>609094</td></tr> 
			<tr valign="top">
        	<td>Conference</td>
            <td valign="top" align="left"  style="padding-bottom: 25px;">
	            <strong style="padding-right:10px">HRI</strong><a href="event.cfm?id=RE285&CFID=105752665&CFTOKEN=60368223" title="ACM/IEEE International Conference on Human-Robot Interaction">ACM/IEEE International Conference on Human-Robot Interaction</a>
                
                       
                        <a href="event.cfm?id=RE285&CFID=105752665&CFTOKEN=60368223" title="ACM/IEEE International Conference on Human-Robot Interaction"><img border="0" src="http://portalparts.acm.org/event_logos/677/677.jpg" title="HRI logo" height="62"  width="100" ALT="HRI logo" style="vertical-align:top"></a>
						 

        	 </td>
            </tr>
		    <tr><td colspan="2">Paper Acceptance Rate 23 of 120 submissions, 19%</td></tr> <tr valign="top"><td style="pading-top:20px;" colspan="2">Overall Acceptance Rate 227 of 905 submissions, 25%</td></tr>
                       <tr valign="top">
                        <td colspan="2" style="padding-left:25px;">
                        	<table>
                            	<tr><td>
                                        <!-- WebCharts3D v5.1(2077) -->
<IMG SRC="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=Images/9129313920525703.JPG" id="Images_9129313920525703_JPG" name="Images_9129313920525703_JPG" usemap="#Images_9129313920525703_JPG_map" border="0"/>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAB' id='GP1338242209558AAAB'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '06</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAC' id='GP1338242209558AAAC'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '06</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>41</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAD' id='GP1338242209558AAAD'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '07</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>101</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAE' id='GP1338242209558AAAE'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '07</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>22</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAF' id='GP1338242209558AAAF'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '08</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>134</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAG' id='GP1338242209558AAAG'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '08</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>48</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAH' id='GP1338242209558AAAH'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '09</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>120</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAI' id='GP1338242209558AAAI'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '09</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>23</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAJ' id='GP1338242209558AAAJ'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '10</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>124</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAK' id='GP1338242209558AAAK'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '10</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>26</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAL' id='GP1338242209558AAAL'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '11</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>149</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAM' id='GP1338242209558AAAM'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '11</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>33</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAN' id='GP1338242209558AAAN'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '12</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>137</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338242209558AAAO' id='GP1338242209558AAAO'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '12</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>34</td></tr></table>
<MAP name='Images_9129313920525703_JPG_map'>
<AREA shape='rect' coords='0,0,1,1'/>
<AREA shape="rect" coords="293,179,309,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAO",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAO",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAO",event)'/>
<AREA shape="rect" coords="277,74,293,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAN",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAN",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAN",event)'/>
<AREA shape="rect" coords="253,180,269,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAM",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAM",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAM",event)'/>
<AREA shape="rect" coords="237,62,253,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAL",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAL",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAL",event)'/>
<AREA shape="rect" coords="213,187,229,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAK",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAK",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAK",event)'/>
<AREA shape="rect" coords="197,87,213,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAJ",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAJ",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAJ",event)'/>
<AREA shape="rect" coords="173,190,189,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAI",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAI",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAI",event)'/>
<AREA shape="rect" coords="157,91,173,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAH",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAH",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAH",event)'/>
<AREA shape="rect" coords="133,165,149,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAG",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAG",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAG",event)'/>
<AREA shape="rect" coords="117,77,133,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAF",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAF",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAF",event)'/>
<AREA shape="rect" coords="93,191,109,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAE",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAE",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAE",event)'/>
<AREA shape="rect" coords="77,111,93,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAD",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAD",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAD",event)'/>
<AREA shape="rect" coords="53,172,69,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAC",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAC",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAC",event)'/>
<AREA shape="rect" coords="37,71,53,213" onMouseover='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAB",event,true)' onMouseout='xx_set_visible("Images_9129313920525703_JPG","GP1338242209558AAAB",event,false)' onMousemove='xx_move_tag("Images_9129313920525703_JPG","GP1338242209558AAAB",event)'/>
<AREA shape="rect" coords="160,13,227,27"/>
<AREA shape="rect" coords="89,13,160,27"/>
</MAP>

<script language="javascript" src="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=script.js"></script>

                                      </td>
                                      <td style="padding-left:20px;">
                                             <table style="border-width: 1px; border-style: solid; width:100%;  border-spacing: 6px;" class="text12">
                                                <tr bgcolor="#ffffff">
                                                  <th style="width:50%">Year</th>
                                                  <th  align="right" style="width:15%">Submitted</th>
                                                  <th  align="right" style="width:15%">Accepted</th>
                                                  <th  align="center">Rate</th>
                                                </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '06</td>
                                                            <td align="right">140</td>
                                                            <td align="right">41</td>
                                                            <td align="center">29%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>HRI '07</td>
                                                            <td align="right">101</td>
                                                            <td align="right">22</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '08</td>
                                                            <td align="right">134</td>
                                                            <td align="right">48</td>
                                                            <td align="center">36%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>HRI '09</td>
                                                            <td align="right">120</td>
                                                            <td align="right">23</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '10</td>
                                                            <td align="right">124</td>
                                                            <td align="right">26</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>HRI '11</td>
                                                            <td align="right">149</td>
                                                            <td align="right">33</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '12</td>
                                                            <td align="right">137</td>
                                                            <td align="right">34</td>
                                                            <td align="center">25%</td>
                                                         </tr>
                                                
                                                 <tr bgcolor="#ffffff">
                                                    <td><strong>Overall</strong></td>
                                                    <td align="right">905</td>
                                                    <td align="right">227</td>
                                                    <td align="center">25%</td>
                                                  </tr>
                                                </table>
                                       </td>
                                     </tr>
                               </table>
                        </td>
                    </tr>
                     
                     
            
</table>


</table>




</div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="revs" class="small-text"><SPAN class="heading">REVIEWS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	<br />Reviews are not available for this item
        
        <div align="left" style="margin-top:30px">
					<a title="Computing Reviews" href="ocr_review_main.cfm?CFID=105752665&CFTOKEN=60368223">
                 <img src="http://dl.acm.org/images/ocrs-s.jpg" alt="Computing Reviews logo" border="0" style="vertical-align:middle"></a>
        
        
       		<ul style="list-style:disc; display:inline-block">
	            <li>Access <a href="ocr_review_main.cfm?CFID=105752665&CFTOKEN=60368223" target="_blank">critical reviews</a> of computing literature.</li>
            	<li><a href="http://www.computingreviews.com/Reviewer/"  target="_blank">Become a reviewer</a> for Computing Reviews</li>
            </ul>
        </div>
        
</div>



<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="comments" class="small-text"><SPAN class="heading">COMMENTS</SPAN></A></h1>
         
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<div>
<div>
	
	<p style="margin-left:5px;">
    <strong>Be the first to comment</strong>
    	
          	To Post a comment please <a href="signin.cfm?CFID=105752665&CFTOKEN=60368223">sign in or create</a> a free Web account</a>
        
    
    
	 </p>
	   	
 
</div>


</div>

	
		<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="prox" class="small-text">Table of Contents</A></h1>
        
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" >

<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">Proceedings of the 4th ACM/IEEE international conference on Human robot interaction</h5>


<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>

<div style="clear:both">
    
        <div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><a href="citation.cfm?id=1349822&picked=prox&CFID=105752665&CFTOKEN=60368223" title="previous: HRI '08"><img hspace="5" align="absmiddle" border="0" src="img/prev.gif" width="19" height="11" alt="previous" />previous proceeding</a> <span style="padding-left:5px;padding-right:5px;">|</span><a href="citation.cfm?id=1734454&picked=prox&CFID=105752665&CFTOKEN=60368223" title="Next: HRI '10">next proceeding <img align="absmiddle" hspace="5" border="0" src="img/next.gif" width="19" height="11" alt="next" /></a></div>
        
</div>


 
<table class="text12" border="0">

  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=1514096&CFID=105752665&CFTOKEN=60368223">Bringing physical characters to life</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          
                        <a href="author_page.cfm?id=81414592674&CFID=105752665&CFTOKEN=60368223">Akhil J. Madhani</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">Pages: 1-2</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514096" title="DOI">10.1145/1514095.1514096</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:0">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514096&ftid=602965&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:0">
          <span id="toShow1" style="display:inline;"><br /><div style="display:inline">At Disney, we are storytellers, and all good stories are filled with compelling characters. One way to present these characters to audiences in immersive, 3D environments is through the use of entertainment robots, or Audio Animatronics Figures, as they ...</div></span>
          <span id="toHide1" style="display:none;"><br /><div style="display:inline"><p>At Disney, we are storytellers, and all good stories are filled with compelling characters. One way to present these characters to audiences in immersive, 3D environments is through the use of entertainment robots, or Audio Animatronics Figures, as they have traditionally been known at Disney in attractions such as Pirates of the Caribbean.</p> <p>In this talk, I hope to give insight into the design and development of entertainment robots at Disney. In particular, I share - from the point of view of a robot builder - some of the guidelines distilled from Disney's tradition of hand-drawn animation as they are applied to these systems.</p> <p>As examples of characters which partake in two-way interactions with audiences via teleoperation, I discuss two newer characters. The first, Lucky the Dinosaur, was designed to roam freely through the Disney theme park environment while interacting with guests. The second, Wall-E, was developed in conjunction with Pixar Animation Studios to represent the character from the film, and has made appearances and given interviews at red carpet premieres, press events, and in television studios around the world.</p> <p>Ultimately, we hope that a further scientific study of the principles of animation and character development would be useful to anyone designing robots, autonomous or teleoperated, which must interact with humans.</p></div></span> <a id="expcoll1" href="JavaScript: expandcollapse('expcoll1',1)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=1514097&CFID=105752665&CFTOKEN=60368223">Interacting with robots on Mars: operation of the mars exploration rovers</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          
                        <a href="author_page.cfm?id=81414613327&CFID=105752665&CFTOKEN=60368223">Steve Squyres</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">Pages: 3-4</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514097" title="DOI">10.1145/1514095.1514097</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:0">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514097&ftid=602966&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:0">
          <span id="toShow2" style="display:inline;"><br /><div style="display:inline">The rovers Spirit and Opportunity have been operating on the surface of Mars since January of 2004. Interaction with these robotic vehicles involves overcoming a number of operational challenges. The challenges include the distance between Mars and Earth ...</div></span>
          <span id="toHide2" style="display:none;"><br /><div style="display:inline"><p>The rovers Spirit and Opportunity have been operating on the surface of Mars since January of 2004. Interaction with these robotic vehicles involves overcoming a number of operational challenges. The challenges include the distance between Mars and Earth (the one-way travel time for commands and data can be as long as 20 minutes), environmental factors (e.g., extreme temperatures, dust storms), and the need to respond quickly and effectively to unexpected events and scientific discoveries. In the five years since the rovers landed, the Mars Exploration Rover project team has developed operational procedures for interacting with the rovers that are both scientifically productive and sustainable for what has become a long-duration mission</p></div></span> <a id="expcoll2" href="JavaScript: expandcollapse('expcoll2',2)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=1514098&CFID=105752665&CFTOKEN=60368223">Robots with emotional intelligence</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          
                        <a href="author_page.cfm?id=81100496593&CFID=105752665&CFTOKEN=60368223">Rosalind W. Picard</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">Pages: 5-6</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514098" title="DOI">10.1145/1514095.1514098</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:0">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514098&ftid=602967&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:0">
          <span id="toShow3" style="display:inline;"><br /><div style="display:inline">This keynote talk will illustrate a basic set of skills of emotional intelligence, how they are important for robots and agents that interact with people, and how our research at MIT addresses part of the problem of giving robots such skills. One of ...</div></span>
          <span id="toHide3" style="display:none;"><br /><div style="display:inline"><p>This keynote talk will illustrate a basic set of skills of emotional intelligence, how they are important for robots and agents that interact with people, and how our research at MIT addresses part of the problem of giving robots such skills. One of the most important skills is the ability to perceive and understand expressions of emotion, which I will highlight by demonstrating our latest technologies developed to read joint facial-head movements in real-time and associate these with complex affective-cognitive states, and technologies to read paralinguistic vocal cues from speech. The latter have been made open-source and are available for free. I will also show some non-traditional ways robots might sense and learn about human emotion, and ways they can respond to what they sense that can help or hurt people. I will discuss social and ethical issues these technologies raise. Finally, I will present some new possibilities for robots to both learn from people and help teach skills of emotional intelligence to people, especially to those with nonverbal learning impairments who may want to learn these skills, including many people with diagnoses of autism spectrum disorders such as Aspergers Syndrome.</p></div></span> <a id="expcoll3" href="JavaScript: expandcollapse('expcoll3',3)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Designing robots based on human behavior</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514100&CFID=105752665&CFTOKEN=60368223">The snackbot: documenting the design of a robot for long-term human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414592368&CFID=105752665&CFTOKEN=60368223">Min Kyung Lee</a>, 
                        <a href="author_page.cfm?id=81100492013&CFID=105752665&CFTOKEN=60368223">Jodi Forlizzi</a>, 
                        <a href="author_page.cfm?id=81100077697&CFID=105752665&CFTOKEN=60368223">Paul E. Rybski</a>, 
                        <a href="author_page.cfm?id=81100315459&CFID=105752665&CFTOKEN=60368223">Frederick Crabbe</a>, 
                        <a href="author_page.cfm?id=81414593408&CFID=105752665&CFTOKEN=60368223">Wayne Chung</a>, 
                        <a href="author_page.cfm?id=81414617462&CFID=105752665&CFTOKEN=60368223">Josh Finkle</a>, 
                        <a href="author_page.cfm?id=81414594358&CFID=105752665&CFTOKEN=60368223">Eric Glaser</a>, 
                        <a href="author_page.cfm?id=81100476487&CFID=105752665&CFTOKEN=60368223">Sara Kiesler</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 7-14</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514100" title="DOI">10.1145/1514095.1514100</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514100&ftid=642062&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow5" style="display:inline;"><br /><div style="display:inline">We present the design of the Snackbot, a robot that will deliver snacks in our university buildings. The robot is intended to provide a useful, continuing service and to serve as a research platform for long-term Human-Robot Interaction. Our design process, ...</div></span>
          <span id="toHide5" style="display:none;"><br /><div style="display:inline"><p>We present the design of the Snackbot, a robot that will deliver snacks in our university buildings. The robot is intended to provide a useful, continuing service and to serve as a research platform for long-term Human-Robot Interaction. Our design process, which occurred over 24 months, is documented as a contribution for others in HRI who may be developing social robots that offer services. We describe the phases of the design project, and the design decisions and tradeoffs that led to the current version of the robot.</p></div></span> <a id="expcoll5" href="JavaScript: expandcollapse('expcoll5',5)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514101&CFID=105752665&CFTOKEN=60368223">Learning about objects with human teachers</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502411&CFID=105752665&CFTOKEN=60368223">Andrea L. Thomaz</a>, 
                        <a href="author_page.cfm?id=81414594397&CFID=105752665&CFTOKEN=60368223">Maya Cakmak</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 15-22</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514101" title="DOI">10.1145/1514095.1514101</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514101&ftid=602969&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow6" style="display:inline;"><br /><div style="display:inline">A general learning task for a robot in a new environment is to learn about objects and what actions/effects they afford. To approach this, we look at ways that a human partner can intuitively help the robot learn, Socially Guided Machine Learning. We ...</div></span>
          <span id="toHide6" style="display:none;"><br /><div style="display:inline"><p>A general learning task for a robot in a new environment is to learn about objects and what actions/effects they afford. To approach this, we look at ways that a human partner can intuitively help the robot learn, Socially Guided Machine Learning. We present experiments conducted with our robot, Junior, and make six observations characterizing how people approached teaching about objects. We show that Junior successfully used transparency to mitigate errors. Finally, we present the impact of "social" versus "non-social" data sets when training SVM classifiers.</p></div></span> <a id="expcoll6" href="JavaScript: expandcollapse('expcoll6',6)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514102&CFID=105752665&CFTOKEN=60368223">How people talk when teaching a robot</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414606528&CFID=105752665&CFTOKEN=60368223">Elizabeth S. Kim</a>, 
                        <a href="author_page.cfm?id=81414619175&CFID=105752665&CFTOKEN=60368223">Dan Leyzberg</a>, 
                        <a href="author_page.cfm?id=81414601137&CFID=105752665&CFTOKEN=60368223">Katherine M. Tsui</a>, 
                        <a href="author_page.cfm?id=81326492306&CFID=105752665&CFTOKEN=60368223">Brian Scassellati</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 23-30</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514102" title="DOI">10.1145/1514095.1514102</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514102&ftid=602970&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow7" style="display:inline;"><br /><div style="display:inline">We examine affective vocalizations provided by human teachers to robotic learners. In unscripted one-on-one interactions, participants provided vocal input to a robotic dinosaur as the robot selected toy buildings to knock down. We find that (1) people ...</div></span>
          <span id="toHide7" style="display:none;"><br /><div style="display:inline"><p>We examine affective vocalizations provided by human teachers to robotic learners. In unscripted one-on-one interactions, participants provided vocal input to a robotic dinosaur as the robot selected toy buildings to knock down. We find that (1) people vary their vocal input depending on the learner's performance history, (2) people do not wait until a robotic learner completes an action before they provide input and (3) people naively and spontaneously use intensely affective prosody. Our findings suggest modifications may be needed to traditional machine learning models to better fit observed human tendencies. Our observations of human behavior contradict the popular assumptions made by machine learning algorithms (in particular, reinforcement learning) that the reward function is stationary and path-independent for social learning interactions.</p> <p>We also propose an interaction taxonomy that describes three phases of a human-teacher's vocalizations: direction, spoken before an action is taken; guidance, spoken as the learner communicates an intended action; and feedback, spoken in response to a completed action.</p></div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Robots as intermediaries</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Greg Trafton 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514104&CFID=105752665&CFTOKEN=60368223">I am my robot: the impact of robot-building and robot form on operators</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81416605221&CFID=105752665&CFTOKEN=60368223">Victoria Groom</a>, 
                        <a href="author_page.cfm?id=81100499212&CFID=105752665&CFTOKEN=60368223">Leila Takayama</a>, 
                        <a href="author_page.cfm?id=81414619122&CFID=105752665&CFTOKEN=60368223">Paloma Ochi</a>, 
                        <a href="author_page.cfm?id=81100153283&CFID=105752665&CFTOKEN=60368223">Clifford Nass</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 31-36</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514104" title="DOI">10.1145/1514095.1514104</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514104&ftid=602971&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow9" style="display:inline;"><br /><div style="display:inline">As robots become more pervasive, operators will develop richer relationships with them. In a 2 (robot form: humanoid vs. car) x 2 (assembler: self vs. other) between-participants experiment (N=56), participants assembled either a humanoid or car robot. ...</div></span>
          <span id="toHide9" style="display:none;"><br /><div style="display:inline"><p>As robots become more pervasive, operators will develop richer relationships with them. In a 2 (robot form: humanoid vs. car) x 2 (assembler: self vs. other) between-participants experiment (N=56), participants assembled either a humanoid or car robot. Participants then used, in the context of a game, either the robot they built or a different robot. Participants showed greater extension of their self-concept into the car robot and preferred the personality of the car robot over the humanoid robot. People showed greater self extension into a robot and preferred the personality of the robot they assembled over a robot they believed to be assembled by another. Implications for the theory and design of robots and human-robot interaction are discussed.</p></div></span> <a id="expcoll9" href="JavaScript: expandcollapse('expcoll9',9)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514105&CFID=105752665&CFTOKEN=60368223">Egocentric and exocentric teleoperation interface using real-time, 3D video projection</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414619234&CFID=105752665&CFTOKEN=60368223">Fran&#231;ois Ferland</a>, 
                        <a href="author_page.cfm?id=81414621428&CFID=105752665&CFTOKEN=60368223">Fran&#231;ois Pomerleau</a>, 
                        <a href="author_page.cfm?id=81414618805&CFID=105752665&CFTOKEN=60368223">Chon Tam Le Dinh</a>, 
                        <a href="author_page.cfm?id=81100593688&CFID=105752665&CFTOKEN=60368223">Fran&#231;ois Michaud</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 37-44</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514105" title="DOI">10.1145/1514095.1514105</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514105&ftid=602972&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow10" style="display:inline;"><br /><div style="display:inline">The user interface is the central element of a telepresence robotic system and its visualization modalities greatly affect the operator's situation awareness, and thus its performance. Depending on the task at hand and the operator's preferences, going ...</div></span>
          <span id="toHide10" style="display:none;"><br /><div style="display:inline"><p>The user interface is the central element of a telepresence robotic system and its visualization modalities greatly affect the operator's situation awareness, and thus its performance. Depending on the task at hand and the operator's preferences, going from ego- and exocentric viewpoints and improving the depth representation can provide better perspectives of the operation environment. Our system, which combines a 3D reconstruction of the environment using laser range finder readings with two video projection methods, allows the operator to easily switch from ego- to exocentric viewpoints. This paper presents the interface developed and demonstrates its capabilities by having 13 operators teleoperate a mobile robot in a navigation task.</p></div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514106&CFID=105752665&CFTOKEN=60368223">Robots in the wild: understanding long-term use</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81330498575&CFID=105752665&CFTOKEN=60368223">JaYoung Sung</a>, 
                        <a href="author_page.cfm?id=81100285247&CFID=105752665&CFTOKEN=60368223">Henrik I. Christensen</a>, 
                        <a href="author_page.cfm?id=81328488487&CFID=105752665&CFTOKEN=60368223">Rebecca E. Grinter</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 45-52</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514106" title="DOI">10.1145/1514095.1514106</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514106&ftid=602973&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow11" style="display:inline;"><br /><div style="display:inline">It has long been recognized that novelty effects exist in the interaction with technologies. Despite this recognition, we still know little about the novelty effects associated with domestic robotic appliances and more importantly, what occurs after ...</div></span>
          <span id="toHide11" style="display:none;"><br /><div style="display:inline"><p>It has long been recognized that novelty effects exist in the interaction with technologies. Despite this recognition, we still know little about the novelty effects associated with domestic robotic appliances and more importantly, what occurs after the novelty wears off. To address this gap, we undertook a longitudinal field study with 30 households to which we gave Roomba vacuuming robots and then observed use over six months. During this study, which spans over 149 home visits, we encountered methodological challenges in understanding households' usage patterns. In this paper we report on our longitudinal research, focusing particularly on the methods that we used 1) to understand human-robot interaction over time despite the constraints of privacy and temporality in the home, and 2) to uncover information when routines became less conscious to the participants themselves.</p></div></span> <a id="expcoll11" href="JavaScript: expandcollapse('expcoll11',11)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Non-verbal communication in HRI</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Dan Levin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514108&CFID=105752665&CFTOKEN=60368223">Providing route directions: design of robot's utterance, gesture, and timing</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414609762&CFID=105752665&CFTOKEN=60368223">Yusuke Okuno</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100282909&CFID=105752665&CFTOKEN=60368223">Michita Imai</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752665&CFTOKEN=60368223">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752665&CFTOKEN=60368223">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 53-60</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514108" title="DOI">10.1145/1514095.1514108</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514108&ftid=602974&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow13" style="display:inline;"><br /><div style="display:inline">Providing route directions is a complicated interaction. Utterances are combined with gestures and pronounced with appropriate timing. This study proposes a model for a robot that generates route directions by integrating three important crucial elements: ...</div></span>
          <span id="toHide13" style="display:none;"><br /><div style="display:inline"><p>Providing route directions is a complicated interaction. Utterances are combined with gestures and pronounced with appropriate timing. This study proposes a model for a robot that generates route directions by integrating three important crucial elements: utterances, gestures, and timing. Two research questions must be answered in this modeling process. First, is it useful to let robot perform gesture even though the information conveyed by the gesture is given by utterance as well? Second, is it useful to implement the timing at which humans speaks? Many previous studies about the natural behavior of computers and robots have learned from human speakers, such as gestures and speech timing. However, our approach is different from such previous studies. We emphasized the listener's perspective. Gestures were designed based on the usefulness, although we were influenced by the basic structure of human gestures. Timing was not based on how humans speak, but modeled from how they listen. The experimental result demonstrated the effectiveness of our approach, not only for task efficiency but also for perceived naturalness.</p></div></span> <a id="expcoll13" href="JavaScript: expandcollapse('expcoll13',13)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514109&CFID=105752665&CFTOKEN=60368223">Footing in human-robot conversations: how robots might shape participant roles using gaze cues</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500023&CFID=105752665&CFTOKEN=60368223">Bilge Mutlu</a>, 
                        <a href="author_page.cfm?id=81414602907&CFID=105752665&CFTOKEN=60368223">Toshiyuki Shiwa</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752665&CFTOKEN=60368223">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752665&CFTOKEN=60368223">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 61-68</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514109" title="DOI">10.1145/1514095.1514109</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514109&ftid=641832&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow14" style="display:inline;"><br /><div style="display:inline">During conversations, speakers establish their and others' participant roles (who participates in the conversation and in what capacity)--or "footing" as termed by Goffman-using gaze cues. In this paper, we study how a robot can establish the participant ...</div></span>
          <span id="toHide14" style="display:none;"><br /><div style="display:inline"><p>During conversations, speakers establish their and others' participant roles (who participates in the conversation and in what capacity)--or "footing" as termed by Goffman-using gaze cues. In this paper, we study how a robot can establish the participant roles of its conversational partners using these cues. We designed a set of gaze behaviors for Robovie to signal three kinds of participant roles: addressee, bystander, and overhearer. We evaluated our design in a controlled laboratory experiment with 72 subjects in 36 trials. In three conditions, the robot signaled to two subjects, only by means of gaze, the roles of (1) two addressees, (2) an addressee and a bystander, or (3) an addressee and an overhearer. Behavioral measures showed that subjects' participation behavior conformed to the roles that the robot communicated to them. In subjective evaluations, significant differences were observed in feelings of groupness between addressees and others and liking between overhearers and others. Participation in the conversation did not affect task performance-measured by recall of information presented by the robot-but affected subjects' ratings of how much they attended to the task.</p></div></span> <a id="expcoll14" href="JavaScript: expandcollapse('expcoll14',14)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514110&CFID=105752665&CFTOKEN=60368223">Nonverbal leakage in robots: communication of intentions through seemingly unintentional behavior</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500023&CFID=105752665&CFTOKEN=60368223">Bilge Mutlu</a>, 
                        <a href="author_page.cfm?id=81310501032&CFID=105752665&CFTOKEN=60368223">Fumitaka Yamaoka</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752665&CFTOKEN=60368223">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752665&CFTOKEN=60368223">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 69-76</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514110" title="DOI">10.1145/1514095.1514110</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514110&ftid=641833&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow15" style="display:inline;"><br /><div style="display:inline">Human communication involves a number of nonverbal cues that are seemingly unintentional, unconscious, and automatic-both in their production and perception-and convey rich information on the emotional state and intentions of an individual. One family ...</div></span>
          <span id="toHide15" style="display:none;"><br /><div style="display:inline"><p>Human communication involves a number of nonverbal cues that are seemingly unintentional, unconscious, and automatic-both in their production and perception-and convey rich information on the emotional state and intentions of an individual. One family of such cues is called "nonverbal leakage." In this paper, we explore whether people can read nonverbal leakage cues-particularly gaze cues-in humanlike robots and make inferences on robots' intentions, and whether the physical design of the robot affects these inferences. We designed a gaze cue for Geminoid-a highly humanlike android-and Robovie-a robot with stylized, abstract humanlike features-that allowed the robots to "leak" information on what they might have in mind. In a controlled laboratory experiment, we asked participants to play a game of guessing with either of the robots and evaluated how the gaze cue affected participants' task performance. We found that the gaze cue did, in fact, lead to better performance, from which we infer that the cue led to attributions of mental states and intentionality. Our results have implications for robot design, particularly for designing expression of intentionality, and for our understanding of how people respond to human social cues when they are enacted by robots.</p></div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514111&CFID=105752665&CFTOKEN=60368223">Visual attention in spoken human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414620059&CFID=105752665&CFTOKEN=60368223">Maria Staudte</a>, 
                        <a href="author_page.cfm?id=81100461013&CFID=105752665&CFTOKEN=60368223">Matthew W. Crocker</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 77-84</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514111" title="DOI">10.1145/1514095.1514111</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514111&ftid=602977&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow16" style="display:inline;"><br /><div style="display:inline">Psycholinguistic studies of situated language processing have revealed that gaze in the visual environment is tightly coupled with both spoken language comprehension and production. It has also been established that interlocutors monitor the gaze of ...</div></span>
          <span id="toHide16" style="display:none;"><br /><div style="display:inline"><p>Psycholinguistic studies of situated language processing have revealed that gaze in the visual environment is tightly coupled with both spoken language comprehension and production. It has also been established that interlocutors monitor the gaze of their partners, a phenomenon called "joint attention", as a further means for facilitating mutual understanding. We hypothesise that human-robot interaction will benefit when the robot's language-related gaze behaviour is similar to that of people, potentially providing the user with valuable non-verbal information concerning the robot's intended message or the robot's successful understanding. We report findings from two eye-tracking experiments demonstrating (1) that human gaze is modulated by both the robot speech and gaze, and (2) that human comprehension of robot speech is improved when the robot's real-time gaze behaviour is similar to that of humans.</p></div></span> <a id="expcoll16" href="JavaScript: expandcollapse('expcoll16',16)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>New methods for studying HRI</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Vanessa Evers 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514113&CFID=105752665&CFTOKEN=60368223">An information pipeline model of human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310499420&CFID=105752665&CFTOKEN=60368223">Kevin Gold</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 85-92</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514113" title="DOI">10.1145/1514095.1514113</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514113&ftid=602978&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow18" style="display:inline;"><br /><div style="display:inline">This paper investigates the potential usefulness of viewing the system of human, robot, and environment as an "information pipeline" from environment to user and back again. Information theory provides tools for analyzing and maximizing the information ...</div></span>
          <span id="toHide18" style="display:none;"><br /><div style="display:inline"><p>This paper investigates the potential usefulness of viewing the system of human, robot, and environment as an "information pipeline" from environment to user and back again. Information theory provides tools for analyzing and maximizing the information rate of each stage of this pipeline, and could thus encompass several common HRI goals: "situational awareness," which can be seen as maximizing the information content of the human's model of the situation; efficient robotic control, which can be seen as finding a good codebook and high throughput for the Human-Robot channel; and artificial intelligence, which can be assessed by how much it reduces the traffic on all four channels. Analysis of the information content of the four channels suggests that human to robot communication tends to be the bottleneck, suggesting the need for greater onboard intelligence and a command interface that can adapt to the situation.</p></div></span> <a id="expcoll18" href="JavaScript: expandcollapse('expcoll18',18)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514114&CFID=105752665&CFTOKEN=60368223">Systemic interaction analysis (SInA) in HRI</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414610931&CFID=105752665&CFTOKEN=60368223">Manja Lohse</a>, 
                        <a href="author_page.cfm?id=81100489150&CFID=105752665&CFTOKEN=60368223">Marc Hanheide</a>, 
                        <a href="author_page.cfm?id=81418594203&CFID=105752665&CFTOKEN=60368223">Katharina J. Rohlfing</a>, 
                        <a href="author_page.cfm?id=81100458351&CFID=105752665&CFTOKEN=60368223">Gerhard Sagerer</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 93-100</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514114" title="DOI">10.1145/1514095.1514114</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514114&ftid=602979&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow19" style="display:inline;"><br /><div style="display:inline">Recent developments in robotics enable advanced human-robot interaction. Especially interactions of novice users with robots are often unpredictable and, therefore, demand for novel methods for the analysis of the interaction in systemic ways. We propose ...</div></span>
          <span id="toHide19" style="display:none;"><br /><div style="display:inline"><p>Recent developments in robotics enable advanced human-robot interaction. Especially interactions of novice users with robots are often unpredictable and, therefore, demand for novel methods for the analysis of the interaction in systemic ways. We propose Systemic Interaction Analysis (SInA) as a method to jointly analyze system level and interaction level in an integrated manner using one tool. The approach allows us to trace back patterns that deviate from prototypical interaction sequences to the distinct system components of our autonomous robot. In this paper, we exemplarily apply the method to the analysis of the follow behavior of our domestic robot BIRON. The analysis is the basis to achieve our goal of improving human-robot interaction iteratively.</p></div></span> <a id="expcoll19" href="JavaScript: expandcollapse('expcoll19',19)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514115&CFID=105752665&CFTOKEN=60368223">The oz of wizard: simulating the human for interaction research</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100236968&CFID=105752665&CFTOKEN=60368223">Aaron Steinfeld</a>, 
                        <a href="author_page.cfm?id=81100598466&CFID=105752665&CFTOKEN=60368223">Odest Chadwicke Jenkins</a>, 
                        <a href="author_page.cfm?id=81326492306&CFID=105752665&CFTOKEN=60368223">Brian Scassellati</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 101-108</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514115" title="DOI">10.1145/1514095.1514115</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514115&ftid=602980&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow20" style="display:inline;"><br /><div style="display:inline">The Wizard of Oz experiment method has a long tradition of acceptance and use within the field of human-robot interaction. The community has traditionally downplayed the importance of interaction evaluations run with the inverse model: the human simulated ...</div></span>
          <span id="toHide20" style="display:none;"><br /><div style="display:inline"><p>The Wizard of Oz experiment method has a long tradition of acceptance and use within the field of human-robot interaction. The community has traditionally downplayed the importance of interaction evaluations run with the inverse model: the human simulated to evaluate robot behavior, or Oz of Wizard. We argue that such studies play an important role in the field of human-robot interaction. We differentiate between methodologically rigorous human modeling and placeholder simulations using simplified human models. Guidelines are proposed for when Oz of Wizard results should be considered acceptable. This paper also describes a framework for describing the various permutations of Wizard and Oz states.</p></div></span> <a id="expcoll20" href="JavaScript: expandcollapse('expcoll20',20)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Modeling social interaction</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jill Drury 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514117&CFID=105752665&CFTOKEN=60368223">How to approach humans?: strategies for social robots to initiate interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81321498073&CFID=105752665&CFTOKEN=60368223">Satoru Satake</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81350582585&CFID=105752665&CFTOKEN=60368223">Dylan F. Glas</a>, 
                        <a href="author_page.cfm?id=81100282909&CFID=105752665&CFTOKEN=60368223">Michita Imai</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752665&CFTOKEN=60368223">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752665&CFTOKEN=60368223">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 109-116</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514117" title="DOI">10.1145/1514095.1514117</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514117&ftid=602981&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow22" style="display:inline;"><br /><div style="display:inline">This paper proposes a model of approach behavior with which a robot can initiate conversation with people who are walking. We developed the model by learning from the failures in a simplistic approach behavior used in a real shopping mall. Sometimes ...</div></span>
          <span id="toHide22" style="display:none;"><br /><div style="display:inline"><p>This paper proposes a model of approach behavior with which a robot can initiate conversation with people who are walking. We developed the model by learning from the failures in a simplistic approach behavior used in a real shopping mall. Sometimes people were unaware of the robot's presence, even when it spoke to them. Sometimes, people were not sure whether the robot was really trying to start a conversation, and they did not start talking with it even though they displayed interest. To prevent such failures, our model includes the following functions: predicting the walking behavior of people, choosing a target person, planning its approaching path, and nonverbally indicating its intention to initiate a conversation. The approach model was implemented and used in a real shopping mall. The field trial demonstrated that our model significantly improves the robot's performance in initiating conversations.</p></div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514118&CFID=105752665&CFTOKEN=60368223">ShadowPlay: a generative model for nonverbal human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414600840&CFID=105752665&CFTOKEN=60368223">Eric M. Meisner</a>, 
                        <a href="author_page.cfm?id=81414621579&CFID=105752665&CFTOKEN=60368223">Selma &#192;banovic</a>, 
                        <a href="author_page.cfm?id=81342498727&CFID=105752665&CFTOKEN=60368223">Volkan Isler</a>, 
                        <a href="author_page.cfm?id=81414619958&CFID=105752665&CFTOKEN=60368223">Linnda R. Caporeal</a>, 
                        <a href="author_page.cfm?id=81100324126&CFID=105752665&CFTOKEN=60368223">Jeff Trinkle</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 117-124</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514118" title="DOI">10.1145/1514095.1514118</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514118&ftid=602982&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow23" style="display:inline;"><br /><div style="display:inline">Humans rely on a finely tuned ability to recognize and adapt to socially relevant patterns in their everyday face-to-face interactions. This allows them to anticipate the actions of others, coordinate their behaviors, and create shared meaning to communicate. ...</div></span>
          <span id="toHide23" style="display:none;"><br /><div style="display:inline"><p>Humans rely on a finely tuned ability to recognize and adapt to socially relevant patterns in their everyday face-to-face interactions. This allows them to anticipate the actions of others, coordinate their behaviors, and create shared meaning to communicate. Social robots must likewise be able to recognize and perform relevant social patterns, including interactional synchrony, imitation, and particular sequences of behaviors. We use existing empirical work in the social sciences and observations of human interaction to develop nonverbal interactive capabilities for a robot in the context of shadow puppet play, where people interact through shadows of hands cast against a wall. We show how information theoretic quantities can be used to model interaction between humans and to generate interactive controllers for a robot. Finally, we evaluate the resulting model in an embodied human-robot interaction study. We show the benefit of modeling interaction as a joint process rather than modeling individual agents.</p></div></span> <a id="expcoll23" href="JavaScript: expandcollapse('expcoll23',23)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514119&CFID=105752665&CFTOKEN=60368223">Creating and using matrix representations of social interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414607056&CFID=105752665&CFTOKEN=60368223">Alan R. Wagner</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 125-132</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514119" title="DOI">10.1145/1514095.1514119</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514119&ftid=602983&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow24" style="display:inline;"><br /><div style="display:inline">This paper explores the use of an outcome matrix as a computational representation of social interaction suitable for implementation on a robot. An outcome matrix expresses the reward afforded to each interacting individual with respect to pairs of potential ...</div></span>
          <span id="toHide24" style="display:none;"><br /><div style="display:inline"><p>This paper explores the use of an outcome matrix as a computational representation of social interaction suitable for implementation on a robot. An outcome matrix expresses the reward afforded to each interacting individual with respect to pairs of potential behaviors. We detail the use of the outcome matrix as a representation of interaction in social psychology and game theory, discuss the need for modeling the robot's interactive partner, and contribute an algorithm for creating outcome matrices from perceptual information. Experimental results explore the use of the algorithm with different types of partners and in different environments.</p></div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514120&CFID=105752665&CFTOKEN=60368223">Developing a model of robot behavior to identify and appropriately respond to implicit attention-shifting</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310501032&CFID=105752665&CFTOKEN=60368223">Fumitaka Yamaoka</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752665&CFTOKEN=60368223">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752665&CFTOKEN=60368223">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 133-140</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514120" title="DOI">10.1145/1514095.1514120</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514120&ftid=602984&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow25" style="display:inline;"><br /><div style="display:inline">In this paper, we present our current research on developing a model of robot behavior that leads to feelings of being together using the robot's body position and orientation. Creating feelings of"being together"will be an essential skill for robots ...</div></span>
          <span id="toHide25" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present our current research on developing a model of robot behavior that leads to feelings of being together using the robot's body position and orientation. Creating feelings of"being together"will be an essential skill for robots that live with humans and adapt to daily human activities such as walking together or establishing joint attention to information in the environment. We observe people's proxemic behavior in joint attention situations and develop a model of behavior for robots to detect a partner's attention shift and appropriately adjust its body position and orientation in establishing joint attention with the partner. We experimentally evaluate the effectiveness of our model, and our results demonstrate the model's effectiveness.</p></div></span> <a id="expcoll25" href="JavaScript: expandcollapse('expcoll25',25)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Situation awareness, interface design and usability</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Kristen Stubbs 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514122&CFID=105752665&CFTOKEN=60368223">How search and its subtasks scale in N robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81361607034&CFID=105752665&CFTOKEN=60368223">Huadong Wang</a>, 
                        <a href="author_page.cfm?id=81100349943&CFID=105752665&CFTOKEN=60368223">Michael Lewis</a>, 
                        <a href="author_page.cfm?id=81361592401&CFID=105752665&CFTOKEN=60368223">Prasanna Velagapudi</a>, 
                        <a href="author_page.cfm?id=81100004712&CFID=105752665&CFTOKEN=60368223">Paul Scerri</a>, 
                        <a href="author_page.cfm?id=81100488454&CFID=105752665&CFTOKEN=60368223">Katia Sycara</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 141-148</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514122" title="DOI">10.1145/1514095.1514122</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514122&ftid=602985&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow27" style="display:inline;"><br /><div style="display:inline">The present study investigates the effect of the number of controlled robots on performance of an urban search and rescue (USAR) task using a realistic simulation. Participants controlled either 4, 8, or 12 robots. In the fulltask control condition participants ...</div></span>
          <span id="toHide27" style="display:none;"><br /><div style="display:inline"><p>The present study investigates the effect of the number of controlled robots on performance of an urban search and rescue (USAR) task using a realistic simulation. Participants controlled either 4, 8, or 12 robots. In the fulltask control condition participants both dictated the robots' paths and controlled their cameras to search for victims. In the exploration condition, participants directed the team of robots in order to explore as wide an area as possible. In the perceptual search condition, participants searched for victims by controlling cameras mounted on robots following predetermined paths selected to match characteristics of paths generated under the other two conditions. By decomposing the search and rescue task into exploration and perceptual search subtasks the experiment allows the determination of their scaling characteristics in order to provide a basis for tentative task allocations among humans and automation for controlling larger robot teams. In the fulltask control condition task performance increased in going from four to eight controlled robots but deteriorated in moving from eight to twelve. Workload increased monotonically with number of robots. Performance per robot decreased with increases in team size. Results are consistent with earlier studies suggesting a limit of between 8-12 robots for direct human control.</p></div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514123&CFID=105752665&CFTOKEN=60368223">Field trial for simultaneous teleoperation of mobile social robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350582585&CFID=105752665&CFTOKEN=60368223">Dylan F. Glas</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752665&CFTOKEN=60368223">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752665&CFTOKEN=60368223">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 149-156</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514123" title="DOI">10.1145/1514095.1514123</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514123&ftid=602986&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow28" style="display:inline;"><br /><div style="display:inline">Simultaneous teleoperation of mobile, social robots presents unique challenges, combining the real-time demands of conversation with the prioritized scheduling of navigational tasks. We have developed a system in which a single operator can effectively ...</div></span>
          <span id="toHide28" style="display:none;"><br /><div style="display:inline"><p>Simultaneous teleoperation of mobile, social robots presents unique challenges, combining the real-time demands of conversation with the prioritized scheduling of navigational tasks. We have developed a system in which a single operator can effectively control four mobile robots performing both conversation and navigation. We compare the teleoperation requirements for mobile, social robots with those of traditional robot systems, and we identify metrics for evaluating task difficulty and operator performance for teleoperation of mobile social robots. As a proof of concept, we present an integrated priority model combining real-time conversational demands and non-real-time navigational demands for operator attention, and in a pioneering study, we apply the model and metrics in a demonstration of our multi-robot system through real-world field trials in a shopping arcade.</p></div></span> <a id="expcoll28" href="JavaScript: expandcollapse('expcoll28',28)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514124&CFID=105752665&CFTOKEN=60368223">Mobile human-robot teaming with environmental tolerance</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81335494161&CFID=105752665&CFTOKEN=60368223">Matthew M. Loper</a>, 
                        <a href="author_page.cfm?id=81414620517&CFID=105752665&CFTOKEN=60368223">Nathan P. Koenig</a>, 
                        <a href="author_page.cfm?id=81333488007&CFID=105752665&CFTOKEN=60368223">Sonia H. Chernova</a>, 
                        <a href="author_page.cfm?id=81414592854&CFID=105752665&CFTOKEN=60368223">Chris V. Jones</a>, 
                        <a href="author_page.cfm?id=81100598466&CFID=105752665&CFTOKEN=60368223">Odest C. Jenkins</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 157-164</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514124" title="DOI">10.1145/1514095.1514124</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514124&ftid=602987&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow29" style="display:inline;"><br /><div style="display:inline">We demonstrate that structured light-based depth sensing with standard perception algorithms can enable mobile peer-to-peer interaction between humans and robots. We posit that the use of recent emerging devices for depth-based imaging can enable robot ...</div></span>
          <span id="toHide29" style="display:none;"><br /><div style="display:inline"><p>We demonstrate that structured light-based depth sensing with standard perception algorithms can enable mobile peer-to-peer interaction between humans and robots. We posit that the use of recent emerging devices for depth-based imaging can enable robot perception of non-verbal cues in human movement in the face of lighting and minor terrain variations. Toward this end, we have developed an integrated robotic system capable of person following and responding to verbal and non-verbal commands under varying lighting conditions and uneven terrain. The feasibility of our system for peer-to-peer HRI is demonstrated through two trials in indoor and outdoor environments.</p></div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Responding to autonomy</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514126&CFID=105752665&CFTOKEN=60368223">On using mixed-initiative control: a perspective for managing large-scale robotic teams</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414608960&CFID=105752665&CFTOKEN=60368223">Benjamin Hardin</a>, 
                        <a href="author_page.cfm?id=81350575550&CFID=105752665&CFTOKEN=60368223">Michael A. Goodrich</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 165-172</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514126" title="DOI">10.1145/1514095.1514126</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514126&ftid=602988&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow31" style="display:inline;"><br /><div style="display:inline">Prior work suggests that the potential benefits of mixed initiative management of multiple robots are mitigated by situational factors, including workload and operator expertise. In this paper, we present an experiment where allowing a supervisor and ...</div></span>
          <span id="toHide31" style="display:none;"><br /><div style="display:inline"><p>Prior work suggests that the potential benefits of mixed initiative management of multiple robots are mitigated by situational factors, including workload and operator expertise. In this paper, we present an experiment where allowing a supervisor and group of searchers to jointly decide the correct level of autonomy for a given situation ("mixed initiative") results in better overall performance than giving an agent exclusive control over their level of autonomy ("adaptive autonomy") or giving a supervisor exclusive control over the agent's level of autonomy ("adjustable autonomy"), regardless of the supervisor's expertise or workload. In light of prior work, we identify two elements of our experiment that appear to be requirements for effective mixed initiative control of large-scale robotic teams: (a) Agents must be capable of making progress toward a goal without having to wait for human input in most circumstances. (b) The operator control interface must help the human to rapidly understand and modify the progress and intent of several agents.</p></div></span> <a id="expcoll31" href="JavaScript: expandcollapse('expcoll31',31)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514127&CFID=105752665&CFTOKEN=60368223">An affective guide robot in a shopping mall</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81310499910&CFID=105752665&CFTOKEN=60368223">Masahiro Shiomi</a>, 
                        <a href="author_page.cfm?id=81414620424&CFID=105752665&CFTOKEN=60368223">Zenta Miyashita</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752665&CFTOKEN=60368223">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752665&CFTOKEN=60368223">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 173-180</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514127" title="DOI">10.1145/1514095.1514127</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514127&ftid=602989&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow32" style="display:inline;"><br /><div style="display:inline">To explore possible robot tasks in daily life, we developed a guide robot for a shopping mall and conducted a field trial with it. The robot was designed to interact naturally with customers and to affectively provide shopping information. It was also ...</div></span>
          <span id="toHide32" style="display:none;"><br /><div style="display:inline"><p>To explore possible robot tasks in daily life, we developed a guide robot for a shopping mall and conducted a field trial with it. The robot was designed to interact naturally with customers and to affectively provide shopping information. It was also designed to repeatedly interact with people to build a rapport; since a shopping mall is a place people repeatedly visit, it provides the chance to explicitly design a robot for multiple interactions. For this capability, we used RFID tags for person identification. The robot was semi-autonomous, partially controlled by a human operator, to cope with the difficulty of speech recognition in a real environment and to handle unexpected situations.</p> <p>A field trial was conducted at a shopping mall for 25 days to observe how the robot performed this task and how people interacted with it. The robot interacted with approximately 100 groups of customers each day. We invited customers to sign up for RFID tags and those who participated answered questionnaires. The results revealed that 63 out of 235 people in fact went shopping based on the information provided by the robot. The experimental results suggest promising potential for robots working in shopping malls.</p></div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514128&CFID=105752665&CFTOKEN=60368223">Concurrent performance of military tasks and robotics tasks: effects of automation unreliability and individual differences</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414613395&CFID=105752665&CFTOKEN=60368223">Jessie Y.C. Chen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 181-188</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514128" title="DOI">10.1145/1514095.1514128</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514128&ftid=602990&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow33" style="display:inline;"><br /><div style="display:inline">This study investigated the performance and workload of the combined position of gunner and robotics operator in a simulated military multitasking environment. Specifically, we investigated how aided target recognition (AiTR) capabilities for the gunnery ...</div></span>
          <span id="toHide33" style="display:none;"><br /><div style="display:inline"><p>This study investigated the performance and workload of the combined position of gunner and robotics operator in a simulated military multitasking environment. Specifically, we investigated how aided target recognition (AiTR) capabilities for the gunnery task with imperfect reliability (false-alarm-prone vs. miss-prone) might affect the concurrent robotics and communication tasks. Additionally, we examined whether performance was affected by individual differences in spatial ability and attentional control. Results showed that when the robotics task was simply monitoring the video, participants had the best performance in their gunnery and communication tasks and the lowest perceived workload, compared with the other robotics tasking conditions. There was a strong interaction between the type of AiTR unreliability and participants' perceived attentional control. Overall, for participants with higher perceived attentional control, false-alarm-prone alerts were more detrimental; for low attentional control participants, conversely, miss-prone automation was more harmful. Low spatial ability participants preferred visual cueing, and high spatial ability participants favored tactile cueing. Potential applications of the findings include personnel selection for robotics operation, robotics user interface designs, and training development.</p></div></span> <a id="expcoll33" href="JavaScript: expandcollapse('expcoll33',33)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>HRI video abstracts</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Aaron Steinfeld, Christoph Bartneck 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:0">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514129&ftid=602991&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514130&CFID=105752665&CFTOKEN=60368223">Non-facial and non-verbal affective expression in appearance-constrained robots for use in victim management: robots to the rescue!</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503105&CFID=105752665&CFTOKEN=60368223">Cindy L. Bethel</a>, 
                        <a href="author_page.cfm?id=81414619390&CFID=105752665&CFTOKEN=60368223">Christine Bringes</a>, 
                        <a href="author_page.cfm?id=81100545387&CFID=105752665&CFTOKEN=60368223">Robin R. Murphy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 191-192</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514130" title="DOI">10.1145/1514095.1514130</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514130&ftid=693164&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1514130&ftid=693162&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1514130&ftid=693163&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow35" style="display:inline;"><br /><div style="display:inline">This video presents a visual summary of large-scale, complex human study in Human-Robot Interaction (HRI) designed to evaluate whether humans would view interactions with two non-anthropomorphic robots more positively and calming when the robots were ...</div></span>
          <span id="toHide35" style="display:none;"><br /><div style="display:inline"><p>This video presents a visual summary of large-scale, complex human study in Human-Robot Interaction (HRI) designed to evaluate whether humans would view interactions with two non-anthropomorphic robots more positively and calming when the robots were operated in an emotive mode versus a standard, non-emotive mode. The video presents actual participants' reactions, the study design, and images from search and rescue operations.</p></div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514131&CFID=105752665&CFTOKEN=60368223">A native iPhone packbot OCU</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414596275&CFID=105752665&CFTOKEN=60368223">Rodrigo Gutierrez</a>, 
                        <a href="author_page.cfm?id=81327488263&CFID=105752665&CFTOKEN=60368223">Jeff Craighead</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 193-194</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514131" title="DOI">10.1145/1514095.1514131</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514131&ftid=602992&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1514131&ftid=645259&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow36" style="display:inline;"><br /><div style="display:inline">This video abstract discusses the details of the implementation of a Packbot operator control unit (OCU) using Apple's official iPhone SDK.</div></span>
          <span id="toHide36" style="display:none;"><br /><div style="display:inline"><p>This video abstract discusses the details of the implementation of a Packbot operator control unit (OCU) using Apple's official iPhone SDK.</p></div></span> <a id="expcoll36" href="JavaScript: expandcollapse('expcoll36',36)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514132&CFID=105752665&CFTOKEN=60368223">FaceBots: social robots utilizing facebook</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310484400&CFID=105752665&CFTOKEN=60368223">Nikolaos Mavridis</a>, 
                        <a href="author_page.cfm?id=81414609591&CFID=105752665&CFTOKEN=60368223">Chandan Datta</a>, 
                        <a href="author_page.cfm?id=81414616109&CFID=105752665&CFTOKEN=60368223">Shervin Emami</a>, 
                        <a href="author_page.cfm?id=81100610991&CFID=105752665&CFTOKEN=60368223">Chiraz BenAbdelkader</a>, 
                        <a href="author_page.cfm?id=81414619870&CFID=105752665&CFTOKEN=60368223">Andry Tanoto</a>, 
                        <a href="author_page.cfm?id=81100366332&CFID=105752665&CFTOKEN=60368223">Tamer Rabie</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 195-196</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514132" title="DOI">10.1145/1514095.1514132</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514132&ftid=316383&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1514132&ftid=316381&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1514132&ftid=316382&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow37" style="display:inline;"><br /><div style="display:inline">Although existing robotic systems are interesting to interact with in the short term, it has been shown that after some weeks of quasi-regular encounters, humans gradually lose their interest, and meaningful longer-term human-robot relationships are ...</div></span>
          <span id="toHide37" style="display:none;"><br /><div style="display:inline"><p>Although existing robotic systems are interesting to interact with in the short term, it has been shown that after some weeks of quasi-regular encounters, humans gradually lose their interest, and meaningful longer-term human-robot relationships are not established. An underlying hypothesis driving the proposed project is that such relationships can be significantly enhanced if the human and the robot are gradually creating a pool of shared episodic memories that they can co-refer to, and if they are both embedded in a social web of other humans and robots they both know and encounter frequently. Thus, here we propose to use Facebook, a highly successful online networking resource for humans, towards enhancing longer-term human-robot relationships, by helping to address the above two prerequisites. As a starting point, we utilize social information in order to personalize human-robot dialogues, and to include references to past encounters and to encounters with friends within dialogues. A robot equipped with a modular software architecture (with IPC-intercommunicating modules for face recognition, a simple dialog system, a navigation subsystem, and a real-time Facebook connection/local social database) has been deployed, and is encountering humans in the environment of our lab. An early demonstration of a basic form of such encounters is shown in the submitted video. The system is expected to achieve two significant novelties: arguably being one of the first robots to be embedded in a social web, and being the first robot that can purposefully exploit and create social information that is available online. Furthermore, it is expected to provide empirical support for our main driving hypothesis, that the formation of shared episodic memories within a social web can lead to more meaningful long-term human-robot relationships.</p></div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514133&CFID=105752665&CFTOKEN=60368223">Keepon goes Seoul-searching</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502486&CFID=105752665&CFTOKEN=60368223">Marek P. Michalowski</a>, 
                        <a href="author_page.cfm?id=81414601196&CFID=105752665&CFTOKEN=60368223">Jaewook Kim</a>, 
                        <a href="author_page.cfm?id=81414614481&CFID=105752665&CFTOKEN=60368223">Bomi Kim</a>, 
                        <a href="author_page.cfm?id=81339511173&CFID=105752665&CFTOKEN=60368223">Sonya S. Kwak</a>, 
                        <a href="author_page.cfm?id=81100620208&CFID=105752665&CFTOKEN=60368223">Hideki Kozima</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 197-198</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514133" title="DOI">10.1145/1514095.1514133</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514133&ftid=602993&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1514133&ftid=645253&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow38" style="display:inline;"><br /><div style="display:inline">Keepon is a robot designed for social interaction with children for the purposes of social development research and autism therapy [1]. Keepon's capacity for rhythmic synchrony in the form of dance has resulted in the popularity of several fictional ...</div></span>
          <span id="toHide38" style="display:none;"><br /><div style="display:inline"><p>Keepon is a robot designed for social interaction with children for the purposes of social development research and autism therapy [1]. Keepon's capacity for rhythmic synchrony in the form of dance has resulted in the popularity of several fictional music videos on the internet [2,3]. During a research collaboration visit at the KAIST PES Design Lab in Korea, Keepon's creators added this new chapter to the story of Keepon's travels. Upon watching a video of traditional Korean "Pungmulnori" dancing, which features distinctive spinning hats, Keepon becomes enamored. The robot has many adventures as he travels around Korea in search of a dance group that finally welcomes him into their cultural performance.</p> <p>Additional credits: Music ("Superfantastic" by Peppertones/Cavare Sound); Videography (Uyoung Chang and Minwoo Kang); Pungmulnori Team "Ghil" (Junhyung Park, Seongbok Chae, Sangmi Lee, Mikyeong Kim, and Sohyun Park).</p> <p>This video is available at http://beatbots.org and at http://www.youtube.com/watch?v=XwqfWR2KPd0.</p></div></span> <a id="expcoll38" href="JavaScript: expandcollapse('expcoll38',38)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514134&CFID=105752665&CFTOKEN=60368223">AURAL: evolutionary sonification with robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100371734&CFID=105752665&CFTOKEN=60368223">Artemis M.F.S. Moroni</a>, 
                        <a href="author_page.cfm?id=81100217326&CFID=105752665&CFTOKEN=60368223">J&#244;natas Manzolli</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 199-200</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514134" title="DOI">10.1145/1514095.1514134</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514134&ftid=602994&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1514134&ftid=645254&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow39" style="display:inline;"><br /><div style="display:inline">This study aims to provide a platform for exploring robotic navigation in line with evolutionary computation of sound control data. Real world devices, two mobile robots and an omnidirectional vision system are integrated to sonify trajectories of robots ...</div></span>
          <span id="toHide39" style="display:none;"><br /><div style="display:inline"><p>This study aims to provide a platform for exploring robotic navigation in line with evolutionary computation of sound control data. Real world devices, two mobile robots and an omnidirectional vision system are integrated to sonify trajectories of robots in real time.</p></div></span> <a id="expcoll39" href="JavaScript: expandcollapse('expcoll39',39)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514135&CFID=105752665&CFTOKEN=60368223">Preliminary observation of HRI in robot-assisted medical response</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100545387&CFID=105752665&CFTOKEN=60368223">Robin Murphy</a>, 
                        <a href="author_page.cfm?id=81336490517&CFID=105752665&CFTOKEN=60368223">Masashi Konyo</a>, 
                        <a href="author_page.cfm?id=81414620140&CFID=105752665&CFTOKEN=60368223">Pedro Davalas</a>, 
                        <a href="author_page.cfm?id=81414614946&CFID=105752665&CFTOKEN=60368223">Gabe Knezek</a>, 
                        <a href="author_page.cfm?id=81100300295&CFID=105752665&CFTOKEN=60368223">Satoshi Tadokoro</a>, 
                        <a href="author_page.cfm?id=81414618813&CFID=105752665&CFTOKEN=60368223">Kazuna Sawata</a>, 
                        <a href="author_page.cfm?id=81414619041&CFID=105752665&CFTOKEN=60368223">Maarten Van Zomeren</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 201-202</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514135" title="DOI">10.1145/1514095.1514135</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514135&ftid=255053&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1514135&ftid=255051&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1514135&ftid=255052&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow40" style="display:inline;"><br /><div style="display:inline">This video captures human-robot interaction which occurred during an evaluation of a novel, snake-like search and rescue robot assisting with victim management. Most of the observations confirmed previous findings- That a 2:1 H-R ratio ratio is appropriate, ...</div></span>
          <span id="toHide40" style="display:none;"><br /><div style="display:inline"><p>This video captures human-robot interaction which occurred during an evaluation of a novel, snake-like search and rescue robot assisting with victim management. Most of the observations confirmed previous findings- That a 2:1 H-R ratio ratio is appropriate, Team coordination is enhanced by shared visual perception, and Poor interfaces continue to lead to incomplete coverage. However, the victims responded to the robot in two surprising ways: grabbing the robot and being concerned about its appearance.</p></div></span> <a id="expcoll40" href="JavaScript: expandcollapse('expcoll40',40)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514136&CFID=105752665&CFTOKEN=60368223">Blog robot: a new style for accessing location-based contents</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414612351&CFID=105752665&CFTOKEN=60368223">Masato Noda</a>, 
                        <a href="author_page.cfm?id=81414599861&CFID=105752665&CFTOKEN=60368223">Toshihiro Osumi</a>, 
                        <a href="author_page.cfm?id=81414592254&CFID=105752665&CFTOKEN=60368223">Kenta Fujimoto</a>, 
                        <a href="author_page.cfm?id=81414619398&CFID=105752665&CFTOKEN=60368223">Yuki Kuwayama</a>, 
                        <a href="author_page.cfm?id=81414597701&CFID=105752665&CFTOKEN=60368223">Hirotaka Osawa</a>, 
                        <a href="author_page.cfm?id=81100282909&CFID=105752665&CFTOKEN=60368223">Michita Imai</a>, 
                        <a href="author_page.cfm?id=81100649131&CFID=105752665&CFTOKEN=60368223">Kazuhiko Shinozawa</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 203-204</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514136" title="DOI">10.1145/1514095.1514136</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514136&ftid=602995&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsAvi" title="Other Formats Avi" href="ft_gateway.cfm?id=1514136&ftid=645255&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/vid.gif" alt="Avi" class="fulltext_lnk" border="0" />Avi</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow41" style="display:inline;"><br /><div style="display:inline">We propose a portable robot named "Blog Robot" which presents blog contents by using verbal and non-verbal expression. Blog Robot is a robotized smart-phone which has a head and arms for making hand gestures, eye contact, and joint attention. The blog ...</div></span>
          <span id="toHide41" style="display:none;"><br /><div style="display:inline"><p>We propose a portable robot named "Blog Robot" which presents blog contents by using verbal and non-verbal expression. Blog Robot is a robotized smart-phone which has a head and arms for making hand gestures, eye contact, and joint attention. The blog is widely used to express personal views or to record daily occurrences. One of the information frequently posted on the blog is related to a certain place such as a tourist site or a shop. Meanwhile, people sit down in front of their PC and check blogs through the text and the image displayed on the Web browser. However, their style of checking the blogs is not good way for them to realize the authentic situations which blog writers let them know. The user carries Blog Robot like cellular phone and can browse blogs related to the location where user is. The browse method makes the user access the blog at the real scene related to the contents of the blog. Blog Robot gives her/him the content of the blog by reading it with synthesized speech. In particular, the nonverbal information generated by Blog Robot enhances the read information as if the blog writer is next her/him while telling her/him it. The browse method is expected to enable the user to obtain more realistic information than the Web browser on the PC.</p> <p>Moreover, it enables the user shares the information with the blog writer. In addition, since the browse through Blog Robot is performed at the location that the blog writer once visited, the blog writer has proper feedback from the user. It is difficult for the blog writer to obtain the same feedback from the user who sits in front of her/his PC because she/he is not there. We have also designed tags specific to generating the nonverbal expression of Blog Robot and the tags are embedded within the text in the blog. The tags can be used not only for Blog Robot but also for the PC. If the user checks the blog including the tags, they are displayed as icon on the Web browser.</p></div></span> <a id="expcoll41" href="JavaScript: expandcollapse('expcoll41',41)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514137&CFID=105752665&CFTOKEN=60368223">Human-robot physical interaction with dynamically stable mobile robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414620343&CFID=105752665&CFTOKEN=60368223">Umashankar Nagarajan</a>, 
                        <a href="author_page.cfm?id=81414598163&CFID=105752665&CFTOKEN=60368223">George Kantor</a>, 
                        <a href="author_page.cfm?id=81100381625&CFID=105752665&CFTOKEN=60368223">Ralph L. Hollis</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 205-206</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514137" title="DOI">10.1145/1514095.1514137</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514137&ftid=602996&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1514137&ftid=645256&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow42" style="display:inline;"><br /><div style="display:inline">Developed by Prof. Ralph Hollis in the Microdynamic Systems Laboratory at Carnegie Mellon University, Ballbot is a dynamically stable mobile robot moving on a single spherical wheel providing omni-directional motion. Unlike statically stable mobile robots, ...</div></span>
          <span id="toHide42" style="display:none;"><br /><div style="display:inline"><p>Developed by Prof. Ralph Hollis in the Microdynamic Systems Laboratory at Carnegie Mellon University, Ballbot is a dynamically stable mobile robot moving on a single spherical wheel providing omni-directional motion. Unlike statically stable mobile robots, dynamically stable mobile robots can be tall and skinny with high center of gravity and small base. The ball drive mechanism is a four motor inverse mouse-ball setup. An Inertial Measuring Unit (IMU) and encoders on the motors provide all information needed for full-state feedback. Ballbot has three legs that provide static stability when powered down and is capable of auto-transitioning from the statically stable state to the dynamically stable state and vice versa. It is also capable of yaw rotation about its vertical axis. An absolute encoder provides the relative angle between the IMU and the ball drive unit.</p> <p>We wish to demonstrate Human-Robot Physical Interaction with dynamically stable mobile robots using Ballbot as an example. The balancing controller on Ballbot is extremely robust to disturbances like shoves, kicks and collisions with furniture and wall. Due to its dynamic stability, Ballbot can be moved around with very little effort. Physically directing a heavy statically stable mobile robot can be a difficult task, whereas Ballbot can be moved around with just a single finger. Similarly, while moving, Ballbot can be stopped with very little effort. We have developed some basic behaviors that enable Ballbot to detect human intentions with the physical interaction it has using just the encoder and IMU data. For example, given a soft push, Ballbot tries to stick to its position on the floor, whereas, when given a hard push, it moves away from its current location and station-keeps at a different point on the floor. We also present our initial results in developing a Learn-Repeat behavior in Ballbot, where in during the Learn mode, the user drives Ballbot around and it remembers the path travelled, and during the Repeat mode, Ballbot attempts to repeat the path learnt. We are in the process of adding stereo cameras and laser range finders to the robot, which will help us explore and extend more areas of Human-Robot Interaction.</p></div></span> <a id="expcoll42" href="JavaScript: expandcollapse('expcoll42',42)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514138&CFID=105752665&CFTOKEN=60368223">Anthropomorphization method using attachable humanoid parts</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414597701&CFID=105752665&CFTOKEN=60368223">Hirotaka Osawa</a>, 
                        <a href="author_page.cfm?id=81314484611&CFID=105752665&CFTOKEN=60368223">Ren Ohmura</a>, 
                        <a href="author_page.cfm?id=81100282909&CFID=105752665&CFTOKEN=60368223">Michita Imai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 207-208</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514138" title="DOI">10.1145/1514095.1514138</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514138&ftid=962877&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1514138&ftid=962875&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1514138&ftid=962876&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow43" style="display:inline;"><br /><div style="display:inline">With this video, we propose a new human-robot interaction that anthropomorphizes a target common object and transform it into a communicative agent using attachable humanoid parts. The user perceives the target to have its own intentions and body image ...</div></span>
          <span id="toHide43" style="display:none;"><br /><div style="display:inline"><p>With this video, we propose a new human-robot interaction that anthropomorphizes a target common object and transform it into a communicative agent using attachable humanoid parts. The user perceives the target to have its own intentions and body image through the attached body parts. This video shows examples of anthropomorphization method as below.</p> <p>First, the video shows the setup process of our method in which a demonstrator attaches each part, such as eye-like parts, arm-like parts, and camera to a common electric oven. The oven becomes a communicative robot by attaching these parts.</p> <p>Second, the video explains three applications - self advertisement, self presentation, and interactive manual - that are achieved by anthropomorphized objects.</p> <p>In the self advertisement situation, the anthropomorphized oven attracts customers and explains its function by itself. This situation assumes that these devices are used in shops in future. In the self presentation situation, an anthropomorphized poster explains its contents by itself. There is no other explainer. This situation assumes that these devices are used on a poster presentation. In the interactive manual situation, an anthropomorphized printer explains its function interactively. This explanation is intuitive and understandable for children and elderly people. After third situation, this anthropomorphized printer is compared to an explanation from the humanoid robot Robovie throught gaze direction analysis. In the Robovie situation, the guidance fails because the robot distracts from the target itself. However in the anthropomorphized printer situation, users can concentrate on the interaction.</p> <p>Last, we use an anthropomorphized shredder using eye-like parts, arm-like parts, and skin sensor. The shredder explains its interactive manual like in the printer situation. However in this interaction, this shredder detects the user's touch and proceeds with the interaction instead of waiting to detect voice.</p></div></span> <a id="expcoll43" href="JavaScript: expandcollapse('expcoll43',43)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514139&CFID=105752665&CFTOKEN=60368223">Roball interacting with children</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414610058&CFID=105752665&CFTOKEN=60368223">Tamie Salter</a>, 
                        <a href="author_page.cfm?id=81100593688&CFID=105752665&CFTOKEN=60368223">Francois Michaud</a>, 
                        <a href="author_page.cfm?id=81100185093&CFID=105752665&CFTOKEN=60368223">Dominic Letourneau</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 209-210</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514139" title="DOI">10.1145/1514095.1514139</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514139&ftid=693167&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsFlv" title="Other Formats Flv" href="ft_gateway.cfm?id=1514139&ftid=693165&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/flashvideo_logo.gif" alt="Flv" class="fulltext_lnk" border="0" />Flv</a>&nbsp;&nbsp;<a name="OtherFormatsMov" title="Other Formats Mov" href="ft_gateway.cfm?id=1514139&ftid=693166&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/qtlogo.gif" alt="Mov" class="fulltext_lnk" border="0" />Mov</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow44" style="display:inline;"><br /><div style="display:inline">This video shows a light hearted view of a rolling autonomous robot named Roball. Roball is shown interacting with various children who age from 10 months old to teenagers at a high school. The clips show the different ways children interact with Roball ...</div></span>
          <span id="toHide44" style="display:none;"><br /><div style="display:inline"><p>This video shows a light hearted view of a rolling autonomous robot named Roball. Roball is shown interacting with various children who age from 10 months old to teenagers at a high school. The clips show the different ways children interact with Roball and also the different types of reactions the children can have to Roball. Each clip was taken from a trial that was conducted to investigate Child-Robot Interaction (CRI).</p> <p>First we see the different reactions of young children (tikes) aged between 2 to 4 years. We see them laughing, chasing Roball, dancing to music that Roball is playing and also running away from Roball. It is possible to see how active this age group can be in there interaction. Next we see a 10 month old toddler enjoying hitting Roball and then we see this child apparently showing some form of affection to Roball. Then after watching Roball bang into a door we see the toddler copy the behaviour by also banging into the door. Proceeding is the very different style of interaction from teenagers. Despite Roball gaining a lot of interest the actual physical contact or interaction is much lower. We see the robot being purposefully kicked and also a teenager pretending to kick Roball in a show of bravado. Finally we see the dangers of being a rolling robot when in the presence of a group of teenagers, as Roball through random wandering rolls into the path of a group of teenagers walking at high speeds.</p> <p>Although this is a lighthearted view there are still many important CRI factors that can be gained from watching the footage.</p></div></span> <a id="expcoll44" href="JavaScript: expandcollapse('expcoll44',44)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514140&CFID=105752665&CFTOKEN=60368223">The SantaBot experiment: a pilot study of human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414609902&CFID=105752665&CFTOKEN=60368223">S&#248;ren Tranberg Hansen</a>, 
                        <a href="author_page.cfm?id=81414619060&CFID=105752665&CFTOKEN=60368223">Mikael Svenstrup</a>, 
                        <a href="author_page.cfm?id=81100570681&CFID=105752665&CFTOKEN=60368223">Hans J&#248;rgen Andersen</a>, 
                        <a href="author_page.cfm?id=81414602620&CFID=105752665&CFTOKEN=60368223">Thomas Bak</a>, 
                        <a href="author_page.cfm?id=81414607864&CFID=105752665&CFTOKEN=60368223">Ole B. Jensen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 211-212</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514140" title="DOI">10.1145/1514095.1514140</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514140&ftid=602997&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsMp4" title="Other Formats Mp4" href="ft_gateway.cfm?id=1514140&ftid=645260&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/mp4.gif" alt="Mp4" class="fulltext_lnk" border="0" />Mp4</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow45" style="display:inline;"><br /><div style="display:inline">The video shows how an autonomous mobile robot dressed as Santa Claus is interacting with people in a shopping mall. The underlying hypothesis is that it is possible to create interesting new living spaces and induce value in terms of experiences, information ...</div></span>
          <span id="toHide45" style="display:none;"><br /><div style="display:inline"><p>The video shows how an autonomous mobile robot dressed as Santa Claus is interacting with people in a shopping mall. The underlying hypothesis is that it is possible to create interesting new living spaces and induce value in terms of experiences, information or economics, by putting socially interactive mobile agents into public urban transit area. To investigate the hypothesis, an experiment was carried out using a robot capable of navigating autonomously based on the input of an onboard laser scanner. The robot would detect and follow random people, who afterwards were asked to fill out a questionnaire for quantitative analysis of the experiment. The presented video is the corresponding video documentation of the experiment used in the evaluation. The results showed that people were generally positive towards having mobile robots in this type of environment where shopping is combined with transit. However, it also showed harder than expected to start interaction with commuters due to their determination and speed towards their goal. Further it was demonstrated that it was possible to track and follow people, who were not beforehand informed on the experiment. The evaluation indicated, that the distance to initiate interaction was shorter than initially expected, but complies with the distance for normal human to human interaction.</p></div></span> <a id="expcoll45" href="JavaScript: expandcollapse('expcoll45',45)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514141&CFID=105752665&CFTOKEN=60368223">Emotion induction during human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414616880&CFID=105752665&CFTOKEN=60368223">Cornelia Wendt</a>, 
                        <a href="author_page.cfm?id=81100061885&CFID=105752665&CFTOKEN=60368223">Michael Popp</a>, 
                        <a href="author_page.cfm?id=81414620701&CFID=105752665&CFTOKEN=60368223">Berthold Faerber</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 213-214</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514141" title="DOI">10.1145/1514095.1514141</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514141&ftid=602998&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsAvi" title="Other Formats Avi" href="ft_gateway.cfm?id=1514141&ftid=645261&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/vid.gif" alt="Avi" class="fulltext_lnk" border="0" />Avi</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow46" style="display:inline;"><br /><div style="display:inline">The aim of the presented study was to measure physiological correlates of emotions that are of particular interest in the field of human-robot interaction (HRI). Therefore, we did not focus on self-induced basic emotions but rather evoked states that ...</div></span>
          <span id="toHide46" style="display:none;"><br /><div style="display:inline"><p>The aim of the presented study was to measure physiological correlates of emotions that are of particular interest in the field of human-robot interaction (HRI). Therefore, we did not focus on self-induced basic emotions but rather evoked states that might occur naturally in this context. Our video shows how such states (namely stress, boredom, surprise, and perplexity) were elicited during a joint construction task with an industrial robot (see figure 1). Participants were asked to build different LEGO objects, while the robot arm was passing the bricks with predetermined velocity. States of stress and boredom were generated by varying the handover interval from 3 seconds (stress) to 5 seconds (normal working condition) up to 35 seconds (boredom). Surprise was induced by passing an unexpected component. At the end of the experiment, we additionally wanted to know how people react if the robot seems to tease them by repeatedly changing the handover position.</p> <p>This experiment was realized by the support of researchers from the MMK and the IWB of the Technical University Munich who provided the technical facilities and know-how. The underlying project is supported within the DFG excellence initiative research cluster Cognition for Technical Systems - CoTeSys, see also www.cotesys.org.</p></div></span> <a id="expcoll46" href="JavaScript: expandcollapse('expcoll46',46)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514142&CFID=105752665&CFTOKEN=60368223">Human-robot interaction for 3D telemanipulated fracture reduction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414621082&CFID=105752665&CFTOKEN=60368223">Ralf Westphal</a>, 
                        <a href="author_page.cfm?id=81100148143&CFID=105752665&CFTOKEN=60368223">Simon Winkelbach</a>, 
                        <a href="author_page.cfm?id=81414621343&CFID=105752665&CFTOKEN=60368223">Thomas Goesling</a>, 
                        <a href="author_page.cfm?id=81414618979&CFID=105752665&CFTOKEN=60368223">Markus Oszwald</a>, 
                        <a href="author_page.cfm?id=81414619380&CFID=105752665&CFTOKEN=60368223">Tobias Huefner</a>, 
                        <a href="author_page.cfm?id=81371594096&CFID=105752665&CFTOKEN=60368223">Christian Krettek</a>, 
                        <a href="author_page.cfm?id=81100420384&CFID=105752665&CFTOKEN=60368223">Friedrich M. Wahl</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 215-216</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514142" title="DOI">10.1145/1514095.1514142</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514142&ftid=602999&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
           
	          Other formats: 
            <a name="OtherFormatsAvi" title="Other Formats Avi" href="ft_gateway.cfm?id=1514142&ftid=645262&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/vid.gif" alt="Avi" class="fulltext_lnk" border="0" />Avi</a>
          </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow47" style="display:inline;"><br /><div style="display:inline">Today, femoral shaft fractures are usually stabilized by means of intramedullary nails. This video presents the development of a telemanipulator system, which, by supporting the fracture reduction process, aims at achieving reliable operation results ...</div></span>
          <span id="toHide47" style="display:none;"><br /><div style="display:inline"><p>Today, femoral shaft fractures are usually stabilized by means of intramedullary nails. This video presents the development of a telemanipulator system, which, by supporting the fracture reduction process, aims at achieving reliable operation results with high reduction accuracies. First, we present a system using 2D X-ray images as base information for the surgeon to guide the reduction. We show the advantages but also the limitations of this approach, which finally led to the development of a telemanipulator system that is based on 3D imaging data instead.</p></div></span> <a id="expcoll47" href="JavaScript: expandcollapse('expcoll47',47)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>HRI late-breaking abstracts</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514144&CFID=105752665&CFTOKEN=60368223">Can users react toward an on-screen agent as if they are reacting toward a robotic agent?</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81328489326&CFID=105752665&CFTOKEN=60368223">Takanori Komatsu</a>, 
                        <a href="author_page.cfm?id=81414620436&CFID=105752665&CFTOKEN=60368223">Nozomi Kuki</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 217-218</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514144" title="DOI">10.1145/1514095.1514144</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514144&ftid=603000&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow49" style="display:inline;"><br /><div style="display:inline">Our former study showed that users tended not to react to an on-screen agent's invitation of a Shiritori game (a last and first game), but did to a robotic agent. Thus, the purpose of this study was to investigate the contributing factors that could ...</div></span>
          <span id="toHide49" style="display:none;"><br /><div style="display:inline"><p>Our former study showed that users tended not to react to an on-screen agent's invitation of a Shiritori game (a last and first game), but did to a robotic agent. Thus, the purpose of this study was to investigate the contributing factors that could make the users react toward an on-screen agent as if they were reacting toward a robotic agent. The results showed that the participants who first accepted the invitation of a robotic agent that was assigned an attractive character reacted toward the on-screen agents as if they were reacting to the robotic one.</p></div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514145&CFID=105752665&CFTOKEN=60368223">Individualization of voxel-based hand model</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414619154&CFID=105752665&CFTOKEN=60368223">Albert J. Causo</a>, 
                        <a href="author_page.cfm?id=81414601140&CFID=105752665&CFTOKEN=60368223">Mai Matsuo</a>, 
                        <a href="author_page.cfm?id=81100364079&CFID=105752665&CFTOKEN=60368223">Etsuko Ueda</a>, 
                        <a href="author_page.cfm?id=81100316393&CFID=105752665&CFTOKEN=60368223">Yoshio Matsumoto</a>, 
                        <a href="author_page.cfm?id=81100012453&CFID=105752665&CFTOKEN=60368223">Tsukasa Ogasawara</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 219-220</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514145" title="DOI">10.1145/1514095.1514145</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514145&ftid=603001&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow50" style="display:inline;"><br /><div style="display:inline">Improvements in hand pose estimation, made possible by refining the model matching step, is necessary in creating a more natural human-robot interface. Individualizing the 3D hand model of the user can result to a better hand pose estimation. This paper ...</div></span>
          <span id="toHide50" style="display:none;"><br /><div style="display:inline"><p>Improvements in hand pose estimation, made possible by refining the model matching step, is necessary in creating a more natural human-robot interface. Individualizing the 3D hand model of the user can result to a better hand pose estimation. This paper presents a way to accomplish the individualization by estimating the length of the finger links (bones), which is unique for every user. The 3D model of the hand is made up of voxel data derived from silhouette images obtained by multiple cameras and the finger link is estimated by searching a set of models generated from the calibration motion of the fingers. Initial pose estimation result using the model shows the feasibility of the system.</p></div></span> <a id="expcoll50" href="JavaScript: expandcollapse('expcoll50',50)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514146&CFID=105752665&CFTOKEN=60368223">Robots with projectors: an alternative to anthropomorphic HRI</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414595981&CFID=105752665&CFTOKEN=60368223">Jongkyeong Park</a>, 
                        <a href="author_page.cfm?id=81452598848&CFID=105752665&CFTOKEN=60368223">Gerard Jounghyun Kim</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 221-222</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514146" title="DOI">10.1145/1514095.1514146</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514146&ftid=603002&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow51" style="display:inline;"><br /><div style="display:inline">Current forms of Human Robot Interaction (HRI) pursue mostly anthropomorphism and direct interaction. That is, the interaction paradigm is based on imitating how "people" interact with one another (e.g. using spoken language, gestures, facial expression, ...</div></span>
          <span id="toHide51" style="display:none;"><br /><div style="display:inline"><p>Current forms of Human Robot Interaction (HRI) pursue mostly anthropomorphism and direct interaction. That is, the interaction paradigm is based on imitating how "people" interact with one another (e.g. using spoken language, gestures, facial expression, etc.). However, "direct" interaction/contact with the "robot," often causes significant inconvenience and usability problems. In this paper, we present an alternative to the anthropomorphic interface using a projected display and indirect, yet already familiar GUI based interaction. That is, the projector (on the moving robot) projects information on the nearby surface and provides a relatively large area through which indirect GUI based interaction can occur. As an instance of such an HRI paradigm, we present a moving robot kiosk that projects displays around itself and serve and interact with multiple people at once. We report our on-going development efforts and a pilot experimental study that compares it to the typical touch screen based direct HRI.</p></div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514147&CFID=105752665&CFTOKEN=60368223">comforTABLE: a robotic environment for aging in place</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414598364&CFID=105752665&CFTOKEN=60368223">Keith Evan Green</a>, 
                        <a href="author_page.cfm?id=81414620158&CFID=105752665&CFTOKEN=60368223">Ian D. Wakjer</a>, 
                        <a href="author_page.cfm?id=81414613101&CFID=105752665&CFTOKEN=60368223">Johnell O. Brooks</a>, 
                        <a href="author_page.cfm?id=81414619983&CFID=105752665&CFTOKEN=60368223">Tarek Mohktar</a>, 
                        <a href="author_page.cfm?id=81414621427&CFID=105752665&CFTOKEN=60368223">Linnea Smolentzov</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 223-224</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514147" title="DOI">10.1145/1514095.1514147</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514147&ftid=603003&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow52" style="display:inline;"><br /><div style="display:inline">While high-technology has become pervasive in hospitals, domestic environments remain essentially low-tech and conventional, despite the care needs of an aging population wishing to age in place. In response, an interdisciplinary team - robotics engineer, ...</div></span>
          <span id="toHide52" style="display:none;"><br /><div style="display:inline"><p>While high-technology has become pervasive in hospitals, domestic environments remain essentially low-tech and conventional, despite the care needs of an aging population wishing to age in place. In response, an interdisciplinary team - robotics engineer, architect, human factors psychologist and gerontologist - are designing, constructing, field testing, and evaluating comforTABLE, an intelligent environment for aging in place. comforTABLE is designed to increase the quality of life of both healthy individuals as well as persons with impaired mobility by intelligently supporting the physical organization of their immediate environment. While comforTABLE features intelligent behavior and robotic elements, comforTABLE aims to help people do things for themselves. This paper introduces the motivations for comforTABLE, presents its three intelligent, networked components and describes scenarios of how the system might operate in domestic situations.</p></div></span> <a id="expcoll52" href="JavaScript: expandcollapse('expcoll52',52)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514148&CFID=105752665&CFTOKEN=60368223">In-home telehealth clinical interaction using a robot</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414620899&CFID=105752665&CFTOKEN=60368223">Simon Bri&#232;re</a>, 
                        <a href="author_page.cfm?id=81340487870&CFID=105752665&CFTOKEN=60368223">Patrick Boissy</a>, 
                        <a href="author_page.cfm?id=81100593688&CFID=105752665&CFTOKEN=60368223">Francois Michaud</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 225-226</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514148" title="DOI">10.1145/1514095.1514148</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514148&ftid=603004&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow53" style="display:inline;"><br /><div style="display:inline">Providing healthcare in remote locations can prove to be costly. Using a static videoconference system in the patient's home has its limitations. A remotely operated mobile robot platform could provide a better interaction with the patient located at ...</div></span>
          <span id="toHide53" style="display:none;"><br /><div style="display:inline"><p>Providing healthcare in remote locations can prove to be costly. Using a static videoconference system in the patient's home has its limitations. A remotely operated mobile robot platform could provide a better interaction with the patient located at home. This paper presents Telerobot, a teleoperated mobile robotic platform equipped with videoconferencing capabilities. Developed by a team of roboticists and clinical experts, the system is designed specifically for the provision of in-home telerehabilitation services. A usability study was done in order to qualify the robot user control scheme and the clinician-patient interaction.</p></div></span> <a id="expcoll53" href="JavaScript: expandcollapse('expcoll53',53)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514149&CFID=105752665&CFTOKEN=60368223">A leader-follower turn-taking model incorporating beat detection in musical human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100638548&CFID=105752665&CFTOKEN=60368223">Gil Weinberg</a>, 
                        <a href="author_page.cfm?id=81414621085&CFID=105752665&CFTOKEN=60368223">Brian Blosser</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 227-228</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514149" title="DOI">10.1145/1514095.1514149</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514149&ftid=603005&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow54" style="display:inline;"><br /><div style="display:inline">This paper describes the implementation of a leader-follower model in a musical HRI based on beat detection analysis and a novel turn taking scheme. The project enables Haile, a robotic percussionist, to fluidly interact with humans in the context of ...</div></span>
          <span id="toHide54" style="display:none;"><br /><div style="display:inline"><p>This paper describes the implementation of a leader-follower model in a musical HRI based on beat detection analysis and a novel turn taking scheme. The project enables Haile, a robotic percussionist, to fluidly interact with humans in the context of an improvisatory jam session. The long-term goal of this work is to facilitate dynamic interactions between humans and machines that will lead to novel and inspiring musical outcomes.</p></div></span> <a id="expcoll54" href="JavaScript: expandcollapse('expcoll54',54)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514150&CFID=105752665&CFTOKEN=60368223">Planning as an architectural control mechanism</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414617742&CFID=105752665&CFTOKEN=60368223">Nick Hawes</a>, 
                        <a href="author_page.cfm?id=81406599589&CFID=105752665&CFTOKEN=60368223">Michael Brenner</a>, 
                        <a href="author_page.cfm?id=81414619396&CFID=105752665&CFTOKEN=60368223">Kristoffer Sj&#246;&#246;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 229-230</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514150" title="DOI">10.1145/1514095.1514150</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514150&ftid=603006&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow55" style="display:inline;"><br /><div style="display:inline">We describe recent work on PECAS, an architecture for intelligent robotics that supports multi-modal interaction.</div></span>
          <span id="toHide55" style="display:none;"><br /><div style="display:inline"><p>We describe recent work on PECAS, an architecture for intelligent robotics that supports multi-modal interaction.</p></div></span> <a id="expcoll55" href="JavaScript: expandcollapse('expcoll55',55)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514151&CFID=105752665&CFTOKEN=60368223">Influences of concerns toward emotional interaction into social acceptability of robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81336491870&CFID=105752665&CFTOKEN=60368223">Tatsuya Nomura</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752665&CFTOKEN=60368223">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81336493182&CFID=105752665&CFTOKEN=60368223">Tomohiro Suzuki</a>, 
                        <a href="author_page.cfm?id=81414594070&CFID=105752665&CFTOKEN=60368223">Sachie Yamada</a>, 
                        <a href="author_page.cfm?id=81414594230&CFID=105752665&CFTOKEN=60368223">Kensuke Kato</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 231-232</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514151" title="DOI">10.1145/1514095.1514151</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514151&ftid=603007&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514152&CFID=105752665&CFTOKEN=60368223">Interactive jamming with Shimon: a social robotic musician</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100638548&CFID=105752665&CFTOKEN=60368223">Gil Weinberg</a>, 
                        <a href="author_page.cfm?id=81414615274&CFID=105752665&CFTOKEN=60368223">Aparna Raman</a>, 
                        <a href="author_page.cfm?id=81414619250&CFID=105752665&CFTOKEN=60368223">Trishul Mallikarjuna</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 233-234</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514152" title="DOI">10.1145/1514095.1514152</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514152&ftid=603008&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow57" style="display:inline;"><br /><div style="display:inline">The paper introduces Shimon: a socially interactive and improvisational robotic marimba player. It presents the interaction schemes used by Shimon in the realization of an interactive musical jam session among human and robotic musicians.</div></span>
          <span id="toHide57" style="display:none;"><br /><div style="display:inline"><p>The paper introduces Shimon: a socially interactive and improvisational robotic marimba player. It presents the interaction schemes used by Shimon in the realization of an interactive musical jam session among human and robotic musicians.</p></div></span> <a id="expcoll57" href="JavaScript: expandcollapse('expcoll57',57)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514153&CFID=105752665&CFTOKEN=60368223">Human-robot interaction observations from a proto-study using SUAVs for structural inspection</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414619316&CFID=105752665&CFTOKEN=60368223">Maarten van Zomeren</a>, 
                        <a href="author_page.cfm?id=81414619501&CFID=105752665&CFTOKEN=60368223">Joshua M. Peschel</a>, 
                        <a href="author_page.cfm?id=81414601870&CFID=105752665&CFTOKEN=60368223">Timothy Mann</a>, 
                        <a href="author_page.cfm?id=81414614946&CFID=105752665&CFTOKEN=60368223">Gabe Knezek</a>, 
                        <a href="author_page.cfm?id=81414620725&CFID=105752665&CFTOKEN=60368223">James Doebbler</a>, 
                        <a href="author_page.cfm?id=81414599585&CFID=105752665&CFTOKEN=60368223">Jeremy Davis</a>, 
                        <a href="author_page.cfm?id=81309486982&CFID=105752665&CFTOKEN=60368223">Tracy A. Hammond</a>, 
                        <a href="author_page.cfm?id=81414610958&CFID=105752665&CFTOKEN=60368223">Augustinus H.J. Oomes</a>, 
                        <a href="author_page.cfm?id=81100545387&CFID=105752665&CFTOKEN=60368223">Robin R. Murphy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 235-236</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514153" title="DOI">10.1145/1514095.1514153</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514153&ftid=603009&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514154&CFID=105752665&CFTOKEN=60368223">What are the benefits of adaptation when applied in the domain of child-robot interaction?</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414610058&CFID=105752665&CFTOKEN=60368223">Tamie Salter</a>, 
                        <a href="author_page.cfm?id=81100593688&CFID=105752665&CFTOKEN=60368223">Francois Michaud</a>, 
                        <a href="author_page.cfm?id=81100185093&CFID=105752665&CFTOKEN=60368223">Dominic L&#233;tourneau</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 237-238</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514154" title="DOI">10.1145/1514095.1514154</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514154&ftid=603010&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow59" style="display:inline;"><br /><div style="display:inline">There is great potential for robotic devices when being applied with children. They can be used from play to assistive applications. We develop robotic devices for a diverse range of children that differ in age, gender and ability, which includes children ...</div></span>
          <span id="toHide59" style="display:none;"><br /><div style="display:inline"><p>There is great potential for robotic devices when being applied with children. They can be used from play to assistive applications. We develop robotic devices for a diverse range of children that differ in age, gender and ability, which includes children that are diagnosed with cognitive difficulties such as autism. Every child is an individual and they vary in their personalities and styles of interaction. Therefore, being able to adjust the robot's behaviour to the type of interaction it is receiving was believed to be essential. In this abstract we examine a series of trials which investigated how adaptation (through changes in motion and sound) on a fully autonomous rolling robot could help gain and sustain the interest of five different children. We discovered surprising benefits to having adaptation on-board Roball.</p></div></span> <a id="expcoll59" href="JavaScript: expandcollapse('expcoll59',59)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514155&CFID=105752665&CFTOKEN=60368223">Making sense of agentic objects and teleoperation: in-the-moment and reflective perspectives</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100499212&CFID=105752665&CFTOKEN=60368223">Leila Takayama</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 239-240</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514155" title="DOI">10.1145/1514095.1514155</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514155&ftid=603011&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow60" style="display:inline;"><br /><div style="display:inline">Agentic objects are those entities that are perceived and responded to in-the-moment as if they were agentic despite the likely reflective perception that they are not agentic at all. They include autonomous robots, but also simpler systems like automatic ...</div></span>
          <span id="toHide60" style="display:none;"><br /><div style="display:inline"><p>Agentic objects are those entities that are perceived and responded to in-the-moment as if they were agentic despite the likely reflective perception that they are not agentic at all. They include autonomous robots, but also simpler systems like automatic doors, trashcans, and staplers--anything that seems to possess agency. It is well known that low-level spatiotemporal information elicits in-the-moment responses that are interpreted as perceiving mentalism [8, 17], but people reflectively believe that there is a distinction between human and non-human agents. How are we to make sense of these agentic objects?</p></div></span> <a id="expcoll60" href="JavaScript: expandcollapse('expcoll60',60)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514156&CFID=105752665&CFTOKEN=60368223">Cognitive architecture for perception-reaction intelligent computer agents (CAPRICA)</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414608981&CFID=105752665&CFTOKEN=60368223">Dustin B. Chertoff</a>, 
                        <a href="author_page.cfm?id=81414619284&CFID=105752665&CFTOKEN=60368223">Sandy Vanderbleek</a>, 
                        <a href="author_page.cfm?id=81332498737&CFID=105752665&CFTOKEN=60368223">Stephen M. Fiore</a>, 
                        <a href="author_page.cfm?id=81414612975&CFID=105752665&CFTOKEN=60368223">Shaun Gallagher</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 241-242</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514156" title="DOI">10.1145/1514095.1514156</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514156&ftid=603012&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow61" style="display:inline;"><br /><div style="display:inline">In this paper, we introduce a cognitive agent architecture that can be used in the study of Human-Robot Interaction. The Cognitive Architecture for Perception-Reaction Intelligent Computer Agents (CAPRICA) is an extensible agent library built around ...</div></span>
          <span id="toHide61" style="display:none;"><br /><div style="display:inline"><p>In this paper, we introduce a cognitive agent architecture that can be used in the study of Human-Robot Interaction. The Cognitive Architecture for Perception-Reaction Intelligent Computer Agents (CAPRICA) is an extensible agent library built around the ideas of theory of mind, episodic memory, and embodied cognition. Existing agent research in each of these areas was used to formulate design requirements. We provide an overview of the library's design and discuss future work in progress.</p></div></span> <a id="expcoll61" href="JavaScript: expandcollapse('expcoll61',61)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514157&CFID=105752665&CFTOKEN=60368223">System design of group communication activator: an entertainment task for elderly care</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414593201&CFID=105752665&CFTOKEN=60368223">Yoichi Matsuyama</a>, 
                        <a href="author_page.cfm?id=81414619066&CFID=105752665&CFTOKEN=60368223">Hikaru Taniyama</a>, 
                        <a href="author_page.cfm?id=81333488400&CFID=105752665&CFTOKEN=60368223">Shinya Fujie</a>, 
                        <a href="author_page.cfm?id=81100604078&CFID=105752665&CFTOKEN=60368223">Tetsunori Kobayashi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 243-244</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514157" title="DOI">10.1145/1514095.1514157</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514157&ftid=603013&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow62" style="display:inline;"><br /><div style="display:inline">Our community is facing serious Aging Society especially in Japan. We have investigated in one of daycare centers which are facilities for elderly care. As the result, we realized that communication is needed for its own sake in these facilities and ...</div></span>
          <span id="toHide62" style="display:none;"><br /><div style="display:inline"><p>Our community is facing serious Aging Society especially in Japan.</p> <p>We have investigated in one of daycare centers which are facilities for elderly care. As the result, we realized that communication is needed for its own sake in these facilities and active communication can cure even depression and dementia. Therefore we propose to cope with these problems using a robot as a communication activator in order to improve group communication. We define group communication as one of types of communication which is formed by several persons. This time, we focus on a recreation game named "Nandoku". Nandoku is a quiz which can be described as group communication with a master of ceremony (MC).</p> <p>The system always selects its behavior and target (a participant in the game) to maximize "communication activeness." Communication activeness is defined as amount of several panelists'(ordinary three: A, B, C) participation, which are calculated with panelists' face direction using camera information.</p> <p>For instance, if participant A is not fully participating by not making eye contact, the system is expected to select one of the behaviors such as "Can you answer, Mr.A?" to encourage A to participate in the game.</p> <p>We experimented with the system in a daycare center. As the result, obvious increase in participation was observed. That offers evidence that the robot can serve a practical role in improving the group communication as a communication activator especially for entertainment use.</p></div></span> <a id="expcoll62" href="JavaScript: expandcollapse('expcoll62',62)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514158&CFID=105752665&CFTOKEN=60368223">How anthropomorphism affects empathy toward robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81325489801&CFID=105752665&CFTOKEN=60368223">Laurel D. Riek</a>, 
                        <a href="author_page.cfm?id=81414621180&CFID=105752665&CFTOKEN=60368223">Tal-Chen Rabinowitch</a>, 
                        <a href="author_page.cfm?id=81414619638&CFID=105752665&CFTOKEN=60368223">Bhismadev Chakrabarti</a>, 
                        <a href="author_page.cfm?id=81350590377&CFID=105752665&CFTOKEN=60368223">Peter Robinson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 245-246</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514158" title="DOI">10.1145/1514095.1514158</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514158&ftid=603014&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow63" style="display:inline;"><br /><div style="display:inline">A long-standing question within the robotics community is about the degree of human-likeness robots ought to have when interacting with humans. We explore an unexamined aspect of this problem: how people empathize with robots along the anthropomorphic ...</div></span>
          <span id="toHide63" style="display:none;"><br /><div style="display:inline"><p>A long-standing question within the robotics community is about the degree of human-likeness robots ought to have when interacting with humans. We explore an unexamined aspect of this problem: how people empathize with robots along the anthropomorphic spectrum. We conducted an experiment that measured how people empathized with robots shown to be experiencing mistreatment by humans. Our results indicate that people empathize more strongly with more human-looking robots and less with mechanical-looking robots.</p></div></span> <a id="expcoll63" href="JavaScript: expandcollapse('expcoll63',63)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514159&CFID=105752665&CFTOKEN=60368223">Responsiveness to robots: effects of ingroup orientation & communication style on hri in china</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414599200&CFID=105752665&CFTOKEN=60368223">Lin Wang</a>, 
                        <a href="author_page.cfm?id=81435602249&CFID=105752665&CFTOKEN=60368223">Pei-Luen Patrick Rau</a>, 
                        <a href="author_page.cfm?id=81100133286&CFID=105752665&CFTOKEN=60368223">Vanessa Evers</a>, 
                        <a href="author_page.cfm?id=81414594748&CFID=105752665&CFTOKEN=60368223">Benjamin Robinson</a>, 
                        <a href="author_page.cfm?id=81100572021&CFID=105752665&CFTOKEN=60368223">Pamela Hinds</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 247-248</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514159" title="DOI">10.1145/1514095.1514159</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514159&ftid=603015&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow64" style="display:inline;"><br /><div style="display:inline">This study investigates the effects of group orientation and communication style on Chinese subjects' responsiveness to robots. A 2x2 experiment was conducted with group orientation (ingroup vs. outgroup) and communication style (implicit vs. explicit) ...</div></span>
          <span id="toHide64" style="display:none;"><br /><div style="display:inline"><p>This study investigates the effects of group orientation and communication style on Chinese subjects' responsiveness to robots. A 2x2 experiment was conducted with group orientation (ingroup vs. outgroup) and communication style (implicit vs. explicit) as dimensions. The results confirm expectations that subjects with a Chinese cultural background are more responsive to robots that use implicit communication styles. We also found some evidence that subjects were more responsive when they thought of the robot as an ingroup member. These findings inform the design of robots for use in China and countries with similar cultural values and reinforce the importance of culturally sensitive design in HRI.</p></div></span> <a id="expcoll64" href="JavaScript: expandcollapse('expcoll64',64)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514160&CFID=105752665&CFTOKEN=60368223">Tele-operators' judgments of their ability to drive through apertures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100555272&CFID=105752665&CFTOKEN=60368223">Keith S. Jones</a>, 
                        <a href="author_page.cfm?id=81414619928&CFID=105752665&CFTOKEN=60368223">Elizabeth A. Schmidlin</a>, 
                        <a href="author_page.cfm?id=81100449146&CFID=105752665&CFTOKEN=60368223">Brian R. Johnson</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 249-250</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514160" title="DOI">10.1145/1514095.1514160</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514160&ftid=603016&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow65" style="display:inline;"><br /><div style="display:inline">It has been suggested that operators should base decisions to enter apertures on their ability to control the robot, rather than its static dimensions. Doing so, however, assumes that operators know whether they can drive a robot through the aperture. ...</div></span>
          <span id="toHide65" style="display:none;"><br /><div style="display:inline"><p>It has been suggested that operators should base decisions to enter apertures on their ability to control the robot, rather than its static dimensions. Doing so, however, assumes that operators know whether they can drive a robot through the aperture. The present study tested that assumption. Results indicated that judgments about control of the robot were not accurate. In contrast, judgments of static dimensions were accurate. Thus, operators will require support if they must base decisions to enter apertures on their ability to control that robot.</p></div></span> <a id="expcoll65" href="JavaScript: expandcollapse('expcoll65',65)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514161&CFID=105752665&CFTOKEN=60368223">Distinguishing defaults and second-line conceptualization in reasoning about humans, robots, and computers</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350571966&CFID=105752665&CFTOKEN=60368223">Daniel T. Levin</a>, 
                        <a href="author_page.cfm?id=81350578238&CFID=105752665&CFTOKEN=60368223">Megan M. Saylor</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 251-252</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514161" title="DOI">10.1145/1514095.1514161</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514161&ftid=603017&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow66" style="display:inline;"><br /><div style="display:inline">In previous research, we demonstrated that people distinguish between human and nonhuman intelligence by assuming that humans are more likely to engage in intentional goal-directed behaviors than computers or robots. In the present study, we tested whether ...</div></span>
          <span id="toHide66" style="display:none;"><br /><div style="display:inline"><p>In previous research, we demonstrated that people distinguish between human and nonhuman intelligence by assuming that humans are more likely to engage in intentional goal-directed behaviors than computers or robots. In the present study, we tested whether participants who respond relatively quickly when making predictions about an entity are more or less likely to distinguish between human and nonhuman agents on the dimension of intentionality. Participants responded to a series of five scenarios in which they chose between intentional and nonintentional actions for a human, a computer, and a robot. Results indicated that participants who chose quickly were more likely to distinguish human and nonhuman agents than participants who deliberated more over their responses. We suggest that the short-RT participants were employing a first-line default to distinguish between human intentionality and more mechanical nonhuman behavior, and that the slower, more deliberative participants engaged in deeper second-line reasoning that led them to change their predictions for the behavior of a human agent.</p></div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514162&CFID=105752665&CFTOKEN=60368223">Probo: a testbed for human robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414619739&CFID=105752665&CFTOKEN=60368223">Kristof Goris</a>, 
                        <a href="author_page.cfm?id=81414620328&CFID=105752665&CFTOKEN=60368223">Jelle Saldien</a>, 
                        <a href="author_page.cfm?id=81100540516&CFID=105752665&CFTOKEN=60368223">Dirk Lefeber</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 253-254</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514162" title="DOI">10.1145/1514095.1514162</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514162&ftid=603018&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow67" style="display:inline;"><br /><div style="display:inline">The concept of the huggable robot Probo is a result of the desire to improve the living conditions of children in hospital environment. These children need distraction and lots of information. In this paper the concept of a new social robot is presented. ...</div></span>
          <span id="toHide67" style="display:none;"><br /><div style="display:inline"><p>The concept of the huggable robot Probo is a result of the desire to improve the living conditions of children in hospital environment. These children need distraction and lots of information. In this paper the concept of a new social robot is presented. This robot can be used in hospitals, as a tele-interface for entertainment, communication and medical assistance.</p> <p>Besides the prototype of the real robot, a virtual model has been developed. With user friendly software these models can be used as an interface between an operator and a child. That way, Probo becomes a platform for experiments concerning human robot interaction with great opportunities in different disciplines.</p></div></span> <a id="expcoll67" href="JavaScript: expandcollapse('expcoll67',67)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514163&CFID=105752665&CFTOKEN=60368223">r-Learning services for elementary school students with a teaching assistant robot</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414594930&CFID=105752665&CFTOKEN=60368223">Jeonghye Han</a>, 
                        <a href="author_page.cfm?id=81414593063&CFID=105752665&CFTOKEN=60368223">Dongho Kim</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 255-256</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514163" title="DOI">10.1145/1514095.1514163</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514163&ftid=603019&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow68" style="display:inline;"><br /><div style="display:inline">The r-Learning paradigm with educational robots is emerging as a part of e-Learning, which means using technology for learning. This study on using robots as a teaching assistant robot opened the possibility of r-Learning for English in classroom. We ...</div></span>
          <span id="toHide68" style="display:none;"><br /><div style="display:inline"><p>The r-Learning paradigm with educational robots is emerging as a part of e-Learning, which means using technology for learning. This study on using robots as a teaching assistant robot opened the possibility of r-Learning for English in classroom. We found that children like robot services for personal relationship in class and teachers prefer them related to their convenience to manage the lesson. Related robot services such as praising and cheering up or calling the roll are the effective way for motivating children to learn, enhancing the relationship between TIRO and children. We are going on conducting further field trials for new scenarios and services that motivate children and make them concentrate on class with teachers, pre-teachers, children, parents, robotic researchers, social scientists, etc.</p></div></span> <a id="expcoll68" href="JavaScript: expandcollapse('expcoll68',68)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514164&CFID=105752665&CFTOKEN=60368223">Autonomous vs. tele-operated: how people perceive human-robot collaboration with hrp-2</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81381602151&CFID=105752665&CFTOKEN=60368223">Astrid Weiss</a>, 
                        <a href="author_page.cfm?id=81414618872&CFID=105752665&CFTOKEN=60368223">Daniela Wurhofer</a>, 
                        <a href="author_page.cfm?id=81319495488&CFID=105752665&CFTOKEN=60368223">Michael Lankes</a>, 
                        <a href="author_page.cfm?id=81100481664&CFID=105752665&CFTOKEN=60368223">Manfred Tscheligi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 257-258</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514164" title="DOI">10.1145/1514095.1514164</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514164&ftid=603020&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow69" style="display:inline;"><br /><div style="display:inline">Effective collaboration between robots and humans is not only a question of interface design and usability, but also of user experience and social acceptance. To investigate these aspects for Human-Robot Collaboration with the HRP-2 robot, two video-based ...</div></span>
          <span id="toHide69" style="display:none;"><br /><div style="display:inline"><p>Effective collaboration between robots and humans is not only a question of interface design and usability, but also of user experience and social acceptance. To investigate these aspects for Human-Robot Collaboration with the HRP-2 robot, two video-based focus groups enhanced with creative stimuli were conducted. The following research question was addressed: Is the HRP-2 robot perceived differently in an autonomous collaboration condition compared to a tele-operated collaboration condition, in terms of social acceptance and user experience?"The results show that participants in general are open to a humanoid robot as working partner as long as there is a clear distinction between a human and a robot, in terms of tasks and working procedures. Furthermore, participants stated a positive attitude toward the remotely-controlled HRP-2 robot.</p></div></span> <a id="expcoll69" href="JavaScript: expandcollapse('expcoll69',69)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514165&CFID=105752665&CFTOKEN=60368223">I would choose the other card: humanoid robot gives an advice</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81381602151&CFID=105752665&CFTOKEN=60368223">Astrid Weiss</a>, 
                        <a href="author_page.cfm?id=81414616801&CFID=105752665&CFTOKEN=60368223">Roland Buchner</a>, 
                        <a href="author_page.cfm?id=81414620600&CFID=105752665&CFTOKEN=60368223">Thomas Scherndl</a>, 
                        <a href="author_page.cfm?id=81100481664&CFID=105752665&CFTOKEN=60368223">Manfred Tscheligi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 259-260</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514165" title="DOI">10.1145/1514095.1514165</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514165&ftid=603021&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow70" style="display:inline;"><br /><div style="display:inline">This article reports on a user study conducted to asses the credibility of a humanoid robot. The study set-up was based on the "Monty Hall Problem. Overall 13 people between the ages of 19 and 84 took part in the study (7 male and 6 female). The experiment ...</div></span>
          <span id="toHide70" style="display:none;"><br /><div style="display:inline"><p>This article reports on a user study conducted to asses the credibility of a humanoid robot. The study set-up was based on the "Monty Hall Problem. Overall 13 people between the ages of 19 and 84 took part in the study (7 male and 6 female). The experiment was set up as a card-game where the participant had to guess which of the three cards shows a price. At one point of the experiment the robot advised the participant to change his/her mind and choose another card. During the user study the participants had to fill in a questionnaire on their level of certainty about their choice and the credibility of the robot. The results showed a significant correlation between the believability of the robot and the certainty in the decision made. Furthermore, the outcomes showed differences between participants who followed the robot's advise and participants who did not, regarding credibility, certainty of the decision made and the estimation whether the robot was helpful or not.</p></div></span> <a id="expcoll70" href="JavaScript: expandcollapse('expcoll70',70)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514166&CFID=105752665&CFTOKEN=60368223">Evaluating the ICRA 2008 HRI challenge</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81381602151&CFID=105752665&CFTOKEN=60368223">Astrid Weiss</a>, 
                        <a href="author_page.cfm?id=81414620600&CFID=105752665&CFTOKEN=60368223">Thomas Scherndl</a>, 
                        <a href="author_page.cfm?id=81100481664&CFID=105752665&CFTOKEN=60368223">Manfred Tscheligi</a>, 
                        <a href="author_page.cfm?id=81100342762&CFID=105752665&CFTOKEN=60368223">Aude Billard</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 261-262</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514166" title="DOI">10.1145/1514095.1514166</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514166&ftid=603022&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow71" style="display:inline;"><br /><div style="display:inline">This paper reports on the evaluation of the ICRA 2008 Human-Robot Interaction (HRI) Challenge. Five research groups demonstrated state-of-the-art work on HRI with a special focus on social and learning abilities. The demonstrations were rated by expert ...</div></span>
          <span id="toHide71" style="display:none;"><br /><div style="display:inline"><p>This paper reports on the evaluation of the ICRA 2008 Human-Robot Interaction (HRI) Challenge. Five research groups demonstrated state-of-the-art work on HRI with a special focus on social and learning abilities. The demonstrations were rated by expert evaluators, in charge of awarding the prize, and 269 participants, i.e. 20 percent of the conference attendees through a standardized questionnaire (semantic differential). The data was analyzed with respect to six independent variables: expert evaluators vs. attendees, nationality of participants, origin region of the demo, age, gender and knowledge level of the attendees. Conference attendees tended to give higher scores for Social Skills, General Impression, and Overall Score than the expert evaluators. Irrespectively of the level of knowledge, age, and gender, conference attendees rated all demos relatively homogeneously. However, a comparative analysis of the conference attendees's ratings nationality-wise showed that demonstrations were rated differently depending on the region of origin. Conference attendees for the USA and Asian countries tended to rate demos from the same country of origin more frequently and more positively.</p></div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514167&CFID=105752665&CFTOKEN=60368223">Using bio-electrical signals to influence the social behaviours of domesticated robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414619149&CFID=105752665&CFTOKEN=60368223">Paul Saulnier</a>, 
                        <a href="author_page.cfm?id=81339528031&CFID=105752665&CFTOKEN=60368223">Ehud Sharlin</a>, 
                        <a href="author_page.cfm?id=81100197069&CFID=105752665&CFTOKEN=60368223">Saul Greenberg</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 263-264</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514167" title="DOI">10.1145/1514095.1514167</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514167&ftid=603023&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow72" style="display:inline;"><br /><div style="display:inline">Several emerging computer devices read bio-electrical signals (e.g., electro-corticographic signals, skin biopotential or facial muscle tension) and translate them into computer- understandable input. We investigated how one low-cost commercially-available ...</div></span>
          <span id="toHide72" style="display:none;"><br /><div style="display:inline"><p>Several emerging computer devices read bio-electrical signals (e.g., electro-corticographic signals, skin biopotential or facial muscle tension) and translate them into computer- understandable input. We investigated how one low-cost commercially-available device could be used to control a domestic robot. First, we used the device to issue direct motion commands; while we could control the device somewhat, it proved difficult to do reliably. Second, we interpreted one class of signals as suggestive of emotional stress, and used that as an emotional parameter to influence (but not directly control) robot behaviour. In this case, the robot would react to human stress by staying out of the person's way. Our work suggests that affecting behaviour may be a reasonable way to leverage such devices.</p></div></span> <a id="expcoll72" href="JavaScript: expandcollapse('expcoll72',72)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514168&CFID=105752665&CFTOKEN=60368223">A robot that says bad!: using negative and positive social feedback from a robotic agent to save energy</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81430644580&CFID=105752665&CFTOKEN=60368223">Jaap Ham</a>, 
                        <a href="author_page.cfm?id=81322501478&CFID=105752665&CFTOKEN=60368223">Cees Midden</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 265-266</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514168" title="DOI">10.1145/1514095.1514168</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514168&ftid=603024&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow73" style="display:inline;"><br /><div style="display:inline">Two experiments explored the persuasive effects of social feedback, as provided by a robotic agent, on behavioral change. Results indicate stronger persuasive effects of social feedback than of factual feedback (Experiment 1) or factual evaluative feedback ...</div></span>
          <span id="toHide73" style="display:none;"><br /><div style="display:inline"><p>Two experiments explored the persuasive effects of social feedback, as provided by a robotic agent, on behavioral change. Results indicate stronger persuasive effects of social feedback than of factual feedback (Experiment 1) or factual evaluative feedback (Experiment 2), and of negative feedback (especially social but also factual) than of positive feedback.</p></div></span> <a id="expcoll73" href="JavaScript: expandcollapse('expcoll73',73)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514169&CFID=105752665&CFTOKEN=60368223">Formal verification of human-robot teamwork</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100596694&CFID=105752665&CFTOKEN=60368223">Rafael H. Bordini</a>, 
                        <a href="author_page.cfm?id=81100551303&CFID=105752665&CFTOKEN=60368223">Michael Fisher</a>, 
                        <a href="author_page.cfm?id=81100440761&CFID=105752665&CFTOKEN=60368223">Maarten Sierhuis</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 267-268</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514169" title="DOI">10.1145/1514095.1514169</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514169&ftid=603025&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow74" style="display:inline;"><br /><div style="display:inline">We here address the modelling and analysis of human-agent teamwork, specifically in the context of proposed astronaut-robot collaboration in future space missions. We are particularly interested in modelling such systems at a level that allows formal ...</div></span>
          <span id="toHide74" style="display:none;"><br /><div style="display:inline"><p>We here address the modelling and analysis of human-agent teamwork, specifically in the context of proposed astronaut-robot collaboration in future space missions. We are particularly interested in modelling such systems at a level that allows formal verification techniques to be applied, and hence carry out sophisticated analysis of the reliability and effectiveness of the teams before the system is deployed in real scenarios. In this paper we describe our ongoing research in this area.</p></div></span> <a id="expcoll74" href="JavaScript: expandcollapse('expcoll74',74)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514170&CFID=105752665&CFTOKEN=60368223">Transactive memory systems: a perspective on coordination in human-robot incident response teams</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414605678&CFID=105752665&CFTOKEN=60368223">Lei Liu</a>, 
                        <a href="author_page.cfm?id=81100572021&CFID=105752665&CFTOKEN=60368223">Pamela J. Hinds</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 269-270</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514170" title="DOI">10.1145/1514095.1514170</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514170&ftid=603026&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow75" style="display:inline;"><br /><div style="display:inline">This paper introduces Transactive Memory System (TMS) theory to the study of human-robot interaction in a complex work setting comprised of people with complementary domains of expertise. New insights regarding the development of TMS in human-robot incident ...</div></span>
          <span id="toHide75" style="display:none;"><br /><div style="display:inline"><p>This paper introduces Transactive Memory System (TMS) theory to the study of human-robot interaction in a complex work setting comprised of people with complementary domains of expertise. New insights regarding the development of TMS in human-robot incident response teams are presented.</p></div></span> <a id="expcoll75" href="JavaScript: expandcollapse('expcoll75',75)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514171&CFID=105752665&CFTOKEN=60368223">Robot-directed speech as a means of exploring conceptualizations of robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81336490641&CFID=105752665&CFTOKEN=60368223">Sarah Kriz</a>, 
                        <a href="author_page.cfm?id=81414612166&CFID=105752665&CFTOKEN=60368223">Gregory Anderson</a>, 
                        <a href="author_page.cfm?id=81100283354&CFID=105752665&CFTOKEN=60368223">Magdalena Bugajska</a>, 
                        <a href="author_page.cfm?id=81100061774&CFID=105752665&CFTOKEN=60368223">J. Gregory Trafton</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 271-272</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514171" title="DOI">10.1145/1514095.1514171</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514171&ftid=603027&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow76" style="display:inline;"><br /><div style="display:inline">Decades of research have shown that speakers adapt the way in which they speak to meet the needs of listeners, and that speech modifications can illuminate speakers' conceptualizations of their listeners' cognitive and communicative abilities. The present ...</div></span>
          <span id="toHide76" style="display:none;"><br /><div style="display:inline"><p>Decades of research have shown that speakers adapt the way in which they speak to meet the needs of listeners, and that speech modifications can illuminate speakers' conceptualizations of their listeners' cognitive and communicative abilities. The present study extends this line of research into human-robot communication by analyzing the linguistic features of commands given to a robotic dog. The results indicate that males and females differed in the way in which they spoke to the robot, suggesting that there was not a uniform expectation of the robot's communicative capacities.</p></div></span> <a id="expcoll76" href="JavaScript: expandcollapse('expcoll76',76)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514172&CFID=105752665&CFTOKEN=60368223">FaceBots: robots utilizing and publishing social information in facebook</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310484400&CFID=105752665&CFTOKEN=60368223">Nikolaos Mavridis</a>, 
                        <a href="author_page.cfm?id=81414609591&CFID=105752665&CFTOKEN=60368223">Chandan Datta</a>, 
                        <a href="author_page.cfm?id=81414616109&CFID=105752665&CFTOKEN=60368223">Shervin Emami</a>, 
                        <a href="author_page.cfm?id=81414619870&CFID=105752665&CFTOKEN=60368223">Andry Tanoto</a>, 
                        <a href="author_page.cfm?id=81100610991&CFID=105752665&CFTOKEN=60368223">Chiraz BenAbdelkader</a>, 
                        <a href="author_page.cfm?id=81100366332&CFID=105752665&CFTOKEN=60368223">Tamer Rabie</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 273-274</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514172" title="DOI">10.1145/1514095.1514172</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514172&ftid=603028&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow77" style="display:inline;"><br /><div style="display:inline">Our project aims at supporting the creation of sustainable and meaningful longer-term human-robot relationships through the creation of embodied robots with face recognition and natural language dialogue capabilities, which exploit and publish social ...</div></span>
          <span id="toHide77" style="display:none;"><br /><div style="display:inline"><p>Our project aims at supporting the creation of sustainable and meaningful longer-term human-robot relationships through the creation of embodied robots with face recognition and natural language dialogue capabilities, which exploit and publish social information available on the web (Facebook). Our main underlying experimental hypothesis is that such relationships can be significantly enhanced if the human and the robot are gradually creating a pool of shared episodic memories that they can co-refer to (shared memories), and if they are both embedded in a social web of other humans and robots they both know and encounter (shared friends). In this paper, we are presenting such a robot, which as we will see achieves two significant novelties.</p></div></span> <a id="expcoll77" href="JavaScript: expandcollapse('expcoll77',77)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514173&CFID=105752665&CFTOKEN=60368223">The effects of robot touch and proactive behaviour on perceptions of human-robot interactions.</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81328487965&CFID=105752665&CFTOKEN=60368223">Henriette S.M. Cramer</a>, 
                        <a href="author_page.cfm?id=81392619070&CFID=105752665&CFTOKEN=60368223">Nicander A. Kemper</a>, 
                        <a href="author_page.cfm?id=81413599750&CFID=105752665&CFTOKEN=60368223">Alia Amin</a>, 
                        <a href="author_page.cfm?id=81100133286&CFID=105752665&CFTOKEN=60368223">Vanessa Evers</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 275-276</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514173" title="DOI">10.1145/1514095.1514173</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514173&ftid=603029&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow78" style="display:inline;"><br /><div style="display:inline">Despite robots' embodiment, the effect of physical contact or touch and its interaction with robots' autonomous behaviour has been a mostly overlooked aspect of human-robot interaction. This video-based, 2x2 between-subject survey experiment (N=119) ...</div></span>
          <span id="toHide78" style="display:none;"><br /><div style="display:inline"><p>Despite robots' embodiment, the effect of physical contact or touch and its interaction with robots' autonomous behaviour has been a mostly overlooked aspect of human-robot interaction. This video-based, 2x2 between-subject survey experiment (N=119) found that touch and proactiveness interacted in their effects on perceived machine-likeness and dependability. Attitude towards robots in general also interacted with the effects of touch. Results show the value of further exploring the combination of physical aspects of human-robot interaction and proactiveness.</p></div></span> <a id="expcoll78" href="JavaScript: expandcollapse('expcoll78',78)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514174&CFID=105752665&CFTOKEN=60368223">Towards a design method for expressive robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100653039&CFID=105752665&CFTOKEN=60368223">Bernt Meerbeek</a>, 
                        <a href="author_page.cfm?id=81414620233&CFID=105752665&CFTOKEN=60368223">Martin Saerbeck</a>, 
                        <a href="author_page.cfm?id=81100461702&CFID=105752665&CFTOKEN=60368223">Christoph Bartneck</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 277-278</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514174" title="DOI">10.1145/1514095.1514174</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514174&ftid=603030&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow79" style="display:inline;"><br /><div style="display:inline">Autonomous robots tend to induce the perception of a personality through their behavior and appearance. It has been suggested that the personality of a robot can be used as a design guideline and as a mental model of the robot. We propose a method to ...</div></span>
          <span id="toHide79" style="display:none;"><br /><div style="display:inline"><p>Autonomous robots tend to induce the perception of a personality through their behavior and appearance. It has been suggested that the personality of a robot can be used as a design guideline and as a mental model of the robot. We propose a method to design and evaluate personality and expressions for domestic robots.</p></div></span> <a id="expcoll79" href="JavaScript: expandcollapse('expcoll79',79)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514175&CFID=105752665&CFTOKEN=60368223">Are we living in a robot cargo cult?</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100544117&CFID=105752665&CFTOKEN=60368223">Ylva Fernaeus</a>, 
                        <a href="author_page.cfm?id=81309488890&CFID=105752665&CFTOKEN=60368223">Mattias Jacobsson</a>, 
                        <a href="author_page.cfm?id=81100194686&CFID=105752665&CFTOKEN=60368223">Sara Ljungblad</a>, 
                        <a href="author_page.cfm?id=81100144729&CFID=105752665&CFTOKEN=60368223">Lars Erik Holmquist</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 279-280</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514175" title="DOI">10.1145/1514095.1514175</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514175&ftid=603031&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow80" style="display:inline;"><br /><div style="display:inline">We use the Cargo Cult metaphor to discuss visions, methods and communication of robot research. Essentially cargo cult involves performing of imitative rituals that are conducted without understanding the underlying cause of a phenomenon. We discuss ...</div></span>
          <span id="toHide80" style="display:none;"><br /><div style="display:inline"><p>We use the Cargo Cult metaphor to discuss visions, methods and communication of robot research. Essentially cargo cult involves performing of imitative rituals that are conducted without understanding the underlying cause of a phenomenon. We discuss how this is an ongoing challenge within the field of HRI, and what researchers could do to avoid contributing to a robotic cargo cult.</p></div></span> <a id="expcoll80" href="JavaScript: expandcollapse('expcoll80',80)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514176&CFID=105752665&CFTOKEN=60368223">Human-robot physical interaction with dynamically stable mobile robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414620343&CFID=105752665&CFTOKEN=60368223">Umashankar Nagarajan</a>, 
                        <a href="author_page.cfm?id=81414598163&CFID=105752665&CFTOKEN=60368223">George Kantor</a>, 
                        <a href="author_page.cfm?id=81100381625&CFID=105752665&CFTOKEN=60368223">Ralph L. Hollis</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 281-282</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514176" title="DOI">10.1145/1514095.1514176</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514176&ftid=603032&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow81" style="display:inline;"><br /><div style="display:inline">Human-Robot Physical Interaction is an important attribute for robots operating in human environments. The authors illustrate some basic physically interactive behaviors with dynamically stable mobile robots using the ballbot as an example. The ballbot ...</div></span>
          <span id="toHide81" style="display:none;"><br /><div style="display:inline"><p>Human-Robot Physical Interaction is an important attribute for robots operating in human environments. The authors illustrate some basic physically interactive behaviors with dynamically stable mobile robots using the ballbot as an example. The ballbot is a dynamically stable mobile robot moving on a single spherical wheel. The dynamic stability and robust controllers enable the ballbot to be physically moved with ease. The authors also demonstrate other behaviors like human intent detection and learn-repeat behavior on the real robot.</p></div></span> <a id="expcoll81" href="JavaScript: expandcollapse('expcoll81',81)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514177&CFID=105752665&CFTOKEN=60368223">Hardware-assisted multiple object tracking for human-robot-interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414591735&CFID=105752665&CFTOKEN=60368223">Claus Lenz</a>, 
                        <a href="author_page.cfm?id=81309487976&CFID=105752665&CFTOKEN=60368223">Giorgio Panin</a>, 
                        <a href="author_page.cfm?id=81414598127&CFID=105752665&CFTOKEN=60368223">Thorsten R&#246;der</a>, 
                        <a href="author_page.cfm?id=81387609049&CFID=105752665&CFTOKEN=60368223">Martin Wojtczyk</a>, 
                        <a href="author_page.cfm?id=81100609341&CFID=105752665&CFTOKEN=60368223">Alois Knoll</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 283-284</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514177" title="DOI">10.1145/1514095.1514177</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514177&ftid=603033&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514178&CFID=105752665&CFTOKEN=60368223">Human-in-the-loop control of an assistive robotic arm in unstructured environments for spinal cord injured users</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414593062&CFID=105752665&CFTOKEN=60368223">Dae-Jin Kim</a>, 
                        <a href="author_page.cfm?id=81100103432&CFID=105752665&CFTOKEN=60368223">Aman Behal</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 285-286</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514178" title="DOI">10.1145/1514095.1514178</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514178&ftid=603034&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow83" style="display:inline;"><br /><div style="display:inline">We describe the progress in implementing a vision based robotic assist device to facilitate Activities of Daily Living (ADL) tasks for a class of users with motor disabilities. The goal of the research is to reduce time to task completion and cognitive ...</div></span>
          <span id="toHide83" style="display:none;"><br /><div style="display:inline"><p>We describe the progress in implementing a vision based robotic assist device to facilitate Activities of Daily Living (ADL) tasks for a class of users with motor disabilities. The goal of the research is to reduce time to task completion and cognitive burden for users interacting with an unstructured environment via a Wheelchair Mounted Robotic Arm (WMRA). A developed robot system is tested with five healthy subjects to assess its usefulness.</p></div></span> <a id="expcoll83" href="JavaScript: expandcollapse('expcoll83',83)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514179&CFID=105752665&CFTOKEN=60368223">Bandwidth allocation in a military teleoperation task</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414607780&CFID=105752665&CFTOKEN=60368223">Alia Fisher</a>, 
                        <a href="author_page.cfm?id=81414593958&CFID=105752665&CFTOKEN=60368223">Patricia L. McDermott</a>, 
                        <a href="author_page.cfm?id=81414607103&CFID=105752665&CFTOKEN=60368223">Shane Fagan</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 287-288</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514179" title="DOI">10.1145/1514095.1514179</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514179&ftid=603035&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow84" style="display:inline;"><br /><div style="display:inline">The implications of bandwidth allocation are described for teleoperation in a military task that involved navigation, target detection, and target identification. Color versus grayscale imagery was manipulated. Participants themselves traded off resolution ...</div></span>
          <span id="toHide84" style="display:none;"><br /><div style="display:inline"><p>The implications of bandwidth allocation are described for teleoperation in a military task that involved navigation, target detection, and target identification. Color versus grayscale imagery was manipulated. Participants themselves traded off resolution and frame rate settings. Participants minimized switching between resolution/frame rate settings and tended to use settings with high resolution/low frame rate. Courses completed with the highest resolution (and lowest frame rate) had the fastest target identification times, but no other differences were observed between settings. Color imagery offered advantages for overall course time and the time to identify a tank as friendly or enemy.</p></div></span> <a id="expcoll84" href="JavaScript: expandcollapse('expcoll84',84)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514180&CFID=105752665&CFTOKEN=60368223">General visualization abstraction algorithm for geographic map-based human-robot interfaces</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81325488567&CFID=105752665&CFTOKEN=60368223">Curtis M. Humphrey</a>, 
                        <a href="author_page.cfm?id=81100313646&CFID=105752665&CFTOKEN=60368223">Julie A. Adams</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 289-290</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514180" title="DOI">10.1145/1514095.1514180</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514180&ftid=603036&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow85" style="display:inline;"><br /><div style="display:inline">This paper presents a novel visualization technique that provides integration, abstraction, and sharing of the information generated by remotely deployed robots or sensors. The General Visualization Abstraction (GVA) algorithm is designed to display ...</div></span>
          <span id="toHide85" style="display:none;"><br /><div style="display:inline"><p>This paper presents a novel visualization technique that provides integration, abstraction, and sharing of the information generated by remotely deployed robots or sensors. The General Visualization Abstraction (GVA) algorithm is designed to display the most useful information items at any moment by determining an importance value for each information item with a focus on two classes of information: historically relevant and currently relevant information, and novel and emerging information.</p></div></span> <a id="expcoll85" href="JavaScript: expandcollapse('expcoll85',85)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514181&CFID=105752665&CFTOKEN=60368223">Preliminary results: humans find emotive non-anthropomorphic robots more calming</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503105&CFID=105752665&CFTOKEN=60368223">Cindy L. Bethel</a>, 
                        <a href="author_page.cfm?id=81414614253&CFID=105752665&CFTOKEN=60368223">Kristen Salomon</a>, 
                        <a href="author_page.cfm?id=81100545387&CFID=105752665&CFTOKEN=60368223">Robin R. Murphy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 291-292</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514181" title="DOI">10.1145/1514095.1514181</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514181&ftid=603037&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow86" style="display:inline;"><br /><div style="display:inline">This paper describes preliminary results of a large-scale, complex human study in HRI in which results show that participants were calmer interacting with non-anthropomorphic robots operated in an emotive mode versus a standard, non-emotive mode.</div></span>
          <span id="toHide86" style="display:none;"><br /><div style="display:inline"><p>This paper describes preliminary results of a large-scale, complex human study in HRI in which results show that participants were calmer interacting with non-anthropomorphic robots operated in an emotive mode versus a standard, non-emotive mode.</p></div></span> <a id="expcoll86" href="JavaScript: expandcollapse('expcoll86',86)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514182&CFID=105752665&CFTOKEN=60368223">Where third wave HCI meets HRI: report from a workshop on user-centred design of robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100544117&CFID=105752665&CFTOKEN=60368223">Ylva Fernaeus</a>, 
                        <a href="author_page.cfm?id=81100194686&CFID=105752665&CFTOKEN=60368223">Sara Ljungblad</a>, 
                        <a href="author_page.cfm?id=81309488890&CFID=105752665&CFTOKEN=60368223">Mattias Jacobsson</a>, 
                        <a href="author_page.cfm?id=81100517358&CFID=105752665&CFTOKEN=60368223">Alex Taylor</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 293-294</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514182" title="DOI">10.1145/1514095.1514182</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514182&ftid=603038&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow87" style="display:inline;"><br /><div style="display:inline">In this report we discuss some of the challenges when applying a user-centred design approach in the field of human-robot interaction (HRI). The discussion is based on a one-day workshop at the NordiCHI'08 conference, investigating how methods, techniques ...</div></span>
          <span id="toHide87" style="display:none;"><br /><div style="display:inline"><p>In this report we discuss some of the challenges when applying a user-centred design approach in the field of human-robot interaction (HRI). The discussion is based on a one-day workshop at the NordiCHI'08 conference, investigating how methods, techniques and perspectives from the field of Human Computer Interaction (HCI) could contribute to and learn from recent developments in the area of HRI. Emphasis was put on topics that are infrequent in mainstream HCI such as machine movement, autonomy, anthropomorphism, physical interaction, environmental issues and issues concerned more generally with cultural notions of robots.</p></div></span> <a id="expcoll87" href="JavaScript: expandcollapse('expcoll87',87)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514183&CFID=105752665&CFTOKEN=60368223">Robot motivator: improving user performance on a physical/mental task</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414620502&CFID=105752665&CFTOKEN=60368223">Juan Fasola</a>, 
                        <a href="author_page.cfm?id=81452618057&CFID=105752665&CFTOKEN=60368223">Maja J. Mataric</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 295-296</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514183" title="DOI">10.1145/1514095.1514183</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514183&ftid=603039&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow88" style="display:inline;"><br /><div style="display:inline">We describe the design and implementation of a socially assistive robot that is able to monitor the performance of a user during a combined mental and physical task, with the purpose of motivating the user to complete the task and to improve performance. ...</div></span>
          <span id="toHide88" style="display:none;"><br /><div style="display:inline"><p>We describe the design and implementation of a socially assistive robot that is able to monitor the performance of a user during a combined mental and physical task, with the purpose of motivating the user to complete the task and to improve performance. A three-condition experimental study was constructed for evaluation of the robot and preliminary results of the robot's interaction with human participants are presented.</p></div></span> <a id="expcoll88" href="JavaScript: expandcollapse('expcoll88',88)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514184&CFID=105752665&CFTOKEN=60368223">Music therapist robot for individuals with cognitive impairments</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350577565&CFID=105752665&CFTOKEN=60368223">Adriana Tapus</a>, 
                        <a href="author_page.cfm?id=81414593344&CFID=105752665&CFTOKEN=60368223">Cristian Tapus</a>, 
                        <a href="author_page.cfm?id=81452618057&CFID=105752665&CFTOKEN=60368223">Maja J. Matari&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 297-298</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514184" title="DOI">10.1145/1514095.1514184</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514184&ftid=603040&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow89" style="display:inline;"><br /><div style="display:inline">Currently the 2 percent growth rate for the world's older population exceeds the 1.2 percent rate for the world's population as a whole. This difference is expected to increase rather than diminish so that by 2050, the number of individuals over the ...</div></span>
          <span id="toHide89" style="display:none;"><br /><div style="display:inline"><p>Currently the 2 percent growth rate for the world's older population exceeds the 1.2 percent rate for the world's population as a whole. This difference is expected to increase rather than diminish so that by 2050, the number of individuals over the age 85 is projected to be three times what it is today. Most of these individuals will need physical, emotional, and cognitive assistance. In this paper, we present a new system based on the socially assistive robotics (SAR) technology that will play the role of a music therapist and will try to provide a customized help protocol through motivation, encouragements, and companionship to users suffering from cognitive changes related to aging and/or Alzheimer's disease.</p></div></span> <a id="expcoll89" href="JavaScript: expandcollapse('expcoll89',89)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514185&CFID=105752665&CFTOKEN=60368223">A preliminary system for recognizing boredom</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414600600&CFID=105752665&CFTOKEN=60368223">Allison M. Jacobs</a>, 
                        <a href="author_page.cfm?id=81325488400&CFID=105752665&CFTOKEN=60368223">Benjamin Fransen</a>, 
                        <a href="author_page.cfm?id=81350583559&CFID=105752665&CFTOKEN=60368223">J. Malcolm McCurry</a>, 
                        <a href="author_page.cfm?id=81414620921&CFID=105752665&CFTOKEN=60368223">Frederick W.P. Heckel</a>, 
                        <a href="author_page.cfm?id=81414607056&CFID=105752665&CFTOKEN=60368223">Alan R. Wagner</a>, 
                        <a href="author_page.cfm?id=81100061774&CFID=105752665&CFTOKEN=60368223">J. Gregory Trafton</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 299-300</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514185" title="DOI">10.1145/1514095.1514185</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514185&ftid=603041&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow90" style="display:inline;"><br /><div style="display:inline">A 3D optical flow tracking system was used to track participants as they watched a series of boring videos. The video stream of the participants was rated for boredom events. Ratings and head position data were combined to predict boredom events.</div></span>
          <span id="toHide90" style="display:none;"><br /><div style="display:inline"><p>A 3D optical flow tracking system was used to track participants as they watched a series of boring videos. The video stream of the participants was rated for boredom events. Ratings and head position data were combined to predict boredom events.</p></div></span> <a id="expcoll90" href="JavaScript: expandcollapse('expcoll90',90)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514186&CFID=105752665&CFTOKEN=60368223">Situated messages for asynchronous human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81324491951&CFID=105752665&CFTOKEN=60368223">Nicolai Marquardt</a>, 
                        <a href="author_page.cfm?id=81416601902&CFID=105752665&CFTOKEN=60368223">James Young</a>, 
                        <a href="author_page.cfm?id=81339528031&CFID=105752665&CFTOKEN=60368223">Ehud Sharlin</a>, 
                        <a href="author_page.cfm?id=81100197069&CFID=105752665&CFTOKEN=60368223">Saul Greenberg</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 301-302</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514186" title="DOI">10.1145/1514095.1514186</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514186&ftid=603358&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow91" style="display:inline;"><br /><div style="display:inline">An ongoing issue in human robot interaction (HRI) is how people and robots communicate with one another. While there is considerable work in real-time human-robot communication, fairly little has been done in asynchronous realm. Our approach, which we ...</div></span>
          <span id="toHide91" style="display:none;"><br /><div style="display:inline"><p>An ongoing issue in human robot interaction (HRI) is how people and robots communicate with one another. While there is considerable work in real-time human-robot communication, fairly little has been done in asynchronous realm. Our approach, which we call situated messages, lets humans and robots asynchronously exchange information by placing physical tokens - each representing a simple message - in meaningful physical locations of their shared environment. Using knowledge of the robot's routines, a person can place a message token at a location, where the location is typically relevant to redirecting the robot's behavior at that location. When the robot passes nearby that location, it detects the message and reacts accordingly. Similarly, robots can themselves place tokens at specific locations for people to read. Thus situated messages leverages embodied interaction, where token placement exploits the everyday practices and routines of both people and robots. We describe our working prototype, introduce application scenarios, explore message categories and usage patterns, and suggest future directions.</p></div></span> <a id="expcoll91" href="JavaScript: expandcollapse('expcoll91',91)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514187&CFID=105752665&CFTOKEN=60368223">Multi-sensor fusion for human daily activity recognition in robot-assisted living</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414604381&CFID=105752665&CFTOKEN=60368223">Chun Zhu</a>, 
                        <a href="author_page.cfm?id=81100242638&CFID=105752665&CFTOKEN=60368223">Weihua Sheng</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 303-304</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514187" title="DOI">10.1145/1514095.1514187</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514187&ftid=603359&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow92" style="display:inline;"><br /><div style="display:inline">In this paper, we propose a human activity recognition method by fusing the data from two wearable inertial sensors attached to one foot and the waist of a human subject, respectively. Our multi-sensor fusion based method combines neural networks and ...</div></span>
          <span id="toHide92" style="display:none;"><br /><div style="display:inline"><p>In this paper, we propose a human activity recognition method by fusing the data from two wearable inertial sensors attached to one foot and the waist of a human subject, respectively. Our multi-sensor fusion based method combines neural networks and hidden Markov models (HMMs), and can reduce the computation load. We conducted experiments using a prototype wearable sensor system and the obtained results prove the effectiveness and the accuracy of our algorithm.</p></div></span> <a id="expcoll92" href="JavaScript: expandcollapse('expcoll92',92)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514188&CFID=105752665&CFTOKEN=60368223">Focus group interview for designing a growing robot</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414606852&CFID=105752665&CFTOKEN=60368223">Ryoung Kim</a>, 
                        <a href="author_page.cfm?id=81414612511&CFID=105752665&CFTOKEN=60368223">Sona S. Kwak</a>, 
                        <a href="author_page.cfm?id=81100398105&CFID=105752665&CFTOKEN=60368223">Youn-kyung Lim</a>, 
                        <a href="author_page.cfm?id=81414595687&CFID=105752665&CFTOKEN=60368223">Myung-suk Kim</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 305-306</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514188" title="DOI">10.1145/1514095.1514188</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514188&ftid=603360&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow93" style="display:inline;"><br /><div style="display:inline">This study describes preliminary research for designing a growing robot. To explore the interaction between a human and an object that changes physically through its growth, focus group interviews were conducted with participants who kept pets, plants, ...</div></span>
          <span id="toHide93" style="display:none;"><br /><div style="display:inline"><p>This study describes preliminary research for designing a growing robot. To explore the interaction between a human and an object that changes physically through its growth, focus group interviews were conducted with participants who kept pets, plants, and a plant-like product. An appropriate target model for designing a growing robot, the value of raising living things, and the features of interaction that induce affinity were examined.</p></div></span> <a id="expcoll93" href="JavaScript: expandcollapse('expcoll93',93)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514189&CFID=105752665&CFTOKEN=60368223">Sociable robot improves toddler vocabulary skills</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100053278&CFID=105752665&CFTOKEN=60368223">Javier Movellan</a>, 
                        <a href="author_page.cfm?id=81414600315&CFID=105752665&CFTOKEN=60368223">Micah Eckhardt</a>, 
                        <a href="author_page.cfm?id=81100142045&CFID=105752665&CFTOKEN=60368223">Marjo Virnes</a>, 
                        <a href="author_page.cfm?id=81414594801&CFID=105752665&CFTOKEN=60368223">Angelica Rodriguez</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 307-308</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514189" title="DOI">10.1145/1514095.1514189</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514189&ftid=603361&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow94" style="display:inline;"><br /><div style="display:inline">We report results of a study in which a low cost sociable robot was immersed at an Early Childhood Education Center for a period of 2 weeks. The study was designed to investigate whether the robot, which operated fully autonomously during the intervention ...</div></span>
          <span id="toHide94" style="display:none;"><br /><div style="display:inline"><p>We report results of a study in which a low cost sociable robot was immersed at an Early Childhood Education Center for a period of 2 weeks. The study was designed to investigate whether the robot, which operated fully autonomously during the intervention period, could improve target vocabulary skills of 18-24 month of age toddlers. The results showed a 27 % improvement in knowledge of the target words taught by the robot when compared to a matched set of control words. The results suggest that sociable robots may be an effective and low cost technology to enrich Early Childhood Education environments.</p></div></span> <a id="expcoll94" href="JavaScript: expandcollapse('expcoll94',94)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514190&CFID=105752665&CFTOKEN=60368223">A vision based human robot interface for robotic walkthroughs in a biotech laboratory.</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81387609049&CFID=105752665&CFTOKEN=60368223">Martin Wojtczyk</a>, 
                        <a href="author_page.cfm?id=81309487976&CFID=105752665&CFTOKEN=60368223">Giorgio Panin</a>, 
                        <a href="author_page.cfm?id=81414591735&CFID=105752665&CFTOKEN=60368223">Claus Lenz</a>, 
                        <a href="author_page.cfm?id=81414598127&CFID=105752665&CFTOKEN=60368223">Thorsten R&#246;der</a>, 
                        <a href="author_page.cfm?id=81414593414&CFID=105752665&CFTOKEN=60368223">Suraj Nair</a>, 
                        <a href="author_page.cfm?id=81414604986&CFID=105752665&CFTOKEN=60368223">Erwin Roth</a>, 
                        <a href="author_page.cfm?id=81100609341&CFID=105752665&CFTOKEN=60368223">Alois Knoll</a>, 
                        <a href="author_page.cfm?id=81436599138&CFID=105752665&CFTOKEN=60368223">R&#252;diger Heidemann</a>, 
                        <a href="author_page.cfm?id=81436592814&CFID=105752665&CFTOKEN=60368223">Klaus Joeris</a>, 
                        <a href="author_page.cfm?id=81414598031&CFID=105752665&CFTOKEN=60368223">Chun Zhang</a>, 
                        <a href="author_page.cfm?id=81436592769&CFID=105752665&CFTOKEN=60368223">Mark Burnett</a>, 
                        <a href="author_page.cfm?id=81414618791&CFID=105752665&CFTOKEN=60368223">Tom Monica</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 309-310</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514190" title="DOI">10.1145/1514095.1514190</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514190&ftid=603362&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow95" style="display:inline;"><br /><div style="display:inline">Both Robots and Personal Computers established new markets about 30 years ago and were enabling factors in Automation and Information Technology. However, while you can see Personal Computers in almost every home nowadays, the domain of Robots in general ...</div></span>
          <span id="toHide95" style="display:none;"><br /><div style="display:inline"><p>Both Robots and Personal Computers established new markets about 30 years ago and were enabling factors in Automation and Information Technology. However, while you can see Personal Computers in almost every home nowadays, the domain of Robots in general still is mostly restricted to industrial automation. Due to the physical impact of robots, a safe design is essential, which most robots still lack of and therefore prevent their application for personal use, although a slow change can be noticed by the introduction of dedicated robots for specific tasks, which can be classified as service robots. Moreover, as more and more robots are designed as service robots, their developers face the challenge of reducing the machines' complexity and providing smart user interface methods. Ideally the robot would be able to cooperate with a human, just like another human would.</p></div></span> <a id="expcoll95" href="JavaScript: expandcollapse('expcoll95',95)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514191&CFID=105752665&CFTOKEN=60368223">On Line - affective state reporting device: a tool for evaluating affective state inference systems</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414621548&CFID=105752665&CFTOKEN=60368223">Susana Zoghbi</a>, 
                        <a href="author_page.cfm?id=81414620079&CFID=105752665&CFTOKEN=60368223">Dana Kuliff</a>, 
                        <a href="author_page.cfm?id=81100651063&CFID=105752665&CFTOKEN=60368223">Elizabeth Croft</a>, 
                        <a href="author_page.cfm?id=81414618794&CFID=105752665&CFTOKEN=60368223">Machiel Van der Loos</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 311-312</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514191" title="DOI">10.1145/1514095.1514191</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514191&ftid=603363&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow96" style="display:inline;"><br /><div style="display:inline">The monitoring of human affective state is a key part of developing responsive and naturally behaving human-robot interaction systems. However, evaluation and calibration of physiologically monitored affective state data is typically done using offline ...</div></span>
          <span id="toHide96" style="display:none;"><br /><div style="display:inline"><p>The monitoring of human affective state is a key part of developing responsive and naturally behaving human-robot interaction systems. However, evaluation and calibration of physiologically monitored affective state data is typically done using offline questionnaires and user reports. In this paper we investigate the use of an online-device for collecting real-time user reports of affective state during interaction with a robot. These reports are compared to both previous survey reports taken after the interaction, and the affective states estimated by an inference system. The aim is to evaluate and characterize the physiological signal-based inference system and determine which factors significantly influence its performance. This analysis will be used in future work, to fine tune the affective estimations by identifying what kind of variations in physiological signals precede or accompany the variations in reported affective states.</p></div></span> <a id="expcoll96" href="JavaScript: expandcollapse('expcoll96',96)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514192&CFID=105752665&CFTOKEN=60368223">An uncanny game of trust: social trustworthiness of robots inferred from subtle anthropomorphic facial cues</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414602593&CFID=105752665&CFTOKEN=60368223">Maya B. Mathur</a>, 
                        <a href="author_page.cfm?id=81414619429&CFID=105752665&CFTOKEN=60368223">David B. Reichling</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 313-314</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514192" title="DOI">10.1145/1514095.1514192</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514192&ftid=603364&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow97" style="display:inline;"><br /><div style="display:inline">Modern android robots have begun to penetrate the social realm of humans. This study quantitatively probed the impact of anthropomorphic robot appearance on human social interpretation of robot facial expression. The Uncanny Valley"theory describing ...</div></span>
          <span id="toHide97" style="display:none;"><br /><div style="display:inline"><p>Modern android robots have begun to penetrate the social realm of humans. This study quantitatively probed the impact of anthropomorphic robot appearance on human social interpretation of robot facial expression. The Uncanny Valley"theory describing the disturbing effect of imperfect human likenesses has been a dominant influence in discussions of human-robot social interaction, but measuring its effect on human social interactions with robots has been problematic. The present study addresses this issue by examining social responses of human participants to a series of digitally composed pictures of realistic robot faces that span a range from mechanical to human in appearance. Our first experiment provides evidence that an Uncanny Valley effect on social attractiveness is indeed a practical concern in the design of robots meant to interact socially with the lay public. In the second experiment, we employed game-theory research methods to measure the effect of subtle facial expressions in robots on human judgments of their trustworthiness as social counterparts. Our application of game-theory research methods to the study of human-robot interactions provides a model for such empirical measurement of human's social responses to android robots.</p></div></span> <a id="expcoll97" href="JavaScript: expandcollapse('expcoll97',97)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514193&CFID=105752665&CFTOKEN=60368223">Incorporating active vision into the body schema</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81418596943&CFID=105752665&CFTOKEN=60368223">Justin W. Hart</a>, 
                        <a href="author_page.cfm?id=81414620434&CFID=105752665&CFTOKEN=60368223">Eleanor R. Avrunin</a>, 
                        <a href="author_page.cfm?id=81414605978&CFID=105752665&CFTOKEN=60368223">David Golub</a>, 
                        <a href="author_page.cfm?id=81326492306&CFID=105752665&CFTOKEN=60368223">Brian Scassellati</a>, 
                        <a href="author_page.cfm?id=81100615306&CFID=105752665&CFTOKEN=60368223">Steven W. Zucker</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 315-316</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514193" title="DOI">10.1145/1514095.1514193</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514193&ftid=603365&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514194&CFID=105752665&CFTOKEN=60368223">The power of suggestion: teaching sequences through assistive robot motions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81442595982&CFID=105752665&CFTOKEN=60368223">Ross Mead</a>, 
                        <a href="author_page.cfm?id=81452618057&CFID=105752665&CFTOKEN=60368223">Maja J. Matari&#263;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 317-318</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514194" title="DOI">10.1145/1514095.1514194</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514194&ftid=603366&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow99" style="display:inline;"><br /><div style="display:inline">We present a preliminary implementation of a robot within the context of social skills intervention. The robot engages a human user in an interactive and adaptive game-playing session that emphasizes a specific sequence of movements over time. Such games ...</div></span>
          <span id="toHide99" style="display:none;"><br /><div style="display:inline"><p>We present a preliminary implementation of a robot within the context of social skills intervention. The robot engages a human user in an interactive and adaptive game-playing session that emphasizes a specific sequence of movements over time. Such games highlight joint attention and encourage forms of interaction that are useful within various assistive domains. Noteworthy robot activities include those that could be used to promote social cues in children with autism, sequences that maintain or improve memory in Alzheimer's patients, and movements that encourage exercises to increase range of motion in post-stroke rehabilitation.</p></div></span> <a id="expcoll99" href="JavaScript: expandcollapse('expcoll99',99)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514195&CFID=105752665&CFTOKEN=60368223">CALLY: the cell-phone robot with affective expressions</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100509994&CFID=105752665&CFTOKEN=60368223">Ji-Dong Yim</a>, 
                        <a href="author_page.cfm?id=81100396860&CFID=105752665&CFTOKEN=60368223">Christopher D. Shaw</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 319-320</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514195" title="DOI">10.1145/1514095.1514195</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514195&ftid=603367&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow100" style="display:inline;"><br /><div style="display:inline">This poster describes a robot cell-phone named CALLY with which we are exploring the roles of facial and gestural expressions of robotic products in the human computer interaction. We discuss non-verbal anthropomorphic affect features as media for building ...</div></span>
          <span id="toHide100" style="display:none;"><br /><div style="display:inline"><p>This poster describes a robot cell-phone named CALLY with which we are exploring the roles of facial and gestural expressions of robotic products in the human computer interaction. We discuss non-verbal anthropomorphic affect features as media for building emotional relationships between a user and a product, and introduce new types of robotic products in the market that may be capable of establish intimacy by applying such features. A couple of social robot application ideas generated from the early phase of our project are also presented with their usage scenarios and implementations. CALLY was used in our initial participatory design workshop and helped participants generate new application ideas.</p></div></span> <a id="expcoll100" href="JavaScript: expandcollapse('expcoll100',100)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514196&CFID=105752665&CFTOKEN=60368223">Relating initial turns of human-robot dialogues to discourse</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100431442&CFID=105752665&CFTOKEN=60368223">Maxim Makatchev</a>, 
                        <a href="author_page.cfm?id=81414592368&CFID=105752665&CFTOKEN=60368223">Min Kyung Lee</a>, 
                        <a href="author_page.cfm?id=81332527865&CFID=105752665&CFTOKEN=60368223">Reid Simmons</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 321-322</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514196" title="DOI">10.1145/1514095.1514196</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514196&ftid=604181&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow101" style="display:inline;"><br /><div style="display:inline">Similarly, User models can be useful for improving dialogue management. In this paper we analyze human-robot dialogues that occur during uncontrolled interactions and estimate relations between the initial dialogue turns and patterns of discourse that ...</div></span>
          <span id="toHide101" style="display:none;"><br /><div style="display:inline"><p>Similarly, User models can be useful for improving dialogue management. In this paper we analyze human-robot dialogues that occur during uncontrolled interactions and estimate relations between the initial dialogue turns and patterns of discourse that are indicative of such user traits as persistence and politeness. The significant effects shown in this preliminary study suggest that initial dialogue turns may be useful in modeling a user's interaction style.</p></div></span> <a id="expcoll101" href="JavaScript: expandcollapse('expcoll101',101)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514197&CFID=105752665&CFTOKEN=60368223">HomeWindow: an augmented reality domestic monitor</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350578065&CFID=105752665&CFTOKEN=60368223">Paul Lapides</a>, 
                        <a href="author_page.cfm?id=81339528031&CFID=105752665&CFTOKEN=60368223">Ehud Sharlin</a>, 
                        <a href="author_page.cfm?id=81100197069&CFID=105752665&CFTOKEN=60368223">Saul Greenberg</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 323-324</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514197" title="DOI">10.1145/1514095.1514197</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514197&ftid=603368&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow102" style="display:inline;"><br /><div style="display:inline">Computation is increasingly prevalent in the home: it serves as a way to control the home itself, or it is part of the many digital appliances within it. The question is: how can home inhabitants effectively understand and control the digital home? Our ...</div></span>
          <span id="toHide102" style="display:none;"><br /><div style="display:inline"><p>Computation is increasingly prevalent in the home: it serves as a way to control the home itself, or it is part of the many digital appliances within it. The question is: how can home inhabitants effectively understand and control the digital home? Our solution lets a person examine and control their home surroundings through a mobile display that serves as a 'magic lens', where the detail shown varies with proximity. In particular, HomeWindow is an augmented reality system that superimposes an interactive graphical interface atop of physical but digital artifacts in the home. One can get an overview of a room's computational state by looking through the display: the basic state of all digital hot spots are shown atop their physical counterparts. As one approaches a particular digital spot, more detailed information as well as a control interface is shown using a semantic zoom. Our current implementation works with two home devices. First, people can examine and remotely control the status of mobile domestic robots. Second, people can discover the power consumption of household appliances, where appliances are surrounded by a colorful aura that reflects its current and historical energy use.</p></div></span> <a id="expcoll102" href="JavaScript: expandcollapse('expcoll102',102)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514198&CFID=105752665&CFTOKEN=60368223">Tea table, come closer to me</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414620729&CFID=105752665&CFTOKEN=60368223">Vikas Reddy Enti</a>, 
                        <a href="author_page.cfm?id=81414619144&CFID=105752665&CFTOKEN=60368223">Rajesh Arumugam</a>, 
                        <a href="author_page.cfm?id=81414617616&CFID=105752665&CFTOKEN=60368223">Krishnamoorthy Baskaran</a>, 
                        <a href="author_page.cfm?id=81414615420&CFID=105752665&CFTOKEN=60368223">Bingbing Liu</a>, 
                        <a href="author_page.cfm?id=81414620652&CFID=105752665&CFTOKEN=60368223">Foo Kong Foong</a>, 
                        <a href="author_page.cfm?id=81414606942&CFID=105752665&CFTOKEN=60368223">Appadorai Senthil Kumar</a>, 
                        <a href="author_page.cfm?id=81414618308&CFID=105752665&CFTOKEN=60368223">Dee Meng Kang</a>, 
                        <a href="author_page.cfm?id=81414617034&CFID=105752665&CFTOKEN=60368223">Xiaojun Wu</a>, 
                        <a href="author_page.cfm?id=81414604869&CFID=105752665&CFTOKEN=60368223">Wai Kit Goh</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 325-326</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514198" title="DOI">10.1145/1514095.1514198</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514198&ftid=603369&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow103" style="display:inline;"><br /><div style="display:inline">We present a new concept (named DA vinCi) of distributed agents, sensor networks and an intelligent server catered to the home environment. Instead of a single multi-tasking human-like robot, we propose a team of networked task-specific robotic agents ...</div></span>
          <span id="toHide103" style="display:none;"><br /><div style="display:inline"><p>We present a new concept (named DA vinCi) of distributed agents, sensor networks and an intelligent server catered to the home environment. Instead of a single multi-tasking human-like robot, we propose a team of networked task-specific robotic agents that interface with each other and the environment through a spatial map built by the server. We also highlight how our server will be a proxy for all the human-robot interactions (HRI) in the system and discuss the challenges involved. The paper's title captures the jist of our system where even a tea table can be inexpensively mobilized and interacted with via the DA vinCi architecture.</p></div></span> <a id="expcoll103" href="JavaScript: expandcollapse('expcoll103',103)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514199&CFID=105752665&CFTOKEN=60368223">Self introducing poster using attachable humanoid parts</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414597701&CFID=105752665&CFTOKEN=60368223">Hirotaka Osawa</a>, 
                        <a href="author_page.cfm?id=81314484611&CFID=105752665&CFTOKEN=60368223">Ren Ohmura</a>, 
                        <a href="author_page.cfm?id=81100282909&CFID=105752665&CFTOKEN=60368223">Michita Imai</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 327-328</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514199" title="DOI">10.1145/1514095.1514199</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514199&ftid=603370&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow104" style="display:inline;"><br /><div style="display:inline">In this paper, we propose new robotics presentation method called, Self Introducing Poster that uses attachable humanoid parts and explains its contents through a self introduction style. Presentation by a conventional robot sometimes fails because the ...</div></span>
          <span id="toHide104" style="display:none;"><br /><div style="display:inline"><p>In this paper, we propose new robotics presentation method called, Self Introducing Poster that uses attachable humanoid parts and explains its contents through a self introduction style. Presentation by a conventional robot sometimes fails because the robot presenter is often too attractive and distracts from the presentation itself. In our method, the poster is anthropomorphized and explains its contents. Due to this self presentation, users can more easily understand its meaning because the information's contents and information provider are strongly related. We designed and implemented our system and evaluated it in the field. The results suggest that the self-introducing system is useful for gaining users attention and effectively presenting information.</p></div></span> <a id="expcoll104" href="JavaScript: expandcollapse('expcoll104',104)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1514200&CFID=105752665&CFTOKEN=60368223">Evaluation of the effects of the shape of the artificial hand on the quality of the interaction: natural appearance vs. symbolic appearance</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81414598361&CFID=105752665&CFTOKEN=60368223">Massimiliano Zecca</a>, 
                        <a href="author_page.cfm?id=81350583057&CFID=105752665&CFTOKEN=60368223">Fumiya Iida</a>, 
                        <a href="author_page.cfm?id=81414597124&CFID=105752665&CFTOKEN=60368223">Nobutsuna Endo</a>, 
                        <a href="author_page.cfm?id=81414608794&CFID=105752665&CFTOKEN=60368223">Yu Mizoguchi</a>, 
                        <a href="author_page.cfm?id=81414616041&CFID=105752665&CFTOKEN=60368223">Keita Endo</a>, 
                        <a href="author_page.cfm?id=81414619389&CFID=105752665&CFTOKEN=60368223">Yousuke Kawabata</a>, 
                        <a href="author_page.cfm?id=81414616650&CFID=105752665&CFTOKEN=60368223">Kazuko Itoh</a>, 
                        <a href="author_page.cfm?id=81100472777&CFID=105752665&CFTOKEN=60368223">Atsuo Takanishi</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 329-330</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1514095.1514200" title="DOI">10.1145/1514095.1514200</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1514200&ftid=603371&dwn=1&CFID=105752665&CFTOKEN=60368223" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow105" style="display:inline;"><br /><div style="display:inline">Personal robots and robot technology (RT)-based assistive devices are expected to play a major role in our elderly-dominated society, by interacting with surrounding people both physically and psychologically. A fundamental role during the interaction ...</div></span>
          <span id="toHide105" style="display:none;"><br /><div style="display:inline"><p>Personal robots and robot technology (RT)-based assistive devices are expected to play a major role in our elderly-dominated society, by interacting with surrounding people both physically and psychologically. A fundamental role during the interaction is of course played by the hand. In this paper we present the evaluation of the effect of hand shape to the quality of the interaction, in particular during handshake.</p></div></span> <a id="expcoll105" href="JavaScript: expandcollapse('expcoll105',105)">expand</a>
          </div>
		  </td>
          </tr>          
          
</table>


</div> 
</div>


 <p class="small-text" align="center">Powered by <a id="theguide" name="theguide" href="javascript:ColdFusion.Window.show('theguide')"><img src="img/poweredbyacm.jpg" width="336" height="11" alt="The ACM Guide to Computing Literature" border="0" /></a></p>



 <br />
<div class="footerbody" align="center" >
	

	The ACM Digital Library is published by the Association for Computing Machinery. Copyright &copy; 2012 ACM, Inc.<br />
	<a href="http://www.acm.org/publications/policies/usage">Terms of Usage</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/privacy-policy">Privacy Policy</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/code-of-ethics">Code of Ethics</a>&nbsp;&nbsp;	  
	<a href="http://www.acm.org/about/contact-us">Contact Us</a>

<br /><br />
Useful downloads: 
<a href="http://www.adobe.com/products/acrobat/readstep2.html"><img src="http://dl.acm.org/images/pdf_logo.gif" width="16" height="16" alt="" border="0" /> Adobe Acrobat</a>
&nbsp;&nbsp;
<a href="http://www.apple.com/quicktime/download/" target="_blank"><img src="http://dl.acm.org/images/qtlogo.gif" width="16" height="16" alt="" border="0" /> QuickTime</a>
&nbsp;&nbsp;
<a href="http://www.microsoft.com/windows/windowsmedia/download/default.asp" target="_blank"><img src="http://dl.acm.org/images/wmv.gif" width="16" height="15" alt="" border="0" /> Windows Media Player</a>
&nbsp;&nbsp;
<a href="http://www.real.com/" target="_blank"><img src="http://dl.acm.org/images/realplayer.gif" width="20" height="18" alt="" border="0" /> Real Player</a>

</div> 



<div  id="cf_window1338242209236" class="yuiextdlg">
	
	<div  id="theguide_title" class="x-dlg-hd">
		The ACM Guide to Computing Literature
	 </div>
	<div  id="theguide_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338242209239" class="yuiextdlg">
	
	<div  id="thetags_title" class="x-dlg-hd">
		All Tags
	 </div>
	<div  id="thetags_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338242209242" class="yuiextdlg">
	
	<div  id="theformats_title" class="x-dlg-hd">
		Export Formats
	 </div>
	<div  id="theformats_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338242209244" class="yuiextdlg">
	
	<div  id="theexplaination_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theexplaination_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338242209246" class="yuiextdlg">
	
	<div  id="theservices_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theservices_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338242209248" class="yuiextdlg">
	
	<div  id="savetobinder_title" class="x-dlg-hd">
		Save to Binder
	 </div>
	<div  id="savetobinder_body" class="x-dlg-bd">
		
		
	 </div>
 </div> 

</body>
</html>