


<!doctype html>


<head><script type="text/javascript">_cf_loadingtexthtml="<img alt=' ' src='/CFIDE/scripts/ajax/resources/cf/images/loading.gif'/>";
_cf_contextpath="";
_cf_ajaxscriptsrc="/CFIDE/scripts/ajax";
_cf_jsonprefix='//';
_cf_clientid='484327F93327335862BC2F747E05A322';</script><script type="text/javascript" src="/CFIDE/scripts/ajax/messages/cfmessage.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfajax.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfform.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/masks.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/cfformhistory.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfrichtexteditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/FCKeditor/fckeditor.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/yahoo-dom-event/yahoo-dom-event.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/yui/animation/animation-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/adapter/yui/ext-yui-adapter.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/ext-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/resizable.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dragdrop/dragdrop.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/util.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/build/state/State-min.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/widget-core.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/ext/package/dialog/dialogs.js"></script>
<script type="text/javascript" src="/CFIDE/scripts/ajax/package/cfwindow.js"></script>
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/ext/css/ext-all.css" />
<link rel="stylesheet" type="text/css" href="/CFIDE/scripts/ajax/resources/cf/cf.css" />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="css/dl.css" />



<title>Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction</title>
<style type="text/css"><!--
    body {margin-left: 0em; margin-top: 0}
    a:link {text-decoration: underline; 	Color: #1d4d0f;}
    a:visited  { color: #990033; text-decoration: underline;}
    a:hover {color: red; text-decoration: none}
    a.dLink1:link {color:#336699}
    a.dLink1:visited {color:#666666}
	a.isblack:link {text-decoration: underline; 	Color: #000000;}
    a.isblack:visited  { color: #000000; text-decoration: underline;}
    a.isblack:hover {color: #000000; text-decoration: none}
    h1 {font-size: 140%; margin-bottom: 0}
	ul {margin-top: .25em; list-style-type: disc}
	ol {margin-top: .25em;}
	li {padding-bottom: .25em}
    h2 {color: white; background-color: #069; 
        font-size: 100%; padding-left: 1em;
		margin: 0}
	h3 {color: black; background-color: yellow; 
    	font-size: 100%;
		margin: 0}
	 h4 {color: black; background-color: #99c5e8; 
        font-size: 100%;
		margin: 0}
    hr {color: #39176d;}
    form {margin-top: 10}
    form.xrs {margin-top: 0}
	
	a {text-decoration: none; }
	
	input {font-size: 1em;}
	.chevron {color: #ff0000;}
	.light-blue {color:#336699;}
	.black {color:#000000;}
	
	/* ### standard text styles, smallest to largest ### */
	
	.footer-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .75em; line-height: 1.33em;
		text-indent: -.75 em; margin-left: 2em; margin-right: .75em;}
		
	.footer-copy-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em; line-height: 1.3em;
		margin-left: .75em; margin-right: .75em;}
		
	.small-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; padding-bottom : 2px;
	  	padding-top : 2px;}

	.smallerer-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .65em;}
	.smaller-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em;}		
	.small-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em;}
	.small-textb {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; font-weight: bold;}
	.medium-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em;}
	.mediumb-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em; font-weight: bold;}
	.large-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1.3em;}		
	.instr-text {font-family: Arial, Helvetica, sans-serif;
		color:#666666; font-size: .83em;}
		
	.list-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .83em; line-height: 1.3em;}
	.list-link-btext {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; line-height: 1.3em;}
	
	.searchbox-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;}
	.footer-header-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;
		margin-left: .75em; margin-right: .75em;}
	.medium-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold; line-height: 1em;
		text-indent: -1.25em; margin-left: 2em; margin-right: .75em;}
	
	.text16 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 16px;}
		
	.text14 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 14px;}
	
	.text12 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 12px;}
		
	.text10 {font-family: Arial, Helvetica, sans-serif;
	    color:#000000; font-size: 12px;}
		
	.text9 {font-family: Arial, Helvetica, sans-serif;
	   color:#000000; font-size: 12px;}
	
	.error-text {color:red;}
	
	.small-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: .75em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}

	.medium-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1.3em; line-height: 1.5em;
		margin-left: .75em; margin-right: .75em;}
	
	.medium-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1.5em;
		margin-left: .75em; margin-right: .75em;}

		#side {
			width: 10px;
			float: left;
			margin-left: -1px;
			padding: 2px;
			}
							
		#content {
			padding: 2px;
			margin-left: 25px;
			
		        
		        }
	 .fulltext_lnk {border:0px;
	 				 margin-right: 2px;
					 vertical-align:baseline;
	 				}
	 
	  .leftcoltab { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:530px;  /* for IE5/WIN */
		  width:520px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	  .rightcoltab {
    float: right;
    margin: 0;
    padding: 5px;
    position: relative;
    right: 50px;
    top: 25px;
    width: 350px;
    z-index: 99;
}
	  .centercoltab {
		  position:absolute;
		  padding:0 0px;
		  }
	  .alt {
		background: #ece9d8;
		margin: 0;
		padding: 1px;
		}
		.leftcolc { 
	position:relative;
	top:5px;
	left:5px;
	float:left;
	width:420px;  /* for IE5/WIN */
	width:400px; /* actual value */
	margin:0 0 0px 0;
	padding:5px;
	z-index:100;
	}
.rightcolc {
	position:relative;
	top:0px;
	right:0px;
	float:right;
	margin:0 0px;
	padding:0px;
	width:500px;
	z-index:99;
	}
.centercolc {
	position:absolute;
	padding:0 0px;
	}
	
	.leftcoltabv { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:460px;  /* for IE5/WIN */
		  width:350px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	.rightcoltabv {
		position:relative;
		top:5px;
		right:0px;
		float:right;
		margin:0 0px 0 0;
		padding:15px;
		width:480px;
		z-index:99;
		}
	
  --></style>
 


<script type="text/javascript" src="cfformprotect/js/cffp.js"></script>


<script type="text/javascript">
 function expandcollapse(anchor,whichone) {
	 var inner = document.getElementById(anchor);
	 var theshow = "toShow" + whichone;
 	 var thehide = "toHide" + whichone;
	 var span = document.getElementById(theshow);
     span.style.display = (span.style.display=='inline')?'none':'inline';
     var span = document.getElementById(thehide);
     span.style.display = (span.style.display=='none')?'inline':'none';
     inner.innerHTML = (inner.innerHTML=='collapse')?'expand':'collapse';
    }

  function setDiv() {
	var m = document.getElementById('divmain');
	var mh = m.offsetHeight;
	var t = document.getElementById('divtools');
	var th = t.offsetHeight;
	var tg = document.getElementById('divtags');
	var tgh = tg.offsetHeight;
	var calcheight = mh - th;
	if (tgh > calcheight  ){
	  var x = (th + tgh) - mh;
	  if ( (th + tgh) - mh < 65) {
	  }
	  else {
		 document.getElementById('divtags').innerHTML = ""; 
		 var tg = document.getElementById('divtags');
		 var tgh = tg.offsetHeight;
		 tg.style.height = tgh  + 'px';
	  }
	}
	else {
		tg.style.height = calcheight + 'px';
		document.getElementById('divtags').innerHTML = "";
	}

//  do I need to check after I resize to be sure I didn't go too big?
//	var tg2 = document.getElementById('divtags');
//	var tgh2 = tg.offsetHeight;	
//	if (tgh2 > mh + 65) {
//	  var y = mh + 65;
//	  alert('expanded too much ' + tgh2 + ' should be at most ' + y);
//	  tg.style.height = y + 'px';
//	  document.getElementById('divtags').innerHTML = "";
//	}

  }
</script>

<script type="text/javascript">
 /* <!-- Begin
	if(document.layers || document.all) {
	a = 1;
	setInterval("Jump()", 10);
	}
	function Jump() {
	a = a + 1;
	//self.moveBy((Math.random() * a * 2 - a), (Math.random() * a * 2) - a);
	}
//  End --> */
</script>



<meta name="citation_publisher" content="ACM"> <meta name="citation_authors" content="General Chair-Goodrich, Michael A.; Program Chair-Schultz, Alan C.; Program Chair-Bruemmer, David J."> <meta name="citation_title" content="Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction"> <meta name="citation_date" content="03/02/2006"> <meta name="citation_isbn" content="1-59593-294-1"> <meta name="citation_abstract_html_url" content="http://dl.acm.org/citation.cfm?id=1121241"> 



<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFAJAXPROXY');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFFORM');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFDIV');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFTEXTAREA');
</script>

<script type="text/javascript">
	ColdFusion.Ajax.importTag('CFWINDOW');
</script>

<script type="text/javascript">
	var _cf_window_init_1338241947206=function()
	{
		_cf_bind_init_1338241947207=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'theguide_body','bindExpr':['whatisguide.cfm']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338241947207);var _cf_window=ColdFusion.Window.create('theguide','The ACM Guide to Computing Literature','whatisguide.cfm',{ modal:false, closable:true, divid:'cf_window1338241947205', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338241947206);
</script>

<script type="text/javascript">
	var _cf_window_init_1338241947209=function()
	{
		_cf_bind_init_1338241947210=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'thetags_body','bindExpr':['showthetags.cfm?id=1121241']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338241947210);var _cf_window=ColdFusion.Window.create('thetags','All Tags','showthetags.cfm?id=1121241',{ modal:false, closable:true, divid:'cf_window1338241947208', draggable:true, resizable:true, fixedcenter:true, width:500, height:300, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338241947209);
</script>

<script type="text/javascript">
	var _cf_window_init_1338241947212=function()
	{
		var _cf_window=ColdFusion.Window.create('theformats','Export Formats','',{ modal:false, closable:true, divid:'cf_window1338241947211', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:250, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338241947212);
</script>

<script type="text/javascript">
	var _cf_window_init_1338241947214=function()
	{
		var _cf_window=ColdFusion.Window.create('theexplaination','','',{ modal:false, closable:true, divid:'cf_window1338241947213', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338241947214);
</script>

<script type="text/javascript">
	var _cf_window_init_1338241947216=function()
	{
		var _cf_window=ColdFusion.Window.create('theservices','','',{ modal:false, closable:true, divid:'cf_window1338241947215', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338241947216);
</script>

<script type="text/javascript">
	var _cf_window_init_1338241947218=function()
	{
		_cf_bind_init_1338241947219=function()
		{
			ColdFusion.Bind.register([],{'bindTo':'savetobinder_body','bindExpr':['savetobinder.cfm?id=1121241']},ColdFusion.Bind.urlBindHandler,false);
		};ColdFusion.Event.registerOnLoad(_cf_bind_init_1338241947219);var _cf_window=ColdFusion.Window.create('savetobinder','Save to Binder','savetobinder.cfm?id=1121241',{ modal:false, closable:true, divid:'cf_window1338241947217', draggable:true, resizable:true, fixedcenter:true, width:600, height:600, shadow:true, callfromtag:true, minwidth:300, minheight:250, initshow:false, _cf_refreshOnShow:true});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_1338241947218);
</script>
</head>

<body style="text-align:center" onLoad="window.focus();">

<script type="text/javascript">
						addthis_pub             = 'acm'; 
						//addthis_logo            = 'http://www.addthis.com/images/yourlogo.png';
						addthis_logo            = 'http://dl.acm.org/images/ACM_transparent.png';
						addthis_logo_background = 'c2d5fc';
						addthis_logo_color      = '000000';
						addthis_brand           = 'Citation Page';
						addthis_options         = 'favorites, email, slashdot, citeulike, digg, delicious, twitter, myspace, facebook, google, more';
						</script>
                        
<script src='AC_RunActiveContent.js' type="text/javascript"></script>




<div style="width:940px; margin-left: auto; margin-right: auto; text-align:left">
<a id="CIT"></a>



<table style="table-layout:fixed; margin-top: 5px; margin-bottom: 10px; border:0px; width:100%; border-collapse:collapse;">
	
    <tr style="vertical-align:top">
		
		<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; width:300px" class="small-link-text"  ><img src="http://dl.acm.org/images/ACMDL_Logo.jpg" alt="ACM DL" style="border:0px" usemap="#port" />
		</td>
        
        <td style="padding-left: 5px; padding-right:10px; padding-bottom:0px;" class="small-link-text">
        	<table style="width:100%; border-collapse:collapse; padding:0px">
			<tr><td style="text-align:center">
				
                            <div style="margin:0px auto;color:#356b20;font-size:10pt;line-height:10%;"> </div>
                    
					</td>		
			</tr>
			</table> 
        </td>
		<td style="padding-top: 0px; padding-left: 0px; padding-bottom:0px; text-align:right;" class="small-link-text">
			 <p style="margin-top:0px; margin-bottom:10px;">
					
                            <a href="https://dl.acm.org/signin.cfm?cfid=105752199&amp;cftoken=69273181" class="small-link-text" title="Sign in to personalize your Digital Library experience">SIGN IN</a>
                            &nbsp;&nbsp;<a href="https://dl.acm.org/signin.cfm?cfid=105752199&amp;cftoken=69273181"  class="small-link-text" title="Sign up to personalize your Digital Library experience">SIGN UP</a>
						
			 </p>
            
			<table style="padding: 5px; border-collapse:collapse; float:right">
				
				
                            
                            <tr>
                            <td class="small-link-text" style="text-align:right">
                            <form name="qiksearch" action="results.cfm?h=1&amp;cfid=105752199&amp;cftoken=69273181" method="post">
                           
                           
                            
                                     
                                    <span style="margin-left:0px"><label><input type="text" name="query" size="34" value=" " /></label>&nbsp;
                                    <input style="vertical-align:top;" type="image" alt="Search" name="Go" src="http://dl.acm.org/images/search_small.jpg" />
                                    
                                    </span>
							  </form>
                                </td>
                            </tr>
                          
				  
			</table>

			
			
		</td>

	</tr>
    
    
    <tr><td colspan="3" class="small-link-text" style="padding-bottom:5px; padding-top:0px; text-align:center">
		<div style="margin:0px auto;color:#356b20;line-height:10%;"> </div>
         
         </td>
    </tr>
    </table>
	
<map name="port" id="port" > 
  <area shape="rect" coords="1,1,60,50" href="http://www.acm.org/" alt="ACM Home Page" />
  <area shape="rect" coords="65,1,275,68" href="http://dl.acm.org/dl.cfm?CFID=105752199&CFTOKEN=69273181" alt="ACM Digital Library Home Page" />
</map>

<table style="table-layout:fixed; padding-bottom:10px; width:100%; padding:0px;">
	<tr style="vertical-align:top">
		<td style="padding-right:10px; text-align:left" class="small-link-text">
        	<div id="divmain" style="border:1px solid #356b20;">
				 
				<div class="large-text" style="text-align:left; margin-left:2px;margin-bottom:5px;">
					
                    	<h1 class="mediumb-text" style="margin-top:0px; margin-bottom:0px;"><strong>Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction</strong></h1>
                        
                </div>
                
                  

<table class="medium-text" style="border-collapse:collapse; padding:0px;">

<col style="width:540px" />

<tr style="vertical-align:top">
  <td>
    <table style="border-collapse:collapse; padding:2px;" class="medium-text">
      <col style="width:80px;" />
      <col style="width:auto" />
      <tr style="vertical-align:top">
        
      </tr>
    </table>

	
        <table style="margin-top: 10px; border-collapse:collapse; padding:2px;" class="medium-text">
            <col style="width:80px" />
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             General Chairs:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81350575550&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105752199&amp;cftoken=69273181" title="Author Profile Page" target="_self">Michael A. Goodrich</a>
                
            </td>
            <td valign="bottom">
                
                        <a href="inst_page.cfm?id=1029077&CFID=105752199&CFTOKEN=69273181" title="Institutional Profile Page"><small>Brigham Young University USA</small></a>
                      	
            </td>
            </tr>
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             Program Chairs:
                
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100622960&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105752199&amp;cftoken=69273181" title="Author Profile Page" target="_self">Alan C. Schultz</a>
                
            </td>
            <td valign="bottom">
                
                        <a href="inst_page.cfm?id=1016192&CFID=105752199&CFTOKEN=69273181" title="Institutional Profile Page"><small>Naval Research Laboratory, USA</small></a>
                      	
            </td>
            </tr>
            
            <tr>
            <td  valign="top" nowrap="nowrap">
             
            </td>
            <td valign="top" nowrap="nowrap">
                
                    <a  href="author_page.cfm?id=81100579981&amp;coll=DL&amp;dl=ACM&amp;trk=0&amp;cfid=105752199&amp;cftoken=69273181" title="Author Profile Page" target="_self">David J. Bruemmer</a>
                
            </td>
            <td valign="bottom">
                
                        <small>Idaho National Laboratory, USA</small>
                    	
            </td>
            </tr>
            
        </table>
    
        <table style="margin-top: 10px" border="0" class="medium-text" cellpadding="2" cellspacing="0">
            <tr><td><table border="0" class="medium-text" cellpadding="1" cellspacing="0">

<tr valign="top">
    <td nowrap="nowrap" style="padding-top:10px;">Publication of:</td>
</tr>

	<tr valign="top">
    	<td nowrap="nowrap" style="padding-bottom:0px">&middot;&nbsp;Conference</td>
	</tr>
    <tr valign="top">
	    <td style="padding-left:10px;">
		   <a href="http://www.hri2006.org" title="Conference Website"  target="_self" class="link-text">HRI'06</a> International Conference on Human Robot Interaction 
        </td>
	</tr>
    
    <tr valign="top">
	    <td style="padding-left:10px; padding-bottom:10px"> Salt Lake City, UT, USA &mdash; March 02 - 03, 2006
                    
                  <br />
                    
                  <a href="http://www.acm.org/publications" class="small-link-text" title="ACM">ACM</a> <span class="small-link-text">New York, NY</span><span class="small-link-text">, USA</span> <span class="small-link-text">  &copy;2006</span> 
                  <br />           
                  
      </td>
	</tr>
	 

</table></td></tr>
        </table>
    

  </td>

  <td rowspan="20" nowrap="nowrap">
	<table border="0" class="medium-text" cellpadding="0" cellspacing="0">
		<tr>
        	<td align="center" style="padding-bottom: 5px;">
			  
               <img src="http://portalparts.acm.org/1130000/1121241/thumb/1121241_thumb.jpg" title="Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction" height="100"  width="77" ALT="Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction" /> 
              </td>
              <td valign="top" align="left" nowrap="nowrap">
	             <img src="images/acm_mini.jpg" title="Published by ACM" alt="Published by ACM" /> 2006 Proceeding<br />
                 
        	 </td>
        </tr>
        
        <tr>
        	<td colspan="2" valign="baseline" style="padding-bottom:5px;">
            <img src="img/stats.jpg" alt="Bibliometrics Data" />&nbsp;
            <a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a>
            </td>
         </tr>
         <tr>
            <td  class="small-text" colspan="2" valign="top" style="padding-left:30px;">
				
	                    	&middot;&nbsp;Downloads (6 Weeks): 396<br />
    	                    &middot;&nbsp;Downloads (12 Months): 2,523<br />
                          
                        &middot;&nbsp;Citation Count: 381 
			</td>
         </tr>

	</table>
  </td>
</tr>
</table>

<br clear="all" />

                  
                 <br clear="all" />
			</div>
			
		</td>
		<td style="padding-left: 5px; vertical-align:top; text-align:left; width:170px" class="small-link-text">
	
            <div id="divtools" style="background-color:#ece9d8; text-align:left; padding-top:5px; padding-bottom:5px; ">
              <div class="medium-text" style="margin-left:3px; margin-top:10px;"><h1 class="mediumb-text" style="margin-top:-15px;"><strong>Tools and Resources</strong></h1></div>


<ul title="Tools and Resources" style="list-style: none; list-style-position:inside;
margin-left: 0px;
padding-left: 0em;
text-indent: 5px;
margin-bottom: 0px;">


	
	

		
             <li style="list-style-image:url(img/shopping-cart16.gif);margin-top:10px;">
                  <span style="margin-left:6px;">
                     
                     <a href="https://dl.acm.org/purchase.cfm?id=1121241&CFID=105752199&CFTOKEN=69273181" class="small-link-text">Buy this Proceeding in Print</a>
                  
                  
                  </span>
              </li>
        
	
<li style="list-style-image:url(img/toc_small.gif);margin-top:10px;"><span style="margin-left:6px;">
   <span class="small-link-text">TOC Service:</span>
   	  
	  <img src="http://dl.acm.org/images/blanks.gif" border="0" alt="Spacer Image reserves space for checkmark when TOC Service is updated" name="saved" />
      <ul style="margin-left: 0; padding-left: 0; display:inline;">
      	
        <li style="list-style:none; display:inline"><br /><img src="img/email_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Email</a></li>
        <li style="list-style:none; display:inline"><img src="img/rss_small.gif" alt="Toc Alert via Email" border="0" hspace="3" /><a href="#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');"  class="small-link-text">RSS</a></li>
		        
      </ul>
    </span>
</li>

        <li style="list-style-image:url(img/binder.gif);margin-top:10px;"><span style="margin-left:6px;">
        <a href="citation.cfm?id=1121241&preflayout=flat#" onclick="window.alert('To use this Feature, you must login with your personal ACM Web Account.');" class="small-link-text">Save to Binder</a>
         </span></li>
    




<li style="list-style-image:url(img/binder_green.gif);margin-top:10px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Export Formats:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1121241&expformat=bibtex','theformats');" class="small-link-text">BibTeX</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1121241&expformat=endnotes','theformats');" class="small-link-text">EndNote</a></li>
        <li style="list-style:disc; display:inline; margin-bottom:0px;"><a href="javascript:ColdFusion.Window.show('theformats');ColdFusion.navigate('exportformats.cfm?id=1121241&expformat=acmref','theformats');" class="small-link-text">ACM&nbsp;Ref</a></li>
      </ul>
    </span>
</li>



 
   <li style="list-style-image:url(img/calbullet.jpg);margin-top:15px;"><span style="margin-left:6px; margin-bottom:0px">
   <span class="small-link-text">Upcoming Conference:</span>
      <ul style="margin-left: 0; padding-left: 0; margin-bottom:0px;">
        <li style="list-style:disc; display:inline; margin-bottom:0px; margin-left:25px;"><a href="http://humanrobotinteraction.org/2013/" title="ACM/IEEE International Conference on Human-Robot Interaction" class="small-link-text">HRI'13</a></li>
      </ul>
    </span>
	</li>
    


</ul>           

  <!-- ADDTHIS BUTTON BEGIN -->
  
  <!-- ADDTHIS BUTTON END -->

<p class="small-link-text" style="padding-top: 0px; margin-left:6px; margin-bottom:0px">Share:</p>
  <!-- AddThis Button BEGIN -->



<!-- AddThis Button BEGIN -->
<div style="margin-left:5px;" class="addthis_toolbox addthis_default_style">
<a class="addthis_button_email"></a>
<a class="addthis_button_facebook"></a>
<a class="addthis_button_google"></a>
<a class="addthis_button_twitter"></a>
<a class="addthis_button_slashdot"></a>
<a class="addthis_button_reddit"></a>


<span class="addthis_separator">|</span>
<a href="http://www.addthis.com/bookmark.php?v=250&amp;username=acm" class="addthis_button_expanded" title="more"></a>
</div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#username=acm"></script>
<!-- AddThis Button END -->

  
 

  
  
            </div>
            
		</td>
	</tr>
    
</table>



</div>


<div class="layout" style="width:940px; margin-left: auto; margin-right: auto; text-align:left">




<div id="fback" style="text-align:left; padding-top:10px; padding-bottom:20px">
<span class="small-text" style="padding-right:10px; margin-bottom:0px;">
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design" style=" vertical-align:middle"><img src="img/feedbackg.gif" width="20" height="19" alt="feedback" border="0" /></a>
<a title="feedback" href="mailto:portal-feedback@hq.acm.org?subject=Comments_on_new_design"><strong>Feedback</strong></a>

<span style="padding:10px;">|</span>




<span>Switch to <a href="citation.cfm?id=1121241&amp;preflayout=tabs">tabbed view</a> <noscript> (javascript required)</noscript></span>


</span>

 
<div class="small-text" style="margin-top:10px; margin-bottom:5px;"> 
<br />

    <a href="#abstract"  title="Abstract" style="padding:5px"><span>Abstract</span></a> |
    
    <a href="#formats"  title="Source Materials" style="padding:5px"><span>Source Materials</span></a> |
    
    <a href="#authors"  title="Authors" style="padding:5px"><span>Authors</span></a> |
    <a href="#references"  title="References" style="padding:5px"><span style='color:#999999'>References</span></a> |
    <a href="#citedby"  title="Cited By" style="padding:5px"><span>Cited By</span></a> |
    <a href="#indexterms"  title="Index Terms" style="padding:5px"><span style='color:#999999'>Index Terms</span></a> |
    <a href="#source"  title="Publication" style="padding:5px"><span>Publication</span></a> |
    <a href="#revs"  title="Reviews" style="padding:5px"><span style='color:#999999'>Reviews</span></a> |               
	<a href="#comments"  title="Comments" style="padding:5px"><span>Comments</span></a>
	
     |               
	<a href="#prox"  title="Table of Contents" style="padding:5px"><span>Table of Contents</span></a>
    
</div>
    
<div style="right: 0pt; border-top:1px solid #356b20; font-size:1px; margin-bottom:20px;"/>



</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="abstract" class="small-text">ABSTRACT</A></h1>
       	
			<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

			

		
			
           
			
				
				<p>
					<div style="display:inline">It is our great pleasure to welcome you to the first <i>ACM SIGCHI/SIGART Conference on Human-Robot Interaction -- HRI'06</i>. This year's inaugural conference is the first step toward becoming the premier interdisciplinary forum for the presentation of research results on leading edge issues of human robot interaction. The three goals of the conference are to promote the inherently interdisciplinary field of HRI, to provide a single track forum for the dissemination of excellent research in the field, and to provide high quality evaluations of mature and emerging research. <i>HRI'06</i> gives researchers and practitioners a unique opportunity to share their perspectives with others interested in the various aspects of human robot interaction.</div>
				</p>
   				
           	</div>
			
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="formats" class="small-text"><SPAN class="heading">SOURCE MATERIALS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


  <div class="abstract">
        <SPAN><strong>FRONT MATTER</strong></span>
  </div>
  <div style="margin-left:10px; line-height:180%;">
      
          <A NAME="FullText" HREF="http://portalparts.acm.org/1130000/1121241/fm/frontmatter.pdf?ip=188.194.239.219&CFID=105752199&CFTOKEN=69273181" title="PDF" target="_blank">
          <img src="http://dl.acm.org/imagetypes/pdf_logo.gif" alt="PDF" border="0" align="middle" style="margin-right: 2px">PDF</A>
          &nbsp;(title page, copyright, welcome, contents, organization, additional reviewers, sponsors) 
  </div>          
  
  <div style="margin-top: 10px;"  class="abstract">
        <SPAN><strong>BACK MATTER</strong></span>
  </div>
  <div style="margin-left:10px; line-height:180%;">
      
          <A NAME="FullText" HREF="http://portalparts.acm.org/1130000/1121241/bm/backmatter.pdf?ip=188.194.239.219&CFID=105752199&CFTOKEN=69273181" title="PDF" target="_blank">
          <img src="http://dl.acm.org/imagetypes/pdf_logo.gif" alt="PDF" border="0" align="middle" style="margin-right: 2px">PDF</A>
          &nbsp;(author index) 
  </div>          
  
<div style="margin-top: 10px; height: auto; padding: 5px; ">
		
		
        


	</div>

<br clear="all" />
</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="authors" class="small-text"><SPAN class="heading">AUTHORS</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<dl title="Authors" style="margin-top:0px">




<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 General Chairs 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="http://portalparts.acm.org/profiles/81350575550/GoodrichMichael08.jpg" border="0" align="middle" alt="Michael A. Goodrich" hspace="5" />
		 
		  
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" >
	<span class="small-text"><strong><a title="author page of Michael A. Goodrich" href="author_page.cfm?id=81350575550&CFID=105752199&CFTOKEN=69273181">Michael A. Goodrich</a></strong><br /></span>
	
	<div style="margin-top: 6px" class="small-text">mike<img src="gifs/at.gif" width="12" height="12" alt="at" />cs.byu.edu</div>
	
	
	
	<span class="small-text">
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1999-2012</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">27</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">122</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">14</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">106</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">911</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Michael A. Goodrich" href="author_page.cfm?id=81350575550&amp;dsp=coll&amp;trk=1&amp;CFID=105752199&CFTOKEN=69273181" target="_self">View colleagues</a> of Michael A. Goodrich
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              



<dt style="float: left; clear: left; width: 100%; margin-top: 0px; margin-bottom: 0px;">
 <strong>
 Program Chairs 
  </strong>
 </dt> 
          
          <dd style="margin: 0 0 0 60px; padding: 0 0 0.5em 0;">
			
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of Alan C. Schultz" href="author_page.cfm?id=81100622960&CFID=105752199&CFTOKEN=69273181">Alan C. Schultz</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">1986-2009</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">32</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">220</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">5</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">54</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">545</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of Alan C. Schultz" href="author_page.cfm?id=81100622960&amp;dsp=coll&amp;trk=1&amp;CFID=105752199&CFTOKEN=69273181" target="_self">View colleagues</a> of Alan C. Schultz
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
								<span>
									
                                    <br><br />
                                    
                                        <table border="0" cellspacing="10">
                                        <tr><td><table border="0" width="300"  cellpadding="0" cellspacing="0">
<col width="120">
<col width="180">
<tr valign="top">

	<td bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px">
		
			<img src="gifs/ProfileSilhouette.gif" alt="Author image not provided" align="middle" hspace="5">
		
	</td>

<td  bgcolor="#cccccc" style="padding-bottom: 5px; padding-top: 5px" colspan="2">
	&nbsp;<span class="small-text"><strong><a title="author page of David J. Bruemmer" href="author_page.cfm?id=81100579981&CFID=105752199&CFTOKEN=69273181">David J. Bruemmer</a></strong><br /></span>
	
	
	
	<span class="small-text"><br><p style="margin-bottom:-10px;" align="center">No contact information provided yet.</p>
	
	
			
	
	</span>
	
	
	
</td>
</tr>


</table></td>
                                            <td><table border="0" width="300" cellpadding="0" cellspacing="0">

<tr>

	<td><strong><a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=1','theexplaination');" title="Bibliometrics: explained">Bibliometrics</a></strong>:&nbsp;publication history<br />
		
        <table width="90%" style="margin-top: 1px; margin-bottom: 10px" border="0" align="left">
			<tr>
				<td class="smaller-text">Publication years</td><td class="small-text" align="right">2000-2008</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Publication count</td><td class="small-text" align="right">11</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Citation Count</td><td class="small-text" align="right">26</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text" style="border-bottom: 2">Available for download</td><td class="small-text" align="right">5</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
			<tr>
				<td class="smaller-text">Downloads (6 Weeks)</td><td class="small-text" align="right">16</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
			<tr>
				<td class="smaller-text">Downloads (12 Months)</td><td class="small-text" align="right">71</td>
			</tr>
			<tr><td height="1" bgcolor="#808080" colspan="2"></td></tr>
 			
		</table>
	</td>
	
</tr>

</table></td>
                                        </tr>
                                        <tr><td style="padding:0px">
                                                    <a title="colleagues of David J. Bruemmer" href="author_page.cfm?id=81100579981&amp;dsp=coll&amp;trk=1&amp;CFID=105752199&CFTOKEN=69273181" target="_self">View colleagues</a> of David J. Bruemmer
                                            </td>
                                         </tr>
                                        </table>
                                     
								</span>
					
			</dd>
                              

</dl>
</div>

		  
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="references" class="small-text"><SPAN class="heading">REFERENCES</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	References are not available

</div>

<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="citedby" class="small-text"><SPAN class="heading">CITED BY</SPAN></A></h1>
		
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

			
			
			
			<table cellpadding="5">
			
				<tr valign="top">
				<td valign="top">
					
					&nbsp;
				</td>
				<td>
					<div>
						
						<a href="citation.cfm?id=1348100&CFID=105752199&CFTOKEN=69273181">
						Michael A. Goodrich , Alan C. Schultz, Human-robot interaction: a survey, Foundations and Trends in Human-Computer Interaction, v.1 n.3, p.203-275, January 2007
						</a>
					</div>  
					
				</td>
				</tr>
			
			</table>
			
 </div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="indexterms" class="small-text"><SPAN class="heading">INDEX TERMS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

Index Terms are not available


</div>


<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="source" class="small-text"><SPAN class="heading">PUBLICATION</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">



<table border="0" class="medium-text" cellpadding="0" cellspacing="5">



    <tr valign="top">
    	<td>Title</td> 
	    <td>
		   <a href="http://www.hri2006.org" title="Conference Website"  target="_self" class="link-text">HRI'06</a> International Conference on Human Robot Interaction 
        </td>
	</tr>
    <tr><td></td><td>Salt Lake City, UT, USA &mdash; March 02 - 03, 2006</td></tr> <tr><td>Pages</td><td>364</td></tr> 
                 <tr>
                 
                     <td>Sponsors</td>
                    
                  <td>
                  <a href="sig.cfm?id=SP918&CFID=105752199&CFTOKEN=69273181"> SIGART</a> ACM Special Interest Group on Artificial Intelligence
                  </td>
                  </tr>
              
                 <tr>
                 
                      <td></td>
                  
                  <td>
                  <a href="sig.cfm?id=SP923&CFID=105752199&CFTOKEN=69273181"> SIGCHI</a> ACM Special Interest Group on Computer-Human Interaction
                  </td>
                  </tr>
              
                 <tr>
                 
                      <td></td>
                  
                  <td>
                  <a href="http://www.acm.org/"> ACM</a> Association for Computing Machinery
                  </td>
                  </tr>
              
                  <tr><td>Publisher</td><td><a href="http://www.acm.org/publications">ACM</a> New York, NY, USA</td>
				  </tr>
             <tr><td>ISBN</td><td>1-59593-294-1 </td></tr> <tr><td>Order Number</td><td>609063</td></tr> 
			<tr valign="top">
        	<td>Conference</td>
            <td valign="top" align="left"  style="padding-bottom: 25px;">
	            <strong style="padding-right:10px">HRI</strong><a href="event.cfm?id=RE285&CFID=105752199&CFTOKEN=69273181" title="ACM/IEEE International Conference on Human-Robot Interaction">ACM/IEEE International Conference on Human-Robot Interaction</a>
                
                       
                        <a href="event.cfm?id=RE285&CFID=105752199&CFTOKEN=69273181" title="ACM/IEEE International Conference on Human-Robot Interaction"><img border="0" src="http://portalparts.acm.org/event_logos/677/677.jpg" title="HRI logo" height="62"  width="100" ALT="HRI logo" style="vertical-align:top"></a>
						 

        	 </td>
            </tr>
		    <tr><td colspan="2">Paper Acceptance Rate 41 of 140 submissions, 29%</td></tr> <tr valign="top"><td style="pading-top:20px;" colspan="2">Overall Acceptance Rate 227 of 905 submissions, 25%</td></tr>
                       <tr valign="top">
                        <td colspan="2" style="padding-left:25px;">
                        	<table>
                            	<tr><td>
                                        <!-- WebCharts3D v5.1(2077) -->
<IMG SRC="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=Images/5224726220525680.JPG" id="Images_5224726220525680_JPG" name="Images_5224726220525680_JPG" usemap="#Images_5224726220525680_JPG_map" border="0"/>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAB' id='GP1338241947743AAAB'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '06</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>140</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAC' id='GP1338241947743AAAC'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '06</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>41</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAD' id='GP1338241947743AAAD'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '07</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>101</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAE' id='GP1338241947743AAAE'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '07</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>22</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAF' id='GP1338241947743AAAF'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '08</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>134</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAG' id='GP1338241947743AAAG'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '08</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>48</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAH' id='GP1338241947743AAAH'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '09</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>120</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAI' id='GP1338241947743AAAI'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '09</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>23</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAJ' id='GP1338241947743AAAJ'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '10</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>124</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAK' id='GP1338241947743AAAK'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '10</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>26</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAL' id='GP1338241947743AAAL'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '11</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>149</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAM' id='GP1338241947743AAAM'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '11</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>33</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAN' id='GP1338241947743AAAN'><tr><td width='8'>&nbsp;</td><td width='62'>Submitted</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>HRI '12</td></tr><tr><td width='8'>&nbsp;</td><td width='62'>137</td></tr></table>
<table cellpadding='0' cellspacing='1' style='visibility: hidden;display: none; position:absolute;font-family: Dialog;font-size: 11px;background:#FFFFFF;foreground:#333333;color:#333333;-moz-opacity:.78;-opacity:.78;filter:alpha(opacity=78);border:1px solid #333333;' name='GP1338241947743AAAO' id='GP1338241947743AAAO'><tr><td width='8'>&nbsp;</td><td width='58'>Accepted</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>HRI '12</td></tr><tr><td width='8'>&nbsp;</td><td width='58'>34</td></tr></table>
<MAP name='Images_5224726220525680_JPG_map'>
<AREA shape='rect' coords='0,0,1,1'/>
<AREA shape="rect" coords="293,179,309,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAO",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAO",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAO",event)'/>
<AREA shape="rect" coords="277,74,293,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAN",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAN",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAN",event)'/>
<AREA shape="rect" coords="253,180,269,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAM",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAM",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAM",event)'/>
<AREA shape="rect" coords="237,62,253,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAL",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAL",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAL",event)'/>
<AREA shape="rect" coords="213,187,229,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAK",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAK",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAK",event)'/>
<AREA shape="rect" coords="197,87,213,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAJ",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAJ",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAJ",event)'/>
<AREA shape="rect" coords="173,190,189,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAI",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAI",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAI",event)'/>
<AREA shape="rect" coords="157,91,173,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAH",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAH",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAH",event)'/>
<AREA shape="rect" coords="133,165,149,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAG",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAG",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAG",event)'/>
<AREA shape="rect" coords="117,77,133,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAF",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAF",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAF",event)'/>
<AREA shape="rect" coords="93,191,109,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAE",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAE",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAE",event)'/>
<AREA shape="rect" coords="77,111,93,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAD",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAD",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAD",event)'/>
<AREA shape="rect" coords="53,172,69,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAC",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAC",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAC",event)'/>
<AREA shape="rect" coords="37,71,53,213" onMouseover='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAB",event,true)' onMouseout='xx_set_visible("Images_5224726220525680_JPG","GP1338241947743AAAB",event,false)' onMousemove='xx_move_tag("Images_5224726220525680_JPG","GP1338241947743AAAB",event)'/>
<AREA shape="rect" coords="160,13,227,27"/>
<AREA shape="rect" coords="89,13,160,27"/>
</MAP>

<script language="javascript" src="/CFIDE/GraphData.cfm?graphCache=wc50&graphID=script.js"></script>

                                      </td>
                                      <td style="padding-left:20px;">
                                             <table style="border-width: 1px; border-style: solid; width:100%;  border-spacing: 6px;" class="text12">
                                                <tr bgcolor="#ffffff">
                                                  <th style="width:50%">Year</th>
                                                  <th  align="right" style="width:15%">Submitted</th>
                                                  <th  align="right" style="width:15%">Accepted</th>
                                                  <th  align="center">Rate</th>
                                                </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '06</td>
                                                            <td align="right">140</td>
                                                            <td align="right">41</td>
                                                            <td align="center">29%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>HRI '07</td>
                                                            <td align="right">101</td>
                                                            <td align="right">22</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '08</td>
                                                            <td align="right">134</td>
                                                            <td align="right">48</td>
                                                            <td align="center">36%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>HRI '09</td>
                                                            <td align="right">120</td>
                                                            <td align="right">23</td>
                                                            <td align="center">19%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '10</td>
                                                            <td align="right">124</td>
                                                            <td align="right">26</td>
                                                            <td align="center">21%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#ffffff">
                                                            <td>HRI '11</td>
                                                            <td align="right">149</td>
                                                            <td align="right">33</td>
                                                            <td align="center">22%</td>
                                                         </tr>
                                                
                                                        <tr bgcolor="#f0f0f0">
                                                            <td>HRI '12</td>
                                                            <td align="right">137</td>
                                                            <td align="right">34</td>
                                                            <td align="center">25%</td>
                                                         </tr>
                                                
                                                 <tr bgcolor="#ffffff">
                                                    <td><strong>Overall</strong></td>
                                                    <td align="right">905</td>
                                                    <td align="right">227</td>
                                                    <td align="center">25%</td>
                                                  </tr>
                                                </table>
                                       </td>
                                     </tr>
                               </table>
                        </td>
                    </tr>
                     
                     
            
</table>


</table>




</div>
<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="revs" class="small-text"><SPAN class="heading">REVIEWS</SPAN></A></h1>
        
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">

    	<br />Reviews are not available for this item
        
        <div align="left" style="margin-top:30px">
					<a title="Computing Reviews" href="ocr_review_main.cfm?CFID=105752199&CFTOKEN=69273181">
                 <img src="http://dl.acm.org/images/ocrs-s.jpg" alt="Computing Reviews logo" border="0" style="vertical-align:middle"></a>
        
        
       		<ul style="list-style:disc; display:inline-block">
	            <li>Access <a href="ocr_review_main.cfm?CFID=105752199&CFTOKEN=69273181" target="_blank">critical reviews</a> of computing literature.</li>
            	<li><a href="http://www.computingreviews.com/Reviewer/"  target="_blank">Become a reviewer</a> for Computing Reviews</li>
            </ul>
        </div>
        
</div>



<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="comments" class="small-text"><SPAN class="heading">COMMENTS</SPAN></A></h1>
         
<div style="margin-left:10px; margin-top:0px; margin-right:10px; margin-bottom: 10px;" class="flatbody">


<div>
<div>
	
	<p style="margin-left:5px;">
    <strong>Be the first to comment</strong>
    	
          	To Post a comment please <a href="signin.cfm?CFID=105752199&CFTOKEN=69273181">sign in or create</a> a free Web account</a>
        
    
    
	 </p>
	   	
 
</div>


</div>

	
		<h1 class="mediumb-text"><A HREF="#CIT"><img name="top" src="http://dl.acm.org/images/arrowu.gif" alt="top of page" hspace="10" border="0"></A><A NAME="prox" class="small-text">Table of Contents</A></h1>
        
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" >

<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction</h5>


<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>

<div style="clear:both">
    
        <div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><span class="link-text">no previous proceeding</span> <span style="padding-left:5px;padding-right:5px;">|</span><a href="citation.cfm?id=1228716&picked=prox&CFID=105752199&CFTOKEN=69273181" title="Next: HRI '07">next proceeding <img align="absmiddle" hspace="5" border="0" src="img/next.gif" width="19" height="11" alt="next" /></a></div>
        
</div>


 
<table class="text12" border="0">

  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=1121242&CFID=105752199&CFTOKEN=69273181">The law of stretched systems in action: exploiting robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          
                        <a href="author_page.cfm?id=81100369616&CFID=105752199&CFTOKEN=69273181">David D. Woods</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">Pages: 1 - 1</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121242" title="DOI">10.1145/1121241.1121242</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:0">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121242&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:0">
          <span id="toShow1" style="display:inline;"><br /><div style="display:inline">Robotic systems represent new capabilities that justifiably excite technologists and problem holders in many areas. But what affordances do the new capabilities represent and how will problem holders and practitioners exploit these capabilities as they ...</div></span>
          <span id="toHide1" style="display:none;"><br /><div style="display:inline">Robotic systems represent new capabilities that justifiably excite technologists and problem holders in many areas. But what affordances do the new capabilities represent and how will problem holders and practitioners exploit these capabilities as they struggle to meet performance demands and resource pressures? Discussions of the impact of new robotic technology typically mistake new capabilities for affordances in use. The dominate note is that robots as autonomous agents will revolutionize human activity. This is a fundamental oversimplification (see Feltovich et al., 2001) as past research has shown that advances in autonomy (an intrinsic capability) have turned out to demand advances in support for coordinated activity (extrinsic affordances). The Law of Stretched Systems captures the co-adaptive dynamic that human leaders under pressure for higher and more efficient levels of performance will exploit new capabilities to demand more complex forms of work (Woods and Dekker, 2000; Woods and Hollnagel, 2006). This law provides a guide to use past findings on the reverberations of technology change to project how effective leaders and operators will exploit the capabilities of future robotic systems. When one applies the Law of Stretched Systems to new robotic capabilities for demanding work settings, one begins to see new stories about how problem holders work with and through robotic systems to accomplish goals. These are not stories about machine autonomy and the substitution myth. Rather, the new capabilities trigger the exploration of new story lines about future operations that concern: <ul> <li> how to coordinate activities over wider ranges,</li> <li> how to expand our perception and action over larger spans through remote devices, and</li> <li> how to project our intent into distant situations to achieve our goals.</li></ul>.</div></span> <a id="expcoll1" href="JavaScript: expandcollapse('expcoll1',1)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:0"><a href="citation.cfm?id=1121243&CFID=105752199&CFTOKEN=69273181">Every body is somebody: The psychology and design of embodiment</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          
                        <a href="author_page.cfm?id=81100153283&CFID=105752199&CFTOKEN=69273181">Clifford Nass</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">Pages: 2 - 2</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:0">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121243" title="DOI">10.1145/1121241.1121243</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:0">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121243&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:0">
          <span id="toShow2" style="display:inline;"><br /><div style="display:inline">There is a long tradition in psychology asking the question, "how does a body affect how people think and respond?" There is a much smaller literature addressing the question, "how does having a body affect how people think about us and respond to us?" ...</div></span>
          <span id="toHide2" style="display:none;"><br /><div style="display:inline">There is a long tradition in psychology asking the question, "how does a body affect how people think and respond?" There is a much smaller literature addressing the question, "how does having a body affect how people think about us and respond to us?" In this talk, I will discuss a series of experimental studies that are guided by the idea that an understanding of people's responses to other people can guide research on human-robot interaction. Questions to be addressed include: When should a robot say "I"? Should robots have body parts that do not operate like human body parts? When should robots use synthetic speech as compared to recorded speech? How should teams of robots interact with teams of people? How should robots respond to human error and their own errors? For each study, I will describe theory, methods, results, and application to design.</div></span> <a id="expcoll2" href="JavaScript: expandcollapse('expcoll2',2)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Metrics and work study practices</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          David Kaber 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121245&CFID=105752199&CFTOKEN=69273181">Daily HRI evaluation at a classroom environment: reports from dance interaction experiments</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310501100&CFID=105752199&CFTOKEN=69273181">Fumihide Tanaka</a>, 
                        <a href="author_page.cfm?id=81100053278&CFID=105752199&CFTOKEN=69273181">Javier R. Movellan</a>, 
                        <a href="author_page.cfm?id=81310502562&CFID=105752199&CFTOKEN=69273181">Bret Fortenberry</a>, 
                        <a href="author_page.cfm?id=81100046267&CFID=105752199&CFTOKEN=69273181">Kazuki Aisaka</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3 - 9</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121245" title="DOI">10.1145/1121241.1121245</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121245&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow4" style="display:inline;"><br /><div style="display:inline">The design and development of social robots that interact and assist people in daily life requires moving into unconstrained daily-life environments. This presents unexplored methodological challenges to robotic researchers. Is it possible, for example, ...</div></span>
          <span id="toHide4" style="display:none;"><br /><div style="display:inline">The design and development of social robots that interact and assist people in daily life requires moving into unconstrained daily-life environments. This presents unexplored methodological challenges to robotic researchers. Is it possible, for example, to perform useful experiments in the uncontrolled conditions of everyday life environments? How long do these studies need to be to provide reliable results? What evaluations methods can be used?In this paper we present preliminary results on a study designed to evaluate an algorithm for social robots in relatively uncontrolled, daily life conditions. The study was conducted as part of the RUBI project, whose goal is to design and develop social robots by immersion in the environment in which the robots are supposed to operate. First we found that in spite of the relative chaotic conditions and lack of control existing in the daily activities of a child-care center, it is possible to perform experiments in a relatively short period of time and with reliable results. We found that continuous audience response methods borrowed from marketing research provided good inter-observer reliabilities, in the order of 70%, and temporal resolution (the cut-off frequency is in the order of 1 cycle per minute) at low cost (evaluation is performed continuously in real time). We also experimented with objective behavioral descriptions, like tracking children's movement across a room. These approaches complemented each other and provided a useful picture of the temporal dynamics of the child-robot interaction, allowing us to gather baseline data for evaluating future systems. Finally, we also touch the ongoing study of behavior analysis through 3 months long-term child-robot interaction.</div></span> <a id="expcoll4" href="JavaScript: expandcollapse('expcoll4',4)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121246&CFID=105752199&CFTOKEN=69273181">Development of a test bed for evaluating human-robot performance for explosive ordnance disposal robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100426546&CFID=105752199&CFTOKEN=69273181">Jean Scholtz</a>, 
                        <a href="author_page.cfm?id=81100484348&CFID=105752199&CFTOKEN=69273181">Mary Theofanos</a>, 
                        <a href="author_page.cfm?id=81100304540&CFID=105752199&CFTOKEN=69273181">Brian Antonishek</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 10 - 17</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121246" title="DOI">10.1145/1121241.1121246</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121246&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow5" style="display:inline;"><br /><div style="display:inline">This paper discusses the development of a test bed to evaluate the combined performance of the human operator and an explosive ordnance disposal robot. We have other means of evaluating the capabilities of the robots but for the robots to be truly useful ...</div></span>
          <span id="toHide5" style="display:none;"><br /><div style="display:inline">This paper discusses the development of a test bed to evaluate the combined performance of the human operator and an explosive ordnance disposal robot. We have other means of evaluating the capabilities of the robots but for the robots to be truly useful it is necessary to understand how effectively and efficiently operators will be able to use these robots in critical situations. In this paper we discuss the tasks developed for the test bed and how we are going about development of the metrics for assessing the human-robot performance and, more specifically, the human-robot user interface.</div></span> <a id="expcoll5" href="JavaScript: expandcollapse('expcoll5',5)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121247&CFID=105752199&CFTOKEN=69273181">Searching for a quantitative proxy for rover science effectiveness</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310499866&CFID=105752199&CFTOKEN=69273181">Erin Pudenz</a>, 
                        <a href="author_page.cfm?id=81100409807&CFID=105752199&CFTOKEN=69273181">Geb Thomas</a>, 
                        <a href="author_page.cfm?id=81310502143&CFID=105752199&CFTOKEN=69273181">Justin Glasgow</a>, 
                        <a href="author_page.cfm?id=81100456679&CFID=105752199&CFTOKEN=69273181">Peter Coppin</a>, 
                        <a href="author_page.cfm?id=81100412265&CFID=105752199&CFTOKEN=69273181">David Wettergreen</a>, 
                        <a href="author_page.cfm?id=81416605027&CFID=105752199&CFTOKEN=69273181">Nathalie Cabrol</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 18 - 25</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121247" title="DOI">10.1145/1121241.1121247</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121247&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow6" style="display:inline;"><br /><div style="display:inline">During two weeks of study in September and October of 2004, a science team directed a rover and explored the arid Atacama Desert in Chile. The objective of the mission was to search for life. Over the course of the mission the team gained experience ...</div></span>
          <span id="toHide6" style="display:none;"><br /><div style="display:inline">During two weeks of study in September and October of 2004, a science team directed a rover and explored the arid Atacama Desert in Chile. The objective of the mission was to search for life. Over the course of the mission the team gained experience with the rover and the rover became more reliable and autonomous. As a result, the rover/operator system became more effective. Several factors likely contributed to the improvement in science effectiveness including increased experience, more effective search strategies, different science team composition, different science site locations, changes in rover operational capabilities, and changes in the operation interface. However, it is difficult to quantify this effectiveness because science is a largely creative and unstructured task. This study considers techniques that quantify science team performance leading to an understanding of which features of the human-rover system are most effective and which features need further development. Continuous observation of the scientists throughout the mission led to coded transcripts enumerating each scientific statement. This study considers whether six variables correlate with scientific effectiveness. Several of these variables are metrics and ratios related to the daily rover plan, the time spent programming the rover, the number of scientific statements made and the data returned. The results indicate that the scientists created more complex rover plans without increasing the time to create the plans. The total number of scientific statements was approximately equal (2187 versus 2415) for each week. There was a 50% reduction in bytes of returned data between the two weeks resulting in an increase in scientific statements per byte of returned data ratio. Of the original six, the most successful proxies for science effectiveness were the time to program each rover task and the number of scientific statements related to data delivered by the rover. Although both these measures have face validity and were consistent with the results of this experiment, their ultimate empirical utility must be measured further.</div></span> <a id="expcoll6" href="JavaScript: expandcollapse('expcoll6',6)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121248&CFID=105752199&CFTOKEN=69273181">Human control of multiple unmanned vehicles: effects of interface type on execution and task switching times</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100536763&CFID=105752199&CFTOKEN=69273181">Peter Squire</a>, 
                        <a href="author_page.cfm?id=81310500426&CFID=105752199&CFTOKEN=69273181">Greg Trafton</a>, 
                        <a href="author_page.cfm?id=81100507913&CFID=105752199&CFTOKEN=69273181">Raja Parasuraman</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 26 - 32</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121248" title="DOI">10.1145/1121241.1121248</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121248&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow7" style="display:inline;"><br /><div style="display:inline">The number and type of unmanned vehicles sought in military operations continues to grow. A critical consideration in designing these systems is identifying interface types or interaction schemes that enhance an operator's ability to supervise multiple ...</div></span>
          <span id="toHide7" style="display:none;"><br /><div style="display:inline">The number and type of unmanned vehicles sought in military operations continues to grow. A critical consideration in designing these systems is identifying interface types or interaction schemes that enhance an operator's ability to supervise multiple unmanned vehicles. Past research has explored how interface types impact overall performance measures (e.g. mission execution time), but has not extensively examined other human performance factors that might influence human-robot interaction. Within a dynamic military environment, it is particularly important to assess how interfaces impact an operator's ability to quickly adapt and alter the unmanned vehicle's tasking. To assess an operator's ability to confront this changing environment, we explored the impact of interface type on task switching. Research has shown performance costs (i.e. increased time response) when individuals switch between different tasks. Results from this study suggest that this task switching effect is also seen when participants controlling multiple unmanned vehicles switch between different strategies. Results also indicate that when utilizing a flexible delegation interface, participants did not incur as large a switch cost effect as they did when using an interface that allowed only the use of fixed automated control of the unmanned vehicles.</div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121249&CFID=105752199&CFTOKEN=69273181">Common metrics for human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100236968&CFID=105752199&CFTOKEN=69273181">Aaron Steinfeld</a>, 
                        <a href="author_page.cfm?id=81455605555&CFID=105752199&CFTOKEN=69273181">Terrence Fong</a>, 
                        <a href="author_page.cfm?id=81100400562&CFID=105752199&CFTOKEN=69273181">David Kaber</a>, 
                        <a href="author_page.cfm?id=81100349943&CFID=105752199&CFTOKEN=69273181">Michael Lewis</a>, 
                        <a href="author_page.cfm?id=81100426546&CFID=105752199&CFTOKEN=69273181">Jean Scholtz</a>, 
                        <a href="author_page.cfm?id=81100622960&CFID=105752199&CFTOKEN=69273181">Alan Schultz</a>, 
                        <a href="author_page.cfm?id=81350575550&CFID=105752199&CFTOKEN=69273181">Michael Goodrich</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 33 - 40</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121249" title="DOI">10.1145/1121241.1121249</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121249&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow8" style="display:inline;"><br /><div style="display:inline">This paper describes an effort to identify common metrics for task-oriented human-robot interaction (HRI). We begin by discussing the need for a toolkit of HRI metrics. We then describe the framework of our work and identify important biasing factors ...</div></span>
          <span id="toHide8" style="display:none;"><br /><div style="display:inline">This paper describes an effort to identify common metrics for task-oriented human-robot interaction (HRI). We begin by discussing the need for a toolkit of HRI metrics. We then describe the framework of our work and identify important biasing factors that must be taken into consideration. Finally, we present suggested common metrics for standardization and a case study. Preparation of a larger, more detailed toolkit is in progress.</div></span> <a id="expcoll8" href="JavaScript: expandcollapse('expcoll8',8)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Programming and OS issues in HRI</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Reid Simmons 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121251&CFID=105752199&CFTOKEN=69273181">The human-robot interaction operating system</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81455605555&CFID=105752199&CFTOKEN=69273181">Terrence Fong</a>, 
                        <a href="author_page.cfm?id=81100548664&CFID=105752199&CFTOKEN=69273181">Clayton Kunz</a>, 
                        <a href="author_page.cfm?id=81336489732&CFID=105752199&CFTOKEN=69273181">Laura M. Hiatt</a>, 
                        <a href="author_page.cfm?id=81350575902&CFID=105752199&CFTOKEN=69273181">Magda Bugajska</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 41 - 48</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121251" title="DOI">10.1145/1121241.1121251</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121251&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow10" style="display:inline;"><br /><div style="display:inline">In order for humans and robots to work effectively together, they need to be able to converse about abilities, goals and achievements. Thus, we are developing an interaction infrastructure called the ``Human-Robot Interaction Operating System'' (HRI/OS). ...</div></span>
          <span id="toHide10" style="display:none;"><br /><div style="display:inline">In order for humans and robots to work effectively together, they need to be able to converse about abilities, goals and achievements. Thus, we are developing an interaction infrastructure called the ``Human-Robot Interaction Operating System'' (HRI/OS). The HRI/OS provides a structured software framework for building human-robot teams, supports a variety of user interfaces, enables humans and robots to engage in task-oriented dialogue, and facilitates integration of robots through an extensible API.</div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121252&CFID=105752199&CFTOKEN=69273181">Developer oriented visualisation of a robot program</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310501104&CFID=105752199&CFTOKEN=69273181">T. H. J. Collett</a>, 
                        <a href="author_page.cfm?id=81100637144&CFID=105752199&CFTOKEN=69273181">B. A. MacDonald</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 49 - 56</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121252" title="DOI">10.1145/1121241.1121252</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121252&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow11" style="display:inline;"><br /><div style="display:inline">Robot programmers are faced with the challenging problem of understanding the robot's view of its world, both when creating and when debugging robot software. As a result tools are created as needed in different laboratories for different robots and ...</div></span>
          <span id="toHide11" style="display:none;"><br /><div style="display:inline">Robot programmers are faced with the challenging problem of understanding the robot's view of its world, both when creating and when debugging robot software. As a result tools are created as needed in different laboratories for different robots and different applications. We discuss the requirements for effective interaction under these conditions, and propose an augmented reality approach to visualising robot input, output and state information, including geometric data such as laser range scans, temporal data such as the past robot path, conditional data such as possible future robot paths, and statistical data such as localisation distributions. The visualisation techniques must scale appropriately as robot data and complexity increases. Our current progress in developing a robot visualisation toolkit is presented.</div></span> <a id="expcoll11" href="JavaScript: expandcollapse('expcoll11',11)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121253&CFID=105752199&CFTOKEN=69273181">Usability evaluation of an automated mission repair mechanism for mobile robot mission specification</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502896&CFID=105752199&CFTOKEN=69273181">Lilia Moshkina</a>, 
                        <a href="author_page.cfm?id=81351605621&CFID=105752199&CFTOKEN=69273181">Yoichiro Endo</a>, 
                        <a href="author_page.cfm?id=81409594784&CFID=105752199&CFTOKEN=69273181">Ronald C. Arkin</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 57 - 63</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121253" title="DOI">10.1145/1121241.1121253</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121253&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow12" style="display:inline;"><br /><div style="display:inline">This paper describes a usability study designed to assess ease of use, user satisfaction, and performance of a mobile robot mission specification system. The software under consideration, MissionLab, allows users to specify a robot mission as ...</div></span>
          <span id="toHide12" style="display:none;"><br /><div style="display:inline">This paper describes a usability study designed to assess ease of use, user satisfaction, and performance of a mobile robot mission specification system. The software under consideration, <i>MissionLab</i>, allows users to specify a robot mission as well as compile it, execute it, and control the robot in real-time. In this work, a new automated mission repair mechanism that aids users in correcting faulty missions was added to the system. This mechanism was compared to an older version in order to better inform the development process, and set a direction for future improvements in usability.</div></span> <a id="expcoll12" href="JavaScript: expandcollapse('expcoll12',12)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121254&CFID=105752199&CFTOKEN=69273181">Interaction debugging: an integral approach to analyze human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500356&CFID=105752199&CFTOKEN=69273181">Tijn Kooijmans</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752199&CFTOKEN=69273181">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100461702&CFID=105752199&CFTOKEN=69273181">Christoph Bartneck</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752199&CFTOKEN=69273181">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752199&CFTOKEN=69273181">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 64 - 71</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121254" title="DOI">10.1145/1121241.1121254</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121254&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow13" style="display:inline;"><br /><div style="display:inline">Along with the development of interactive robots, controlled experiments and field trials are regularly conducted to stage human-robot interaction. Experience in this field has shown that analyzing human-robot interaction for evaluation purposes fosters ...</div></span>
          <span id="toHide13" style="display:none;"><br /><div style="display:inline">Along with the development of interactive robots, controlled experiments and field trials are regularly conducted to stage human-robot interaction. Experience in this field has shown that analyzing human-robot interaction for evaluation purposes fosters the development of improved systems and the generation of new knowledge. In this paper, we present the interaction debugging approach, which is based on the collection and analysis of data from robots and their environment. Considering the multimodality of robotic technology, often only audio and video are insufficient for detailed analysis of human-robot interaction. Therefore, in our analysis we integrate multimodal information using audio, video, sensory data, and intermediate variables. An important aspect of the interaction debugging approach is using a tool called Interaction Debugger to analyze data. By supporting user-friendly data presentation, annotation and navigation, Interaction Debugger enables fine-grained inspection of human-robot interaction. The main goal of this paper is to address how an integral approach to the analysis of human-robot interaction can be adopted. This is demonstrated by three case studies.</div></span> <a id="expcoll13" href="JavaScript: expandcollapse('expcoll13',13)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Situational awareness</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Maja Mataric 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121256&CFID=105752199&CFTOKEN=69273181">Changing shape: improving situation awareness for a polymorphic robot</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100059315&CFID=105752199&CFTOKEN=69273181">Jill L. Drury</a>, 
                        <a href="author_page.cfm?id=81100443257&CFID=105752199&CFTOKEN=69273181">Holly A. Yanco</a>, 
                        <a href="author_page.cfm?id=81310500099&CFID=105752199&CFTOKEN=69273181">Whitney Howell</a>, 
                        <a href="author_page.cfm?id=81310501998&CFID=105752199&CFTOKEN=69273181">Brian Minten</a>, 
                        <a href="author_page.cfm?id=81100545769&CFID=105752199&CFTOKEN=69273181">Jennifer Casper</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 72 - 79</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121256" title="DOI">10.1145/1121241.1121256</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121256&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow15" style="display:inline;"><br /><div style="display:inline">Polymorphic, or shape-shifting, robots can normally tackle more types of tasks than non-polymorphic robots due to their flexible morphology. Their versatility adds to the challenge of designing a human interface, however. To investigate the utility of ...</div></span>
          <span id="toHide15" style="display:none;"><br /><div style="display:inline">Polymorphic, or shape-shifting, robots can normally tackle more types of tasks than non-polymorphic robots due to their flexible morphology. Their versatility adds to the challenge of designing a human interface, however. To investigate the utility of providing awareness information about the robot's physical configuration (or "pose"), we performed a within-subjects experiment with presence or absence of pose information being the independent variable. We found that participants were more likely to tip the robot or have it ride up on obstacles when they used the display that lacked pose information and also more likely to move the robot to the highest position to become oriented. There was no significant difference in the number of times that participants bumped into obstacles, however, indicating that having more awareness of the robot's state does not affect awareness of the robots' immediate surroundings. Participants thought the display with pose information was easier to use, helped their performance and was more enjoyable than having no pose information. Future research directions point toward providing recommendations to robot operators for which pose they should change to given the terrain to be traversed.</div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121257&CFID=105752199&CFTOKEN=69273181">Attaining situational awareness for sliding autonomy</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503099&CFID=105752199&CFTOKEN=69273181">Brennan P. Sellner</a>, 
                        <a href="author_page.cfm?id=81336489732&CFID=105752199&CFTOKEN=69273181">Laura M. Hiatt</a>, 
                        <a href="author_page.cfm?id=81332527865&CFID=105752199&CFTOKEN=69273181">Reid Simmons</a>, 
                        <a href="author_page.cfm?id=81310501052&CFID=105752199&CFTOKEN=69273181">Sanjiv Singh</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 80 - 87</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121257" title="DOI">10.1145/1121241.1121257</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121257&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow16" style="display:inline;"><br /><div style="display:inline">We are interested in the problems of a human operator who is responsible for rapidly and accurately responding to requests for help from an autonomous robotic construction team. A difficult aspect of this problem is gaining an awareness of the requesting ...</div></span>
          <span id="toHide16" style="display:none;"><br /><div style="display:inline">We are interested in the problems of a human operator who is responsible for rapidly and accurately responding to requests for help from an autonomous robotic construction team. A difficult aspect of this problem is gaining an awareness of the requesting robot's situation quickly enough to avoid slowing the whole team down. One approach to speeding the initial acquisition of situational awareness is to maintain a buffer of data, and play it back for the human when their help is needed. We report here on an experiment to determine how the composition and length of this buffer affect the human's speed and accuracy in our multi-robot construction domain. The experiments show that, for our scenario, 5 - 10 seconds of one raw video feed led to the fastest operator attainment of situational awareness, while accuracy was maximized by viewing 10 seconds of three video feeds. These results are necessarily specific to our scenario, but we feel that they indicate general trends which may be of use in other situations. We discuss the interacting effects of buffer composition and length on operator speed and accuracy, and draw several conclusions from this experiment which may generalize to other scenarios.</div></span> <a id="expcoll16" href="JavaScript: expandcollapse('expcoll16',16)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121258&CFID=105752199&CFTOKEN=69273181">A decomposition of UAV-related situation awareness</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100059315&CFID=105752199&CFTOKEN=69273181">Jill L. Drury</a>, 
                        <a href="author_page.cfm?id=81325489801&CFID=105752199&CFTOKEN=69273181">Laurel Riek</a>, 
                        <a href="author_page.cfm?id=81310500232&CFID=105752199&CFTOKEN=69273181">Nathan Rackliffe</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 88 - 94</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121258" title="DOI">10.1145/1121241.1121258</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121258&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow17" style="display:inline;"><br /><div style="display:inline">This paper presents a fine-grained decomposition of situation awareness (SA) as it pertains to the use of unmanned aerial vehicles (UAVs), and uses this decomposition to understand the types of SA attained by operators of the Desert Hawk UAV. Since UAVs ...</div></span>
          <span id="toHide17" style="display:none;"><br /><div style="display:inline">This paper presents a fine-grained decomposition of situation awareness (SA) as it pertains to the use of unmanned aerial vehicles (UAVs), and uses this decomposition to understand the types of SA attained by operators of the Desert Hawk UAV. Since UAVs are airborne robots, we adapt a definition previously developed for human-robot awareness after learning about the SA needs of operators through observations and interviews. We describe the applicability of UAV-related SA for people in three roles: UAV operators, air traffic controllers, and pilots of manned aircraft in the vicinity of UAVs. Using our decomposition, UAV interaction designers can specify SA needs and analysts can evaluate a UAV interface's SA support with greater precision and specificity than can be attained using other SA definitions.</div></span> <a id="expcoll17" href="JavaScript: expandcollapse('expcoll17',17)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121259&CFID=105752199&CFTOKEN=69273181">Comparing the usefulness of video and map information in navigation tasks</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81337492155&CFID=105752199&CFTOKEN=69273181">Curtis W. Nielsen</a>, 
                        <a href="author_page.cfm?id=81350575550&CFID=105752199&CFTOKEN=69273181">Michael A. Goodrich</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 95 - 101</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121259" title="DOI">10.1145/1121241.1121259</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121259&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow18" style="display:inline;"><br /><div style="display:inline">One of the fundamental aspects of robot teleoperation is the ability to successfully navigate a robot through an environment. We define successful navigation to mean that the robot minimizes collisions and arrives at the destination in a timely manner. ...</div></span>
          <span id="toHide18" style="display:none;"><br /><div style="display:inline">One of the fundamental aspects of robot teleoperation is the ability to successfully navigate a robot through an environment. We define successful navigation to mean that the robot minimizes collisions and arrives at the destination in a timely manner. Often video and map information is presented to a robot operator to aid in navigation tasks. This paper addresses the usefulness of map and video information in a navigation task by comparing a side-by-side (2D) representation and an integrated (3D) representation in both a simulated and a real world study. The results suggest that sometimes video is more helpful than a map and other times a map is more helpful than video. From a design perspective, an integrated representation seems to help navigation more than placing map and video side-by-side.</div></span> <a id="expcoll18" href="JavaScript: expandcollapse('expcoll18',18)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Learning, adaptation and imitation in HRI</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Aude Billard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121261&CFID=105752199&CFTOKEN=69273181">FOCUS: a generalized method for object discovery for robots that observe and interact with humans</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100032034&CFID=105752199&CFTOKEN=69273181">Manuela M. Veloso</a>, 
                        <a href="author_page.cfm?id=81100077697&CFID=105752199&CFTOKEN=69273181">Paul E. Rybski</a>, 
                        <a href="author_page.cfm?id=81385595356&CFID=105752199&CFTOKEN=69273181">Felix von Hundelshausen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 102 - 109</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121261" title="DOI">10.1145/1121241.1121261</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121261&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow20" style="display:inline;"><br /><div style="display:inline">The essence of the signal-to-symbol problem consists of associating a symbolic description of an object (e.g., a chair) to a signal (e.g., an image) that captures the real object. Robots that interact with humans in natural environments must be ...</div></span>
          <span id="toHide20" style="display:none;"><br /><div style="display:inline">The essence of the <i>signal-to-symbol problem</i> consists of associating a symbolic description of an object (e.g., a chair) to a signal (e.g., an image) that captures the real object. Robots that interact with humans in natural environments must be able to solve this problem correctly and robustly. However, the problem of providing complete object models <i>a priori</i> to a robot so that it can understand its environment from any viewpoint is extremely difficult to solve. Additionally, many objects have different uses which in turn can cause ambiguities when a robot attempts to reason about the activities of a human and their interactions with those objects. In this paper, we build upon the fact that robots that co-exist with humans should have the ability of observing humans using the different objects and learn the corresponding object definitions. We contribute an object recognition algorithm, FOCUS, that is robust to the variations of signals, combines <i>structure</i> and <i>function</i> of an object, and generalizes to multiple similar objects. FOCUS, which stands for <i>Finding Object Classification through Use and Structure</i>, combines an activity recognizer capable of capturing how an object is used with a traditional visual structure processor. FOCUS learns <i>structural properties</i> (visual features) of objects by knowing first the object's <i>affordance properties</i> and observing humans interacting with that object with known activities. The strength of the method relies on the fact that we can define multiple aspects of an object model, i.e., structure and use, that are individually robust but insufficient to define the object, but can do when combined.</div></span> <a id="expcoll20" href="JavaScript: expandcollapse('expcoll20',20)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121262&CFID=105752199&CFTOKEN=69273181">Using context and sensory data to learn first and second person pronouns</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310499420&CFID=105752199&CFTOKEN=69273181">Kevin Gold</a>, 
                        <a href="author_page.cfm?id=81326492306&CFID=105752199&CFTOKEN=69273181">Brian Scassellati</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 110 - 117</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121262" title="DOI">10.1145/1121241.1121262</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121262&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow21" style="display:inline;"><br /><div style="display:inline">We present a method of grounded word learning that can learn the meanings of first and second person pronouns. The model selectively associates new words with agents in the environment by using already understood words to establish context. The method ...</div></span>
          <span id="toHide21" style="display:none;"><br /><div style="display:inline">We present a method of grounded word learning that can learn the meanings of first and second person pronouns. The model selectively associates new words with agents in the environment by using already understood words to establish context. The method uses chi-square tests to find significant associations between the new words and attributes of the relevant agents. We show that this model can learn from a transcript of a parent-child interaction that "I" refers to the person who is speaking. With the additional information that questions about wants refer to the person being asked about them, the system learns that "you" refers to the person being addressed. We show that an incorrect assumption about the subject of "want" questions can lead to pronoun reversal, a linguistic error most commonly found in autistic and congenitally blind children. Finally, we present results from a physical implementation on a robot that runs in real time.</div></span> <a id="expcoll21" href="JavaScript: expandcollapse('expcoll21',21)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121263&CFID=105752199&CFTOKEN=69273181">Teaching robots by moulding behavior and scaffolding the environment</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81351602744&CFID=105752199&CFTOKEN=69273181">Joe Saunders</a>, 
                        <a href="author_page.cfm?id=81100341427&CFID=105752199&CFTOKEN=69273181">Chrystopher L. Nehaniv</a>, 
                        <a href="author_page.cfm?id=81100447769&CFID=105752199&CFTOKEN=69273181">Kerstin Dautenhahn</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 118 - 125</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121263" title="DOI">10.1145/1121241.1121263</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121263&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow22" style="display:inline;"><br /><div style="display:inline">Programming robots to carry out useful tasks is both a complex and non-trivial exercise. A simple and intuitive method to allow humans to train and shape robot behaviour is clearly a key goal in making this task easier. This paper describes an approach ...</div></span>
          <span id="toHide22" style="display:none;"><br /><div style="display:inline">Programming robots to carry out useful tasks is both a complex and non-trivial exercise. A simple and intuitive method to allow humans to train and shape robot behaviour is clearly a key goal in making this task easier. This paper describes an approach to this problem based on studies of social animals where two teaching strategies are applied to allow a human teacher to train a robot by <i>moulding</i> its actions within a carefully <i>scaffolded</i> environment. Within these enviroments sets of competences can be built by building stateslash action memory maps of the robot's interaction within that environment. These memory maps are then polled using a k-nearest neighbour based algorithm to provide a generalised competence. We take a novel approach in building the memory models by allowing the human teacher to construct them in a hierarchical manner. This mechanism allows a human trainer to build and extend an action-selection mechanism into which new skills can be added to the robot's repertoire of existing competencies. These techniques are implemented on physical Khepera miniature robots and validated on a variety of tasks.</div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121264&CFID=105752199&CFTOKEN=69273181">Effects of adaptive robot dialogue on information exchange and social relations</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500984&CFID=105752199&CFTOKEN=69273181">Cristen Torrey</a>, 
                        <a href="author_page.cfm?id=81310502228&CFID=105752199&CFTOKEN=69273181">Aaron Powers</a>, 
                        <a href="author_page.cfm?id=81310500818&CFID=105752199&CFTOKEN=69273181">Matthew Marge</a>, 
                        <a href="author_page.cfm?id=81100583820&CFID=105752199&CFTOKEN=69273181">Susan R. Fussell</a>, 
                        <a href="author_page.cfm?id=81100476487&CFID=105752199&CFTOKEN=69273181">Sara Kiesler</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 126 - 133</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121264" title="DOI">10.1145/1121241.1121264</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121264&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow23" style="display:inline;"><br /><div style="display:inline">Human-robot interaction could be improved by designing robots that engage in adaptive dialogue with users. An adaptive robot could estimate the information needs of individuals and change its dialogue to suit these needs. We test the value of adaptive ...</div></span>
          <span id="toHide23" style="display:none;"><br /><div style="display:inline">Human-robot interaction could be improved by designing robots that engage in adaptive dialogue with users. An adaptive robot could estimate the information needs of individuals and change its dialogue to suit these needs. We test the value of adaptive robot dialogue by experimentally comparing the effects of adaptation versus no adaptation on information exchange and social relations. In Experiment 1, a robot chef adapted to novices by providing detailed explanations of cooking tools; doing so improved information exchange for novice participants but did not influence experts. Experiment 2 added incentives for speed and accuracy and replicated the results from Experiment 1 with respect to information exchange. When the robot's dialogue was adapted for expert knowledge (names of tools rather than explanations), expert participants found the robot to be more effective, more authoritative, and less patronizing. This work suggests adaptation in human-robot interaction has consequences for both task performance and social cohesion. It also suggests that people may be more sensitive to social relations with robots when under task or time pressure.</div></span> <a id="expcoll23" href="JavaScript: expandcollapse('expcoll23',23)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121265&CFID=105752199&CFTOKEN=69273181">Evaluation of robot imitation attempts: comparison of the system's and the human's perspectives</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502395&CFID=105752199&CFTOKEN=69273181">Aris Alissandrakis</a>, 
                        <a href="author_page.cfm?id=81100341427&CFID=105752199&CFTOKEN=69273181">Chrystopher L. Nehaniv</a>, 
                        <a href="author_page.cfm?id=81100447769&CFID=105752199&CFTOKEN=69273181">Kerstin Dautenhahn</a>, 
                        <a href="author_page.cfm?id=81351602744&CFID=105752199&CFTOKEN=69273181">Joe Saunders</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 134 - 141</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121265" title="DOI">10.1145/1121241.1121265</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121265&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow24" style="display:inline;"><br /><div style="display:inline">Imitation is a powerful learning tool when humans and robots interact in a social context. A series of experimental runs and a small pilot user study were conducted to evaluate the performance of a system designed for robot imitation. Performance assessments ...</div></span>
          <span id="toHide24" style="display:none;"><br /><div style="display:inline">Imitation is a powerful learning tool when humans and robots interact in a social context. A series of experimental runs and a small pilot user study were conducted to evaluate the performance of a system designed for robot imitation. Performance assessments of similarity of imitative behaviours were carried out by machines and by humans: the system was evaluated quantitatively (from a machine-centric perspective) and qualitatively (from a human perspective) in order to study the reconciliation of these views. The experimental results presented here illustrate how the number of <i>exceptions</i> can be used as a performance measure by a robotic or software imitator of an object manipulation behaviour. (In this context, exceptions are events when the optimal displacement and/or rotation that minimize the dissimilarity metrics used to generate a corresponding imitative behaviour cannot be directly achieved in the particular context.) Results of the user study giving similarity judgments on imitative behaviours were used to examine how the quantitative measure of the number of exceptions (<i>from a robot's perspective</i>) corresponds to the qualitative evaluation of similarity (<i>from a human's perspective</i>) for the imitative behaviours generated by the <sc>jabberwocky</sc> system. Results suggest that there is a good alignment between this quantitive system centered assessment and the more qualitative human-centered assessment of imitative performance.</div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Assistive robotics</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Holly Yanco 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121267&CFID=105752199&CFTOKEN=69273181">Ergonomics-for-one in a robotic shopping cart for the blind</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100299510&CFID=105752199&CFTOKEN=69273181">Vladimir A. Kulyukin</a>, 
                        <a href="author_page.cfm?id=81310501339&CFID=105752199&CFTOKEN=69273181">Chaitanya Gharpure</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 142 - 149</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121267" title="DOI">10.1145/1121241.1121267</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121267&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow26" style="display:inline;"><br /><div style="display:inline">Assessment and design frameworks for human-robot teams attempt to maximize generality by covering a broad range of potential applications. In this paper, we argue that, in assistive robotics, the other side of generality is limited applicability: it ...</div></span>
          <span id="toHide26" style="display:none;"><br /><div style="display:inline">Assessment and design frameworks for human-robot teams attempt to maximize generality by covering a broad range of potential applications. In this paper, we argue that, in assistive robotics, the other side of generality is limited applicability: it is oftentimes more feasible to custom-design and evolve an application that alleviates a specific disability than to spend resources on figuring out how to customize an existing generic framework. We present a case study that shows how we used a pure bottom-up learn-through-deployment approach inspired by the principles of ergonomics-for-one to design, deploy and iteratively re-design a proof-of-concept robotic shopping cart for the blind.</div></span> <a id="expcoll26" href="JavaScript: expandcollapse('expcoll26',26)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121268&CFID=105752199&CFTOKEN=69273181">Encouraging physical therapy compliance with a hands-Off mobile robot</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81311485201&CFID=105752199&CFTOKEN=69273181">Rachel Gockley</a>, 
                        <a href="author_page.cfm?id=81452618057&CFID=105752199&CFTOKEN=69273181">Maja J. Matari&#262;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 150 - 155</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121268" title="DOI">10.1145/1121241.1121268</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121268&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow27" style="display:inline;"><br /><div style="display:inline">This paper presents results toward our ongoing research program into hands-off assistive human-robot interaction [6]. Our work has focused on applications of socially assistive robotics in health care and education, where human supervision can be significantly ...</div></span>
          <span id="toHide27" style="display:none;"><br /><div style="display:inline">This paper presents results toward our ongoing research program into hands-off assistive human-robot interaction [6]. Our work has focused on applications of socially assistive robotics in health care and education, where human supervision can be significantly augmented and complemented by intelligent machines. In this paper, we focus on the role of <i>embodiment</i>, empirically addressing the question: "In what ways can the robot's physical embodiment be used effectively to positively influence human task-related behavior?" We hypothesized that users' personalities would correlate with their preferences of robot behavior expression. To test this hypothesis, we implemented an autonomous mobile robot aimed at the role of a monitoring and encouragement system for stroke patient rehabilitation. We performed a pilot study that indicates that the presence and behavior of the robot can influence how well people comply with their physical therapy.</div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121269&CFID=105752199&CFTOKEN=69273181">Spatial routines for a simulated speech-controlled vehicle</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100089105&CFID=105752199&CFTOKEN=69273181">Stefanie Tellex</a>, 
                        <a href="author_page.cfm?id=81100653347&CFID=105752199&CFTOKEN=69273181">Deb Roy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 156 - 163</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121269" title="DOI">10.1145/1121241.1121269</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121269&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow28" style="display:inline;"><br /><div style="display:inline">We have defined a lexicon of words in terms of spatial routines, and used that lexicon to build a speech controlled vehicle in a simulator. A spatial routine is a script composed from a set of primitive operations on occupancy grids, analogous ...</div></span>
          <span id="toHide28" style="display:none;"><br /><div style="display:inline">We have defined a lexicon of words in terms of <i>spatial routines</i>, and used that lexicon to build a speech controlled vehicle in a simulator. A spatial routine is a script composed from a set of primitive operations on occupancy grids, analogous to Ullman's visual routines. The vehicle understands the meaning of context-dependent natural language commands such as "Go across the room." When the system receives a command, it combines definitions from the lexicon according to the parse structure of the command, creating a script that selects a goal for the vehicle. Spatial routines may provide the basis for interpreting spatial language in a broad range of physically situated language understanding systems.</div></span> <a id="expcoll28" href="JavaScript: expandcollapse('expcoll28',28)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121270&CFID=105752199&CFTOKEN=69273181">On natural language dialogue with assistive robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100299510&CFID=105752199&CFTOKEN=69273181">Vladimir A. Kulyukin</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 164 - 171</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121270" title="DOI">10.1145/1121241.1121270</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121270&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow29" style="display:inline;"><br /><div style="display:inline">This paper examines the appropriateness of natural language dialogue (NLD) with assistive robots. Assistive robots are defined in terms of an existing human-robot interaction taxonomy. A decision support procedure is outlined for assistive technology ...</div></span>
          <span id="toHide29" style="display:none;"><br /><div style="display:inline">This paper examines the appropriateness of natural language dialogue (NLD) with assistive robots. Assistive robots are defined in terms of an existing human-robot interaction taxonomy. A decision support procedure is outlined for assistive technology researchers and practitioners to evaluate the appropriateness of NLD in assistive robots. Several conjectures are made on when NLD may be appropriate as a human-robot interaction mode.</div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>User studies I</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Dennis Perzanowski 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121272&CFID=105752199&CFTOKEN=69273181">How may I serve you?: a robot companion approaching a seated person in a helping context</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100447769&CFID=105752199&CFTOKEN=69273181">K. Dautenhahn</a>, 
                        <a href="author_page.cfm?id=81350572990&CFID=105752199&CFTOKEN=69273181">M. Walters</a>, 
                        <a href="author_page.cfm?id=81100365903&CFID=105752199&CFTOKEN=69273181">S. Woods</a>, 
                        <a href="author_page.cfm?id=81350568813&CFID=105752199&CFTOKEN=69273181">K. L. Koay</a>, 
                        <a href="author_page.cfm?id=81100341427&CFID=105752199&CFTOKEN=69273181">C. L. Nehaniv</a>, 
                        <a href="author_page.cfm?id=81310501269&CFID=105752199&CFTOKEN=69273181">A. Sisbot</a>, 
                        <a href="author_page.cfm?id=81100454878&CFID=105752199&CFTOKEN=69273181">R. Alami</a>, 
                        <a href="author_page.cfm?id=81310502624&CFID=105752199&CFTOKEN=69273181">T. Sim&#233;on</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 172 - 179</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121272" title="DOI">10.1145/1121241.1121272</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121272&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow31" style="display:inline;"><br /><div style="display:inline">This paper presents the combined results of two studies that investigated how a robot should best approach and place itself relative to a seated human subject. Two live Human Robot Interaction (HRI) trials were performed involving a robot fetching an ...</div></span>
          <span id="toHide31" style="display:none;"><br /><div style="display:inline">This paper presents the combined results of two studies that investigated how a robot should best approach and place itself relative to a seated human subject. Two live Human Robot Interaction (HRI) trials were performed involving a robot fetching an object that the human had requested, using different approach directions. Results of the trials indicated that most subjects disliked a frontal approach, except for a small minority of females, and most subjects preferred to be approached from either the left or right side, with a small overall preference for a right approach by the robot. Handedness and occupation were not related to these preferences. We discuss the results of the user studies in the context of developing a path planning system for a mobile robot.</div></span> <a id="expcoll31" href="JavaScript: expandcollapse('expcoll31',31)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121273&CFID=105752199&CFTOKEN=69273181">Effects of head movement on perceptions of humanoid robot behavior</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500573&CFID=105752199&CFTOKEN=69273181">Emily Wang</a>, 
                        <a href="author_page.cfm?id=81310502872&CFID=105752199&CFTOKEN=69273181">Constantine Lignos</a>, 
                        <a href="author_page.cfm?id=81310501955&CFID=105752199&CFTOKEN=69273181">Ashish Vatsal</a>, 
                        <a href="author_page.cfm?id=81326492306&CFID=105752199&CFTOKEN=69273181">Brian Scassellati</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 180 - 185</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121273" title="DOI">10.1145/1121241.1121273</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121273&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow32" style="display:inline;"><br /><div style="display:inline">This paper examines human perceptions of humanoid robot behavior, specifically how perception is affected by variations in head tracking behavior under constant gestural behavior. Subjects were invited to the lab to "play with Nico," an upper-torso humanoid ...</div></span>
          <span id="toHide32" style="display:none;"><br /><div style="display:inline">This paper examines human perceptions of humanoid robot behavior, specifically how perception is affected by variations in head tracking behavior under constant gestural behavior. Subjects were invited to the lab to "play with Nico," an upper-torso humanoid robot. The follow-up survey asked subjects to rate and write about the experience. A coding scheme originally created to gauge human intentionality was applied to written responses to measure the level of intentionality that subjects perceived in the robot. Subjects were presented with one of four variations of head movement: a motionless head, a smooth tracking head, a tracking head without smoothed movements, and an avoidance behavior, while a pre-scripted wave and beckon sequence was carried out in all cases. Surprisingly, subjects rated the interaction as most enjoyable and Nico as possessing more intentionality when avoidance and unsmooth tracking were used. These data suggest that na&#239;ve users of robots may prefer caricatured and exaggerated behaviors to more natural ones. Also, correlations between ratings across modes suggest that simple features of robot behavior reliably evoke notable changes in many perception scales.</div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121274&CFID=105752199&CFTOKEN=69273181">Interactions with a moody robot</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81311485201&CFID=105752199&CFTOKEN=69273181">Rachel Gockley</a>, 
                        <a href="author_page.cfm?id=81100492013&CFID=105752199&CFTOKEN=69273181">Jodi Forlizzi</a>, 
                        <a href="author_page.cfm?id=81332527865&CFID=105752199&CFTOKEN=69273181">Reid Simmons</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 186 - 193</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121274" title="DOI">10.1145/1121241.1121274</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121274&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow33" style="display:inline;"><br /><div style="display:inline">This paper reports on the results of a long-term experiment in which a social robot's facial expressions were changed to reflect different moods. While the facial changes in each condition were not extremely different, they still altered how people interacted ...</div></span>
          <span id="toHide33" style="display:none;"><br /><div style="display:inline">This paper reports on the results of a long-term experiment in which a social robot's facial expressions were changed to reflect different moods. While the facial changes in each condition were not extremely different, they still altered how people interacted with the robot. On days when many visitors were present, average interactions with the robot were longer when the robot displayed either a "happy" or a "sad" expression instead of a neutral face, but the opposite was true for low-visitor days. The implications of these findings for human-robot social interaction are discussed.</div></span> <a id="expcoll33" href="JavaScript: expandcollapse('expcoll33',33)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>User studies II</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Hiroshi Ishiguro 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121276&CFID=105752199&CFTOKEN=69273181">Empirical results from using a comfort level device in human-robot interaction studies</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350568813&CFID=105752199&CFTOKEN=69273181">K. L. Koay</a>, 
                        <a href="author_page.cfm?id=81100447769&CFID=105752199&CFTOKEN=69273181">K. Dautenhahn</a>, 
                        <a href="author_page.cfm?id=81100365903&CFID=105752199&CFTOKEN=69273181">S. N. Woods</a>, 
                        <a href="author_page.cfm?id=81350572990&CFID=105752199&CFTOKEN=69273181">M. L. Walters</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 194 - 201</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121276" title="DOI">10.1145/1121241.1121276</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121276&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow35" style="display:inline;"><br /><div style="display:inline">This paper describes an extensive analysis of the comfort level data of 7 subjects with respect to 12 robot behaviours as part of a human-robot interaction trial. This includes robot action, proximity and motion relative to the subjects. Two researchers ...</div></span>
          <span id="toHide35" style="display:none;"><br /><div style="display:inline">This paper describes an extensive analysis of the comfort level data of 7 subjects with respect to 12 robot behaviours as part of a human-robot interaction trial. This includes robot action, proximity and motion relative to the subjects. Two researchers coded the video material, identifying visible states of discomfort displayed by subjects in relation to the robot's behaviour. Agreement between the coders varied from moderate to high, except for more ambiguous situations involving robot approach directions. The detected visible states of discomfort were correlated with the situations where the comfort level device (CLD) indicated states of discomfort. Results show that the uncomfortable states identified by both coders, and by either of the coders corresponded with 31% and 64% of the uncomfortable states identified by the subjects' CLD data (N=58), respectively. Conversely there was 72% agreement between subjects' CLD data and the uncomfortable states identified by both coders (N=25). Results show that the majority of the subjects expressed discomfort when the robot blocked their path or was on a collision course towards them, especially when the robot was within 3 meters proximity. Other observations include that the majority of subjects experienced discomfort when the robot was closer than 3m, within the social zone reserved for human-human face to face conversation, while they were performing a task. The advantages and disadvantages of the CLD in comparison to other techniques for assessing subjects' internal states are discussed and future work concludes the paper.</div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121277&CFID=105752199&CFTOKEN=69273181">An investigation of real world control of robotic assets under communication latency</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503278&CFID=105752199&CFTOKEN=69273181">Jason P. Luck</a>, 
                        <a href="author_page.cfm?id=81414593958&CFID=105752199&CFTOKEN=69273181">Patricia L. McDermott</a>, 
                        <a href="author_page.cfm?id=81310502516&CFID=105752199&CFTOKEN=69273181">Laurel Allender</a>, 
                        <a href="author_page.cfm?id=81310500749&CFID=105752199&CFTOKEN=69273181">Deborah C. Russell</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 202 - 209</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121277" title="DOI">10.1145/1121241.1121277</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121277&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow36" style="display:inline;"><br /><div style="display:inline">Robots are already being used in a variety of applications, including the military battlefield. As robotic technology continues to advance, those applications will increase, as will the demands on the associated network communication links. Two experiments ...</div></span>
          <span id="toHide36" style="display:none;"><br /><div style="display:inline">Robots are already being used in a variety of applications, including the military battlefield. As robotic technology continues to advance, those applications will increase, as will the demands on the associated network communication links. Two experiments investigated the effects of communication latency on the control of a robot across four Levels Of Automation (LOAs), (1) full teleoperation, (2) guarded teleoperation, (3) autonomous obstacle avoidance, and (4) full autonomy. Latency parameters studied included latency duration, latency variability, and the "direction" in which the latency occurs, that is from user-to-robot or from robot-to-user. The results indicate that the higher the LOA, the better the performance in terms of both time and number of errors made, and also the more resistant to the degrading effects of latency. Subjective reports confirmed these findings. Implications of constant vs. variable-latency, user-to-robot vs. robot-to-user latency, and latency duration are also discussed.</div></span> <a id="expcoll36" href="JavaScript: expandcollapse('expcoll36',36)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121278&CFID=105752199&CFTOKEN=69273181">Effective team-driven multi-model motion tracking</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310499804&CFID=105752199&CFTOKEN=69273181">Yang Gu</a>, 
                        <a href="author_page.cfm?id=81100032034&CFID=105752199&CFTOKEN=69273181">Manuela Veloso</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 210 - 217</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121278" title="DOI">10.1145/1121241.1121278</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121278&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow37" style="display:inline;"><br /><div style="display:inline">Autonomous robots use sensors to perceive and track objects in the world. Tracking algorithms use object motion models to estimate the position of a moving object. Tracking efficiency completely depends on the accuracy of the motion model and of the ...</div></span>
          <span id="toHide37" style="display:none;"><br /><div style="display:inline">Autonomous robots use sensors to perceive and track objects in the world. Tracking algorithms use object motion models to estimate the position of a moving object. Tracking efficiency completely depends on the accuracy of the motion model and of the sensory information. Interestingly, when the robots can actuate the object being tracked, the motion can become highly discontinuous and nonlinear. We have previously developed a successful tracking approach that effectively switches among object motion models as a function of the robot's actions. If the object to be tracked is actuated by a team, the set of motion models is quite more complex. In this paper, we report on a tracking approach that can use a dynamic multiple motion model based on a team coordination plan. We present the multi-model probabilistic tracking algorithms in detail and present empirical results both in simulation and real robot test. Our physical team is composed of a robot and a human in a real Segway soccer game scenario. We show how the coordinated plan allows the robot to better track a mobile object through the effective interaction with its human teammate.</div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Cognitive science in HRI</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Cynthia Breazeal 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121280&CFID=105752199&CFTOKEN=69273181">The advisor robot: tracing people's mental model from a robot's physical attributes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502228&CFID=105752199&CFTOKEN=69273181">Aaron Powers</a>, 
                        <a href="author_page.cfm?id=81100476487&CFID=105752199&CFTOKEN=69273181">Sara Kiesler</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 218 - 225</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121280" title="DOI">10.1145/1121241.1121280</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121280&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow39" style="display:inline;"><br /><div style="display:inline">Humanoid robots offer many physical design choices such as voice frequency and head dimensions. We used hierarchical statistical mediation analysis to trace differences in people's mental model of robots from these choices. In an experiment, a humanoid ...</div></span>
          <span id="toHide39" style="display:none;"><br /><div style="display:inline">Humanoid robots offer many physical design choices such as voice frequency and head dimensions. We used hierarchical statistical mediation analysis to trace differences in people's mental model of robots from these choices. In an experiment, a humanoid robot gave participants online advice about their health. We used mediation analysis to identify the causal path from the robot's voice and head dimensions to the participants' mental model, and to their willingness to follow the robot's advice. The male robot voice predicted impressions of a knowledgeable robot, whose advice participants said they would follow. Increasing the voice's fundamental frequency reduced this effect. The robot's short chin length (but not its forehead dimensions) predicted impressions of a sociable robot, which also predicted intentions to take the robot's advice. We discuss the use of this approach for designing robots for different roles, when people's mental model of the robot matters.</div></span> <a id="expcoll39" href="JavaScript: expandcollapse('expcoll39',39)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121281&CFID=105752199&CFTOKEN=69273181">The utility of affect expression in natural language interactions in joint human-robot tasks</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100029514&CFID=105752199&CFTOKEN=69273181">Matthias Scheutz</a>, 
                        <a href="author_page.cfm?id=81100573922&CFID=105752199&CFTOKEN=69273181">Paul Schermerhorn</a>, 
                        <a href="author_page.cfm?id=81318489538&CFID=105752199&CFTOKEN=69273181">James Kramer</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 226 - 233</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121281" title="DOI">10.1145/1121241.1121281</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121281&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow40" style="display:inline;"><br /><div style="display:inline">Recognizing and responding to human affect is important in collaborative tasks in joint human-robot teams. In this paper we present an integrated affect and cognition architecture for HRI and report results from an experiment with this architecture that ...</div></span>
          <span id="toHide40" style="display:none;"><br /><div style="display:inline">Recognizing and responding to human affect is important in collaborative tasks in joint human-robot teams. In this paper we present an integrated affect and cognition architecture for HRI and report results from an experiment with this architecture that shows that expressing affect and responding to human affect with affect expressions can significantly improve team performance in a joint human-robot task.</div></span> <a id="expcoll40" href="JavaScript: expandcollapse('expcoll40',40)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121282&CFID=105752199&CFTOKEN=69273181">Analysis of human behavior to a communication robot in an open field</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350574137&CFID=105752199&CFTOKEN=69273181">Shogo Nabe</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752199&CFTOKEN=69273181">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81343494660&CFID=105752199&CFTOKEN=69273181">Kazuo Hiraki</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752199&CFTOKEN=69273181">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81330493569&CFID=105752199&CFTOKEN=69273181">Kiyoshi Kogure</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752199&CFTOKEN=69273181">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 234 - 241</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121282" title="DOI">10.1145/1121241.1121282</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121282&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow41" style="display:inline;"><br /><div style="display:inline">This paper investigates human behavior around an interactive robot at a science museum. To develop a communication robot that works in daily environments, it is important to investigate the available information from a robot about people's behavior. ...</div></span>
          <span id="toHide41" style="display:none;"><br /><div style="display:inline">This paper investigates human behavior around an interactive robot at a science museum. To develop a communication robot that works in daily environments, it is important to investigate the available information from a robot about people's behavior. Such information will enable the robot to predict people's behavior so that the robot can optimize its interactive behavior. We analyzed visitor behavior toward a simple interactive robot exhibited at a science museum in relation to information from sound level and range sensors. We discovered factors that influence the way people approach, maintain distance, and interact both physically and verbally with the robot. This enabled us to extract meaningful information from the sensory information and apply it to communication robots.</div></span> <a id="expcoll41" href="JavaScript: expandcollapse('expcoll41',41)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121283&CFID=105752199&CFTOKEN=69273181">Children and robots learning to play hide and seek</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100061774&CFID=105752199&CFTOKEN=69273181">J. Gregory Trafton</a>, 
                        <a href="author_page.cfm?id=81100622960&CFID=105752199&CFTOKEN=69273181">Alan C. Schultz</a>, 
                        <a href="author_page.cfm?id=81100314905&CFID=105752199&CFTOKEN=69273181">Dennis Perznowski</a>, 
                        <a href="author_page.cfm?id=81100283354&CFID=105752199&CFTOKEN=69273181">Magdalena D. Bugajska</a>, 
                        <a href="author_page.cfm?id=81100312796&CFID=105752199&CFTOKEN=69273181">William Adams</a>, 
                        <a href="author_page.cfm?id=81319489294&CFID=105752199&CFTOKEN=69273181">Nicholas L. Cassimatis</a>, 
                        <a href="author_page.cfm?id=81100455302&CFID=105752199&CFTOKEN=69273181">Derek P. Brock</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 242 - 249</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121283" title="DOI">10.1145/1121241.1121283</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121283&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow42" style="display:inline;"><br /><div style="display:inline">How do children learn how to play hide and seek? At age 3-4, children do not typically have perspective taking ability, so their hiding ability should be extremely limited. We show through a case study that a 3 1/2 year old child can, in fact, play a ...</div></span>
          <span id="toHide42" style="display:none;"><br /><div style="display:inline">How do children learn how to play hide and seek? At age 3-4, children do not typically have perspective taking ability, so their hiding ability should be extremely limited. We show through a case study that a 3 1/2 year old child can, in fact, play a credible game of hide and seek, even though she does not seem to have perspective taking ability. We propose that children are able to learn how to play hide and seek by learning the features and relations of objects (e.g., containment, under) and use that information to play a credible game of hide and seek. We model this hypothesis within the ACT-R cognitive architecture and put the model on a robot, which is able to mimic the child's hiding behavior. We also take the "hiding" model and use it as the basis for a "seeking" model. We suggest that using the same representations and procedures that a person uses allows better interaction between the human and robotic system.</div></span> <a id="expcoll42" href="JavaScript: expandcollapse('expcoll42',42)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Interface design and analysis</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          Jodi Forlizzi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121285&CFID=105752199&CFTOKEN=69273181">Effective user interface design for rescue robotics</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100337188&CFID=105752199&CFTOKEN=69273181">M. Waleed Kadous</a>, 
                        <a href="author_page.cfm?id=81310502841&CFID=105752199&CFTOKEN=69273181">Raymond Ka-Man Sheh</a>, 
                        <a href="author_page.cfm?id=81100218388&CFID=105752199&CFTOKEN=69273181">Claude Sammut</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 250 - 257</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121285" title="DOI">10.1145/1121241.1121285</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121285&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow44" style="display:inline;"><br /><div style="display:inline">Until robots are able to autonomously navigate, carry out a mission and report back to base, effective human-robot interfaces will be an integral part of any practical mobile robot system. This is especially the case for robot-assisted Urban Search and ...</div></span>
          <span id="toHide44" style="display:none;"><br /><div style="display:inline">Until robots are able to autonomously navigate, carry out a mission and report back to base, effective human-robot interfaces will be an integral part of any practical mobile robot system. This is especially the case for robot-assisted Urban Search and Rescue (USAR). Unfamiliar and unstructured environments, unreliable communications and many sensors combine to make the job of a human operator, and hence the interface designer challenging.This paper presents the design, implementation and deployment of a human-robot interface for the teleoperated USAR research robot, textsfCASTER. Proven HCI-based user interface design principles were adopted in order to produce an interface that was intuitive and minimised learning time while maximising effectiveness.The human-robot interface was deployed by Team CASualty in the 2005 RoboCup Rescue Robot League competition. This competition allows a wide variety of approaches to USAR research to be evaluated in a realistic environment. Despite the operator having less than one month of experience, Team CASualty came 3rd, beating teams that had far longer to train their operators. In particular, the ease with which the robot could be driven and high quality information gathered played a crucial part in Team CASualty's success. Further empirical evaluations of the system on a group of twelve users as well as members of the public further reinforce our belief that this interface is quick to learn, easy to use and effective.</div></span> <a id="expcoll44" href="JavaScript: expandcollapse('expcoll44',44)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121286&CFID=105752199&CFTOKEN=69273181">Service robots in the domestic environment: a study of the roomba vacuum in the home</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100492013&CFID=105752199&CFTOKEN=69273181">Jodi Forlizzi</a>, 
                        <a href="author_page.cfm?id=81100258547&CFID=105752199&CFTOKEN=69273181">Carl DiSalvo</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 258 - 265</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121286" title="DOI">10.1145/1121241.1121286</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121286&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow45" style="display:inline;"><br /><div style="display:inline">Domestic service robots have long been a staple of science fiction and commercial visions of the future. Until recently, we have only been able to speculate about what the experience of using such a device might be. Current domestic service robots, introduced ...</div></span>
          <span id="toHide45" style="display:none;"><br /><div style="display:inline">Domestic service robots have long been a staple of science fiction and commercial visions of the future. Until recently, we have only been able to speculate about what the experience of using such a device might be. Current domestic service robots, introduced as consumer products, allow us to make this vision a reality.This paper presents ethnographic research on the actual use of these products, to provide a grounded understanding of how design can influence human-robot interaction in the home. We used an ecological approach to broadly explore the use of this technology in this context, and to determine how an autonomous, mobile robot might "fit" into such a space. We offer initial implications for the design of these products: first, the way the technology is introduced is critical; second, the use of the technology becomes social; and third, that ideally, homes and domestic service robots must adapt to each other.</div></span> <a id="expcoll45" href="JavaScript: expandcollapse('expcoll45',45)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121287&CFID=105752199&CFTOKEN=69273181">A video game-based framework for analyzing human-robot interaction: characterizing interface design in real-time interactive multimedia applications</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503021&CFID=105752199&CFTOKEN=69273181">Justin Richer</a>, 
                        <a href="author_page.cfm?id=81100059315&CFID=105752199&CFTOKEN=69273181">Jill L. Drury</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 266 - 273</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121287" title="DOI">10.1145/1121241.1121287</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121287&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow46" style="display:inline;"><br /><div style="display:inline">There is growing interest in mining the world of video games to find inspiration for human-robot interaction (HRI) design. This paper segments video game interaction into domain-independent components which together form a framework that can be used ...</div></span>
          <span id="toHide46" style="display:none;"><br /><div style="display:inline">There is growing interest in mining the world of video games to find inspiration for human-robot interaction (HRI) design. This paper segments video game interaction into domain-independent components which together form a framework that can be used to characterize real-time interactive multimedia applications in general and HRI in particular. We provide examples of using the components in both the video game and the Unmanned Aerial Vehicle (UAV) domains (treating UAVs as airborne robots). Beyond characterization, the framework can be used to inspire new HRI designs and compare different designs; we provide an example comparison of two UAV ground station applications.</div></span> <a id="expcoll46" href="JavaScript: expandcollapse('expcoll46',46)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121288&CFID=105752199&CFTOKEN=69273181">User, robot and automation evaluations in high-throughput biological screening processes</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81319500632&CFID=105752199&CFTOKEN=69273181">Noa Segall</a>, 
                        <a href="author_page.cfm?id=81406593429&CFID=105752199&CFTOKEN=69273181">Rebecca S. Green</a>, 
                        <a href="author_page.cfm?id=81100400562&CFID=105752199&CFTOKEN=69273181">David B. Kaber</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 274 - 281</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121288" title="DOI">10.1145/1121241.1121288</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121288&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow47" style="display:inline;"><br /><div style="display:inline">This paper introduces high-throughput screening of biological samples in life sciences, as a domain for analysis of human-robot interaction (HRI) and development of usable human interface design principles. High-throughput screening (HTS) processes involve ...</div></span>
          <span id="toHide47" style="display:none;"><br /><div style="display:inline">This paper introduces high-throughput screening of biological samples in life sciences, as a domain for analysis of human-robot interaction (HRI) and development of usable human interface design principles. High-throughput screening (HTS) processes involve use of robotics and highly automated analytical measurement devices to transport and chemically evaluate biological compounds for potential use as drug derivatives. Humans act as supervisory controllers in HTS processes by performing test planning and device programming prior to experiments, systems monitoring, and real-time process intervention and error correction to maintain experiment safety and output. Process errors are infrequent but can be costly. Two forms of cognitive task analysis were applied to a highly automated HTS process to address different classes of errors, including goal-directed task analysis to describe critical operator decisions and information requirements and abstraction hierarchy modeling to represent HTS process devices and automation integrated in screening lines. The outcomes of the analyses were used as bases for generating supervisory control interface design recommendations to improve existing system usefulness and usability.</div></span> <a id="expcoll47" href="JavaScript: expandcollapse('expcoll47',47)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">SESSION: <strong>Dialog, mixed-initiative and multimodal interfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:0">
          David Breummer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121290&CFID=105752199&CFTOKEN=69273181">Clarification dialogues in human-augmented mapping</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100597768&CFID=105752199&CFTOKEN=69273181">Geert-Jan M. Kruijff</a>, 
                        <a href="author_page.cfm?id=81367597763&CFID=105752199&CFTOKEN=69273181">Hendrik Zender</a>, 
                        <a href="author_page.cfm?id=81310499394&CFID=105752199&CFTOKEN=69273181">Patric Jensfelt</a>, 
                        <a href="author_page.cfm?id=81100285247&CFID=105752199&CFTOKEN=69273181">Henrik I. Christensen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 282 - 289</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121290" title="DOI">10.1145/1121241.1121290</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121290&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow49" style="display:inline;"><br /><div style="display:inline">An approach to dialogue based interaction for resolution of ambiguities encountered as part of Human-Augmented Mapping (HAM) is presented. The paper focuses on issues related to spatial organisation and localisation. The dialogue pattern naturally arises ...</div></span>
          <span id="toHide49" style="display:none;"><br /><div style="display:inline">An approach to dialogue based interaction for resolution of ambiguities encountered as part of Human-Augmented Mapping (HAM) is presented. The paper focuses on issues related to spatial organisation and localisation. The dialogue pattern naturally arises as robots are introduced to novel environments. The paper discusses an approach based on the notion of Questions under Discussion (QUD). The presented approach has been implemented on a mobile platform that has dialogue capabilities and methods for metric SLAM. Experimental results from a pilot study clearly demonstrate that the system can resolve problematic situations.</div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121291&CFID=105752199&CFTOKEN=69273181">The effect of head-nod recognition in human-robot conversation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100223737&CFID=105752199&CFTOKEN=69273181">Candace L. Sidner</a>, 
                        <a href="author_page.cfm?id=81100399488&CFID=105752199&CFTOKEN=69273181">Christopher Lee</a>, 
                        <a href="author_page.cfm?id=81100300540&CFID=105752199&CFTOKEN=69273181">Louis-Philippe Morency</a>, 
                        <a href="author_page.cfm?id=81100584798&CFID=105752199&CFTOKEN=69273181">Clifton Forlines</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 290 - 296</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121291" title="DOI">10.1145/1121241.1121291</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121291&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow50" style="display:inline;"><br /><div style="display:inline">This paper reports on a study of human participants with a robot designed to participate in a collaborative conversation with a human. The purpose of the study was to investigate a particular kind of gestural feedback from human to the robot in these ...</div></span>
          <span id="toHide50" style="display:none;"><br /><div style="display:inline">This paper reports on a study of human participants with a robot designed to participate in a collaborative conversation with a human. The purpose of the study was to investigate a particular kind of gestural feedback from human to the robot in these conversations: head nods. During these conversations, the robot recognized head nods from the human participant. The conversations between human and robot concern demonstrations of inventions created in a lab. We briefly discuss the robot hardware and architecture and then focus the paper on a study of the effects of understanding head nods in three different conditions. We conclude that conversation itself triggers head nods by people in human-robot conversations and that telling participants that the robot recognizes their nods as well as having the robot provide gestural feedback of its nod recognition is effective in producing more nods.</div></span> <a id="expcoll50" href="JavaScript: expandcollapse('expcoll50',50)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121292&CFID=105752199&CFTOKEN=69273181">Working with robots and objects: revisiting deictic reference for achieving spatial common ground</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          Andrew G. Brooks, 
                        <a href="author_page.cfm?id=81100258451&CFID=105752199&CFTOKEN=69273181">Cynthia Breazeal</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 297 - 304</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121292" title="DOI">10.1145/1121241.1121292</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121292&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow51" style="display:inline;"><br /><div style="display:inline">Robust joint visual attention is necessary for achieving a common frame of reference between humans and robots interacting multimodally in order to work together on real-world spatial tasks involving objects. We make a comprehensive examination of one ...</div></span>
          <span id="toHide51" style="display:none;"><br /><div style="display:inline">Robust joint visual attention is necessary for achieving a common frame of reference between humans and robots interacting multimodally in order to work together on real-world spatial tasks involving objects. We make a comprehensive examination of one component of this process that is often otherwise implemented in an ad hoc fashion: the ability to correctly determine the object referent from deictic reference including pointing gestures and speech. From this we describe the development of a modular spatial reasoning framework based around decomposition and resynthesis of speech and gesture into a language of pointing and object labeling. This framework supports multimodal and unimodal access in both real-world and mixed-reality workspaces, accounts for the need to discriminate and sequence identical and proximate objects, assists in overcoming inherent precision limitations in deictic gesture, and assists in the extraction of those gestures. We further discuss an implementation of the framework that has been deployed on two humanoid robot platforms to date.</div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121293&CFID=105752199&CFTOKEN=69273181">Interactive humanoid robots for a science museum</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310499910&CFID=105752199&CFTOKEN=69273181">Masahiro Shiomi</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752199&CFTOKEN=69273181">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752199&CFTOKEN=69273181">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752199&CFTOKEN=69273181">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 305 - 312</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121293" title="DOI">10.1145/1121241.1121293</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121293&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow52" style="display:inline;"><br /><div style="display:inline">This paper reports on a field trial with interactive humanoid robots at a science museum where visitors are supposed to study and develop an interest in science. In the trial, each visitor wore an RFID tag while looking around the museum's exhibits. ...</div></span>
          <span id="toHide52" style="display:none;"><br /><div style="display:inline">This paper reports on a field trial with interactive humanoid robots at a science museum where visitors are supposed to study and develop an interest in science. In the trial, each visitor wore an RFID tag while looking around the museum's exhibits. Information obtained from the RFID tags was used to direct the robots' interaction with the visitors. The robots autonomously interacted with visitors via gestures and utterances resembling the free play of children [1]. In addition, they performed exhibit-guiding by moving around several exhibits and explaining the exhibits based on sensor information. The robots were highly evaluated by visitors during the two-month trial. Moreover, we conducted an experiment in the field trial to compare the detailed effects of exhibit-guiding and free-play interaction under three operating conditions. This revealed that the combination of the free-play interaction and exhibit-guiding positively affected visitors' experiences at the science museum.</div></span> <a id="expcoll52" href="JavaScript: expandcollapse('expcoll52',52)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121294&CFID=105752199&CFTOKEN=69273181">How contingent should a communication robot be?</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310501032&CFID=105752199&CFTOKEN=69273181">Fumitaka Yamaoka</a>, 
                        <a href="author_page.cfm?id=81311482839&CFID=105752199&CFTOKEN=69273181">Takayuki Kanda</a>, 
                        <a href="author_page.cfm?id=81100572813&CFID=105752199&CFTOKEN=69273181">Hiroshi Ishiguro</a>, 
                        <a href="author_page.cfm?id=81100399958&CFID=105752199&CFTOKEN=69273181">Norihiro Hagita</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 313 - 320</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121294" title="DOI">10.1145/1121241.1121294</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121294&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow53" style="display:inline;"><br /><div style="display:inline">The purpose of our research is to develop lifelike behavior in a communication robot, which is expected to potentially make human-robot interaction more natural. Our earlier research demonstrated the importance of a robot's contingency for lifelikeness ...</div></span>
          <span id="toHide53" style="display:none;"><br /><div style="display:inline">The purpose of our research is to develop lifelike behavior in a communication robot, which is expected to potentially make human-robot interaction more natural. Our earlier research demonstrated the importance of a robot's contingency for lifelikeness [1]. On the other hand, perfect contingency seems to give us a non-lifelike impression. In order to explore the appropriate contingency for communication robots, we developed a robot system that allows us to adjust its contingency to an interacting person in a simple mimic interaction. As a result of an experiment, we identified the relationships between the degree of contingency and the subjective impressions of lifelikeness, autonomy, and preference. However, the experimental result also seems to suggest the importance of the complexity of interaction for investigating the appropriate contingency of communication robots.</div></span> <a id="expcoll53" href="JavaScript: expandcollapse('expcoll53',53)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="2">POSTER SESSION: <strong>Short papers</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121296&CFID=105752199&CFTOKEN=69273181">The first segway soccer experience: towards peer-to-peer human-robot teams</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310499255&CFID=105752199&CFTOKEN=69273181">Brenna Argall</a>, 
                        <a href="author_page.cfm?id=81310499804&CFID=105752199&CFTOKEN=69273181">Yang Gu</a>, 
                        <a href="author_page.cfm?id=81100556983&CFID=105752199&CFTOKEN=69273181">Brett Browning</a>, 
                        <a href="author_page.cfm?id=81100032034&CFID=105752199&CFTOKEN=69273181">Manuela Veloso</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 321 - 322</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121296" title="DOI">10.1145/1121241.1121296</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121296&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow55" style="display:inline;"><br /><div style="display:inline">In this paper, we focus on human-robot interaction in a team task where we identify the need for peer-to-peer (P2P) teamwork, with no fixed hierarchy for decision making between robots and humans. Instead, all team members are equal participants and ...</div></span>
          <span id="toHide55" style="display:none;"><br /><div style="display:inline">In this paper, we focus on human-robot interaction in a team task where we identify the need for peer-to-peer (P2P) teamwork, with no fixed hierarchy for decision making between robots and humans. Instead, all team members are equal participants and decision making is truly distributed. We have fully developed a P2P team within Segway Soccer, a research domain, built upon Robocup robot soccer, that we have introduced to explore the challenge of P2P coordination in human-robot teams with dynamic, adversarial tasks. We recently participated in the first Segway Soccer games between two competing teams at the 2005 RoboCup US Open. We believe these games are the first ever between two human-robot P2P teams. Based on the competition, we realized two different approaches to P2P teams. We present our robot-centric approach to P2P team coordination and contrast it to the human-centric approach of the opponent team.</div></span> <a id="expcoll55" href="JavaScript: expandcollapse('expcoll55',55)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121297&CFID=105752199&CFTOKEN=69273181">Gesture-based control of highly articulated biomechatronic systems</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503513&CFID=105752199&CFTOKEN=69273181">Zhiqiang Luo</a>, 
                        <a href="author_page.cfm?id=81310500922&CFID=105752199&CFTOKEN=69273181">I-Ming Chen</a>, 
                        <a href="author_page.cfm?id=81310501236&CFID=105752199&CFTOKEN=69273181">Shusong Xing</a>, 
                        <a href="author_page.cfm?id=81100369572&CFID=105752199&CFTOKEN=69273181">Henry Been-Lirn Duh</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 323 - 324</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121297" title="DOI">10.1145/1121241.1121297</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121297&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow56" style="display:inline;"><br /><div style="display:inline">A robotic puppet is developed for studying motion generation and control of highly articulated biomimic mechatronic systems with anatomical motion data of human in real time. The system is controlled by a pair of data gloves tracking human fingers' actions. ...</div></span>
          <span id="toHide56" style="display:none;"><br /><div style="display:inline">A robotic puppet is developed for studying motion generation and control of highly articulated biomimic mechatronic systems with anatomical motion data of human in real time. The system is controlled by a pair of data gloves tracking human fingers' actions. With the primitives designed in a multilayered motion synthesis structure, the puppet can realize some complex human-like actions. Continuous full body movements are produced on the robotic puppet by combining and sequencing the actions on different body parts using temporal and spatial information provided by the data gloves. Human is involved in the interactive design of the coordination and timing of the body movements of the robotic puppet in a natural and intuitive manner. The methods of motion generation exhibited on the robotic puppet may be applied to the interactive media, entertainment and biomedical engineering.</div></span> <a id="expcoll56" href="JavaScript: expandcollapse('expcoll56',56)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121298&CFID=105752199&CFTOKEN=69273181">Human telesupervision of a fleet of autonomous robots for safe and efficient space exploration</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310501678&CFID=105752199&CFTOKEN=69273181">Gregg Podnar</a>, 
                        <a href="author_page.cfm?id=81100557506&CFID=105752199&CFTOKEN=69273181">John Dolan</a>, 
                        <a href="author_page.cfm?id=81100191583&CFID=105752199&CFTOKEN=69273181">Alberto Elfes</a>, 
                        <a href="author_page.cfm?id=81100492609&CFID=105752199&CFTOKEN=69273181">Marcel Bergerman</a>, 
                        <a href="author_page.cfm?id=81100012759&CFID=105752199&CFTOKEN=69273181">H. Benjamin Brown</a>, 
                        <a href="author_page.cfm?id=81310503376&CFID=105752199&CFTOKEN=69273181">Alan D. Guisewite</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 325 - 326</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121298" title="DOI">10.1145/1121241.1121298</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121298&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow57" style="display:inline;"><br /><div style="display:inline">In January 2004, NASA began a bold enterprise to return to the Moon, and with the technologies and expertise gained, press on to Mars. The underlying Vision for Space Exploration calls for a sustained and affordable human and robotic program to explore ...</div></span>
          <span id="toHide57" style="display:none;"><br /><div style="display:inline">In January 2004, NASA began a bold enterprise to return to the Moon, and with the technologies and expertise gained, press on to Mars. The underlying Vision for Space Exploration calls for a sustained and affordable human and robotic program to explore the solar system and beyond; to conduct human expeditions to Mars after successfully demonstrating sustained human exploration missions on the Moon. The approach is to "send human and robotic explorers as partners, leveraging the capabilities of each where most useful." Human-robot interfacing technologies for this approach are required at readiness levels above any available today. In this paper, we describe the HRI aspects of a robot supervision architecture we are developing under NASA's auspices, based on the authors' extensive experience with field deployment of ground, underwater, lighter-than-air, and inspection autonomous and semi-autonomous robotic vehicles and systems.</div></span> <a id="expcoll57" href="JavaScript: expandcollapse('expcoll57',57)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121299&CFID=105752199&CFTOKEN=69273181">Affective expression in appearance constrained robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310503105&CFID=105752199&CFTOKEN=69273181">Cindy L. Bethel</a>, 
                        <a href="author_page.cfm?id=81100545387&CFID=105752199&CFTOKEN=69273181">Robin R. Murphy</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 327 - 328</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121299" title="DOI">10.1145/1121241.1121299</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121299&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121300&CFID=105752199&CFTOKEN=69273181">3-D modeling of spatial referencing language for human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500412&CFID=105752199&CFTOKEN=69273181">Samuel Blisard</a>, 
                        <a href="author_page.cfm?id=81100367106&CFID=105752199&CFTOKEN=69273181">Marjorie Skubic</a>, 
                        <a href="author_page.cfm?id=81330495123&CFID=105752199&CFTOKEN=69273181">Robert H. Luke, III</a>, 
                        <a href="author_page.cfm?id=81100011975&CFID=105752199&CFTOKEN=69273181">James M. Keller</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 329 - 330</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121300" title="DOI">10.1145/1121241.1121300</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121300&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow59" style="display:inline;"><br /><div style="display:inline">One of the key components for natural interaction between humans and robots is the ability to understand the spatial relationships that exist in the natural world. Previous research has shown that modeling the 2D spatial relationships of FRONT, BEHIND, ...</div></span>
          <span id="toHide59" style="display:none;"><br /><div style="display:inline">One of the key components for natural interaction between humans and robots is the ability to understand the spatial relationships that exist in the natural world. Previous research has shown that modeling the 2D spatial relationships of FRONT, BEHIND, LEFT, RIGHT, and BETWEEN can be accomplished with results consistent with that of a human being. Upcoming research will involve a human subject study to investigate the use of spatial relationships in 3D space. This will be the first step in extending previous research of the 2D spatial relations into a 3D representation through the use of 3D object point clouds generated by the SIFT algorithm and stereo vision. This will allow for the enrichment of our human-robot dialog to include phrases such as "Bring me the coffee cup on top of the desk and to the right of the computer.</div></span> <a id="expcoll59" href="JavaScript: expandcollapse('expcoll59',59)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121301&CFID=105752199&CFTOKEN=69273181">The art of designing robot faces: dimensions for human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500885&CFID=105752199&CFTOKEN=69273181">Mike Blow</a>, 
                        <a href="author_page.cfm?id=81100447769&CFID=105752199&CFTOKEN=69273181">Kerstin Dautenhahn</a>, 
                        <a href="author_page.cfm?id=81310501161&CFID=105752199&CFTOKEN=69273181">Andrew Appleby</a>, 
                        <a href="author_page.cfm?id=81100341427&CFID=105752199&CFTOKEN=69273181">Chrystopher L. Nehaniv</a>, 
                        <a href="author_page.cfm?id=81310503423&CFID=105752199&CFTOKEN=69273181">David Lee</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 331 - 332</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121301" title="DOI">10.1145/1121241.1121301</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121301&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow60" style="display:inline;"><br /><div style="display:inline">As robots enter everyday life and start to interact with ordinary people [5]the question of their appearance becomes increasingly important. A user's perception of a robot can be strongly influenced by its facial appearance [6]. The dimensions and issues ...</div></span>
          <span id="toHide60" style="display:none;"><br /><div style="display:inline">As robots enter everyday life and start to interact with ordinary people [5]the question of their appearance becomes increasingly important. A user's perception of a robot can be strongly influenced by its facial appearance [6]. The dimensions and issues of face design are illustrated in the design rationale, details of construction and intended uses of a new minimal expressive robot called KASPAR.</div></span> <a id="expcoll60" href="JavaScript: expandcollapse('expcoll60',60)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121302&CFID=105752199&CFTOKEN=69273181">Dynamic leadership for human-robot teams</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100264309&CFID=105752199&CFTOKEN=69273181">Douglas A. Few</a>, 
                        <a href="author_page.cfm?id=81100579981&CFID=105752199&CFTOKEN=69273181">David J. Bruemmer</a>, 
                        <a href="author_page.cfm?id=81310502603&CFID=105752199&CFTOKEN=69273181">Miles C. Walton</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 333 - 334</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121302" title="DOI">10.1145/1121241.1121302</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121302&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow61" style="display:inline;"><br /><div style="display:inline">This paper evaluates collaborative tasking tools that facilitate dynamic sharing of responsibilities between robot and operator throughout a search and detection task Participants who utilize Collaborative Tasking Mode (CTM) do not experience a significant ...</div></span>
          <span id="toHide61" style="display:none;"><br /><div style="display:inline">This paper evaluates collaborative tasking tools that facilitate dynamic sharing of responsibilities between robot and operator throughout a search and detection task Participants who utilize Collaborative Tasking Mode (CTM) do not experience a significant performance penalty, yet benefit from reduced workload and fewer instances of confusion. In addition, CTM participants report a higher overall feeling of control as compared to those using Standard Shared Mode.</div></span> <a id="expcoll61" href="JavaScript: expandcollapse('expcoll61',61)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121303&CFID=105752199&CFTOKEN=69273181">Affective feedback in closed loop human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100468063&CFID=105752199&CFTOKEN=69273181">Pramila Rani</a>, 
                        <a href="author_page.cfm?id=81310499887&CFID=105752199&CFTOKEN=69273181">Changchun Liu</a>, 
                        <a href="author_page.cfm?id=81100596835&CFID=105752199&CFTOKEN=69273181">Nilanjan Sarkar</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 335 - 336</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121303" title="DOI">10.1145/1121241.1121303</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121303&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121304&CFID=105752199&CFTOKEN=69273181">Shaping human behavior by observing mobility gestures</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81385594144&CFID=105752199&CFTOKEN=69273181">David Feil-Seifer</a>, 
                        <a href="author_page.cfm?id=81452618057&CFID=105752199&CFTOKEN=69273181">Maja J. Matari&#262;</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 337 - 338</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121304" title="DOI">10.1145/1121241.1121304</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121304&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          
          </td>
          </tr>
		  
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121305&CFID=105752199&CFTOKEN=69273181">Commonality of control paradigms for unmanned systems</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502778&CFID=105752199&CFTOKEN=69273181">Marc Gacy</a>, 
                        <a href="author_page.cfm?id=81310501003&CFID=105752199&CFTOKEN=69273181">David Dahn</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 339 - 340</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121305" title="DOI">10.1145/1121241.1121305</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121305&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow64" style="display:inline;"><br /><div style="display:inline">One of the technical thrusts within the Robotics Collaborative Technology Alliance (CTA) from the Army Research Laboratory has been to design, build, and experiment with new concept control systems that will allow a single human to simultaneously control ...</div></span>
          <span id="toHide64" style="display:none;"><br /><div style="display:inline">One of the technical thrusts within the Robotics Collaborative Technology Alliance (CTA) from the Army Research Laboratory has been to design, build, and experiment with new concept control systems that will allow a single human to simultaneously control multiple unmanned ground and air vehicles. We have developed both vehicle mounted and dismounted controllers that all provide a similar look and feel, with relatively equivalent control capabilities. The similarity in capabilities includes not only support functions such as map management and reporting, but the actual planning, tasking and control of the unmanned systems including small unmanned ground vehicles (SUGV), larger unmanned ground vehicles (UGV) and unmanned air vehicles (UAV).</div></span> <a id="expcoll64" href="JavaScript: expandcollapse('expcoll64',64)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121306&CFID=105752199&CFTOKEN=69273181">A model for imitating human reaching movements</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350599923&CFID=105752199&CFTOKEN=69273181">Micha Hersch</a>, 
                        <a href="author_page.cfm?id=81100342762&CFID=105752199&CFTOKEN=69273181">Aude G. Billard</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 341 - 342</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121306" title="DOI">10.1145/1121241.1121306</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121306&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow65" style="display:inline;"><br /><div style="display:inline">We present a model of human-like reaching movements. This model is then used to give a humanoid robot the ability to imitate human reaching motions. It illustrates that having a robot control similar to human control can greatly ease the human-robot ...</div></span>
          <span id="toHide65" style="display:none;"><br /><div style="display:inline">We present a model of human-like reaching movements. This model is then used to give a humanoid robot the ability to imitate human reaching motions. It illustrates that having a robot control similar to human control can greatly ease the human-robot interaction.</div></span> <a id="expcoll65" href="JavaScript: expandcollapse('expcoll65',65)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121307&CFID=105752199&CFTOKEN=69273181">Structural descriptions in human-assisted robot visual learning</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81100597768&CFID=105752199&CFTOKEN=69273181">Geert-Jan M. Kruijff</a>, 
                        <a href="author_page.cfm?id=81310500308&CFID=105752199&CFTOKEN=69273181">John D. Kelleher</a>, 
                        <a href="author_page.cfm?id=81310501572&CFID=105752199&CFTOKEN=69273181">Gregor Berginc</a>, 
                        <a href="author_page.cfm?id=81100548756&CFID=105752199&CFTOKEN=69273181">Ale&#353; Leonardis</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 343 - 344</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121307" title="DOI">10.1145/1121241.1121307</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121307&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow66" style="display:inline;"><br /><div style="display:inline">The paper presents an approach to using structural descriptions, obtained through a human-robot tutoring dialogue, as labels for the visual object models a robot learns. The paper shows how structural descriptions enable relating models for different ...</div></span>
          <span id="toHide66" style="display:none;"><br /><div style="display:inline">The paper presents an approach to using structural descriptions, obtained through a human-robot tutoring dialogue, as labels for the visual object models a robot learns. The paper shows how structural descriptions enable relating models for different aspects of one and the same object, and how being able to relate descriptions for visual models and discourse referents enables incremental updating of model descriptions through dialogue (either robot- or human initiated). The approach has been implemented in an integrated architecture for human-assisted robot visual learning.</div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121308&CFID=105752199&CFTOKEN=69273181">Auditory perspective taking</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310501807&CFID=105752199&CFTOKEN=69273181">Eric Martinson</a>, 
                        <a href="author_page.cfm?id=81100455302&CFID=105752199&CFTOKEN=69273181">Derek Brock</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 345 - 346</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121308" title="DOI">10.1145/1121241.1121308</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121308&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow67" style="display:inline;"><br /><div style="display:inline">Auditory perspective taking is the process of imagining the auditory scene from another's place and inferring what that person can (and cannot) hear, as well as how this affects his or her auditory comprehension. With this inferred knowledge, a conversational ...</div></span>
          <span id="toHide67" style="display:none;"><br /><div style="display:inline">Auditory perspective taking is the process of imagining the auditory scene from another's place and inferring what that person can (and cannot) hear, as well as how this affects his or her auditory comprehension. With this inferred knowledge, a conversational partner can then adapt his or her vocal presentation to overcome or cope with competing sounds and other auditory challenges to ensure that what is being said can be understood. In this poster, we explore several aspects of auditory perspective taking in the context of a robot speech and listening interface.</div></span> <a id="expcoll67" href="JavaScript: expandcollapse('expcoll67',67)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121310&CFID=105752199&CFTOKEN=69273181">Multimodal person tracking and attention classification</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502486&CFID=105752199&CFTOKEN=69273181">Marek P. Michalowski</a>, 
                        <a href="author_page.cfm?id=81332527865&CFID=105752199&CFTOKEN=69273181">Reid Simmons</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 347 - 358</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121310" title="DOI">10.1145/1121241.1121310</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121310&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow68" style="display:inline;"><br /><div style="display:inline">The problems of human detection, tracking, and attention recognition can be solved more effectively by integrating multiple sensory modalities, such as vision and range data. We present a system that uses a laser range scanner and a single camera to ...</div></span>
          <span id="toHide68" style="display:none;"><br /><div style="display:inline">The problems of human detection, tracking, and attention recognition can be solved more effectively by integrating multiple sensory modalities, such as vision and range data. We present a system that uses a laser range scanner and a single camera to detect and track people, and to classify their attention relative to a socially interactive robot.</div></span> <a id="expcoll68" href="JavaScript: expandcollapse('expcoll68',68)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121309&CFID=105752199&CFTOKEN=69273181">Socially distributed perception</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502486&CFID=105752199&CFTOKEN=69273181">Marek P. Michalowski</a>, 
                        <a href="author_page.cfm?id=81100258547&CFID=105752199&CFTOKEN=69273181">Carl DiSalvo</a>, 
                        <a href="author_page.cfm?id=81100303991&CFID=105752199&CFTOKEN=69273181">Didac Busquets</a>, 
                        <a href="author_page.cfm?id=81336489732&CFID=105752199&CFTOKEN=69273181">Laura M. Hiatt</a>, 
                        <a href="author_page.cfm?id=81310500427&CFID=105752199&CFTOKEN=69273181">Nik A. Melchior</a>, 
                        <a href="author_page.cfm?id=81332527865&CFID=105752199&CFTOKEN=69273181">Reid Simmons</a>, 
                        <a href="author_page.cfm?id=81310500639&CFID=105752199&CFTOKEN=69273181">Selma Sabanovic</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 349 - 350</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121309" title="DOI">10.1145/1121241.1121309</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121309&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow69" style="display:inline;"><br /><div style="display:inline">This paper presents a robot search task (social tag) that uses social interaction, in the form of asking for help, as an integral component of task completion. We define socially distributed perception as a robot's ability to augment its ...</div></span>
          <span id="toHide69" style="display:none;"><br /><div style="display:inline">This paper presents a robot search task (<i>social tag</i>) that uses social interaction, in the form of asking for help, as an integral component of task completion. We define <i>socially distributed perception</i> as a robot's ability to augment its limited sensory capacities through social interaction.</div></span> <a id="expcoll69" href="JavaScript: expandcollapse('expcoll69',69)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121311&CFID=105752199&CFTOKEN=69273181">Perceptions of ASIMO: an exploration on co-operation and competition with humans and humanoid robots</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310500023&CFID=105752199&CFTOKEN=69273181">Bilge Mutlu</a>, 
                        <a href="author_page.cfm?id=81310503346&CFID=105752199&CFTOKEN=69273181">Steven Osman</a>, 
                        <a href="author_page.cfm?id=81100492013&CFID=105752199&CFTOKEN=69273181">Jodi Forlizzi</a>, 
                        <a href="author_page.cfm?id=81100049661&CFID=105752199&CFTOKEN=69273181">Jessica Hodgins</a>, 
                        <a href="author_page.cfm?id=81100476487&CFID=105752199&CFTOKEN=69273181">Sara Kiesler</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 351 - 352</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121311" title="DOI">10.1145/1121241.1121311</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121311&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow70" style="display:inline;"><br /><div style="display:inline">Recent developments in humanoid robotics have made possible a vision of robots in everyday use in the home and workplace. However, little is known about how we should design social interactions with humanoid robots. We explored how co-operation versus ...</div></span>
          <span id="toHide70" style="display:none;"><br /><div style="display:inline">Recent developments in humanoid robotics have made possible a vision of robots in everyday use in the home and workplace. However, little is known about how we should design social interactions with humanoid robots. We explored how co-operation versus competition in a game shaped people's perceptions of ASIMO. We found that in the co-operative interaction, people found the robot more sociable and more intellectual than in the competitive interaction while people felt more positive and were more involved in the task in the competitive condition than in the co-operative condition. Our poster presents these findings with the supporting theoretical background.</div></span> <a id="expcoll70" href="JavaScript: expandcollapse('expcoll70',70)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121312&CFID=105752199&CFTOKEN=69273181">On the effect of the user's background on communicating grasping commands</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502901&CFID=105752199&CFTOKEN=69273181">Maria Ralph</a>, 
                        <a href="author_page.cfm?id=81100569730&CFID=105752199&CFTOKEN=69273181">Medhat A. Moussa</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 353 - 354</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121312" title="DOI">10.1145/1121241.1121312</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121312&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow71" style="display:inline;"><br /><div style="display:inline">In this paper, we investigate the impact of the user's background on their ability to communicate grasping commands to a robot. We conducted a study where a group of 15 non-technical users use natural language to instruct a robotic arm to grasp five ...</div></span>
          <span id="toHide71" style="display:none;"><br /><div style="display:inline">In this paper, we investigate the impact of the user's background on their ability to communicate grasping commands to a robot. We conducted a study where a group of 15 non-technical users use natural language to instruct a robotic arm to grasp five small everyday objects. We found that users with less technical backgrounds choose simple more predictable commands over complex unpredictable movements. These users also required more time and commands to complete a grasping task compared to users with more technical backgrounds. Other results however suggest that the user's background is not the most critical factor. Individual preferences and learning approaches also appear to play a role in command choices.</div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121313&CFID=105752199&CFTOKEN=69273181">Sociality of robots: do robots construct or collapse human relations?</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81329491765&CFID=105752199&CFTOKEN=69273181">Daisuke Sakamoto</a>, 
                        <a href="author_page.cfm?id=81100261578&CFID=105752199&CFTOKEN=69273181">Tetsuo Ono</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 355 - 356</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121313" title="DOI">10.1145/1121241.1121313</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121313&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow72" style="display:inline;"><br /><div style="display:inline">With developments in robotics, robots "living" with people will become a part of daily life in the near future. However, there are many problems with social robots. In particular, the behavior of robots can influence human relations, and societies have ...</div></span>
          <span id="toHide72" style="display:none;"><br /><div style="display:inline">With developments in robotics, robots "living" with people will become a part of daily life in the near future. However, there are many problems with social robots. In particular, the behavior of robots can influence human relations, and societies have not yet clarified this. In this paper, we report on an experiment we conducted to verify the influence of robot behavior on human relations using the "balance theory." The results show that robots can have both good and bad influence on human relations. One person's impression of another can undergo changes because of a robot. In other words, robots can construct or collapse human relations.</div></span> <a id="expcoll72" href="JavaScript: expandcollapse('expcoll72',72)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121314&CFID=105752199&CFTOKEN=69273181">Challenges to grounding in human-robot interaction</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81350575708&CFID=105752199&CFTOKEN=69273181">Kristen Stubbs</a>, 
                        <a href="author_page.cfm?id=81100572021&CFID=105752199&CFTOKEN=69273181">Pamela Hinds</a>, 
                        <a href="author_page.cfm?id=81100412265&CFID=105752199&CFTOKEN=69273181">David Wettergreen</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 357 - 358</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121314" title="DOI">10.1145/1121241.1121314</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121314&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow73" style="display:inline;"><br /><div style="display:inline">We report a study of a human-robot system composed of a science team (located in Pittsburgh), an engineering team (located in Chile), and a robot (located in Chile). We performed ethnographic observations simultaneously at both sites over two weeks as ...</div></span>
          <span id="toHide73" style="display:none;"><br /><div style="display:inline">We report a study of a human-robot system composed of a science team (located in Pittsburgh), an engineering team (located in Chile), and a robot (located in Chile). We performed ethnographic observations simultaneously at both sites over two weeks as scientists collected data using the robot. Our data reveal problems in establishing and maintaining common ground between the science team and the robot due to missing contextual information about the robot. Our results have implications for the design of systems to support human-robot interaction.</div></span> <a id="expcoll73" href="JavaScript: expandcollapse('expcoll73',73)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121315&CFID=105752199&CFTOKEN=69273181">Experiments in socially guided machine learning: understanding how humans teach</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310502411&CFID=105752199&CFTOKEN=69273181">Andrea L. Thomaz</a>, 
                        <a href="author_page.cfm?id=81100537802&CFID=105752199&CFTOKEN=69273181">Guy Hoffman</a>, 
                        <a href="author_page.cfm?id=81100258451&CFID=105752199&CFTOKEN=69273181">Cynthia Breazeal</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 359 - 360</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121315" title="DOI">10.1145/1121241.1121315</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121315&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow74" style="display:inline;"><br /><div style="display:inline">In Socially Guided Machine Learning we explore the ways in which machine learning can more fully take advantage of natural human interaction. In this work we are studying the role real-time human interaction plays in training assistive robots to perform ...</div></span>
          <span id="toHide74" style="display:none;"><br /><div style="display:inline">In Socially Guided Machine Learning we explore the ways in which machine learning can more fully take advantage of natural human interaction. In this work we are studying the role real-time human interaction plays in training assistive robots to perform new tasks. We describe an experimental platform, Sophie's World, and present descriptive analysis of human teaching behavior found in a user study. We report three important observations of how people administer reward and punishment to teach a simulated robot a new task through Reinforcement Learning. People adjust their behavior as they develop a model of the learner, they use the reward channel for guidance as well as feedback, and they may also use it as a motivational channel.</div></span> <a id="expcoll74" href="JavaScript: expandcollapse('expcoll74',74)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
  <td></td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=1121316&CFID=105752199&CFTOKEN=69273181">Acquiring a shared environment representation</a></span></td>
  </tr>
  
          <tr>
          <td></td>
          <td>
          <span style="padding-left:20">
          
                        <a href="author_page.cfm?id=81310499943&CFID=105752199&CFTOKEN=69273181">Elin Anna Topp</a>, 
                        <a href="author_page.cfm?id=81100285247&CFID=105752199&CFTOKEN=69273181">Henrik I. Christensen</a>, 
                        <a href="author_page.cfm?id=81100050138&CFID=105752199&CFTOKEN=69273181">Kerstin Severinson Eklundh</a> 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 361 - 362</span></td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">doi&gt;<a href="http://dx.doi.org/10.1145/1121241.1121316" title="DOI">10.1145/1121241.1121316</a></span></td>
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPdf" title="FullText Pdf" href="ft_gateway.cfm?id=1121316&type=pdf&CFID=105752199&CFTOKEN=69273181" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="Pdf" class="fulltext_lnk" border="0" />Pdf</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow75" style="display:inline;"><br /><div style="display:inline">Interacting with a domestic service robot implies the existence for a joint environment model for a user and a robot. We present a pilot study that investigates, how humans present a familiar environment to a mobile robot. Results from this study are ...</div></span>
          <span id="toHide75" style="display:none;"><br /><div style="display:inline">Interacting with a domestic service robot implies the existence for a joint environment model for a user and a robot. We present a pilot study that investigates, how humans present a familiar environment to a mobile robot. Results from this study are used to evaluate a generic environment model for a service robot that can be personalised by interaction.</div></span> <a id="expcoll75" href="JavaScript: expandcollapse('expcoll75',75)">expand</a>
          </div>
		  </td>
          </tr>          
          
</table>


</div> 
</div>


 <p class="small-text" align="center">Powered by <a id="theguide" name="theguide" href="javascript:ColdFusion.Window.show('theguide')"><img src="img/poweredbyacm.jpg" width="336" height="11" alt="The ACM Guide to Computing Literature" border="0" /></a></p>



 <br />
<div class="footerbody" align="center" >
	

	The ACM Digital Library is published by the Association for Computing Machinery. Copyright &copy; 2012 ACM, Inc.<br />
	<a href="http://www.acm.org/publications/policies/usage">Terms of Usage</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/privacy-policy">Privacy Policy</a>&nbsp;&nbsp;
	<a href="http://www.acm.org/about/code-of-ethics">Code of Ethics</a>&nbsp;&nbsp;	  
	<a href="http://www.acm.org/about/contact-us">Contact Us</a>

<br /><br />
Useful downloads: 
<a href="http://www.adobe.com/products/acrobat/readstep2.html"><img src="http://dl.acm.org/images/pdf_logo.gif" width="16" height="16" alt="" border="0" /> Adobe Acrobat</a>
&nbsp;&nbsp;
<a href="http://www.apple.com/quicktime/download/" target="_blank"><img src="http://dl.acm.org/images/qtlogo.gif" width="16" height="16" alt="" border="0" /> QuickTime</a>
&nbsp;&nbsp;
<a href="http://www.microsoft.com/windows/windowsmedia/download/default.asp" target="_blank"><img src="http://dl.acm.org/images/wmv.gif" width="16" height="15" alt="" border="0" /> Windows Media Player</a>
&nbsp;&nbsp;
<a href="http://www.real.com/" target="_blank"><img src="http://dl.acm.org/images/realplayer.gif" width="20" height="18" alt="" border="0" /> Real Player</a>

</div> 



<div  id="cf_window1338241947205" class="yuiextdlg">
	
	<div  id="theguide_title" class="x-dlg-hd">
		The ACM Guide to Computing Literature
	 </div>
	<div  id="theguide_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338241947208" class="yuiextdlg">
	
	<div  id="thetags_title" class="x-dlg-hd">
		All Tags
	 </div>
	<div  id="thetags_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338241947211" class="yuiextdlg">
	
	<div  id="theformats_title" class="x-dlg-hd">
		Export Formats
	 </div>
	<div  id="theformats_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338241947213" class="yuiextdlg">
	
	<div  id="theexplaination_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theexplaination_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338241947215" class="yuiextdlg">
	
	<div  id="theservices_title" class="x-dlg-hd">
		&nbsp;
	 </div>
	<div  id="theservices_body" class="x-dlg-bd">
		
		
	 </div>
 </div> <div  id="cf_window1338241947217" class="yuiextdlg">
	
	<div  id="savetobinder_title" class="x-dlg-hd">
		Save to Binder
	 </div>
	<div  id="savetobinder_body" class="x-dlg-bd">
		
		
	 </div>
 </div> 

</body>
</html>